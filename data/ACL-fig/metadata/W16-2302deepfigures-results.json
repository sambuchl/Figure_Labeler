{"raw_detected_boxes": [[], [{"x2": 714.0, "y1": 67.0, "x1": 113.0, "y2": 199.0}], [], [], [{"x2": 710.0, "y1": 92.0, "x1": 121.0, "y2": 225.0}], [], [{"x2": 720.0, "y1": 86.0, "x1": 103.0, "y2": 177.0}], [{"x2": 708.0, "y1": 96.0, "x1": 445.0, "y2": 423.0}], [{"x2": 734.0, "y1": 118.0, "x1": 103.0, "y2": 440.0}, {"x2": 719.0, "y1": 577.0, "x1": 104.0, "y2": 972.0}], [{"x2": 719.0, "y1": 109.0, "x1": 108.0, "y2": 984.0}], [{"x2": 723.0, "y1": 107.0, "x1": 101.0, "y2": 1021.0}], [{"x2": 692.0, "y1": 171.0, "x1": 135.0, "y2": 837.0}], [{"x2": 692.0, "y1": 103.0, "x1": 135.0, "y2": 458.0}, {"x2": 692.0, "y1": 605.0, "x1": 134.0, "y2": 958.0}], [{"x2": 750.0, "y1": 94.0, "x1": 116.0, "y2": 385.0}], [{"x2": 668.0, "y1": 154.0, "x1": 155.0, "y2": 418.0}, {"x2": 675.0, "y1": 613.0, "x1": 152.0, "y2": 921.0}], [{"x2": 749.0, "y1": 94.0, "x1": 117.0, "y2": 362.0}], [{"x2": 340.0, "y1": 88.0, "x1": 175.0, "y2": 311.0}, {"x2": 701.0, "y1": 92.0, "x1": 450.0, "y2": 359.0}], [{"x2": 729.0, "y1": 100.0, "x1": 109.0, "y2": 427.0}, {"x2": 723.0, "y1": 585.0, "x1": 108.0, "y2": 931.0}], [{"x2": 692.0, "y1": 94.0, "x1": 139.0, "y2": 987.0}], [{"x2": 691.0, "y1": 214.0, "x1": 135.0, "y2": 816.0}], [{"x2": 602.0, "y1": 86.0, "x1": 228.0, "y2": 321.0}], [], [], [], [{"x2": 765.0, "y1": 247.0, "x1": 117.0, "y2": 964.0}], [{"x2": 726.0, "y1": 131.0, "x1": 115.0, "y2": 814.0}], [{"x2": 719.0, "y1": 131.0, "x1": 118.0, "y2": 794.0}], [{"x2": 725.0, "y1": 131.0, "x1": 115.0, "y2": 814.0}], [{"x2": 728.0, "y1": 131.0, "x1": 114.0, "y2": 805.0}], [{"x2": 720.0, "y1": 131.0, "x1": 114.0, "y2": 813.0}], [{"x2": 722.0, "y1": 131.0, "x1": 115.0, "y2": 814.0}], [{"x2": 719.0, "y1": 131.0, "x1": 115.0, "y2": 814.0}], [{"x2": 729.0, "y1": 131.0, "x1": 114.0, "y2": 421.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.546875, "y1": 756.4223022460938, "x1": 72.00094604492188, "y2": 817.1910400390625}, "imageText": ["en-ru", "newstest2016", "CharacTer", "BEER", "mtevalNIST", "mosesWER", "mosesCDER", "MPEDA", "mosesPER", "mtevalBLEU", "mosesBLEU", "LE", "U", "es", "B", "m", "os", "LE", "U", "va", "lB", "m", "te", "E", "R", "es", "P", "m", "os", "A", "E", "D", "M", "P", "R", "D", "E", "es", "C", "m", "os", "mosesBLEU", "mtevalBLEU", "wordF1", "wordF2", "wordF3", "mosesPER", "MPEDA", "mosesCDER", "mosesWER", "mosesTER", "mtevalNIST", "BEER", "chrF1", "chrF2", "chrF3", "CharacTer", "C", "ha", "ra", "cT", "er", "B", "E", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "W", "E", "R", "LE", "U", "es", "B", "m", "os", "LE", "U", "va", "lB", "m", "te", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "E", "R", "es", "P", "m", "os", "D", "E", "R", "M", "P", "E", "D", "A", "es", "C", "m", "os", "E", "R", "es", "W", "m", "os", "E", "R", "es", "T", "m", "os", "IS", "T", "va", "lN", "m", "te", "ra", "cT", "er", "ch", "rF", "3", "ch", "rF", "2", "ch", "rF", "1", "B", "E", "E", "R", "C", "ha", "mosesBLEU", "mtevalBLEU", "wordF3", "wordF2", "wordF1", "MPEDA", "mosesPER", "mosesCDER", "mosesTER", "mosesWER", "mtevalNIST", "chrF1", "BEER", "chrF2", "chrF3", "CharacTer", "LE", "U", "es", "B", "m", "os", "LE", "U", "va", "lB", "m", "te", "D", "E", "R", "m", "os", "es", "P", "E", "R", "M", "P", "E", "D", "A", "w", "or", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "es", "C", "m", "os", "E", "R", "es", "T", "m", "os", "E", "R", "es", "W", "m", "os", "IS", "T", "va", "lN", "m", "te", "ra", "cT", "er", "ch", "rF", "3", "ch", "rF", "2", "B", "E", "E", "R", "ch", "rF", "1", "C", "ha", "RR", "DA", "DA", "Hybrids", "12", "Systems", "12", "Systems", "10k", "Systems", "tr-en", "newstest2016", "mosesWER", "mosesBLEU", "wordF1", "wordF3", "wordF2", "mosesTER", "mosesCDER", "CharacTer", "mtevalBLEU", "chrF3", "chrF2", "mtevalNIST", "mosesPER", "UoW.ReVal", "chrF1", "MPEDA", "BEER", "B", "E", "E", "R", "M", "P", "E", "D", "A", "U", "oW", ".R", "eV", "al", "m", "te", "va", "lN", "IS", "T", "m", "te", "va", "lB", "LE", "U", "C", "ha", "ra", "cT", "er", "m", "os", "es", "C", "D", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "W", "E", "R", "mosesWER", "mosesBLEU", "mosesPER", "mosesCDER", "CharacTer", "mtevalBLEU", "mtevalNIST", "UoW.ReVal", "MPEDA", "BEER", ".R", "eV", "al", "m", "os", "es", "P", "E", "R", "m", "te", "va", "lN", "IS", "T", "ch", "rF", "2", "ch", "rF", "3", "m", "te", "va", "lB", "LE", "U", "C", "ha", "ra", "cT", "er", "m", "os", "es", "C", "D", "E", "R", "m", "os", "es", "T", "E", "R", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "W", "E", "R", "U", "oW", "E", "D", "A", "ch", "rF", "1", "M", "P", "E", "R", "B", "E", "mosesWER", "mosesBLEU", "CharacTer", "wordF3", "mosesTER", "wordF1", "wordF2", "mosesCDER", "mtevalBLEU", "chrF3", "chrF2", "mosesPER", "mtevalNIST", "MPEDA", "chrF1", "UoW.ReVal", "BEER", "E", "D", "A", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "P", "E", "R", "ch", "rF", "2", "ch", "rF", "3", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "C", "D", "E", "R", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "os", "es", "T", "E", "R", "w", "or", "dF", "3", "C", "ha", "ra", "cT", "er", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "W", "E", "R", "M", "P", ".R", "eV", "al", "ch", "rF", "1", "U", "oW", "E", "R", "B", "E", "RR", "DA", "DA", "Hybrids", "8", "Systems", "8", "Systems", "10k", "Systems", "ru-en", "newstest2016", "UoW.ReVal", "MPEDA", "CharacTer", "BEER", "mosesPER", "mtevalNIST", "mosesCDER", "mosesWER", "mtevalBLEU", "mosesBLEU", "LE", "U", "es", "B", "m", "os", "LE", "U", "va", "lB", "m", "te", "E", "R", "es", "W", "m", "os", "R", "D", "E", "es", "C", "m", "os", "mosesBLEU", "wordF1", "wordF2", "wordF3", "mtevalBLEU", "mosesWER", "mosesTER", "mtevalNIST", "mosesCDER", "mosesPER", "chrF1", "BEER", "chrF2", "chrF3", "MPEDA", "CharacTer", "UoW.ReVal", "U", "oW", ".R", "eV", "al", "M", "P", "E", "D", "A", "C", "ha", "ra", "cT", "er", "B", "E", "E", "R", "m", "os", "es", "P", "E", "R", "m", "te", "va", "lN", "IS", "T", "D", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "m", "te", "va", "lB", "LE", "U", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "es", "C", "m", "os", "E", "R", "es", "P", "m", "os", ".R", "eV", "al", "C", "ha", "ra", "cT", "er", "M", "P", "E", "D", "A", "ch", "rF", "3", "ch", "rF", "2", "B", "E", "E", "R", "ch", "rF", "1", "U", "oW", "mosesBLEU", "wordF1", "CharacTer", "wordF3", "wordF2", "mosesWER", "mosesTER", "mtevalBLEU", "mtevalNIST", "mosesCDER", "mosesPER", "chrF3", "chrF1", "chrF2", "MPEDA", "BEER", "UoW.ReVal", ".R", "eV", "al", "B", "E", "E", "R", "M", "P", "E", "D", "A", "ch", "rF", "2", "ch", "rF", "1", "ch", "rF", "3", "m", "os", "es", "P", "E", "R", "m", "os", "es", "C", "D", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "w", "or", "dF", "2", "w", "or", "dF", "3", "C", "ha", "ra", "cT", "er", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "U", "oW"], "regionBoundary": {"x2": 522.0, "y1": 102.8900146484375, "x1": 73.0, "y2": 744.8900146484375}, "caption": "Figure 2: Russian-to-English (ru-en), Turkish-to-English (tr-en) and English-to-Russian (en-ru) systemlevel metric significance test results for human assessment variants; green cells denote a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling.", "page": 10}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.5466918945312, "y1": 318.0223083496094, "x1": 72.0009994506836, "y2": 338.1440124511719}, "imageText": ["newstest2016", "MPEDA", ".988", ".923", ".971", ".905", ".923", ".975", ".860", "BEER", ".985", ".871", ".964", ".828", ".894", ".975", ".914", "CHARACTER", ".989", ".918", ".915", ".850", ".919", ".822", ".954", "MTEVALNIST", ".971", ".790", ".919", ".784", ".853", ".919", ".890", "MTEVALBLEU", ".985", ".802", ".849", ".828", ".833", ".868", ".831", "MOSESCDER", ".984", ".819", ".851", ".777", ".850", ".822", ".868", "UOW.REVAL", ".981", ".976", ".964", ".930", ".967", ".951", "-", "MOSESPER", ".970", ".728", ".758", ".745", ".877", ".798", ".846", "MOSESWER", ".962", ".814", ".758", ".741", ".834", ".642", ".870", "MOSESBLEU", ".979", ".753", ".747", ".772", ".819", ".708", ".813", "CHRF3", ".984", ".892", "-", "-", "-", "-", "-", "CHRF2", ".984", ".882", "-", "-", "-", "-", "-", "CHRF1", ".982", ".856", "-", "-", "-", "-", "-", "cs-en", "de-en", "\ufb01-en", "ro-en", "ru-en", "tr-en", "en-ru", "Human", "DA", "DA", "DA", "DA", "DA", "DA", "DA", "Systems", "10K", "10K", "10K", "10K", "10K", "10K", "10K"], "regionBoundary": {"x2": 485.0, "y1": 104.8900146484375, "x1": 110.0, "y2": 305.8900146484375}, "caption": "Table 7: Absolute Pearson correlation of system-level metric scores with 10K hybrid systems: DA Hybrid = direct assessment of translation adequacy of 10K hybrid MT systems.", "page": 14}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 525.546630859375, "y1": 680.2552490234375, "x1": 72.0009994506836, "y2": 713.927001953125}, "imageText": ["ittest2016", "CHARACTER", "1.000", "0.901", "0.930", "0.963", "1.000", "0.927", "0.976", "CHRF3", "1.000", "0.831", "0.700", "0.938", "1.000", "0.961", "0.990", "CHRF2", "1.000", "0.837", "0.672", "0.933", "1.000", "0.959", "0.986", "BEER", "1.000", "0.744", "0.621", "0.931", "1.000", "0.983", "0.989", "CHRF1", "1.000", "0.845", "0.588", "0.915", "1.000", "0.951", "0.967", "MTEVALNIST", "1.000", "0.905", "0.524", "0.926", "1.000", "0.722", "0.993", "MPEDA", "1.000", "0.620", "0.599", "0.951", "1.000", "0.856", "0.989", "MOSESTER", "1.000", "0.616", "0.628", "0.908", "1.000", "0.835", "0.994", "MTEVALBLEU", "1.000", "0.750", "0.621", "0.976", "1.000", "0.596", "0.997", "MOSESWER", "1.000", "0.009", "0.656", "0.916", "1.000", "0.903", "0.991", "MOSESCDER", "1.000", "0.181", "0.652", "0.932", "1.000", "0.914", "0.997", "WORDF1", "1.000", "0.240", "0.644", "0.959", "1.000", "0.911", "0.997", "WORDF2", "1.000", "0.266", "0.652", "0.965", "1.000", "0.900", "0.997", "WORDF3", "1.000", "0.274", "0.655", "0.966", "1.000", "0.897", "0.996", "MOSESBLEU", "1.000", "0.296", "0.650", "0.974", "1.000", "0.886", "0.992", "MOSESPER", "1.000", "0.307", "0.548", "0.911", "1.000", "0.938", "0.998", "en-bg", "en-cs", "en-de", "en-es", "en-eu", "en-nl", "en-pt", "Human", "RR", "RR", "RR", "RR", "RR", "RR", "RR", "Systems", "2", "5", "10", "4", "2", "4", "4"], "regionBoundary": {"x2": 488.0, "y1": 436.8900146484375, "x1": 107.0, "y2": 668.8900146484375}, "caption": "Table 8: System-level metric results (ittest2016): Pearson correlation of system-level metric scores with human assessment computed over standard WMT relative ranking (RR) human assessments; absolute values of correlation coefficients reported for all metrics.", "page": 14}, {"figType": "Table", "name": "11", "captionBoundary": {"x2": 520.039306640625, "y1": 252.36732482910156, "x1": 77.51200103759766, "y2": 258.9400634765625}, "imageText": ["himl-2015", "CHRF3", ".544", ".480", ".639", ".413", "CHRF2", ".537", ".479", ".634", ".417", "BEER", ".516", ".480", ".620", ".435", "CHRF1", ".506", ".467", ".611", ".427", "MPEDA", ".468", ".478", ".595", ".425", "WORDF3", ".413", ".425", ".587", ".383", "WORDF2", ".408", ".424", ".583", ".383", "WORDF1", ".392", ".415", ".569", ".381", "SENTBLEU", ".349", ".377", ".550", ".328", "Correlation", "r", "r", "r", "r", "Direction", "en-cs", "en-de", "en-ro", "en-pl", "Human", "Gold", "HUME", "HUME", "HUME", "HUME", "n", "339", "330", "349", "345"], "regionBoundary": {"x2": 433.0, "y1": 62.8900146484375, "x1": 162.0, "y2": 240.8900146484375}, "caption": "Table 11: Pearson correlation of segment-level metric scores with HUME human assessment variant.", "page": 20}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5484619140625, "y1": 159.7143096923828, "x1": 72.00100708007812, "y2": 193.38604736328125}, "imageText": ["cs", "de", "ro", "\ufb01", "ru", "tr", "English", "into", "Track", "Test", "set", "Systems", "into-English", "cs", "de", "ro", "\ufb01", "ru", "tr", "bg", "es", "eu", "nl", "pl", "pt", "RRsysNews", "newstest2016", "3", "3", "3", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "RRsysIT", "it-test2016", "3", "3", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "DAsysNews", "newstest2016", "3", "3", "3", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u2022", "\u00b7", "RRsegNews", "newstest2016", "3", "3", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "DAsegNews", "newstest2016", "3", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "\u2022", "HUMEseg", "himl2015", "3", "\u2022", "\u2022", "\u2022", "\u2022", "ear", "1", "Hy", "brid", "IT", "T", "ask", "Him", "L", "Y", "Tas", "k", "Tun", "ing", "sk", "New", "s", "Ta"], "regionBoundary": {"x2": 517.0, "y1": 43.165313720703125, "x1": 80.0, "y2": 143.8900146484375}, "caption": "Table 1: Overview of \u201ctracks\u201d of the WMT16 metrics task. \u201c\u2022\u201d indicates language pairs covered in the evaluation, \u201c\u00b7\u201d are language pairs planned but abandoned due to difficulties in obtaining human judgments.", "page": 1}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5466918945312, "y1": 143.77430725097656, "x1": 72.00098419189453, "y2": 163.89605712890625}, "imageText": ["cs", "de", "ro", "\ufb01", "ru", "tr", "English", "into", "Track", "into-English", "cs", "de", "ro", "\ufb01", "ru", "tr", "bg", "es", "eu", "nl", "pl", "pt", "RRsysNews", "T4,F3,T6", "T4,F1", "T4,F1", "T4,F1", "T4,F2", "T4,F2", "T5,F4,T6", "T5,F5", "T5,F6", "T5,F6", "T5,F2", "T5,F6", "RRsysIT", "T8,F4", "T8,F5", "T8", "T8,F7", "T8", "T8,F7", "T8,F7", "DAsysNews", "T4,F3,T7", "T4,F1,T7", "T4,F1,T7", "T4,F1,T7", "T4,F2,T7", "T4,F2,T7", "T5,F2,T7", "RRsegNews", "T9", "T9", "T9", "T9", "T9", "T9", "T10", "T10", "T10", "T10", "T10", "T10", "DAsegNews", "T9,F8", "T9,F8", "T9,F8", "T9,F8", "T9,F8", "T9,F8", "T10,F9", "HUMEseg", "T11,F10", "T11,F10", "T11,F10", "T11,F10"], "regionBoundary": {"x2": 524.0, "y1": 61.8900146484375, "x1": 74.0, "y2": 127.8900146484375}, "caption": "Table 3: Overview of tables (T) and figures (F) reporting results of the individual \u201ctracks\u201d and language pairs.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5467529296875, "y1": 729.4031982421875, "x1": 72.0009765625, "y2": 803.7219848632812}, "imageText": ["ro-en", "newstest2016", "UoW.ReVal", "MPEDA", "CharacTer", "BEER", "mtevalBLEU", "mtevalNIST", "mosesCDER", "mosesBLEU", "mosesPER", "mosesWER", "E", "R", "es", "W", "m", "os", "E", "R", "es", "P", "m", "os", "LE", "U", "es", "B", "m", "os", "R", "D", "E", "es", "C", "m", "os", "IS", "T", "va", "lN", "m", "te", "LE", "U", "va", "lB", "m", "te", "E", "R", "B", "E", "er", "ra", "cT", "C", "ha", "A", "E", "D", "M", "P", "al", ".R", "eV", "U", "oW", "mosesPER", "mosesWER", "mosesTER", "mosesBLEU", "mosesCDER", "wordF1", "mtevalNIST", "wordF2", "wordF3", "mtevalBLEU", "BEER", "chrF1", "CharacTer", "chrF2", "chrF3", "MPEDA", "UoW.ReVal", "D", "E", "R", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "m", "os", "es", "P", "E", "R", "es", "C", "m", "os", "dF", "1", "w", "or", "IS", "T", "va", "lN", "m", "te", "dF", "2", "w", "or", "dF", "3", "w", "or", "LE", "U", "va", "lB", "m", "te", "ra", "cT", "er", "ch", "rF", "1", "B", "E", "E", "R", "C", "ha", ".R", "eV", "al", "M", "P", "E", "D", "A", "ch", "rF", "3", "ch", "rF", "2", "U", "oW", "mosesPER", "mtevalNIST", "mosesBLEU", "wordF1", "mosesWER", "mtevalBLEU", "mosesTER", "chrF1", "wordF2", "BEER", "wordF3", "chrF2", "chrF3", "UoW.ReVal", "mosesCDER", "MPEDA", "CharacTer", "ch", "rF", "1", "m", "os", "es", "T", "E", "R", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "W", "E", "R", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "P", "E", "R", "dF", "2", "w", "or", "E", "R", "B", "E", "dF", "3", "w", "or", "ch", "rF", "3", "ch", "rF", "2", "eV", "al", "D", "E", "R", "U", "oW", ".R", "es", "C", "m", "os", "ra", "cT", "er", "M", "P", "E", "D", "A", "C", "ha", "RR", "DA", "DA", "Hybrids", "7", "Systems", "7", "Systems", "10k", "Systems", "\ufb01-en", "newstest2016", "MPEDA", "BEER", "UoW.ReVal", "mtevalNIST", "CharacTer", "mosesCDER", "mtevalBLEU", "mosesWER", "mosesPER", "mosesBLEU", "LE", "U", "es", "B", "m", "os", "E", "R", "es", "P", "m", "os", "E", "R", "es", "W", "m", "os", "LE", "U", "va", "lB", "m", "te", "R", "D", "E", "es", "C", "m", "os", "er", "ra", "cT", "C", "ha", "IS", "T", "va", "lN", "m", "te", "al", ".R", "eV", "U", "oW", "E", "R", "B", "E", "A", "E", "D", "M", "P", "mosesBLEU", "mosesPER", "mosesWER", "wordF3", "wordF2", "wordF1", "mosesTER", "mosesCDER", "mtevalBLEU", "CharacTer", "mtevalNIST", "chrF3", "chrF2", "UoW.ReVal", "BEER", "MPEDA", "chrF1", ".R", "eV", "al", "ch", "rF", "2", "ch", "rF", "3", "m", "te", "va", "lN", "IS", "T", "C", "ha", "ra", "cT", "er", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "C", "D", "E", "R", "m", "os", "es", "T", "E", "R", "w", "or", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "m", "os", "es", "W", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "B", "LE", "U", "U", "oW", "ch", "rF", "1", "M", "P", "E", "D", "A", "B", "E", "E", "R", "mosesBLEU", "mosesPER", "mosesWER", "wordF3", "wordF2", "wordF1", "mosesCDER", "mosesTER", "mtevalBLEU", "CharacTer", "mtevalNIST", "chrF3", "chrF2", "UoW.ReVal", "BEER", "MPEDA", "chrF1", ".R", "eV", "al", "ch", "rF", "2", "ch", "rF", "3", "m", "te", "va", "lN", "IS", "T", "C", "ha", "ra", "cT", "er", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "T", "E", "R", "m", "os", "es", "C", "D", "E", "R", "w", "or", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "m", "os", "es", "W", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "B", "LE", "U", "U", "oW", "ch", "rF", "1", "M", "P", "E", "D", "A", "B", "E", "E", "R", "RR", "DA", "DA", "Hybrids", "9", "Systems", "9", "Systems", "10k", "Systems", "de-en", "newstest2016", "mosesPER", "mosesBLEU", "mtevalNIST", "mtevalBLEU", "mosesWER", "mosesCDER", "chrF1", "BEER", "chrF2", "chrF3", "CharacTer", "MPEDA", "UoW.ReVal", "D", "E", "R", "m", "os", "es", "W", "E", "R", "m", "te", "va", "lB", "LE", "U", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "P", "E", "R", "es", "C", "m", "os", "ra", "cT", "er", "ch", "rF", "3", "ch", "rF", "2", "B", "E", "E", "R", "ch", "rF", "1", "C", "ha", ".R", "eV", "al", "M", "P", "E", "D", "A", "U", "oW", "mosesPER", "mosesBLEU", "wordF1", "wordF2", "wordF3", "mtevalNIST", "mtevalBLEU", "mosesWER", "mosesCDER", "mosesTER", "chrF1", "BEER", "chrF2", "chrF3", "CharacTer", "MPEDA", "UoW.ReVal", "D", "E", "R", "m", "os", "es", "W", "E", "R", "m", "te", "va", "lB", "LE", "U", "m", "te", "va", "lN", "IS", "T", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "P", "E", "R", "es", "C", "m", "os", "E", "R", "es", "T", "m", "os", "ra", "cT", "er", "ch", "rF", "3", "ch", "rF", "2", "B", "E", "E", "R", "ch", "rF", "1", "C", "ha", ".R", "eV", "al", "M", "P", "E", "D", "A", "U", "oW", "mosesPER", "mosesBLEU", "mtevalNIST", "wordF1", "wordF2", "wordF3", "mtevalBLEU", "mosesWER", "mosesTER", "mosesCDER", "chrF1", "UoW.ReVal", "BEER", "chrF2", "MPEDA", "chrF3", "CharacTer", "D", "E", "R", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "m", "te", "va", "lB", "LE", "U", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "P", "E", "R", "es", "C", "m", "os", ".R", "eV", "al", "ch", "rF", "1", "U", "oW", "E", "D", "A", "ch", "rF", "2", "B", "E", "E", "R", "M", "P", "ra", "cT", "er", "ch", "rF", "3", "C", "ha"], "regionBoundary": {"x2": 522.0, "y1": 102.8900146484375, "x1": 73.0, "y2": 717.8900146484375}, "caption": "Figure 1: German-to-English (de-en), Finnish-to-English (fi-en) and Romanian-to-English (ro-en) system-level metric significance test results for human assessment variants; green cells denote a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling. 208", "page": 9}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 525.5467529296875, "y1": 308.5713195800781, "x1": 72.00100708007812, "y2": 355.79205322265625}, "imageText": ["newstest2016", "en-tr", "mosesWER", "mosesPER", "mosesTER", "mosesBLEU", "wordF1", "wordF3", "wordF2", "mtevalBLEU", "mtevalNIST", "mosesCDER", "MPEDA", "chrF3", "CharacTer", "chrF1", "chrF2", "BEER", "E", "D", "A", "m", "os", "es", "C", "D", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "te", "va", "lB", "LE", "U", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "T", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "W", "E", "R", "M", "P", "ra", "cT", "er", "ch", "rF", "3", "C", "ha", "ch", "rF", "2", "ch", "rF", "1", "E", "R", "B", "E", "RR", "8", "Systems", "en-ro", "MPEDA", "chrF3", "chrF2", "chrF1", "mtevalNIST", "mtevalBLEU", "mosesTER", "mosesWER", "wordF3", "wordF2", "wordF1", "mosesBLEU", "mosesPER", "BEER", "mosesCDER", "CharacTer", "ra", "cT", "er", "m", "os", "es", "C", "D", "E", "R", "B", "E", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "B", "LE", "U", "w", "or", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "m", "os", "es", "W", "E", "R", "m", "os", "es", "T", "E", "R", "m", "te", "va", "lB", "LE", "U", "m", "te", "va", "lN", "IS", "T", "ch", "rF", "1", "ch", "rF", "2", "ch", "rF", "3", "M", "P", "E", "D", "A", "C", "ha", "RR", "12", "Systems", "en-\ufb01", "mosesPER", "mosesWER", "mosesBLEU", "mosesTER", "mtevalBLEU", "wordF1.2ref", "mtevalNIST", "wordF2.2ref", "wordF1", "wordF3.2ref", "wordF2", "wordF3", "mosesCDER", "chrF1.2ref", "chrF1", "CharacTer", "BEER", "MPEDA", "chrF2.2ref", "chrF3.2ref", "chrF2", "chrF3", "D", "E", "R", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "3.", "2r", "ef", "w", "or", "dF", "1", "w", "or", "dF", "2.", "2r", "ef", "m", "te", "va", "lN", "IS", "T", "w", "or", "dF", "1.", "2r", "ef", "m", "te", "va", "lB", "LE", "U", "m", "os", "es", "T", "E", "R", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "W", "E", "R", "m", "os", "es", "P", "E", "R", "es", "C", "m", "os", "3.", "2r", "ef", "ch", "rF", "2.", "2r", "ef", "M", "P", "E", "D", "A", "B", "E", "E", "R", "C", "ha", "ra", "cT", "er", "ch", "rF", "1", "ch", "rF", "1.", "2r", "ef", "ch", "rF", "ch", "rF", "3", "ch", "rF", "2", "RR", "13", "Systems"], "regionBoundary": {"x2": 552.0, "y1": 69.30074310302734, "x1": 72.0, "y2": 290.8900146484375}, "caption": "Figure 6: English-to-Finnish (en-fi), English-to-Romanian (en-ro) and English-to-Turkish (en-tr) systemlevel metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking.", "page": 13}, {"figType": "Table", "name": "10", "captionBoundary": {"x2": 525.5482788085938, "y1": 691.7132568359375, "x1": 72.00096893310547, "y2": 752.4830322265625}, "imageText": ["newstest-2016", "CHRF3-2R.", "-", "-", ".334", "-", "-", "-", "-", "-", "-", "-", "-", "-", "CHRF2-2R.", "-", "-", ".331", "-", "-", "-", "-", "-", "-", "-", "-", "-", "CHRF1-2R.", "-", "-", ".324", "-", "-", "-", "-", "-", "-", "-", "-", "-", "WORDF3-2.", "-", "-", ".251", "-", "-", "-", "-", "-", "-", "-", "-", "-", "WORDF2-2.", "-", "-", ".251", "-", "-", "-", "-", "-", "-", "-", "-", "-", "WORDF1-2.", "-", "-", ".250", "-", "-", "-", "-", "-", "-", "-", "-", "-", "DEPCHECK", ".109", "-", "-", "-", "-", "-", "-", "-", "-", "-", "-", "-", "BEER", ".422", "-", ".333", "-", ".364", "-", ".307", "-", ".405", ".666", ".337", "-", "CHRF2", ".420", "-", ".329", "-", ".374", "-", ".304", "-", ".406", ".661", ".330", "-", "CHRF3", ".421", "-", ".327", "-", ".380", "-", ".304", "-", ".400", ".661", ".326", "-", "CHRF1", ".402", "-", ".320", "-", ".350", "-", ".305", "-", ".389", ".642", ".320", "-", "MPEDA", ".393", "-", ".274", "-", ".342", "-", ".238", "-", ".372", ".645", ".255", "-", "WORDF2", ".373", "-", ".247", "-", ".313", "-", ".250", "-", ".358", ".580", ".218", "-", "WORDF3", ".373", "-", ".247", "-", ".314", "-", ".245", "-", ".359", ".582", ".216", "-", "WORDF1", ".369", "-", ".245", "-", ".311", "-", ".248", "-", ".351", ".573", ".209", "-", "SENTBLEU", ".359", "-", ".236", "-", ".306", "-", ".233", "-", ".328", ".550", ".222", "-", "Correlation", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "Direction", "en-cs", "en-de", "en-\ufb01", "en-ro", "en-ru", "en-tr", "Human", "Gold", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "#", "Assessments", "118k", "-", "35k", "-", "31k", "-", "7k", "-", "21k", "20k", "7k", "-", "#", "Translations", "12.9k", "-", "6.2k", "-", "4.1k", "-", "1.9k", "-", "6.0k", "-", "3.0k", "-"], "regionBoundary": {"x2": 523.0, "y1": 416.8900146484375, "x1": 72.0, "y2": 679.8900146484375}, "caption": "Table 10: Segment-level metric results for out-of-English language pairs (newstest2016): Absolute correlation of segment-level metric scores with human assessment variants, where \u03c4 are official results computed similar to Kendall\u2019s \u03c4 and over standard WMT relative ranking (RR) human assessments; r are Pearson correlation coefficients of metric scores with direct assessment (DA) of absolute translation adequacy; absolute value of correlation coefficients reported for all metrics.", "page": 17}, {"figType": "Table", "name": "9", "captionBoundary": {"x2": 525.5475463867188, "y1": 334.49127197265625, "x1": 72.0009994506836, "y2": 395.2610168457031}, "imageText": ["newstest-2016", "DPMFCOMB", ".388", ".713", ".420", ".584", ".481", ".598", ".383", ".627", ".420", ".615", ".401", ".663", "METRICS-F", ".345", ".696", ".421", ".601", ".447", ".557", ".388", ".662", ".412", ".618", ".424", ".649", "COBALT-F.", ".336", ".671", ".415", ".591", ".433", ".554", ".361", ".639", ".397", ".618", ".423", ".627", "UPF-COBA.", ".359", ".652", ".387", ".550", ".436", ".490", ".356", ".616", ".394", ".556", ".379", ".626", "BEER", ".342", ".661", ".371", ".462", ".416", ".471", ".331", ".551", ".376", ".533", ".372", ".545", "MPEDA", ".331", ".644", ".375", ".538", ".425", ".513", ".339", ".587", ".387", ".545", ".335", ".616", "CHRF2", ".341", ".658", ".358", ".457", ".418", ".469", ".344", ".581", ".383", ".534", ".346", ".556", "CHRF3", ".343", ".660", ".351", ".455", ".421", ".472", ".341", ".582", ".382", ".535", ".345", ".555", "CHRF1", ".323", ".644", ".372", ".454", ".410", ".452", ".339", ".570", ".379", ".522", ".345", ".551", "UOW-REVAL", ".261", ".577", ".329", ".528", ".376", ".471", ".313", ".547", ".314", ".528", ".342", ".531", "WORDF3", ".299", ".599", ".293", ".447", ".377", ".473", ".304", ".525", ".343", ".504", ".287", ".536", "WORDF2", ".297", ".596", ".296", ".445", ".378", ".471", ".300", ".522", ".341", ".503", ".283", ".537", "WORDF1", ".290", ".585", ".293", ".435", ".369", ".464", ".293", ".508", ".336", ".497", ".275", ".535", "SENTBLEU", ".284", ".557", ".265", ".448", ".368", ".484", ".272", ".499", ".330", ".502", ".245", ".532", "DTED", ".201", ".394", ".130", ".254", ".209", ".361", ".144", ".329", ".201", ".375", ".142", ".267", "Correlation", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "\u03c4", "r", "Direction", "cs-en", "de-en", "\ufb01-en", "ro-en", "ru-en", "tr-en", "Human", "Gold", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "#", "Assessments", "70k", "12k", "15k", "12k", "19k", "14k", "11k", "12k", "18k", "13k", "7k", "13k", "#", "Translations", "8.6k", "560", "2.4k", "560", "4.6k", "560", "2.2k", "560", "4.7k", "560", "2.2k", "560"], "regionBoundary": {"x2": 529.0, "y1": 72.0093994140625, "x1": 72.0, "y2": 316.8900146484375}, "caption": "Table 9: Segment-level metric results for to-English language pairs (newstest2016): Correlation of segment-level metric scores with human assessment variants, where \u03c4 are official results computed similar to Kendall\u2019s \u03c4 and over standard WMT relative ranking (RR) human assessments; r are Pearson correlation coefficients of metric scores with direct assessment (DA) of absolute translation adequacy; absolute value of correlation coefficients reported for all metrics.", "page": 17}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.546630859375, "y1": 354.97430419921875, "x1": 72.00100708007812, "y2": 402.1950378417969}, "imageText": ["en-cs", "en-cs", "newstest2016", "ittest2016", "mosesWER", "mosesCDER", "wordF1", "wordF2", "wordF3", "mosesBLEU", "mosesPER", "mosesTER", "MPEDA", "BEER", "mtevalBLEU", "chrF3", "chrF2", "chrF1", "CharacTer", "mtevalNIST", "E", "D", "A", "m", "os", "es", "T", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "B", "LE", "U", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "os", "es", "C", "D", "E", "R", "m", "os", "es", "W", "E", "R", "M", "P", "E", "R", "B", "E", "LE", "U", "va", "lB", "m", "te", "ra", "cT", "er", "ch", "rF", "1", "ch", "rF", "2", "ch", "rF", "3", "C", "ha", "IS", "T", "va", "lN", "m", "te", "mosesWER", "mosesTER", "CharacTer", "mosesPER", "chrF3", "chrF2", "chrF1", "BEER", "mosesCDER", "MPEDA", "mtevalNIST", "mtevalBLEU", "mosesBLEU", "wordF3", "wordF1", "wordF2", "E", "D", "A", "m", "os", "es", "C", "D", "E", "R", "B", "E", "E", "R", "ch", "rF", "1", "ch", "rF", "2", "ch", "rF", "3", "m", "os", "es", "P", "E", "R", "C", "ha", "ra", "cT", "er", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "M", "P", "IS", "T", "va", "lN", "m", "te", "LE", "U", "va", "lB", "m", "te", "LE", "U", "es", "B", "m", "os", "dF", "3", "w", "or", "dF", "1", "w", "or", "dF", "2", "w", "or"], "regionBoundary": {"x2": 505.0, "y1": 101.8900146484375, "x1": 90.0, "y2": 342.8900146484375}, "caption": "Figure 4: English-to-Czech (en-cs) system-level metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking; RR + TT = standard WMT relative ranking for translation and tuning task systems.", "page": 12}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5465698242188, "y1": 714.8662719726562, "x1": 72.00103759765625, "y2": 748.5370483398438}, "imageText": ["en-de", "en-de", "newstest2016", "ittest2016", "mtevalNIST", "mosesPER", "chrF1", "MPEDA", "mtevalBLEU", "BEER", "mosesTER", "wordF1", "mosesBLEU", "wordF2", "mosesCDER", "wordF3", "mosesWER", "chrF2", "chrF3", "CharacTer", "ra", "cT", "er", "ch", "rF", "3", "ch", "rF", "2", "m", "os", "es", "W", "E", "R", "w", "or", "dF", "3", "m", "os", "es", "C", "D", "E", "R", "w", "or", "dF", "2", "m", "os", "es", "B", "LE", "U", "w", "or", "dF", "1", "m", "os", "es", "T", "E", "R", "B", "E", "E", "R", "m", "te", "va", "lB", "LE", "U", "M", "P", "E", "D", "A", "ch", "rF", "1", "m", "os", "es", "P", "E", "R", "m", "te", "va", "lN", "IS", "T", "C", "ha", "mtevalNIST", "chrF1", "mosesPER", "MPEDA", "chrF2", "BEER", "mosesTER", "chrF3", "mtevalBLEU", "wordF1", "wordF2", "wordF3", "mosesWER", "mosesCDER", "mosesBLEU", "CharacTer", "ra", "cT", "er", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "C", "D", "E", "R", "m", "os", "es", "W", "E", "R", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "dF", "1", "m", "te", "va", "lB", "LE", "U", "ch", "rF", "3", "m", "os", "es", "T", "E", "R", "B", "E", "E", "R", "ch", "rF", "2", "M", "P", "E", "D", "A", "m", "os", "es", "P", "E", "R", "ch", "rF", "1", "m", "te", "va", "lN", "IS", "T", "C", "ha"], "regionBoundary": {"x2": 505.0, "y1": 462.8900146484375, "x1": 90.0, "y2": 702.8900146484375}, "caption": "Figure 5: English-to-German (en-de) system-level metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking.", "page": 12}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.546142578125, "y1": 316.1773376464844, "x1": 307.2770080566406, "y2": 363.3980407714844}, "imageText": ["newstest2016", "WORDF2", ".988", ".990", "WORDF1", ".989", ".990", "MOSESBLEU", ".989", ".987", "WORDF3", ".988", ".989", "MTEVALBLEU", ".985", ".986", "MOSESCDER", ".991", ".976", "BEER", ".995", ".972", "MPEDA", ".988", ".977", "CHRF1", ".990", ".965", "MTEVALNIST", ".976", ".979", "CHRF2", ".990", ".952", "CHRF3", ".989", ".935", "CHARACTER", ".997", ".779", "MOSESPER", ".970", ".803", "MOSESTER", ".974", ".758", "MOSESWER", ".964", ".755", "UOW.REVAL", ".982", "-", "cs-en", "en-cs", "Human", "RR", "+", "TT", "RR", "+", "TT", "Systems", "12", "20"], "regionBoundary": {"x2": 510.0, "y1": 62.8900146484375, "x1": 320.0, "y2": 304.8900146484375}, "caption": "Table 6: Absolute Pearson correlation of cs-en and en-cs system-level metric scores with human assessment variant RR + TT, i.e. standard WMT relative ranking including tuning task systems.", "page": 7}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 525.546630859375, "y1": 727.2652587890625, "x1": 72.00103759765625, "y2": 760.93603515625}, "imageText": ["DPMFcomb", "metrics.f", "cobalt.f.comp", "upf.cobalt", "MPEDA", "chrF2", "chrF3", "chrF1", "BEER", "wordF2", "wordF3", "wordF1", "sentBLEU", "UoW.ReVal", "DTED", "E", "D", "D", "T", "al", ".R", "eV", "U", "oW", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "3", "w", "or", "dF", "2", "w", "or", "E", "R", "B", "E", "1", "ch", "rF", "3", "ch", "rF", "2", "ch", "rF", "A", "E", "D", "M", "P", "t", "ob", "al", "up", "f.c", "om", "p", "lt.", "f.c", "co", "ba", "f", "ric", "s.", "m", "et", "b", "co", "m", "M", "F", "D", "P", "cobalt.f.comp", "metrics.f", "DPMFcomb", "upf.cobalt", "MPEDA", "chrF3", "chrF2", "BEER", "UoW.ReVal", "chrF1", "wordF3", "wordF2", "sentBLEU", "wordF1", "DTED", "E", "D", "D", "T", "dF", "1", "w", "or", "U", "B", "LE", "se", "nt", "dF", "2", "w", "or", "dF", "3", "w", "or", "1", "ch", "rF", "al", ".R", "eV", "U", "oW", "E", "R", "B", "E", "2", "ch", "rF", "3", "ch", "rF", "A", "E", "D", "M", "P", "t", "ob", "al", "up", "f.c", "b", "co", "m", "M", "F", "D", "P", "f", "ric", "s.", "m", "et", "om", "p", "lt.", "f.c", "co", "ba", "ru-en", "tr-en", "metrics.f", "cobalt.f.comp", "DPMFcomb", "upf.cobalt", "MPEDA", "chrF3", "chrF2", "chrF1", "BEER", "UoW.ReVal", "wordF3", "wordF2", "wordF1", "sentBLEU", "DTED", "E", "D", "D", "T", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "al", ".R", "eV", "U", "oW", "E", "R", "B", "E", "1", "ch", "rF", "2", "ch", "rF", "3", "ch", "rF", "A", "E", "D", "M", "P", "t", "ob", "al", "up", "f.c", "b", "co", "m", "M", "F", "D", "P", "om", "p", "lt.", "f.c", "co", "ba", "cobalt.f.comp", "metrics.f", "m", "et", "ric", "s.", "f", "DPMFcomb", "upf.cobalt", "MPEDA", "UoW.ReVal", "BEER", "chrF2", "chrF3", "chrF1", "sentBLEU", "wordF3", "wordF2", "wordF1", "DTED", "E", "D", "D", "T", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "U", "B", "LE", "se", "nt", "1", "ch", "rF", "3", "ch", "rF", "2", "ch", "rF", "E", "R", "B", "E", "al", ".R", "eV", "U", "oW", "A", "E", "D", "M", "P", "t", "ob", "al", "up", "f.c", "b", "co", "m", "M", "F", "D", "P", "om", "p", "lt.", "f.c", "co", "ba", "f", "ric", "s.", "m", "et", "\ufb01-en", "ro-en", "DPMFcomb", "metrics.f", "cobalt.f.comp", "MPEDA", "upf.cobalt", "sentBLEU", "wordF3", "chrF3", "wordF2", "UoW.ReVal", "BEER", "chrF2", "wordF1", "chrF1", "DTED", "E", "D", "D", "T", "1", "ch", "rF", "dF", "1", "w", "or", "2", "ch", "rF", "E", "R", "B", "E", "al", ".R", "eV", "U", "oW", "dF", "2", "w", "or", "3", "ch", "rF", "dF", "3", "w", "or", "U", "B", "LE", "se", "nt", "t", "ob", "al", "up", "f.c", "A", "E", "D", "M", "P", "om", "p", "lt.", "f.c", "co", "ba", "f", "ric", "s.", "m", "et", "b", "co", "m", "M", "F", "D", "P", "DPMFcomb", "metrics.f", "cobalt.f.comp", "BEER", "chrF3", "chrF2", "upf.cobalt", "chrF1", "MPEDA", "wordF3", "wordF2", "wordF1", "UoW.ReVal", "sentBLEU", "DTED", "E", "D", "D", "T", "U", "B", "LE", "se", "nt", "al", ".R", "eV", "U", "oW", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "A", "E", "D", "M", "P", "1", "ch", "rF", "t", "ob", "al", "up", "f.c", "2", "ch", "rF", "3", "ch", "rF", "E", "R", "B", "E", "om", "p", "lt.", "f.c", "co", "ba", "f", "ric", "s.", "m", "et", "b", "co", "m", "M", "F", "D", "P", "cs-en", "de-en"], "regionBoundary": {"x2": 498.4246826171875, "y1": 65.71932220458984, "x1": 96.0, "y2": 711.3886108398438}, "caption": "Figure 8: Direct Assessment (DA) segment-level metric significance test results for to-English language pairs (newstest2016): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation.", "page": 18}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 525.546142578125, "y1": 278.5722961425781, "x1": 307.2770080566406, "y2": 352.89105224609375}, "imageText": ["BEER", "chrF2", "chrF3", "MPEDA", "chrF1", "wordF3", "wordF2", "wordF1", "sentBLEU", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "1", "ch", "rF", "A", "E", "D", "M", "P", "3", "ch", "rF", "2", "ch", "rF", "E", "R", "B", "E", "en-ru"], "regionBoundary": {"x2": 505.60845947265625, "y1": 65.19580841064453, "x1": 324.0, "y2": 262.53448486328125}, "caption": "Figure 9: Direct Assessment (DA) segment-level metric significance test results for English to Russian (newstest2016): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation.", "page": 16}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.54833984375, "y1": 627.7982177734375, "x1": 72.00103759765625, "y2": 702.1170043945312}, "imageText": ["cs-en", "newstest2016", "mosesWER", "mosesPER", "mtevalNIST", "mosesBLEU", "UoW.ReVal", "chrF1", "mosesCDER", "chrF2", "chrF3", "mtevalBLEU", "BEER", "MPEDA", "CharacTer", ".R", "eV", "al", "m", "os", "es", "B", "LE", "U", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "P", "E", "R", "m", "os", "es", "W", "E", "R", "U", "oW", "D", "E", "R", "ch", "rF", "1", "es", "C", "m", "os", "ch", "rF", "3", "ch", "rF", "2", "LE", "U", "va", "lB", "m", "te", "ra", "cT", "er", "M", "P", "E", "D", "A", "B", "E", "E", "R", "C", "ha", "mosesWER", "mosesTER", "mosesPER", "mtevalNIST", "mosesBLEU", "wordF1", "wordF3", "wordF2", "UoW.ReVal", "chrF1", "mosesCDER", "chrF2", "chrF3", "mtevalBLEU", "BEER", "MPEDA", "CharacTer", ".R", "eV", "al", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "dF", "1", "m", "os", "es", "B", "LE", "U", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "P", "E", "R", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "U", "oW", "D", "E", "R", "ch", "rF", "1", "es", "C", "m", "os", "ch", "rF", "3", "ch", "rF", "2", "LE", "U", "va", "lB", "m", "te", "ra", "cT", "er", "M", "P", "E", "D", "A", "B", "E", "E", "R", "C", "ha", "DA", "DA", "Hybrids", "6", "Systems", "10k", "Systems", "mosesWER", "mosesPER", "mosesTER", "mtevalNIST", "UoW.ReVal", "mtevalBLEU", "wordF3", "MPEDA", "wordF2", "wordF1", "mosesBLEU", "chrF3", "chrF1", "chrF2", "mosesCDER", "BEER", "CharacTer", "ra", "cT", "er", "B", "E", "E", "R", "m", "os", "es", "C", "D", "E", "R", "ch", "rF", "2", "ch", "rF", "1", "ch", "rF", "3", "m", "os", "es", "B", "LE", "U", "w", "or", "dF", "1", "w", "or", "dF", "2", "M", "P", "E", "D", "A", "w", "or", "dF", "3", "m", "te", "va", "lB", "LE", "U", "U", "oW", ".R", "eV", "al", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "T", "E", "R", "m", "os", "es", "P", "E", "R", "m", "os", "es", "W", "E", "R", "C", "ha", "mosesPER", "mosesWER", "mosesTER", "mtevalNIST", "wordF3", "mosesBLEU", "chrF3", "wordF2", "mtevalBLEU", "chrF2", "wordF1", "UoW.ReVal", "chrF1", "mosesCDER", "MPEDA", "BEER", "CharacTer", "ch", "rF", "3", "m", "os", "es", "B", "LE", "U", "w", "or", "dF", "3", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "T", "E", "R", "m", "os", "es", "W", "E", "R", "m", "os", "es", "P", "E", "R", "dF", "2", "w", "or", "LE", "U", "va", "lB", "m", "te", ".R", "eV", "al", "w", "or", "dF", "1", "ch", "rF", "2", "U", "oW", "D", "E", "R", "ch", "rF", "1", "es", "C", "m", "os", "ra", "cT", "er", "B", "E", "E", "R", "M", "P", "E", "D", "A", "C", "ha"], "regionBoundary": {"x2": 505.0, "y1": 146.8900146484375, "x1": 90.0, "y2": 615.8900146484375}, "caption": "Figure 3: Czech-to-English (cs-en) system-level metric significance test results for human assessment variants; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; RR + TT = standard WMT relative ranking for all cs-en newstest2016 systems; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling.", "page": 11}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.546630859375, "y1": 340.1552734375, "x1": 72.0009994506836, "y2": 360.2770080566406}, "imageText": ["newstest2016", "MPEDA", ".996", ".993", ".956", ".937", ".967", ".976", ".938", ".932", ".986", ".929", ".972", ".982", "UOW.REVAL", ".993", ".986", ".949", ".985", ".958", ".970", ".919", ".957", ".990", ".976", ".977", ".958", "BEER", ".996", ".990", ".949", ".879", ".964", ".972", ".908", ".852", ".986", ".901", ".981", ".982", "CHRF1", ".993", ".986", ".934", ".868", ".974", ".980", ".903", ".865", ".984", ".898", ".973", ".961", "CHRF2", ".992", ".989", ".952", ".893", ".957", ".967", ".913", ".886", ".985", ".918", ".937", ".933", "CHRF3", ".991", ".989", ".958", ".902", ".946", ".958", ".915", ".892", ".981", ".923", ".918", ".917", "CHARACTER", ".997", ".995", ".985", ".929", ".921", ".927", ".970", ".883", ".955", ".930", ".799", ".827", "MTEVALNIST", ".988", ".978", ".887", ".801", ".924", ".929", ".834", ".807", ".966", ".854", ".952", ".938", "MTEVALBLEU", ".992", ".989", ".905", ".808", ".858", ".864", ".899", ".840", ".962", ".837", ".899", ".895", "MOSESCDER", ".995", ".988", ".927", ".827", ".846", ".860", ".925", ".800", ".968", ".855", ".836", ".826", "MOSESTER", ".983", ".969", ".926", ".834", ".852", ".846", ".900", ".793", ".962", ".847", ".805", ".788", "WORDF2", ".991", ".985", ".897", ".786", ".790", ".806", ".905", ".815", ".955", ".831", ".807", ".787", "WORDF3", ".991", ".985", ".898", ".787", ".786", ".803", ".909", ".818", ".955", ".833", ".803", ".786", "WORDF1", ".992", ".984", ".894", ".780", ".796", ".808", ".890", ".804", ".954", ".825", ".806", ".776", "MOSESPER", ".981", ".970", ".843", ".730", ".770", ".767", ".791", ".748", ".974", ".887", ".947", ".940", "MOSESBLEU", ".991", ".983", ".880", ".757", ".752", ".759", ".878", ".793", ".950", ".817", ".765", ".739", "MOSESWER", ".982", ".967", ".926", ".822", ".773", ".768", ".895", ".762", ".958", ".837", ".680", ".651", "cs-en", "de-en", "\ufb01-en", "ro-en", "ru-en", "tr-en", "Human", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "Systems", "6", "6", "10", "10", "9", "9", "7", "7", "10", "10", "8", "8"], "regionBoundary": {"x2": 535.0, "y1": 80.8900146484375, "x1": 72.0, "y2": 321.8900146484375}, "caption": "Table 4: Absolute Pearson correlation of to-English system-level metric scores with human assessment variants: RR = standard WMT relative ranking; DA = direct assessment of translation adequacy.", "page": 8}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5466918945312, "y1": 718.6272583007812, "x1": 72.0009994506836, "y2": 738.75}, "imageText": ["newstest2016", "CHARACTER", ".947", "-", ".915", "-", ".933", "-", ".959", "-", ".954", ".966", ".930", "-", "BEER", ".973", "-", ".732", "-", ".940", "-", ".947", "-", ".906", ".922", ".956", "-", "CHRF2", ".954", "-", ".725", "-", ".974", "-", ".828", "-", ".930", ".955", ".940", "-", "CHRF3", ".954", "-", ".745", "-", ".974", "-", ".818", "-", ".936", ".960", ".916", "-", "MOSESCDER", ".968", "-", ".779", "-", ".910", "-", ".952", "-", ".874", ".874", ".791", "-", "CHRF1", ".955", "-", ".645", "-", ".931", "-", ".858", "-", ".901", ".928", ".938", "-", "WORDF3", ".964", "-", ".768", "-", ".901", "-", ".931", "-", ".836", ".840", ".714", "-", "WORDF2", ".964", "-", ".766", "-", ".899", "-", ".933", "-", ".836", ".840", ".715", "-", "WORDF1", ".964", "-", ".756", "-", ".888", "-", ".937", "-", ".836", ".839", ".711", "-", "MPEDA", ".964", "-", ".684", "-", ".944", "-", ".786", "-", ".856", ".866", ".860", "-", "MOSESBLEU", ".968", "-", ".784", "-", ".857", "-", ".944", "-", ".820", ".820", ".693", "-", "MTEVALBLEU", ".968", "-", ".752", "-", ".868", "-", ".897", "-", ".835", ".838", ".745", "-", "MTEVALNIST", ".975", "-", ".625", "-", ".886", "-", ".882", "-", ".890", ".897", ".788", "-", "MOSESTER", ".940", "-", ".742", "-", ".863", "-", ".906", "-", ".882", ".879", ".644", "-", "MOSESWER", ".935", "-", ".771", "-", ".855", "-", ".912", "-", ".882", ".876", ".570", "-", "MOSESPER", ".974", "-", ".681", "-", ".700", "-", ".944", "-", ".857", ".854", ".641", "-", "CHRF3.2REF", "-", "-", "-", "-", ".973", "-", "-", "-", "-", "-", "-", "-", "CHRF2.2REF", "-", "-", "-", "-", ".970", "-", "-", "-", "-", "-", "-", "-", "CHRF1.2REF", "-", "-", "-", "-", ".923", "-", "-", "-", "-", "-", "-", "-", "WORDF3.2REF", "-", "-", "-", "-", ".890", "-", "-", "-", "-", "-", "-", "-", "WORDF2.2REF", "-", "-", "-", "-", ".887", "-", "-", "-", "-", "-", "-", "-", "WORDF1.2REF", "-", "-", "-", "-", ".876", "-", "-", "-", "-", "-", "-", "-", "en-cs", "en-de", "en-\ufb01", "en-ro", "en-ru", "en-tr", "Human", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "RR", "DA", "Systems", "10", "15", "13", "12", "12", "12", "8"], "regionBoundary": {"x2": 525.0, "y1": 408.8900146484375, "x1": 72.0, "y2": 700.8900146484375}, "caption": "Table 5: Absolute Pearson correlation of out-of-English system-level metric scores with human assessment variants: RR = standard WMT relative ranking; DA = direct assessment of translation adequacy.", "page": 8}, {"figType": "Figure", "name": "10", "captionBoundary": {"x2": 525.5467529296875, "y1": 607.4112548828125, "x1": 72.00103759765625, "y2": 668.1810302734375}, "imageText": ["chrF3", "chrF2", "BEER", "chrF1", "MPEDA", "wordF3", "wordF2", "wordF1", "sentBLEU", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "A", "E", "D", "M", "P", "1", "ch", "rF", "E", "R", "B", "E", "2", "ch", "rF", "3", "ch", "rF", "BEER", "chrF1", "MPEDA", "chrF2", "chrF3", "wordF3", "wordF2", "wordF1", "sentBLEU", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "3", "ch", "rF", "2", "ch", "rF", "A", "E", "D", "M", "P", "1", "ch", "rF", "E", "R", "B", "E", "en-pl", "en-ro", "BEER", "chrF3", "chrF2", "MPEDA", "chrF1", "wordF3", "wordF2", "wordF1", "sentBLEU", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "1", "ch", "rF", "A", "E", "D", "M", "P", "2", "ch", "rF", "3", "ch", "rF", "E", "R", "B", "E", "chrF3", "chrF2", "BEER", "chrF1", "MPEDA", "wordF3", "wordF2", "wordF1", "sentBLEU", "U", "B", "LE", "se", "nt", "dF", "1", "w", "or", "dF", "2", "w", "or", "dF", "3", "w", "or", "A", "E", "D", "M", "P", "1", "ch", "rF", "E", "R", "B", "E", "2", "ch", "rF", "3", "ch", "rF", "en-cs", "en-de"], "regionBoundary": {"x2": 498.2528991699219, "y1": 153.58631896972656, "x1": 96.0, "y2": 591.3624877929688}, "caption": "Figure 10: HUME segment-level metric significance test results (himl2015): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation; Winning metrics are those not significantly outperformed by any other (en-cs: CHRF3; en-de: BEER, CHRF3, CHRF2, MPEDA, CHRF1; en-pl: BEER, CHRF1, MPEDA, CHRF2; en-ro: CHRF3).", "page": 19}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 415.8557434082031, "y1": 179.63929748535156, "x1": 181.69200134277344, "y2": 186.2120361328125}, "imageText": ["UPF-COBALT,", "COBALTF,", "METRICSF", "Universitat", "Pompeu", "Fabra", "(Fomicheva", "et", "al.,", "2016)", "DTED", "University", "of", "St", "Andrews,", "(McCaffery", "and", "Nederhof,", "2016)", "MPEDA", "Jiangxi", "Normal", "University", "(Zhang", "et", "al.,", "2016)", "UOW.REVAL", "University", "of", "Wolverhampton", "(Gupta", "et", "al.,", "2015b)", "DEPCHECK", "Charles", "University,", "no", "corresponding", "paper", "DPMFCOMB-WITHOUT-RED", "Chinese", "Academy", "of", "Sciences", "and", "Dublin", "City", "University", "(Yu", "et", "al.,", "2015)", "CHARACTER", "RWTH", "Aachen", "University", "(Wang", "et", "al.,", "2016)", "CHRF1,2,3,", "WORDF1,2,3", "Humboldt", "University", "of", "Berlin", "(Popovic\u0301,", "2016)", "Metric", "Participant", "BEER", "ILLC", "\u2013", "University", "of", "Amsterdam", "(Stanojevic\u0301", "and", "Sima\u2019an,", "2015)"], "regionBoundary": {"x2": 513.0, "y1": 63.94842529296875, "x1": 84.0, "y2": 159.84405517578125}, "caption": "Table 2: Participants of WMT16 Metrics Shared Task", "page": 4}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 525.546630859375, "y1": 290.5393371582031, "x1": 72.00100708007812, "y2": 324.2100830078125}, "imageText": ["en-pt", "chrF1", "CharacTer", "chrF2", "MPEDA", "BEER", "chrF3", "mosesWER", "mosesBLEU", "mtevalNIST", "mosesTER", "wordF3", "mosesCDER", "mtevalBLEU", "wordF2", "wordF1", "mosesPER", "D", "E", "R", "w", "or", "dF", "3", "m", "os", "es", "T", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "B", "LE", "U", "m", "os", "es", "W", "E", "R", "ch", "rF", "3", "B", "E", "E", "R", "M", "P", "E", "D", "A", "ch", "rF", "2", "C", "ha", "ra", "cT", "er", "ch", "rF", "1", "es", "C", "m", "os", "LE", "U", "va", "lB", "m", "te", "dF", "2", "w", "or", "dF", "1", "w", "or", "E", "R", "es", "P", "m", "os", "en-nl", "mtevalBLEU", "mtevalNIST", "mosesTER", "MPEDA", "mosesBLEU", "wordF3", "wordF2", "mosesWER", "wordF1", "mosesCDER", "CharacTer", "mosesPER", "chrF1", "chrF2", "chrF3", "BEER", "D", "E", "R", "w", "or", "dF", "1", "m", "os", "es", "W", "E", "R", "w", "or", "dF", "2", "w", "or", "dF", "3", "m", "os", "es", "B", "LE", "U", "M", "P", "E", "D", "A", "m", "os", "es", "T", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "te", "va", "lB", "LE", "U", "es", "C", "m", "os", "ch", "rF", "3", "ch", "rF", "2", "ch", "rF", "1", "m", "os", "es", "P", "E", "R", "C", "ha", "ra", "cT", "er", "E", "R", "B", "E", "en-es", "mosesTER", "mosesPER", "chrF1", "mosesWER", "mtevalNIST", "BEER", "mosesCDER", "chrF2", "chrF3", "MPEDA", "wordF1", "CharacTer", "wordF2", "wordF3", "mosesBLEU", "mtevalBLEU", "D", "E", "R", "B", "E", "E", "R", "m", "te", "va", "lN", "IS", "T", "m", "os", "es", "W", "E", "R", "ch", "rF", "1", "m", "os", "es", "P", "E", "R", "m", "os", "es", "T", "E", "R", "es", "C", "m", "os", "ra", "cT", "er", "w", "or", "dF", "1", "M", "P", "E", "D", "A", "ch", "rF", "3", "ch", "rF", "2", "C", "ha", "dF", "2", "w", "or", "dF", "3", "w", "or", "LE", "U", "es", "B", "m", "os", "LE", "U", "va", "lB", "m", "te"], "regionBoundary": {"x2": 552.0, "y1": 104.8900146484375, "x1": 72.0, "y2": 272.8900146484375}, "caption": "Figure 7: System-level metric ittest2016 significance test results for differences in metric correlation with human assessment for remaining out-of-English language pairs evaluated with relative ranking (RR) human assessment.", "page": 15}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9284193250868, "y1": 221.82543012830945, "x1": 100.00139872233072, "y2": 268.5917324490017}, "name": "1", "caption_text": "Table 1: Overview of \u201ctracks\u201d of the WMT16 metrics task. \u201c\u2022\u201d indicates language pairs covered in the evaluation, \u201c\u00b7\u201d are language pairs planned but abandoned due to difficulties in obtaining human judgments.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 718.0, "y1": 58.0, "x1": 112.0, "y2": 199.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 577.5774214002821, "y1": 249.49902428521048, "x1": 252.3500018649631, "y2": 258.62782796223956}, "name": "2", "caption_text": "Table 2: Participants of WMT16 Metrics Shared Task", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 713.0, "y1": 88.0, "x1": 117.0, "y2": 225.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9259609646267, "y1": 199.68653784857855, "x1": 100.00136693318684, "y2": 227.63341267903644}, "name": "3", "caption_text": "Table 3: Overview of tables (T) and figures (F) reporting results of the individual \u201ctracks\u201d and language pairs.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 86.0, "x1": 103.0, "y2": 177.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9251980251736, "y1": 439.13519117567273, "x1": 426.77362230088977, "y2": 504.71950107150604}, "name": "6", "caption_text": "Table 6: Absolute Pearson correlation of cs-en and en-cs system-level metric scores with human assessment variant RR + TT, i.e. standard WMT relative ranking including tuning task systems.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 709.0, "y1": 86.0, "x1": 428.0, "y2": 440.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 472.43787977430554, "x1": 100.00138812594943, "y2": 500.38473341200086}, "name": "4", "caption_text": "Table 4: Absolute Pearson correlation of to-English system-level metric scores with human assessment variants: RR = standard WMT relative ranking; DA = direct assessment of translation adequacy.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 743.0, "y1": 111.0, "x1": 100.0, "y2": 448.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9259609646267, "y1": 998.0934143066406, "x1": 100.00138812594943, "y2": 1026.0416666666667}, "name": "5", "caption_text": "Table 5: Absolute Pearson correlation of out-of-English system-level metric scores with human assessment variants: RR = standard WMT relative ranking; DA = direct assessment of translation adequacy.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 568.0, "x1": 101.0, "y2": 973.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.926045735677, "y1": 1013.0599975585938, "x1": 100.00135633680556, "y2": 1116.280534532335}, "name": "1", "caption_text": "Figure 1: German-to-English (de-en), Finnish-to-English (fi-en) and Romanian-to-English (ro-en) system-level metric significance test results for human assessment variants; green cells denote a significant increase in correlation with human assessment for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling. 208", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 107.0, "x1": 101.0, "y2": 997.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9262152777777, "y1": 1050.5865308973523, "x1": 100.00131395128038, "y2": 1134.987555609809}, "name": "2", "caption_text": "Figure 2: Russian-to-English (ru-en), Turkish-to-English (tr-en) and English-to-Russian (en-ru) systemlevel metric significance test results for human assessment variants; green cells denote a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 107.0, "x1": 101.0, "y2": 1034.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9282497829861, "y1": 871.9419691297743, "x1": 100.0014411078559, "y2": 975.1625061035156}, "name": "3", "caption_text": "Figure 3: Czech-to-English (cs-en) system-level metric significance test results for human assessment variants; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking for translation task systems only; RR + TT = standard WMT relative ranking for all cs-en newstest2016 systems; DA = direct assessment of translation adequacy; DA Hybrids = direct assessment with hybrid super-sampling.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 161.0, "x1": 125.0, "y2": 854.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 493.0198669433594, "x1": 100.00139872233072, "y2": 558.6042192247179}, "name": "4", "caption_text": "Figure 4: English-to-Czech (en-cs) system-level metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking; RR + TT = standard WMT relative ranking for translation and tuning task systems.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 96.0, "x1": 125.0, "y2": 458.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 992.8698221842448, "x1": 100.0014411078559, "y2": 1039.634789360894}, "name": "5", "caption_text": "Figure 5: English-to-German (en-de) system-level metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 599.0, "x1": 125.0, "y2": 975.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.926045735677, "y1": 428.5712771945529, "x1": 100.00139872233072, "y2": 494.15562947591144}, "name": "6", "caption_text": "Figure 6: English-to-Finnish (en-fi), English-to-Romanian (en-ro) and English-to-Turkish (en-tr) systemlevel metric significance test results; a green cell corresponds to a significant increase in correlation for the metric in a given row over the metric in a given column according to Williams test; RR = standard WMT relative ranking.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 767.0, "y1": 88.0, "x1": 100.0, "y2": 385.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9259609646267, "y1": 441.69765048556854, "x1": 100.00138812594943, "y2": 469.6444617377387}, "name": "7", "caption_text": "Table 7: Absolute Pearson correlation of system-level metric scores with 10K hybrid systems: DA Hybrid = direct assessment of translation adequacy of 10K hybrid MT systems.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 674.0, "y1": 144.0, "x1": 153.0, "y2": 426.0}, "page": 14, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 944.7989569769965, "x1": 100.00138812594943, "y2": 991.5652804904513}, "name": "8", "caption_text": "Table 8: System-level metric results (ittest2016): Pearson correlation of system-level metric scores with human assessment computed over standard WMT relative ranking (RR) human assessments; absolute values of correlation coefficients reported for all metrics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 678.0, "y1": 606.0, "x1": 149.0, "y2": 929.0}, "page": 14, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 403.526857164171, "x1": 100.00139872233072, "y2": 450.2917819552951}, "name": "7", "caption_text": "Figure 7: System-level metric ittest2016 significance test results for differences in metric correlation with human assessment for remaining out-of-English language pairs evaluated with relative ranking (RR) human assessment.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 766.0, "y1": 88.0, "x1": 100.0, "y2": 379.0}, "page": 15, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9251980251736, "y1": 386.90596686469183, "x1": 426.77362230088977, "y2": 490.12646145290796}, "name": "9", "caption_text": "Figure 9: Direct Assessment (DA) segment-level metric significance test results for English to Russian (newstest2016): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 702.0, "y1": 92.0, "x1": 450.0, "y2": 364.0}, "page": 16, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9271477593315, "y1": 464.57121107313367, "x1": 100.00138812594943, "y2": 548.973634507921}, "name": "9", "caption_text": "Table 9: Segment-level metric results for to-English language pairs (newstest2016): Correlation of segment-level metric scores with human assessment variants, where \u03c4 are official results computed similar to Kendall\u2019s \u03c4 and over standard WMT relative ranking (RR) human assessments; r are Pearson correlation coefficients of metric scores with direct assessment (DA) of absolute translation adequacy; absolute value of correlation coefficients reported for all metrics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 734.0, "y1": 92.0, "x1": 100.0, "y2": 440.0}, "page": 17, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9281650119358, "y1": 960.7128567165798, "x1": 100.00134574042426, "y2": 1045.1153225368923}, "name": "10", "caption_text": "Table 10: Segment-level metric results for out-of-English language pairs (newstest2016): Absolute correlation of segment-level metric scores with human assessment variants, where \u03c4 are official results computed similar to Kendall\u2019s \u03c4 and over standard WMT relative ranking (RR) human assessments; r are Pearson correlation coefficients of metric scores with direct assessment (DA) of absolute translation adequacy; absolute value of correlation coefficients reported for all metrics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 578.0, "x1": 101.0, "y2": 945.0}, "page": 17, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 1010.0906372070312, "x1": 100.0014411078559, "y2": 1056.8556043836804}, "name": "8", "caption_text": "Figure 8: Direct Assessment (DA) segment-level metric significance test results for to-English language pairs (newstest2016): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 692.0, "y1": 89.0, "x1": 134.0, "y2": 988.0}, "page": 18, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.926045735677, "y1": 843.6267428927952, "x1": 100.0014411078559, "y2": 928.0292087131076}, "name": "10", "caption_text": "Figure 10: HUME segment-level metric significance test results (himl2015): Green cells denote a significant win for the metric in a given row over the metric in a given column according to Williams test for difference in dependent correlation; Winning metrics are those not significantly outperformed by any other (en-cs: CHRF3; en-de: BEER, CHRF3, CHRF2, MPEDA, CHRF1; en-pl: BEER, CHRF1, MPEDA, CHRF2; en-ro: CHRF3).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 691.0, "y1": 211.0, "x1": 134.0, "y2": 821.0}, "page": 19, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 722.2768147786458, "y1": 350.51017337375214, "x1": 107.6555569966634, "y2": 359.63897705078125}, "name": "11", "caption_text": "Table 11: Pearson correlation of segment-level metric scores with HUME human assessment variant.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 602.0, "y1": 86.0, "x1": 225.0, "y2": 334.0}, "page": 20, "dpi": 0}], "error": null, "pdf": "/work/host-output/6316c4fbfca99aa6c9b7ff6489d3597dedbbb211/W16-2302.pdf", "dpi": 100}