{"raw_detected_boxes": [[{"x2": 726.0, "y1": 324.0, "x1": 428.0, "y2": 441.0}], [{"x2": 723.0, "y1": 378.0, "x1": 428.0, "y2": 769.0}], [{"x2": 730.0, "y1": 91.0, "x1": 100.0, "y2": 219.0}], [{"x2": 718.0, "y1": 138.0, "x1": 105.0, "y2": 308.0}, {"x2": 724.0, "y1": 375.0, "x1": 106.0, "y2": 556.0}], [{"x2": 721.0, "y1": 92.0, "x1": 103.0, "y2": 430.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2009887695312, "y1": 171.20852661132812, "x1": 72.0, "y2": 213.0770263671875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 158.8900146484375}, "caption": "Figure 2: An overview of framework which integrates visual semantic knowledge with Entity Synset Alignment(ESA). (a) A raw image goes into inference models as an input. (b) Inference models(Bottom-up attention and CompTransR) generate (c) scene graphs from each dataset(VG, VG200, VrR-VG). (e) Integrated scene graph is built as an output via (d) Entity Synset Alignment method.", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.54736328125, "y1": 325.6075439453125, "x1": 71.6709976196289, "y2": 355.52099609375}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 313.8900146484375}, "caption": "Figure 3: Qualitative results for our Entity Synset Alignment(ESA) method with Top 20 relations. Each scene graph (c),(d),(e) generated from inference models are combined into an integrated scene graph (b) for an image (a).", "page": 4}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5469970703125, "y1": 65.1745376586914, "x1": 71.69100189208984, "y2": 83.13201904296875}, "imageText": ["VrR-VG", "\u2227", "BU-VG", "42.04", "141", "29.57", "50", "26.35", "55", "VG200", "\u2227", "VrR-VG", "\u2227", "BU-VG", "41.95", "127", "79.67", "100", "26.35", "55", "VG200", "\u2227", "VrR-VG", "37.00", "167", "100", "100.0", "0.0", "0", "VG200", "\u2227", "BU-VG", "27.21", "66", "44.39", "50", "26.35", "55", "Method", "Number", "of", "object", "Number", "of", "relation", "Number", "of", "attributes", "Avg.", "Max", "Avg.", "Max", "Avg.", "Max", "VG200", "12.53", "62", "50.0", "50", "0.0", "0", "VrR-VG", "36.77", "167", "50.0", "50", "0.0", "0", "BU-VG", "26.35", "55", "0.0", "0", "26.35", "55"], "regionBoundary": {"x2": 524.0, "y1": 96.8900146484375, "x1": 73.0, "y2": 222.8900146484375}, "caption": "Table 1: The average and max number of object, relation and attribute with various combinations of scene graph datasets.", "page": 3}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5470581054688, "y1": 237.70755004882812, "x1": 71.69100189208984, "y2": 255.6650390625}, "imageText": ["VrR-VG", "\u2227", "BU-VG", "27.9", "70.5", "83.2", "23.7", "37.7", "41.4", "VG200", "\u2227", "VrR-VG", "\u2227", "BU-VG", "27.2", "70.0", "82.4", "24.7", "37.7", "41.0", "GCN", "based", "VG200", "\u2227", "VrR-VG", "29.3", "67.6", "81.9", "23.4", "37.4", "41.0", "VG200", "\u2227", "BU-VG", "29.4", "68.7", "82.8", "24.1", "37.5", "41.1", "VrR-VG", "28.1", "66.2", "80.4", "23.2", "37.2", "40.9", "BU-VG", "27.0", "65.4", "80.6", "23.1", "37.0", "40.7", "CNN", "based", "ResNet-152", "26.9", "65.1", "79.4", "24.2", "36.4", "39.9", "VG200", "22.2", "57.6", "73.2", "19.7", "34.6", "39.5", "Method", "Caption", "Retrieval", "Image", "Retrieval", "R@1", "R@5", "R@10", "R@1", "R@5", "R@10"], "regionBoundary": {"x2": 525.0, "y1": 268.8900146484375, "x1": 73.0, "y2": 409.8900146484375}, "caption": "Table 2: Quantitative results for our method on image-to-caption retrieval(caption retrieval) and caption-to-image retrieval(image retrieval) task. BU-VG is an abbreviation of BottomUp-VG.", "page": 3}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2001953125, "y1": 331.41253662109375, "x1": 307.2760009765625, "y2": 361.32598876953125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 231.8900146484375, "x1": 307.0, "y2": 319.8900146484375}, "caption": "Figure 1: An example of scene graph for a common image from Visual Genome 200 (VG200) and VisuallyRelevant Relationship (VrR-VG) dataset.", "page": 0}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2224934895833, "y1": 460.2951897515191, "x1": 426.772223578559, "y2": 501.8416510687934}, "name": "1", "caption_text": "Figure 1: An example of scene graph for a common image from Visual Genome 200 (VG200) and VisuallyRelevant Relationship (VrR-VG) dataset.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 324.0, "x1": 428.0, "y2": 442.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2235955132378, "y1": 237.78962029351126, "x1": 100.0, "y2": 295.9403143988715}, "name": "2", "caption_text": "Figure 2: An overview of framework which integrates visual semantic knowledge with Entity Synset Alignment(ESA). (a) A raw image goes into inference models as an input. (b) Inference models(Bottom-up attention and CompTransR) generate (c) scene graphs from each dataset(VG, VG200, VrR-VG). (e) Integrated scene graph is built as an output via (d) Entity Synset Alignment method.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 91.0, "x1": 100.0, "y2": 220.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9263848198784, "y1": 90.52019119262695, "x1": 99.57083596123589, "y2": 115.46113755967882}, "name": "1", "caption_text": "Table 1: The average and max number of object, relation and attribute with various combinations of scene graph datasets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 134.0, "x1": 102.0, "y2": 310.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9264695909288, "y1": 330.14937506781683, "x1": 99.57083596123589, "y2": 355.09033203125}, "name": "2", "caption_text": "Table 2: Quantitative results for our method on image-to-caption retrieval(caption retrieval) and caption-to-image retrieval(image retrieval) task. BU-VG is an abbreviation of BottomUp-VG.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 374.0, "x1": 101.0, "y2": 569.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268934461805, "y1": 452.2326999240451, "x1": 99.54305224948459, "y2": 493.7791612413194}, "name": "3", "caption_text": "Figure 3: Qualitative results for our Entity Synset Alignment(ESA) method with Top 20 relations. Each scene graph (c),(d),(e) generated from inference models are combined into an integrated scene graph (b) for an image (a).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 87.0, "x1": 100.0, "y2": 431.0}, "page": 4, "dpi": 0}], "error": null, "pdf": "/work/host-output/f674a7b35f4783c4b5f7135c7088b225a1b28f72/2020.alvr-1.2.pdf", "dpi": 100}