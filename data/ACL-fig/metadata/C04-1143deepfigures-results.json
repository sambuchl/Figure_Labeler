{"raw_detected_boxes": [[], [], [{"x2": 744.0, "y1": 116.0, "x1": 438.0, "y2": 381.0}], [{"x2": 741.0, "y1": 330.0, "x1": 446.0, "y2": 546.0}], [{"x2": 738.0, "y1": 197.0, "x1": 446.0, "y2": 388.0}, {"x2": 740.0, "y1": 512.0, "x1": 447.0, "y2": 669.0}, {"x2": 402.0, "y1": 793.0, "x1": 111.0, "y2": 984.0}], [{"x2": 406.0, "y1": 143.0, "x1": 108.0, "y2": 287.0}, {"x2": 407.0, "y1": 569.0, "x1": 109.0, "y2": 738.0}], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 540.13818359375, "y1": 537.7467651367188, "x1": 313.20025634765625, "y2": 705.178955078125}, "text": "Figure 1 illustrates the main two difficulties faced by the summariser in this situation. While the threaded content from the previous reply should be filtered out to identify the reply, the reply on its own is meaningless without any form of context. The summariser tries to overcome this by identifying this style of embedded responses when the original content is split into chunks or is only partially included in the reply. The text falling before the answer is then treated as part of the reply. Although this strategy gives acceptable results in some cases, more research is needed into finding the optimal strategy to extract the right amount of context from the thread without either destroying the context or copying too much from the original request back into the summary.", "name": "1", "page": 1}, {"figType": "Figure", "boundary": {"x2": 540.0794067382812, "y1": 471.08660888671875, "x1": 313.2002258300781, "y2": 615.5388793945312}, "text": "Figure 3 shows how the quadratic positional weight function \u03b3 changes with position, giving less importance to sentences as they occur further from the start (although the weight is always bigger than zero). Different kinds of emails were used to calibrate the weight function. Series 1 (bottom) represents a typical mobile text message length summary with a very long message. Series 4 and 5 (middle) represent the weight function behaviour when the summary maximum length is long (approximately more than 1,000 characters), irrelevant of the email message length itself. Series 2 and 3 (top) represent email messages that fall within the maximum length constraints.", "name": "3", "page": 3}], "figures": [{"figType": "Figure", "name": "8", "captionBoundary": {"x2": 298.89715576171875, "y1": 545.697021484375, "x1": 72.00025177001953, "y2": 622.07958984375}, "imageText": ["Summariser", "Utility", "Gold", "Standard", "Utility", "Value", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "Sample", "Group", "2", "1.5", "1", "0.5", "0"], "regionBoundary": {"x2": 294.0, "y1": 409.9976806640625, "x1": 78.35969543457031, "y2": 534.0}, "caption": "Figure 8 Utility Score Comparison In Figure 8 a random extraction system is expected to get a score of 1 averaged across an infinite amount of runs. The average sentence compression factor for the summariser was 42%, exactly the same as the human judges\u2019 results. The selected emails had an average length of 14 sentences, varying from 7 to 27 sentences.", "page": 5}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 283.82281494140625, "y1": 219.95709228515625, "x1": 101.4000015258789, "y2": 227.15997314453125}, "imageText": ["Recall", "Precision", "Value", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "Sample", "Group", "1.5", "1", "0.5", "0"], "regionBoundary": {"x2": 295.0, "y1": 103.10226440429688, "x1": 77.39985656738281, "y2": 207.0}, "caption": "Figure 7 Summaries Recall and Precision", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 487.04827880859375, "y1": 513.95703125, "x1": 327.6000061035156, "y2": 521.159912109375}, "imageText": [">", "\u2026", "now", "coming", "back", "to", "the", "issue", ">", "of", "whether", "to", "include", "support", "for", ">", "location", "names", "in", "the", "recogniser", ">", "I", "think", "that", "we", "should", "include", ">", "this", "\u2013", "your", "opinions", "appreciated.", "I", "agree", "with", "this."], "regionBoundary": {"x2": 537.5782470703125, "y1": 431.6930236816406, "x1": 327.6014709472656, "y2": 496.85406494140625}, "caption": "Figure 1 Sample Embedded Answer", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 530.7830200195312, "y1": 267.8970947265625, "x1": 336.8399963378906, "y2": 275.0999755859375}, "imageText": [], "regionBoundary": {"x2": 536.0, "y1": 83.0, "x1": 315.0, "y2": 263.0}, "caption": "Figure 2 Summariser and VPA Architecture", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 538.2446899414062, "y1": 400.1971130371094, "x1": 329.2799987792969, "y2": 419.9995422363281}, "imageText": ["Series4", "Series5", "Series1", "Series2", "Series3", "Weight", "1", "3", "5", "7", "9", "11", "13", "15", "17", "19", "Number", "of", "Sentences", "0", "1", "2", "3", "4", "5", "6", "7", "8"], "regionBoundary": {"x2": 533.0, "y1": 235.51832580566406, "x1": 321.1199951171875, "y2": 393.0}, "caption": "Figure 3 Positional sentence weight for varying summarisation parameters", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 285.22076416015625, "y1": 708.4171142578125, "x1": 100.0199966430664, "y2": 715.6199951171875}, "imageText": ["M", "F", "P", "L", "Mt", "Ft", "t", "TIME", "Ma", "Fa", "a", "Precision", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "Sample", "Group", "1", "0.8", "0.6", "0.4", "0.2", "0"], "regionBoundary": {"x2": 292.0, "y1": 567.23828125, "x1": 79.91939544677734, "y2": 702.0}, "caption": "Figure 4 Precision by Named Entity Class", "page": 4}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 519.9677124023438, "y1": 279.35711669921875, "x1": 347.6400146484375, "y2": 286.55999755859375}, "imageText": ["M", "F", "P", "L", "Mt", "Ft", "t", "TIME", "Ma", "Fa", "a", "Recall", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "Sample", "Group", "1", "0.8", "0.6", "0.4", "0.2", "0"], "regionBoundary": {"x2": 534.0, "y1": 137.457275390625, "x1": 321.1194152832031, "y2": 271.0}, "caption": "Figure 5 Recall by Named Entity Class", "page": 4}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 540.0281982421875, "y1": 303.2067565917969, "x1": 313.20025634765625, "y2": 355.7395935058594}, "imageText": ["Value", "0.75", "1", "0", "0.25", "0.5"], "regionBoundary": {"x2": 533.0, "y1": 368.65618896484375, "x1": 321.8998718261719, "y2": 445.0}, "caption": "Figure 6 shows the average precision and recall averaged across all the eleven types of named entity classes, for the 10 sample email groups. An average precision of 93% was achieved throughout, with 97% recall.", "page": 4}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 518.8441162109375, "y1": 494.2171325683594, "x1": 348.7200012207031, "y2": 501.4200134277344}, "imageText": ["Recall", "Precision", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "Sample", "Group"], "regionBoundary": {"x2": 527.4092407226562, "y1": 450.6571350097656, "x1": 350.8199462890625, "y2": 484.0}, "caption": "Figure 6 Average Precision and Recall", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 737.1986389160156, "y1": 372.0792982313368, "x1": 467.8333282470703, "y2": 382.0832994249132}, "name": "2", "caption_text": "Figure 2 Summariser and VPA Architecture", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 744.0, "y1": 116.0, "x1": 438.0, "y2": 385.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 747.5620693630642, "y1": 555.8293236626519, "x1": 457.3333316379123, "y2": 583.3326975504557}, "name": "3", "caption_text": "Figure 3 Positional sentence weight for varying summarisation parameters", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 747.0, "y1": 327.0, "x1": 446.0, "y2": 563.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 722.1773783365885, "y1": 387.9959954155816, "x1": 482.8333536783854, "y2": 397.99999660915796}, "name": "5", "caption_text": "Figure 5 Recall by Named Entity Class", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 741.0, "y1": 191.0, "x1": 446.0, "y2": 401.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 720.6168280707465, "y1": 686.4126841227213, "x1": 484.33333502875433, "y2": 696.4166853162977}, "name": "6", "caption_text": "Figure 6 Average Precision and Recall", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 740.0, "y1": 512.0, "x1": 447.0, "y2": 686.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 396.1399502224392, "y1": 983.9126586914062, "x1": 138.91666200425888, "y2": 993.9166598849826}, "name": "4", "caption_text": "Figure 4 Precision by Named Entity Class", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 406.0, "y1": 788.0, "x1": 111.0, "y2": 997.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 394.19835408528644, "y1": 305.49596150716144, "x1": 140.8333354526096, "y2": 315.49996270073785}, "name": "7", "caption_text": "Figure 7 Summaries Recall and Precision", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 410.0, "y1": 126.0, "x1": 100.0, "y2": 288.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.1349385579427, "y1": 757.9125298394097, "x1": 100.00034968058267, "y2": 863.9994303385416}, "name": "8", "caption_text": "Figure 8 Utility Score Comparison In Figure 8 a random extraction system is expected to get a score of 1 averaged across an infinite amount of runs. The average sentence compression factor for the summariser was 42%, exactly the same as the human judges\u2019 results. The selected emails had an average length of 14 sentences, varying from 7 to 27 sentences.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 408.0, "y1": 552.0, "x1": 101.0, "y2": 742.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/16dd426a90879d26ba77b4b8050d358e7ad69e41/C04-1143.pdf", "dpi": 100}