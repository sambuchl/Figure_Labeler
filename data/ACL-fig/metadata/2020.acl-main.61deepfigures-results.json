{"raw_detected_boxes": [[{"x2": 728.0, "y1": 311.0, "x1": 427.0, "y2": 437.0}], [], [], [{"x2": 724.0, "y1": 89.0, "x1": 107.0, "y2": 343.0}], [], [{"x2": 721.0, "y1": 86.0, "x1": 106.0, "y2": 232.0}], [{"x2": 728.0, "y1": 86.0, "x1": 102.0, "y2": 189.0}, {"x2": 384.0, "y1": 297.0, "x1": 119.0, "y2": 464.0}, {"x2": 726.0, "y1": 299.0, "x1": 432.0, "y2": 370.0}], [{"x2": 724.0, "y1": 86.0, "x1": 111.0, "y2": 364.0}, {"x2": 389.0, "y1": 444.0, "x1": 114.0, "y2": 571.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5465698242188, "y1": 328.9865417480469, "x1": 307.2760009765625, "y2": 358.89898681640625}, "imageText": ["wealthy", "Jackie", "was", "a", "\u2026", "Response", "Document", "Jackie", "can", "afford", "best", "treatment.", "Fans", "will", "pray", "for", "him.", "Memory", "Jackie", "was", "a", "renowned", "actor", "and", "starred", "many", "films,", "so", "he", "had", "many", "fans.", "He\u2019s", "generous", "and", "wealthy.", "Context", "But,", "he\u2019s", "struggling", "with", "diseases", "now."], "regionBoundary": {"x2": 525.0, "y1": 224.8900146484375, "x1": 308.0, "y2": 314.8900146484375}, "caption": "Figure 1: A motivating example of constructing a response-anticipated document memory for response generation. Details are provided in the introduction.", "page": 0}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5400390625, "y1": 180.34255981445312, "x1": 71.69100189208984, "y2": 186.34503173828125}, "imageText": ["RAM", "T", "2.510", "1.43%", "7.74%", "4.46%", "0.26%", "0.49%", "1.04%", "0.08%", "0.15%", "9.900", "0.053", "0.290", "15.1", "RAM", "P", "2.353", "1.40%", "7.59%", "3.89%", "0.21%", "0.41%", "0.97%", "0.07%", "0.13%", "9.891", "0.049", "0.279", "14.9", "RAM", "T+Copy", "2.467", "1.41%", "7.64%", "6.14%", "0.32%", "0.61%", "0.65%", "0.04%", "0.08%", "9.813", "0.045", "0.265", "14.9", "RAM", "P+Copy", "2.342", "1.41%", "7.51%", "5.83%", "0.30%", "0.57%", "0.84%", "0.06%", "0.10%", "9.798", "0.045", "0.267", "14.6", "Human", "2.650", "3.13%", "8.31%", "2.89%", "0.45%", "0.78%", "0.44%", "0.09%", "0.14%", "10.445", "0.167", "0.670", "18.8", "Seq2Seq", "2.223", "1.09%", "7.34%", "1.20%", "0.05%", "0.10%", "0.89%", "0.05%", "0.09%", "9.745", "0.023", "0.174", "15.9", "MemNet", "2.185", "1.10%", "7.31%", "1.25%", "0.06%", "0.12%", "0.91%", "0.05%", "0.10%", "9.821", "0.035", "0.226", "15.5", "GLKS", "2.413", "1.34%", "7.61%", "2.47%", "0.13%", "0.24%", "0.84%", "0.05%", "0.10%", "9.715", "0.034", "0.213", "15.3", "CMR", "2.238", "1.38%", "7.46%", "3.39%", "0.20%", "0.38%", "0.91%", "0.05%", "0.10%", "9.887", "0.052", "0.283", "15.2", "CMR+Copy", "2.155", "1.41%", "7.39%", "5.37%", "0.28%", "0.54%", "0.92%", "0.06%", "0.11%", "9.798", "0.044", "0.266", "14.4", "Appropriateness", "Grounding", "Informativeness", "NIST", "BLEU", "Meteor", "P", "R", "F1", "PGT", "RGT", "F1GT", "Ent4", "Dist1", "Dist2", "Len"], "regionBoundary": {"x2": 523.0, "y1": 63.8900146484375, "x1": 75.0, "y2": 167.8900146484375}, "caption": "Table 1: Automatic evaluation results on all competing methods. Len denotes the length of the generated responses.", "page": 5}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.2002563476562, "y1": 278.7735290527344, "x1": 306.9670104980469, "y2": 308.68603515625}, "imageText": ["CMR", "0.482", "0.356", "0.571", "0.420", "RAM", "T", "Soft", "0.745", "0.520", "0.867", "0.616", "RAM", "P", "Soft", "0.518", "0.441", "0.634", "0.493", "Top10", "tokens", "Top20", "tokens", "Emb-M", "Emb-B", "Emb-M", "Emb-B"], "regionBoundary": {"x2": 525.0, "y1": 213.8900146484375, "x1": 308.0, "y2": 266.8900146484375}, "caption": "Table 4: Similarity between important document tokens picked by gold responses and the accumulated attention weights in the models.", "page": 6}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5472412109375, "y1": 149.25955200195312, "x1": 71.69100189208984, "y2": 191.1270751953125}, "imageText": ["RAM", "T", "2.510", "1.43%", "7.74%", "4.46%", "0.26%", "0.49%", "1.04%", "0.08%", "0.15%", "9.900", "0.053", "0.290", "15.1", "RAM", "P", "2.353", "1.40%", "7.59%", "3.89%", "0.21%", "0.41%", "0.97%", "0.07%", "0.13%", "9.891", "0.049", "0.279", "14.9", "RAM", "T", "(Teacher)", "2.539", "1.43%", "7.85%", "4.47%", "0.26%", "0.49%", "1.05%", "0.08%", "0.15%", "9.904", "0.053", "0.290", "15.1", "RAM", "P", "(Teacher)", "2.551", "1.47%", "7.88%", "4.56%", "0.27%", "0.50%", "0.99%", "0.08%", "0.16%", "9.900", "0.053", "0.287", "15.1", "RAM", "T", "Binary", "2.560", "1.63%", "7.91%", "3.75%", "0.21%", "0.40%", "0.87%", "0.07%", "0.12%", "9.890", "0.052", "0.283", "15.1", "RAM", "P", "Binary", "2.403", "1.51%", "7.63%", "3.55%", "0.18%", "0.38%", "0.85%", "0.07%", "0.12%", "9.887", "0.046", "0.274", "14.6", "Appropriateness", "Grounding", "Informativeness", "NIST", "BLEU", "Meteor", "P", "R", "F1", "PGT", "RGT", "F1GT", "Ent4", "Dist1", "Dist2", "Len"], "regionBoundary": {"x2": 525.0, "y1": 63.8900146484375, "x1": 73.0, "y2": 136.8900146484375}, "caption": "Table 2: Performance comparison on our model variants. Line1&2: our models trained by the full teacher-student framework. Line3&4: our models trained with the teacher model only. Line5&6: our models with binary weight matrices. Bold values are the best results among the first four lines; underlines mark the best ones among the first two and last two lines.", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 251.02708435058594, "y1": 346.12054443359375, "x1": 110.93299865722656, "y2": 352.1230163574219}, "imageText": ["Seq2Seq", "1.902", "1.564", "2.040", "MemNet", "1.872", "1.574", "2.105", "GLKS", "2.073", "1.593", "2.071", "CMR", "2.188", "1.678", "2.219", "CMR+Copy", "2.063", "1.773", "2.075", "RAM", "T", "2.259", "1.714", "2.312", "RAM", "P", "2.213", "1.682", "2.231", "RAM", "T+Copy", "2.109", "1.861", "2.240", "RAM", "P+Copy", "2.114", "1.775", "2.115", "H-Appr", "H-Ground", "H-Info", "Human", "2.986", "2.521", "3.007"], "regionBoundary": {"x2": 277.0, "y1": 213.8900146484375, "x1": 85.0, "y2": 333.8900146484375}, "caption": "Table 3: Human annotation results.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 292.013427734375, "y1": 431.5185546875, "x1": 71.5320053100586, "y2": 461.4320068359375}, "imageText": ["RAM", "T", "CMR", "ts", "ei", "gh", "on", "W", "en", "ti", "A", "tt", "0.30", "0.25", "0.20", "0.15", "0.10", "0.05", "0.00", "f", "<P", "AD", ">", "to", ",", "itio", "n", "sea", "son", "o", "com", "pet", "er", "<U", "NK", ">", "fa", "lea", "gu", "e", "bo", "lto", "n", "the", "clu", "bs", "nu", "m", "pre", "mi"], "regionBoundary": {"x2": 280.0, "y1": 319.8900146484375, "x1": 83.96188354492188, "y2": 413.20074462890625}, "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5472412109375, "y1": 274.0415344238281, "x1": 72.0, "y2": 291.9990234375}, "imageText": ["Document", "fa", "premier", "league", "was", "the", "fourth", "season", "of", "the", "competition,", "since", "its", "formation", "in", "1992.", "due", "to", "the", "decision", "to", "reduce", "the", "number", "of", "clubs", "in", "the", "premier", "league", "from", "22", "to", "20,", "only", "two", "clubs", "were", "promoted", "instead", "of", "the", "usual", "three", ",", "middlesbrough", "and", "bolton", "wanderers.", "darko", "milicic.", "darko", "milicic", "(", "serbian", "cyrillic.", "serbian", "pronunciation.", "born", "june", "20,", "1985)", "is", "a", "serbian", "former", "professional", "basketball", "player", ".", "he", "is", "2.13", "m", "(", "7", "ft", "0", "in", ")", ",", "and", "played", "center", ".", "Context", "at", "least", "we", "quali\ufb01ed", "for", "a", "european", "competition", "we\u2019re", "capable", "of", "winning", "now", "that", "darko", "milicic,", "who", "was", "drafted", "2nd", "overall", "in", "the", "2003.nba", "draft", "is", "currently", "an", "apple", "farmer", "in", "serbia.", "Seq2Seq", "i", "do", "n\u2019t", "really", "need", "to", "take", "a", "time", "and", "a", "bit", "more", "and", "i", "think", "he", "\u2019s", "saying", "it", "was", "n\u2019t", "in", "an", "accident", ".", "he", "is", "so", "happy", "when", "i", "\u2019m", "not", "in", "0ame", "universe", "as", "the", "\ufb01rst", "time.", "MemNet", "i", "am", "not", "saying", "i", "was", "a", "kid", ".", "you", "know", "what", "?", "is", "there", "anything", "in", "a", "book", "?", "GLKS", "i", "have", "a", "pretty", "good", "chance", "of", "being", "the", "\ufb01rst", "person", "i", "know", "!", "i", "think", "a", "lot", "of", "people", "are", "still", "able", "to", "get", "in", "a", "hour", "CMR", "well", ",", "at", "what", "point", "do", "you", "think", "about", "how", "they", "are", "getting", "play", "for", "?", "i", "remember", "my", "comment", "on", "my", "post.", "and", "i", "am", "not", "sure", "why", "but", "my", "point", "is", "that", "he", "has", "the", "best", "score", "that", "will", "always", "get", "a", "good", "CMR+Copy", "they", "are", ",", "but", "not", "the", "same", "as", "the", "\ufb01rst", "one", ".", "he", "also", "played", "the", "same", "game,", "is", "there", "title", "to", "be", "a", "team", "RAM", "T", "i", "think", "we", "have", "num", "teams", "playing", "the", "premier", "league", "team.", "in", "my", "opi-", "nion", "he", "was", "not", "a", "good", "player,", "but", "the", "united", "kingdom", "was", "in", "the", "europa", "i", "love", "him", "the", "next", "time", "i", "play", "for", "num", "years,", "so", "that", "is", "probably", "the", "only", "option", "i", "understand.", "RAM", "T", "+Copy", "they", "are", "the", "best", "player", "in", "the", "world.", "he", "also", "played", "the", "second", "one,", "but", "that", "doesn\u2019t", "mean", "it", "was", "num", "years", "ago.", "Case", "1", "Case", "2"], "regionBoundary": {"x2": 522.0, "y1": 63.8900146484375, "x1": 80.0, "y2": 261.8900146484375}, "caption": "Figure 3: Test samples with generated responses of all models. A colored word in the responses indicate that it has similar words with documents or contexts, which are marked in the same color.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 526.7926025390625, "y1": 266.6295471191406, "x1": 71.64099884033203, "y2": 308.498046875}, "imageText": ["\u2299", "G\u0302", "transpose\u2297", "\u2297", "\u2297\u2297", "G", "G", "response-anticipated", "weight", "matrix", "y", "ea", "lth", "w", "as", "a", "\u2026", "\u2026", "w", "ie", "Ja", "ck", "a", "\u2026", "\u2026", "wealthy", "Student", "Network", "Jackie", "was", "or", "Decoder", "D", "RTI", "RPI", "R", "response-aware", "weight", "matrix", "y", "ea", "lth", "w", "as", "a", "\u2026", "\u2026", "w", "ie", "Ja", "ck", "Jackie", "was", "a", "\u2026", "\u2026", "wealthy", "1", "1", "1", "1", "1", "1", "r|R|", "D\u22a4", "R", "Memory", "\u2026", "Jackie", "was", "a", "\u2026", "\u2026", "wealthy", "y", "ea", "lth", "w", "as", "a", "\u2026", "\u2026", "w", "ie", "Ja", "ck", "Jackie", "was", "a", "\u2026", "\u2026", "wealthy", "response-aware", "weight", "matrix", "se", "ns", "po", "Encodert", "ra", "Response", "Jackie", "can", "afford", "best", "treatment.", "Fans", "will", "pray", "for", "him.", "R\u22a4", "D", "Encoder", "Document", "Jackie", "was", "a", "renowned", "actor", "and", "starred", "many", "films,", "so", "he", "had", "many", "fans.", "He\u2019s", "generous", "and", "wealthy.", "Context", "But,", "he\u2019s", "struggling", "with", "diseases", "now.", "Self", "Attention", "Cross", "Attention", "Encoder"], "regionBoundary": {"x2": 523.0, "y1": 64.8900146484375, "x1": 73.0, "y2": 251.8900146484375}, "caption": "Figure 2: The architecture of our model. Blocks and lines in gray color compose the base model. Blue and gray parts compose the teacher model, while purple parts compose the student model. All components work for training, while only the student model and the decoder works for inference. In the response-aware/anticipated weight matrix, darker grids indicate higher weights. ( \u2297 : matrix multiplication; \u2299 : element-wise matrix multiplication.)", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 456.92575242784284, "x1": 426.772223578559, "y2": 498.47081502278644}, "name": "1", "caption_text": "Figure 1: A motivating example of constructing a response-anticipated document memory for response generation. Details are provided in the introduction.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 294.0, "x1": 427.0, "y2": 437.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 731.6563924153645, "y1": 370.31881544325086, "x1": 99.50138727823892, "y2": 428.4695095486111}, "name": "2", "caption_text": "Figure 2: The architecture of our model. Blocks and lines in gray color compose the base model. Blue and gray parts compose the teacher model, while purple parts compose the student model. All components work for training, while only the student model and the decoder works for inference. In the response-aware/anticipated weight matrix, darker grids indicate higher weights. ( \u2297 : matrix multiplication; \u2299 : element-wise matrix multiplication.)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 89.0, "x1": 101.0, "y2": 350.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9167209201389, "y1": 250.47577752007376, "x1": 99.57083596123589, "y2": 258.81254408094617}, "name": "1", "caption_text": "Table 1: Automatic evaluation results on all competing methods. Len denotes the length of the generated responses.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 86.0, "x1": 104.0, "y2": 234.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 207.304933336046, "x1": 99.57083596123589, "y2": 265.4542711046007}, "name": "2", "caption_text": "Table 2: Performance comparison on our model variants. Line1&2: our models trained by the full teacher-student framework. Line3&4: our models trained with the teacher model only. Line5&6: our models with binary weight matrices. Bold values are the best results among the first four lines; underlines mark the best ones among the first two and last two lines.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 86.0, "x1": 100.0, "y2": 206.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 348.6487282647027, "y1": 480.7229783799913, "x1": 154.073609246148, "y2": 489.0597449408637}, "name": "3", "caption_text": "Table 3: Human annotation results.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 385.0, "y1": 297.0, "x1": 118.0, "y2": 481.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 387.18545701768664, "x1": 426.3430701361762, "y2": 428.73060438368054}, "name": "4", "caption_text": "Table 4: Similarity between important document tokens picked by gold responses and the accumulated attention weights in the models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 297.0, "x1": 426.0, "y2": 387.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 380.61324225531683, "x1": 100.0, "y2": 405.55419921875}, "name": "3", "caption_text": "Figure 3: Test samples with generated responses of all models. A colored word in the responses indicate that it has similar words with documents or contexts, which are marked in the same color.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 86.0, "x1": 100.0, "y2": 381.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.57420518663196, "y1": 599.3313259548611, "x1": 99.35000737508138, "y2": 640.8777872721354}, "name": "4", "caption_text": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 389.0, "y1": 444.0, "x1": 114.0, "y2": 574.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/c21d17308dfdd05bb4498abff56a5909132a519d/2020.acl-main.61.pdf", "dpi": 100}