{"raw_detected_boxes": [[], [], [{"x2": 729.0, "y1": 90.0, "x1": 444.0, "y2": 342.0}], [{"x2": 323.0, "y1": 79.0, "x1": 187.0, "y2": 287.0}], [], [], [{"x2": 657.0, "y1": 76.0, "x1": 194.0, "y2": 189.0}], [{"x2": 688.0, "y1": 76.0, "x1": 498.0, "y2": 173.0}, {"x2": 406.0, "y1": 81.0, "x1": 104.0, "y2": 366.0}, {"x2": 743.0, "y1": 299.0, "x1": 440.0, "y2": 370.0}, {"x2": 406.0, "y1": 399.0, "x1": 104.0, "y2": 509.0}], [{"x2": 730.0, "y1": 78.0, "x1": 123.0, "y2": 164.0}, {"x2": 734.0, "y1": 245.0, "x1": 450.0, "y2": 446.0}], [{"x2": 388.0, "y1": 78.0, "x1": 115.0, "y2": 276.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 515.5374755859375, "y1": 369.5955810546875, "x1": 337.664794921875, "y2": 376.1683044433594}, "imageText": ["Extras", "This", "single-disc", "DVD", "comes", "packed", "in", "a", "black", "amaray", "case", "with", "a", "glossy", "slipcover.", "Cover", "art", "has", "clearly", "been", "designed", "to", "appeal", "the", "Twilight", "crowd", "...", "Finally,", "we\u2019ve", "got", "a", "deleted", "scenes", "reel.", "Most", "of", "the", "excised", "scenes", "are", "actually", "pretty", "interesting.", "Audio", "Audio", "choices", "are", "English,", "Spanish", "and", "French", "Dolby", "Digital", "5.1", "...", "Bass", "is", "still", "robust", "and", "powerful,", "giving", "weight", "to", "just", "about", "any", "scene", "\u2013", "most", "notably", "the", "\ufb01lm\u2019s", "exciting", "\ufb01nal", "\ufb01ght.", "Fans", "should", "be", "pleased", "with", "the", "presentation."], "regionBoundary": {"x2": 542.0, "y1": 228.0, "x1": 313.0, "y2": 356.0}, "caption": "Table 1: An excerpt from a DVD review.", "page": 0}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 540.0009765625, "y1": 151.35255432128906, "x1": 72.00080108642578, "y2": 185.0233154296875}, "imageText": ["Amazon", "35", "24", "12,684", "214", "11.7", "Yelp", "48", "48", "33,015", "178", "11.2", "Train", "Test", "Words", "Sents", "Multi-aspect", "sentiment", "600", "65", "\u2014", "1,027", "20.5", "Multi-aspect", "summarization", "Unlabeled", "Avg.", "Size", "Task", "Labeled"], "regionBoundary": {"x2": 473.0, "y1": 55.0, "x1": 139.0, "y2": 138.0}, "caption": "Table 2: This table summarizes the size of each corpus. In each case, the unlabeled texts of both labeled and unlabeled documents are used for training the content model, while only the labeled training corpus is used to train the task model. Note that the entire data set for the multi-aspect sentiment analysis task is labeled.", "page": 6}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 298.8038024902344, "y1": 216.1695098876953, "x1": 72.00080108642578, "y2": 276.9383544921875}, "imageText": ["18.9", "20.8", "22.6", "15.1", "20", "Percentage", "of", "unlabeled", "data", "F", "1", "be", "l", "ti-", "la", "M", "ul", "0%", "12.5%", "25%", "25", "15", "10"], "regionBoundary": {"x2": 284.0, "y1": 55.20765686035156, "x1": 88.99862670898438, "y2": 196.860107421875}, "caption": "Figure 5: Results on the Amazon corpus using half of the annotated training documents. The content model is trained with 0%, 12.5%, and 25% of additional unlabeled data.7 The dashed horizontal line represents NoCM with the complete annotated set.", "page": 9}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 540.006103515625, "y1": 265.9775695800781, "x1": 313.20074462890625, "y2": 369.0303039550781}, "imageText": ["si", "(w2i", "=", "pleased)", "\u2227", "(Ti", "=", "3)", "w2i", "=", "pleased...", "Ti\u22121", "Ti+1", "w1i", "w", "m", "iw", "2", "i", ".", ".", ".", "Ti", "y1i", "y", "m", "iy", "2", "i", ".", ".", "."], "regionBoundary": {"x2": 525.0, "y1": 63.0, "x1": 320.0, "y2": 250.0}, "caption": "Figure 1: A graphical depiction of our model for sequence labeling tasks. The Ti variable represents the content model topic for the ith sentence si. The words of si, (w1i , . . . , w m i ), each have a task label (y1i , . . . , y m i ). Note that each token label has an undirected edge to a factor containing the words of the current sentence, si as well as the topic of the current sentence Ti.", "page": 2}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 540.0008544921875, "y1": 279.56854248046875, "x1": 313.2008056640625, "y2": 326.7882995605469}, "imageText": ["F1", "F2", "Prec.", "Recall", "NoCM", "28.8%", "34.8%", "22.4%", "40.3%", "IndepCM", "37.9%", "43.7%", "31.1%\u2020*", "48.6%\u2020*", "JointCM", "39.2%", "44.4%", "32.9%\u2020*", "48.6%\u2020"], "regionBoundary": {"x2": 537.0, "y1": 215.0, "x1": 316.0, "y2": 266.0}, "caption": "Table 4: Results for multi-aspect summarization on the Yelp corpus. Marked precision and recall are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 298.80096435546875, "y1": 397.23956298828125, "x1": 72.00080108642578, "y2": 471.5583190917969}, "imageText": ["(c)", "Sample", "labeled", "text", "from", "the", "Yelp", "multi-aspect", "summarization", "corpus", "[A", "The", "place", "is", "a", "pretty", "good", "size]", "and", "[S", "the", "staff", "is", "super", "friendly].", "[O", "This", "place", "rocks!]", "[V", "Pricey,", "but", "worth", "it]", ".", "A", "=", "Atmosphere", "V", "=", "Value", "S", "=", "Service", "O", "=", "Overall", "[F", "All", "the", "ingredients", "are", "fresh],", "[V", "the", "sizes", "are", "huge]", "and", "[V", "the", "price", "is", "cheap].", "F", "=", "Food", "(b)", "Sample", "labeled", "text", "from", "the", "Amazon", "multi-aspect", "summa-", "rization", "corpus", "[I", "Plenty", "of", "inputs],", "including", "[I", "2", "HDMI", "ports],", "which", "is", "[E", "unheard", "of", "in", "this", "price", "range].", "I", "bought", "this", "TV", "because", "the", "[V", "overall", "picture", "quality", "is", "good]", "and", "it's", "[A", "unbelievably", "thin].", "[R", "Big", "multifunction", "remote]", "with", "[R", "easy-to-", "read", "keys].", "The", "on-screen", "menu", "is", "[M", "easy", "to", "use]", "and", "you", "[M", "can", "rename", "the", "inputs]", "to", "one", "of", "several", "options", "(DVD,", "Cable,", "etc.).", "R", "=", "Remote", "M", "=", "Menu", "I", "=", "Inputs", "E", "=", "Economy", "V", "=", "Video", "S", "=", "Sound", "A", "=", "Appearance", "F", "=", "Features", "(a)", "Sample", "labeled", "text", "from", "the", "multi-aspect", "sentiment", "corpus", "E", "The", "deleted", "scenes", "were", "quite", "lengthy,", "but", "only", "shelled", "out", "a", "few", "extra", "laughs.", "(4)", "A", "Bass", "is", "still", "robust", "and", "powerful.", "Fans", "should", "be", "pleased", "with", "this", "presentation.", "(8)", "V", "Regardless,", "this", "is", "a", "fairly", "solid", "presentation,", "but", "it's", "obvious", "there", "was", "room", "for", "improvement.", "(7)", "M", "This", "collection", "certainly", "offers", "some", "nostalgic", "fun,", "but", "at", "the", "end", "of", "the", "day,", "the", "shows", "themselves,", "for", "the", "most", "part,", "just", "don't", "hold", "up.", "(5)", "M", "=", "Movie", "V", "=", "Video", "A", "=", "Audio", "E", "=", "Extras"], "regionBoundary": {"x2": 304.2574157714844, "y1": 57.0, "x1": 72.00080108642578, "y2": 380.081298828125}, "caption": "Figure 3: Excerpts from the three corpora with the corresponding labels. Note that sentences from the multi-aspect summarization corpora generally focus on only one or two aspects. The multi-aspect sentiment corpus has labels per paragraph rather than per sentence.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 540.0013427734375, "y1": 137.8035430908203, "x1": 313.2007751464844, "y2": 198.57232666015625}, "imageText": ["L1", "L2", "NoCM", "1.37", "3.15", "IndepCM", "1.28\u2020*", "2.80\u2020*", "JointCM", "1.25\u2020", "2.65\u2020*", "Gold", "1.18\u2020*", "2.48\u2020*"], "regionBoundary": {"x2": 495.0, "y1": 55.0, "x1": 358.0, "y2": 124.0}, "caption": "Table 3: The error rate on the multi-aspect sentiment ranking. We report mean L1 and L2 between system prediction and true values over all aspects. Marked results are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 298.8032531738281, "y1": 226.1315460205078, "x1": 72.00079345703125, "y2": 368.19635009765625}, "imageText": ["Content", "Structure", "Text", "Task", "Labels", "Task", "Parameters", "Content", "Parameters", "\u03c6", "\u03b8", "y\u2217", "T", "s"], "regionBoundary": {"x2": 236.82301330566406, "y1": 55.0, "x1": 133.0, "y2": 206.72747802734375}, "caption": "Figure 2: A graphical depiction of the generative process for a labeled document at training time (See Section 3); shaded nodes indicate variables which are observed at training time. First the latent underlying content structure T is drawn. Then, the document text s is drawn conditioned on the content structure utilizing content parameters \u03b8. Finally, the observed task labels for the document are modeled given s and T using the task parameters \u03c6. Note that the arrows for the task labels are undirected since they are modeled discriminatively.", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 540.0008544921875, "y1": 339.3295593261719, "x1": 313.2008056640625, "y2": 373.00128173828125}, "imageText": ["be", "l", "F", "1", "Percentage", "of", "unlabeled", "data", "22.8", "26.0", "28.2", "ti-", "la", "M", "ul", "0%", "50%", "100%", "30", "20", "10"], "regionBoundary": {"x2": 529.0, "y1": 175.93289184570312, "x1": 330.2780456542969, "y2": 319.9866027832031}, "caption": "Figure 4: Results on the Amazon corpus using the complete annotated set with varying amounts of additional unlabeled data.7", "page": 8}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 540.0025024414062, "y1": 131.59852600097656, "x1": 72.00080108642578, "y2": 151.72027587890625}, "imageText": ["NoCM", "18.9%", "18.0%", "20.4%", "17.5%", "35.1%", "33.6%", "38.1%", "32.6%", "43.8%", "IndepCM", "24.5%", "23.8%", "25.8%\u2020*", "23.3%\u2020*", "43.0%", "41.8%", "45.3%\u2020*", "40.9%\u2020*", "47.4%\u2020*", "JointCM", "28.2%", "31.3%", "24.3%\u2020", "33.7%\u2020*", "47.8%", "53.0%", "41.2%\u2020", "57.1%\u2020*", "47.6%\u2020*", "Multi-label", "Binary", "labels", "F1", "F2", "Prec.", "Recall", "F1", "F2", "Prec.", "Recall", "ROUGE"], "regionBoundary": {"x2": 526.0, "y1": 56.0, "x1": 86.0, "y2": 118.0}, "caption": "Table 5: Results for multi-aspect summarization on the Amazon corpus. Marked ROUGE, precision, and recall are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 750.0084771050347, "y1": 369.41329108344183, "x1": 435.0010342068142, "y2": 512.5420888264974}, "name": "1", "caption_text": "Figure 1: A graphical depiction of our model for sequence labeling tasks. The Ti variable represents the content model topic for the ith sentence si. The words of si, (w1i , . . . , w m i ), each have a task label (y1i , . . . , y m i ). Note that each token label has an undirected edge to a factor containing the words of the current sentence, si as well as the topic of the current sentence Ti.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 90.0, "x1": 444.0, "y2": 345.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.0045182969835, "y1": 314.0715916951497, "x1": 100.00110202365451, "y2": 511.3838195800781}, "name": "2", "caption_text": "Figure 2: A graphical depiction of the generative process for a labeled document at training time (See Section 3); shaded nodes indicate variables which are observed at training time. First the latent underlying content structure T is drawn. Then, the document text s is drawn conditioned on the content structure utilizing content parameters \u03b8. Finally, the observed task labels for the document are modeled given s and T using the task parameters \u03c6. Note that the arrows for the task labels are undirected since they are modeled discriminatively.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 329.0, "y1": 78.0, "x1": 187.0, "y2": 287.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0013563368055, "y1": 210.21188100179035, "x1": 100.0011126200358, "y2": 256.97682698567706}, "name": "2", "caption_text": "Table 2: This table summarizes the size of each corpus. In each case, the unlabeled texts of both labeled and unlabeled documents are used for training the content model, while only the labeled training corpus is used to train the task model. Note that the entire data set for the multi-aspect sentiment analysis task is labeled.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 657.0, "y1": 76.0, "x1": 193.0, "y2": 191.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0018649631077, "y1": 191.39380984836154, "x1": 435.0010765923394, "y2": 275.7948981391059}, "name": "3", "caption_text": "Table 3: The error rate on the multi-aspect sentiment ranking. We report mean L1 and L2 between system prediction and true values over all aspects. Marked results are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 688.0, "y1": 76.0, "x1": 497.0, "y2": 173.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0011867947048, "y1": 388.2896423339844, "x1": 435.00111897786456, "y2": 453.8726382785373}, "name": "4", "caption_text": "Table 4: Results for multi-aspect summarization on the Yelp corpus. Marked precision and recall are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 746.0, "y1": 299.0, "x1": 439.0, "y2": 387.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.00133938259546, "y1": 551.7216152615017, "x1": 100.0011126200358, "y2": 654.9421098497179}, "name": "3", "caption_text": "Figure 3: Excerpts from the three corpora with the corresponding labels. Note that sentences from the multi-aspect summarization corpora generally focus on only one or two aspects. The multi-aspect sentiment corpus has labels per paragraph rather than per sentence.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 422.0, "y1": 382.0, "x1": 100.0, "y2": 526.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0034756130642, "y1": 182.7757305569119, "x1": 100.0011126200358, "y2": 210.72260538736978}, "name": "5", "caption_text": "Table 5: Results for multi-aspect summarization on the Amazon corpus. Marked ROUGE, precision, and recall are statistically significant with p < 0.05: * over the previous model and \u2020 over NoCM.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 76.0, "x1": 119.0, "y2": 164.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0011867947048, "y1": 471.29105461968317, "x1": 435.00111897786456, "y2": 518.0573357476128}, "name": "4", "caption_text": "Figure 4: Results on the Amazon corpus using the complete annotated set with varying amounts of additional unlabeled data.7", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 734.0, "y1": 245.0, "x1": 450.0, "y2": 447.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.00528123643664, "y1": 300.2354303995768, "x1": 100.0011126200358, "y2": 384.6366034613715}, "name": "5", "caption_text": "Figure 5: Results on the Amazon corpus using half of the annotated training documents. The content model is trained with 0%, 12.5%, and 25% of additional unlabeled data.7 The dashed horizontal line represents NoCM with the complete annotated set.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 393.0, "y1": 77.0, "x1": 115.0, "y2": 276.0}, "page": 9, "dpi": 0}], "error": null, "pdf": "/work/host-output/25313fd001d8fc7000e1fcd379de92a13aa5cf3a/D10-1037.pdf", "dpi": 100}