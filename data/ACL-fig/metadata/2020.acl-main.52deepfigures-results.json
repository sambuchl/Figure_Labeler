{"raw_detected_boxes": [[{"x2": 727.0, "y1": 369.0, "x1": 430.0, "y2": 629.0}], [], [{"x2": 366.0, "y1": 144.0, "x1": 133.0, "y2": 372.0}], [], [{"x2": 379.0, "y1": 791.0, "x1": 122.0, "y2": 941.0}], [{"x2": 727.0, "y1": 92.0, "x1": 106.0, "y2": 237.0}, {"x2": 717.0, "y1": 317.0, "x1": 113.0, "y2": 421.0}], [{"x2": 726.0, "y1": 93.0, "x1": 104.0, "y2": 612.0}, {"x2": 730.0, "y1": 720.0, "x1": 426.0, "y2": 815.0}], [{"x2": 729.0, "y1": 92.0, "x1": 428.0, "y2": 154.0}, {"x2": 400.0, "y1": 810.0, "x1": 100.0, "y2": 990.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2899169921875, "y1": 468.2905578613281, "x1": 306.9670104980469, "y2": 546.02392578125}, "imageText": ["r", "[Happy]", "Haha,", "you", "too.", "4", "q", "Happy", "birthday,", "Xinxin.", "May", "you", "be", "more", "beautiful,", "\ufb01nd", "a", "good", "person", "and", "get", "married", "soon!", "(Happy)", "3", "q", "We", "should", "study", "hard.", "(Neural)", "r", "[Disgust]", "You", "are", "so", "bad.", "2", "q", "So", "pets", "live", "better", "than", "humans", "now...", "(Sad)", "r1", "[Disgust]", "You", "are", "so", "bad.", "r2", "[Happy]", "Haha,", "you", "too.", "q", "It", "is", "very", "pleasant", "to", "have", "a", "cup", "of", "black", "tea", "with", "sugar", "on", "a", "cold", "day.", "(Happy)", "r1", "[Neural]", "It", "starts", "to", "cool", "down", "today.", "r2", "[Like]", "I", "will", "try,", "thanks", "for", "your", "advice.", "r3", "[Sad]", "I", "am", "frozen", "to", "death", "...", "r4", "[Disgust]", "Winner", "is", "the", "worst", "season.", "r5", "[Angry]", "You", "know", "nothing!", "r6", "[Happy]", "I", "really", "like", "to", "drink", "black", "tea.", "1"], "regionBoundary": {"x2": 524.0, "y1": 261.8900146484375, "x1": 309.0, "y2": 455.8900146484375}, "caption": "Table 1: Examples of emotion-controllable response generation (response emotions are denoted in brackets). Example 1 is one query and 6 emotional responses. Example 2 and 3 have different queries, but the responses generated with emotion \u201cDisgust\u201d are the same. Similar to Example 2 and 4 with emotion \u201cHappy\u201d. The emotions of queries are marked in parentheses.", "page": 0}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 492.0467224121094, "y1": 318.1265563964844, "x1": 105.18900299072266, "y2": 324.1290283203125}, "imageText": ["Method", "Like", "Sad", "Disgust", "Angry", "Happy", "OverallCon.", "Emo.", "Con.", "Emo.", "Con.", "Emo.", "Con.", "Emo.", "Con.", "Emo.", "Con.", "Emo.", "S2S-Attn", "1.295", "0.435", "1.125", "0.120", "1.160", "0.115", "1.255", "0.045", "1.155", "0.305", "1.198", "0.204", "EmoEmb", "1.290", "0.630", "0.990", "0.225", "1.125", "0.295", "1.220", "0.220", "1.275", "0.400", "1.180", "0.354", "EmoDS", "1.375", "0.685", "1.210", "0.395", "1.200", "0.340", "1.225", "0.345", "1.260", "0.535", "1.254", "0.460", "ECM", "1.375", "0.690", "1.205", "0.425", "1.205", "0.325", "1.240", "0.385", "1.255", "0.590", "1.256", "0.483", "CDL", "1.395", "0.700", "1.245", "0.565", "1.235", "0.490", "1.250", "0.525", "1.305", "0.630", "1.286", "0.582"], "regionBoundary": {"x2": 516.0, "y1": 227.8900146484375, "x1": 81.0, "y2": 305.8900146484375}, "caption": "Table 4: Human evaluation results. \u201cCon.\u201d and \u201cEmo.\u201d denote content and emotion, respectively.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 526.7926025390625, "y1": 182.88351440429688, "x1": 71.69100189208984, "y2": 212.7960205078125}, "imageText": ["Method", "Embedding", "Metrics", "Diversity", "BLEU", "Scores", "Emotion", "ExpressionAvg.", "Ext.", "Gre.", "Coh.", "Dist-1", "Dist-2", "BLEU-1", "BLEU-2", "Emo-acc.", "Emo-word.", "S2S-Attn", "0.497", "0.352", "0.328", "0.582", "0.035", "0.119", "0.0424", "0.0073", "0.244", "0.285", "EmoEmb", "0.532", "0.381", "0.356", "0.594", "0.040", "0.133", "0.0722", "0.0164", "0.693", "0.436", "EmoDS", "0.623", "0.427", "0.403", "0.603", "0.050", "0.174", "0.0976", "0.0282", "0.746", "0.527", "ECM", "0.625", "0.433", "0.405", "0.607", "0.052", "0.177", "0.1023", "0.0332", "0.753", "0.562", "CDL-emo", "(ours)", "0.631", "0.451", "0.435", "0.615", "0.058", "0.193", "0.1162", "0.0342", "0.765", "0.583", "CDL-con", "(ours)", "0.628", "0.441", "0.417", "0.612", "0.055", "0.182", "0.1059", "0.0338", "0.758", "0.566", "CDL-DL", "(ours)", "0.635", "0.452", "0.431", "0.630", "0.062", "0.217", "0.1187", "0.0353", "0.794", "0.615", "CDL", "(ours)", "0.642", "0.457", "0.438", "0.635", "0.065", "0.221", "0.1254", "0.0370", "0.823", "0.620"], "regionBoundary": {"x2": 523.0, "y1": 65.8900146484375, "x1": 74.0, "y2": 170.8900146484375}, "caption": "Table 3: Automatic evaluation results for content and emotion measurements. The metrics Average, Extrema, Greedy, Coherence, Emotion-acc and Emotion-word are abbreviated as Avg., Ext., Gre., Coh., Emo-acc. and Emo-word., respectively.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 527.2001953125, "y1": 598.6765747070312, "x1": 306.9670104980469, "y2": 628.5889892578125}, "imageText": ["Method", "(%)", "2-1", "1-1", "0-1", "2-0", "1-0", "0-0", "S2S-Attn", "10.3", "7.2", "2.8", "36.4", "26.5", "16.8", "EmoEmb", "21.8", "12.6", "7.5", "24.6", "15.3", "18.2", "EmoDS", "28.7", "15.6", "4.0", "22.7", "13.5", "15.5", "ECM", "27.1", "12.7", "4.5", "23.5", "15.4", "16.8", "CDL", "32.5", "17.6", "4.1", "17.7", "12.8", "15.3"], "regionBoundary": {"x2": 526.0, "y1": 518.8900146484375, "x1": 307.0, "y2": 585.8900146484375}, "caption": "Table 6: The percentage of responses in human evaluation of Content-Emotion scores. 2-1 means content score is 2 and emotion score is 1.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5470581054688, "y1": 453.7025451660156, "x1": 71.69100189208984, "y2": 471.6610107421875}, "imageText": ["Disgust", "\u79cb\u5929\u7684\u666f\u8272\u5f88\u96be\u770b\u3002", "The", "autumn", "scenery", "is", "ugly.", "Angry", "\u4f60\u6709\u75c5\u5427\uff1f", "Are", "you", "insane?", "Happy", "\u54c8\u54c8\uff0c\u8981\u4e0d\u8981\u53bb\u79cb\u6e38\uff1f", "Haha,", "do", "you", "want", "to", "go", "to", "the", "autumn", "tour?", "Like", "\u79cb\u5929\u7684\u5929\u7a7a\u975e\u5e38\u7f8e\u4e3d\u3002", "The", "autumn", "sky", "is", "very", "beautiful.", "season.", "Sad", "\u6211\u5f88\u60f3\u5ff5\u8fc7\u53bb\u7684\u590f\u5929\u3002", "I", "miss", "the", "past", "summer", "very", "much.", "CDL", "\u6211\u6700\u559c\u6b22\u7684\u5b63\u8282\u5c31\u662f\u79cb", "Angry", "\u4f60\u600e\u4e48\u4e0d\u8bf4\u6211\u662f\u7231\uff1f", "Why", "don\u2019t", "you", "say", "that", "I", "love", "it?", "\u5929\u3002", "Happy", "\u54c8\u54c8\uff0c\u6211\u4e5f\u559c\u6b22\u3002", "Haha,", "I", "like", "it", "too.", "Autumn", "is", "my", "favorite", "ECM", "Like", "\u6211\u4e5f\u559c\u6b22\u79cb\u5929\u3002", "I", "also", "like", "autumn.", "Sad", "\u6211\u4e5f\u60f3\u5ff5\u79cb\u5929\u3002", "I", "also", "miss", "autumn.", "Disgust", "\u4f60\u592a\u8fc7\u5206\u5566\u3002", "You", "are", "too", "much.", "S2S-Attn", "\u6211\u4e5f\u5f88\u559c\u6b22\u3002", "I", "like", "it,", "too.", "CDL", "Like", "\u4f60\u662f\u4e0d\u662f\u5728\u5938\u6211\uff1f", "Are", "you", "praising", "me?", "Sad", "\u53ef\u60dc\u6211\u4e0d\u60f3\u505a\u3002", "Unfortunately,", "I", "do", "not", "want", "to", "be.", "Disgust", "\u542c\u8d77\u6765\u50cf\u5047\u8bdd\u3002", "It", "sounds", "like", "a", "lie.", "Angry", "\u6211\u4e00\u70b9\u4e5f\u6ca1\u89c9\u5f97\u3002", "I", "feel", "nothing", "at", "all.", "Happy", "\u8981\u5bf9\u751f\u6d3b\u5145\u6ee1\u5e0c\u671b\u3002", "Be", "hopeful", "about", "life.", "\u5584\u826f\u7684\u4eba\u8fd8\u662f\u5b58\u5728\u7684\u3002", "Happy", "\u54c8\u54c8\uff0c\u4f60\u4e5f\u662f\u3002", "Haha,", "you", "too.", "Kind", "people", "still", "exist.", "ECM", "Like", "\u662f\u7684\uff0c\u559c\u6b22\u5c31\u597d\u3002", "Yes,", "it", "is", "ok", "you", "like", "it.", "Sad", "\u662f\u554a\uff0c\u6211\u5f88\u65e0\u8f9c\u7684\u3002", "Yeah,", "I", "am", "innocent.", "Disgust", "\u4e0d\u662f\u4e0d\u662f\uff0c\u4e0d\u662f\u597d\u4eba\u3002", "No,", "no,", "not", "a", "good", "person.", "Angry", "\u4f60\u662f\u4ec0\u4e48\u610f\u601d\uff1f\uff1f\uff1f", "What", "do", "you", "mean???", "S2S-Attn", "\u6211\u4e0d\u505a\u597d\u4e8b\u3002", "I", "do", "not", "do", "good", "things.", "Angry", "\u4f60\u6839\u672c\u4e0d\u61c2\u751f\u6d3b\uff01", "You", "do", "not", "understand", "life", "at", "all!", "Happy", "\u5f00\u5fc3\u662f\u6700\u91cd\u8981\u7684\u3002", "Happiness", "is", "the", "most", "important.", "CDL", "Like", "\u5e0c\u671b\u6bcf\u5929\u90fd\u6709\u597d\u5fc3\u60c5\u3002", "Hope", "to", "have", "a", "good", "mood", "every", "day.", "and", "depends", "on", "your", "Sad", "\u6211\u89c9\u5f97\u6211\u5f88\u4e0d\u6de1\u5b9a\u3002", "I", "do", "not", "think", "I", "am", "calm.", "attitude.", "Disgust", "\u522b\u8bf4\u5e9f\u8bdd\u4e86\u3002", "Stop", "talking", "nonsense.", "\u521b\u610f\u6e90\u4e8e\u751f\u6d3b\uff0c\u770b\u4f60\u5bf9\u751f", "Angry", "\u4f60\u600e\u4e48\u8fd8\u6ca1\u7761\u89c9\uff1f", "how", "come", "you", "are", "still", "up?", "\u6d3b\u7684\u6001\u5ea6\u5982\u4f55\u3002", "Happy", "\u54c8\u54c8\uff0c\u662f\u554a\u3002", "Haha,", "yes.", "Creativity", "comes", "from", "life,", "ECM", "Like", "\u5e0c\u671b\u6709\u4e2a\u597d\u5fc3\u60c5\u3002", "Hope", "to", "have", "a", "good", "mood.", "Sad", "\u6211\u4e5f\u662f\u5f88\u7ea0\u7ed3\u7684\u3002", "I", "am", "also", "very", "tangled.", "Disgust", "\u4f60\u592a\u8fc7\u5206\u4e86\u3002", "You", "are", "too", "much.", "Query", "Method", "Response", "Translated", "Response", "S2S-Attn", "\u751f\u6d3b\u9700\u8981\u6539\u53d8\u5fc3\u6001\u3002", "Life", "needs", "a", "change", "of", "mindset."], "regionBoundary": {"x2": 525.0, "y1": 65.8900146484375, "x1": 73.0, "y2": 440.8900146484375}, "caption": "Table 5: Sample responses generated by S2S-Attn, ECM and CDL (original Chinese and English translation). The colored words are the emotion words corresponding to the given emotion category.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 291.9193115234375, "y1": 289.5295715332031, "x1": 71.64100646972656, "y2": 331.3980407714844}, "imageText": [], "regionBoundary": {"x2": 269.0, "y1": 100.8900146484375, "x1": 93.0, "y2": 272.8900146484375}, "caption": "Figure 1: The architecture of dual learning. CLS, Mf andMb are emotion classifier, forward model and backward model, respectively. Red parts are for the forward process, while blue parts are for the backward process.", "page": 2}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 527.2900390625, "y1": 123.1075210571289, "x1": 305.95098876953125, "y2": 176.9310302734375}, "imageText": ["Like", "Sad", "Disgust", "Angry", "Happy", "Lex.", "Size", "1,629", "294", "1,142", "30", "405", "ACC", "(f", ")", "0.653", "0.691", "0.609", "0.736", "0.818", "ACC", "(b)", "0.690", "0.655", "0.602", "0.756", "0.808"], "regionBoundary": {"x2": 525.0, "y1": 62.8900146484375, "x1": 308.0, "y2": 110.8900146484375}, "caption": "Table 7: Emotion lexicon size and classification accuracy after pre-training of each emotion category. \u201cLex.\u201d, \u201cACC(f )\u201d and \u201cACC(b)\u201d represent lexicon, classification accuracy of forward process and classification accuracy of backward process, respectively.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.43988037109375, "y1": 730.5055541992188, "x1": 71.69100189208984, "y2": 748.4630126953125}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 582.8900146484375, "x1": 72.0, "y2": 713.8900146484375}, "caption": "Figure 2: Comparison of CDL and CDL-DL for Emotion-acc on the validation set.", "page": 7}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 291.92431640625, "y1": 689.318603515625, "x1": 71.69100189208984, "y2": 719.2310180664062}, "imageText": ["Test", "2,000", "1,105,487", "Validation", "11,720", "Emotion", "Query", "Response", "Happy", "120,358", "197,528", "Angry", "79,611", "138,198", "Disgust", "184,427", "197,428", "Sad", "128,482", "179,215", "Like", "257,471", "197,565", "Neutral", "335,138", "195,553", "Training"], "regionBoundary": {"x2": 274.0, "y1": 568.8900146484375, "x1": 88.0, "y2": 676.8900146484375}, "caption": "Table 2: Statistics of the NLPCC2017 Dataset. In the training set, we count the number of queries and responses for each emotion category.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.3471069335938, "y1": 650.403552585178, "x1": 426.3430701361762, "y2": 758.3665635850695}, "name": "1", "caption_text": "Table 1: Examples of emotion-controllable response generation (response emotions are denoted in brackets). Example 1 is one query and 6 emotional responses. Example 2 and 3 have different queries, but the responses generated with emotion \u201cDisgust\u201d are the same. Similar to Example 2 and 4 with emotion \u201cHappy\u201d. The emotions of queries are marked in parentheses.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 363.0, "x1": 430.0, "y2": 634.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4434882269965, "y1": 402.12440490722656, "x1": 99.50139787462022, "y2": 460.2750566270616}, "name": "1", "caption_text": "Figure 1: The architecture of dual learning. CLS, Mf andMb are emotion classifier, forward model and backward model, respectively. Red parts are for the forward process, while blue parts are for the backward process.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 369.0, "y1": 144.0, "x1": 133.0, "y2": 374.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.450439453125, "y1": 957.386949327257, "x1": 99.57083596123589, "y2": 998.9319695366753}, "name": "2", "caption_text": "Table 2: Statistics of the NLPCC2017 Dataset. In the training set, we count the number of queries and responses for each emotion category.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 393.0, "y1": 790.0, "x1": 105.0, "y2": 958.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 731.6563924153645, "y1": 254.00488111707898, "x1": 99.57083596123589, "y2": 295.5500284830729}, "name": "3", "caption_text": "Table 3: Automatic evaluation results for content and emotion measurements. The metrics Average, Extrema, Greedy, Coherence, Emotion-acc and Emotion-word are abbreviated as Avg., Ext., Gre., Coh., Emo-acc. and Emo-word., respectively.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 86.0, "x1": 100.0, "y2": 254.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 683.3982255723741, "y1": 441.84243943956164, "x1": 146.0958374871148, "y2": 450.179206000434}, "name": "4", "caption_text": "Table 4: Human evaluation results. \u201cCon.\u201d and \u201cEmo.\u201d denote content and emotion, respectively.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 717.0, "y1": 316.0, "x1": 113.0, "y2": 425.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9264695909288, "y1": 630.1424238416884, "x1": 99.57083596123589, "y2": 655.084737141927}, "name": "5", "caption_text": "Table 5: Sample responses generated by S2S-Attn, ECM and CDL (original Chinese and English translation). The colored words are the emotion words corresponding to the given emotion category.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 100.0, "y2": 629.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2224934895833, "y1": 831.4952426486545, "x1": 426.3430701361762, "y2": 873.0402628580729}, "name": "6", "caption_text": "Table 6: The percentage of responses in human evaluation of Content-Emotion scores. 2-1 means content score is 2 and emotion score is 1.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 703.0, "x1": 426.0, "y2": 832.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3472764756945, "y1": 170.98266813490125, "x1": 424.93192884657117, "y2": 245.73754204644095}, "name": "7", "caption_text": "Table 7: Emotion lexicon size and classification accuracy after pre-training of each emotion category. \u201cLex.\u201d, \u201cACC(f )\u201d and \u201cACC(b)\u201d represent lexicon, classification accuracy of forward process and classification accuracy of backward process, respectively.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 426.0, "y2": 171.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.3887227376302, "y1": 1014.5910474989149, "x1": 99.57083596123589, "y2": 1039.531962076823}, "name": "2", "caption_text": "Figure 2: Comparison of CDL and CDL-DL for Emotion-acc on the validation set.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 793.0, "x1": 100.0, "y2": 990.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/3990622dc6c9446f7d520c0e35f0116ca0e1eef7/2020.acl-main.52.pdf", "dpi": 100}