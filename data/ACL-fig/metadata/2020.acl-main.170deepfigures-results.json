{"raw_detected_boxes": [[], [{"x2": 703.0, "y1": 95.0, "x1": 120.0, "y2": 223.0}], [], [{"x2": 690.0, "y1": 96.0, "x1": 137.0, "y2": 277.0}], [{"x2": 398.0, "y1": 95.0, "x1": 100.0, "y2": 447.0}, {"x2": 714.0, "y1": 95.0, "x1": 437.0, "y2": 236.0}], [{"x2": 344.0, "y1": 91.0, "x1": 158.0, "y2": 243.0}, {"x2": 724.0, "y1": 90.0, "x1": 434.0, "y2": 254.0}], [{"x2": 676.0, "y1": 91.0, "x1": 478.0, "y2": 233.0}, {"x2": 394.0, "y1": 89.0, "x1": 106.0, "y2": 212.0}, {"x2": 351.0, "y1": 325.0, "x1": 147.0, "y2": 395.0}], [{"x2": 718.0, "y1": 87.0, "x1": 112.0, "y2": 229.0}, {"x2": 396.0, "y1": 304.0, "x1": 107.0, "y2": 459.0}, {"x2": 728.0, "y1": 311.0, "x1": 429.0, "y2": 582.0}], [], [], [{"x2": 724.0, "y1": 95.0, "x1": 429.0, "y2": 438.0}, {"x2": 712.0, "y1": 515.0, "x1": 444.0, "y2": 657.0}, {"x2": 687.0, "y1": 750.0, "x1": 468.0, "y2": 945.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5465698242188, "y1": 199.68356323242188, "x1": 307.2760009765625, "y2": 217.64105224609375}, "imageText": [], "regionBoundary": {"x2": 523.0, "y1": 61.8900146484375, "x1": 310.0, "y2": 187.8900146484375}, "caption": "Figure 3: BLEU scores. Models trained on random subsets of WMT14 En-Fr.", "page": 5}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.2705993652344, "y1": 193.00155639648438, "x1": 72.0, "y2": 222.9150390625}, "imageText": [], "regionBoundary": {"x2": 252.0, "y1": 61.8900146484375, "x1": 110.0, "y2": 180.8900146484375}, "caption": "Figure 2: BLEU scores for the models trained with BPE-dropout with different values of p. WMT14 EnFr, 500k sentence pairs.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.5465698242188, "y1": 334.0595397949219, "x1": 307.2760009765625, "y2": 352.0169982910156}, "imageText": ["ASPEC", "En-Ja", "280", "165", "462", "Ja-En", "239", "144", "576", "WMT14", "En-De", "468", "450", "501", "De-En", "447", "442", "525", "IWSLT17", "En-Fr", "36", "45", "60", "Fr-En", "32", "46", "85", "En-Ar", "30", "60", "62", "Ar-En", "41", "51", "59", "IWSLT15", "En-Vi", "23", "26", "36", "Vi-En", "23", "29", "33", "En-Zh", "30", "29", "43", "Zh-En", "39", "51", "100", "BPE", "Kudo", "(2018)", "BPE-dropout"], "regionBoundary": {"x2": 524.0, "y1": 62.8900146484375, "x1": 309.0, "y2": 321.8900146484375}, "caption": "Table 6: Number of thousands of training batches for the experiments from Table 2.", "page": 10}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.546630859375, "y1": 484.8935546875, "x1": 307.2760009765625, "y2": 526.761962890625}, "imageText": ["250k", "47", "53", "53", "85", "500k", "160", "210", "250", "320", "1m", "30", "114", "67", "180", "4m", "100", "321", "180", "600", "16m", "345", "345", "-", "400", "BPE", "BPE-dropout", "src-only", "dst-only", "both"], "regionBoundary": {"x2": 513.0, "y1": 365.8900146484375, "x1": 320.0, "y2": 472.8900146484375}, "caption": "Table 7: Number of thousands of training batches for the experiments from Table 3. Note that we use batch size 4k tokens for small corpora (250k and 500k) and 32k tokens for large corpora (1m, 4m and 16m).", "page": 10}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 525.546630859375, "y1": 692.2135620117188, "x1": 307.2760009765625, "y2": 734.08203125}, "imageText": ["IWSLT17", "En-Fr", "38.79", "39.83", "Fr-En", "38.06", "38.60", "En-Ar", "14.30", "15.20", "Ar-En", "31.56", "33.00", "IWSLT15", "En-Vi", "31.44", "32.70", "Vi-En", "32.19", "33.22", "BPE", "BPE-dropout"], "regionBoundary": {"x2": 496.0, "y1": 539.8900146484375, "x1": 337.0, "y2": 679.8900146484375}, "caption": "Table 8: BLEU scores. Bold indicates the best score; differences with the baselines are statistically significant (with p-value of 0.05). (Statistical significance is computed via bootstrapping (Koehn, 2004).)", "page": 10}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.54736328125, "y1": 170.82455444335938, "x1": 72.0, "y2": 200.737060546875}, "imageText": ["(a)", "(b)"], "regionBoundary": {"x2": 509.0, "y1": 61.8900146484375, "x1": 86.0, "y2": 160.416015625}, "caption": "Figure 1: Segmentation process of the word \u2018unrelated\u2019 using (a) BPE, (b) BPE-dropout. Hyphens indicate possible merges (merges which are present in the merge table); merges performed at each iteration are shown in green, dropped \u2013 in red.", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 290.2706604003906, "y1": 300.0025329589844, "x1": 72.0, "y2": 353.82598876953125}, "imageText": ["32k", "1.0", "1.03", "4k", "1.44", "1.46", "voc", "size", "BPE", "BPE-dropout"], "regionBoundary": {"x2": 256.0, "y1": 234.8900146484375, "x1": 106.0, "y2": 287.8900146484375}, "caption": "Table 4: Relative inference time of models trained with different subword segmentation methods. Results obtained by (1) computing averaged over 1000 runs time needed to translate WMT14 En-Fr test set, (2) dividing all results by the smallest of the obtained times.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.2706604003906, "y1": 166.15853881835938, "x1": 72.0, "y2": 219.9810791015625}, "imageText": ["(a)", "(b)"], "regionBoundary": {"x2": 287.0, "y1": 61.8900146484375, "x1": 75.0, "y2": 150.84100341796875}, "caption": "Figure 4: Distributions of length (in tokens) of (a) the French part of WMT14 En-Fr test set segmented using BPE or BPE-dropout; and (b) the generated translations for the same test set by models trained with BPE or BPE-dropout.", "page": 6}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5473022460938, "y1": 183.51956176757812, "x1": 307.2760009765625, "y2": 249.298095703125}, "imageText": [], "regionBoundary": {"x2": 493.0, "y1": 61.8900146484375, "x1": 340.0, "y2": 171.8900146484375}, "caption": "Figure 5: Distribution of token to substring ratio for texts segmented using BPE or BPE-dropout for the same vocabulary of 32k tokens; only 10% most frequent substrings are shown. (Token to substring ratio of a token is the ratio between its frequency as an individual token and as a sequence of characters.)", "page": 6}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 525.5430297851562, "y1": 177.19851684570312, "x1": 72.0, "y2": 195.156005859375}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 61.8900146484375, "x1": 75.0, "y2": 164.8900146484375}, "caption": "Figure 6: Examples of nearest neighbours in the source embedding space of models trained with BPE and BPEdropout. Models trained on WMT14 En-Fr (4m).", "page": 7}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5465698242188, "y1": 435.7225341796875, "x1": 307.2760009765625, "y2": 477.5899658203125}, "imageText": ["misspelled", "31.23", "32.94", "+1.71", "En-Fr", "(16m)", "original", "34.37", "34.82", "+0.45", "misspelled", "30.30", "32.13", "+1.83", "En-Fr", "(4m)", "original", "33.38", "33.85", "+0.47", "misspelled", "29.71", "32.03", "+2.32", "De-En", "original", "32.69", "34.19", "+1.5", "misspelled", "24.45", "26.03", "+1.58", "En-De", "original", "27.41", "28.01", "+0.6", "source", "BPE", "BPE-dropout", "diff"], "regionBoundary": {"x2": 524.0, "y1": 218.8900146484375, "x1": 309.0, "y2": 423.8900146484375}, "caption": "Table 5: BLEU scores for models trained on WMT14 dataset evaluated given the original and misspelled source. For En-Fr trained on 16m sentence pairs, BPEdropout was used only on the source side (Section 5.2).", "page": 7}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 290.27056884765625, "y1": 343.7455749511719, "x1": 72.0, "y2": 361.7030334472656}, "imageText": ["(a)", "BPE", "(b)", "BPE-dropout"], "regionBoundary": {"x2": 288.0, "y1": 217.8900146484375, "x1": 74.0, "y2": 328.42803955078125}, "caption": "Figure 7: Visualization of source embeddings. Models trained on WMT14 En-Fr (4m).", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5444946289062, "y1": 211.46151733398438, "x1": 72.0, "y2": 229.41998291015625}, "imageText": ["ASPEC", "En\u2194", "Ja", "2M", "/", "1700", "/", "1812", "16k", "32k", "0.1", "/", "0.6", "WMT14", "En\u2194", "De", "4.5M", "/", "3000", "/", "3003", "32k", "32k", "0.1", "/", "0.1", "IWSLT17", "En\u2194", "Fr", "232k", "/", "890", "/", "1210", "4k", "4k", "0.1", "/", "0.1", "En\u2194", "Ar", "231k", "/", "888", "/", "1205", "4k", "4k", "0.1", "/", "0.1", "IWSLT15", "En\u2194", "Vi", "133k", "/", "1553", "/", "1268", "4k", "4k", "0.1", "/", "0.1", "En\u2194", "Zh", "209k", "/", "887", "/", "1261", "4k", "/", "16k", "4k", "0.1", "/", "0.6", "Number", "of", "sentences", "Voc", "size", "Batch", "size", "The", "value", "of", "p", "(train/dev/test)", "in", "BPE-dropout"], "regionBoundary": {"x2": 499.0, "y1": 62.8900146484375, "x1": 99.0, "y2": 198.8900146484375}, "caption": "Table 1: Overview of the datasets and dataset-dependent hyperparametes; values of p are shown in pairs: source language / target language. (We explain the choice of the value of p for BPE-dropout in Section 5.3.)", "page": 3}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.2706298828125, "y1": 334.0595397949219, "x1": 71.99999237060547, "y2": 387.8829650878906}, "imageText": ["ASPEC", "En-Ja", "54.51", "55.46", "55.00", "Ja-En", "30.77", "31.23", "31.29", "WMT14", "En-De", "27.41", "27.82", "28.01", "De-En", "32.69", "33.65", "34.19", "IWSLT17", "En-Fr", "39.37", "39.45", "40.02", "Fr-En", "38.18", "38.88", "39.39", "En-Ar", "13.89", "14.43", "15.05", "Ar-En", "31.90", "32.80", "33.72", "IWSLT15", "En-Vi", "31.78", "32.43", "33.27", "Vi-En", "30.83", "32.36", "32.99", "En-Zh", "20.48", "23.01", "22.84", "Zh-En", "19.72", "21.10", "21.45", "BPE", "Kudo", "(2018)", "BPE-dropout"], "regionBoundary": {"x2": 291.0, "y1": 62.8900146484375, "x1": 72.0, "y2": 321.8900146484375}, "caption": "Table 2: BLEU scores. Bold indicates the best score and all scores whose difference from the best is not statistically significant (with p-value of 0.05). (Statistical significance is computed via bootstrapping (Koehn, 2004).)", "page": 4}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.546630859375, "y1": 182.13552856445312, "x1": 307.2760009765625, "y2": 247.9140625}, "imageText": ["250k", "26.94", "27.98", "27.71", "28.40", "500k", "29.28", "30.12", "29.40", "29.89", "1m", "30.53", "31.09", "30.62", "31.23", "4m", "33.38", "33.89", "33.46", "33.85", "16m", "34.37", "34.82", "-", "33.66", "BPE", "BPE-dropout", "src-only", "dst-only", "both"], "regionBoundary": {"x2": 518.0, "y1": 62.8900146484375, "x1": 315.0, "y2": 169.8900146484375}, "caption": "Table 3: BLEU scores for models trained with BPEdropout on a single side of a translation pair or on both sides. Models trained on random subsets of WMT14 En-Fr dataset. Bold indicates the best score and all scores whose difference from the best is not statistically significant (with p-value of 0.05).", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9268934461805, "y1": 237.2563256157769, "x1": 100.0, "y2": 278.8014729817708}, "name": "1", "caption_text": "Figure 1: Segmentation process of the word \u2018unrelated\u2019 using (a) BPE, (b) BPE-dropout. Hyphens indicate possible merges (merges which are present in the merge table); merges performed at each iteration are shown in green, dropped \u2013 in red.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 720.0, "y1": 87.0, "x1": 103.0, "y2": 240.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9229092068142, "y1": 293.69655185275604, "x1": 100.0, "y2": 318.63886515299475}, "name": "1", "caption_text": "Table 1: Overview of the datasets and dataset-dependent hyperparametes; values of p are shown in pairs: source language / target language. (We explain the choice of the value of p for BPE-dropout in Section 5.3.)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 693.0, "y1": 86.0, "x1": 120.0, "y2": 294.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15365261501734, "y1": 463.97158304850257, "x1": 99.9999894036187, "y2": 538.726340399848}, "name": "2", "caption_text": "Table 2: BLEU scores. Bold indicates the best score and all scores whose difference from the best is not statistically significant (with p-value of 0.05). (Statistical significance is computed via bootstrapping (Koehn, 2004).)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 86.0, "x1": 100.0, "y2": 464.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 252.96601189507376, "x1": 426.772223578559, "y2": 344.32508680555554}, "name": "3", "caption_text": "Table 3: BLEU scores for models trained with BPEdropout on a single side of a translation pair or on both sides. Models trained on random subsets of WMT14 En-Fr dataset. Bold indicates the best score and all scores whose difference from the best is not statistically significant (with p-value of 0.05).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 86.0, "x1": 427.0, "y2": 253.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 268.0577172173394, "x1": 100.0, "y2": 309.60422092013886}, "name": "2", "caption_text": "Figure 2: BLEU scores for the models trained with BPE-dropout with different values of p. WMT14 EnFr, 500k sentence pairs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 346.0, "y1": 91.0, "x1": 158.0, "y2": 247.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 277.33828226725257, "x1": 426.772223578559, "y2": 302.27923923068573}, "name": "3", "caption_text": "Figure 3: BLEU scores. Models trained on random subsets of WMT14 En-Fr.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 90.0, "x1": 434.0, "y2": 257.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 254.88828023274738, "x1": 426.772223578559, "y2": 346.24735514322913}, "name": "5", "caption_text": "Figure 5: Distribution of token to substring ratio for texts segmented using BPE or BPE-dropout for the same vocabulary of 32k tokens; only 10% most frequent substrings are shown. (Token to substring ratio of a token is the ratio between its frequency as an individual token and as a sequence of characters.)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 680.0, "y1": 91.0, "x1": 478.0, "y2": 233.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15369500054254, "y1": 230.77574835883246, "x1": 100.0, "y2": 305.5292765299479}, "name": "4", "caption_text": "Figure 4: Distributions of length (in tokens) of (a) the French part of WMT14 En-Fr test set segmented using BPE or BPE-dropout; and (b) the generated translations for the same test set by models trained with BPE or BPE-dropout.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 397.0, "y1": 89.0, "x1": 105.0, "y2": 212.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15369500054254, "y1": 416.67018466525604, "x1": 100.0, "y2": 491.4249844021267}, "name": "4", "caption_text": "Table 4: Relative inference time of models trained with different subword segmentation methods. Results obtained by (1) computing averaged over 1000 runs time needed to translate WMT14 En-Fr test set, (2) dividing all results by the smallest of the obtained times.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 356.0, "y1": 325.0, "x1": 147.0, "y2": 400.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9208747016058, "y1": 246.10905117458768, "x1": 100.0, "y2": 271.0500081380208}, "name": "6", "caption_text": "Figure 6: Examples of nearest neighbours in the source embedding space of models trained with BPE and BPEdropout. Models trained on WMT14 En-Fr (4m).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 87.0, "x1": 100.0, "y2": 246.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.153567843967, "y1": 477.42440965440534, "x1": 100.0, "y2": 502.36532423231336}, "name": "7", "caption_text": "Figure 7: Visualization of source embeddings. Models trained on WMT14 En-Fr (4m).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 304.0, "x1": 100.0, "y2": 476.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 605.170186360677, "x1": 426.772223578559, "y2": 663.3193969726562}, "name": "5", "caption_text": "Table 5: BLEU scores for models trained on WMT14 dataset evaluated given the original and misspelled source. For En-Fr trained on 16m sentence pairs, BPEdropout was used only on the source side (Section 5.2).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 303.0, "x1": 429.0, "y2": 588.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 463.97158304850257, "x1": 426.772223578559, "y2": 488.9124976264106}, "name": "6", "caption_text": "Table 6: Number of thousands of training batches for the experiments from Table 2.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 86.0, "x1": 429.0, "y2": 447.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 673.4632703993055, "x1": 426.772223578559, "y2": 731.6138373480902}, "name": "7", "caption_text": "Table 7: Number of thousands of training batches for the experiments from Table 3. Note that we use batch size 4k tokens for small corpora (250k and 500k) and 32k tokens for large corpora (1m, 4m and 16m).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 720.0, "y1": 507.0, "x1": 427.0, "y2": 674.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 961.407725016276, "x1": 426.772223578559, "y2": 1019.5583767361111}, "name": "8", "caption_text": "Table 8: BLEU scores. Bold indicates the best score; differences with the baselines are statistically significant (with p-value of 0.05). (Statistical significance is computed via bootstrapping (Koehn, 2004).)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 692.0, "y1": 733.0, "x1": 462.0, "y2": 962.0}, "page": 10, "dpi": 0}], "error": null, "pdf": "/work/host-output/bd9e10d0a8b77d319e3a3250d0e2baa6f8e93de9/2020.acl-main.170.pdf", "dpi": 100}