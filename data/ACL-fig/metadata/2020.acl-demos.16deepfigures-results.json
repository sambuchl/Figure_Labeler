{"raw_detected_boxes": [[], [{"x2": 723.0, "y1": 88.0, "x1": 435.0, "y2": 333.0}], [{"x2": 644.0, "y1": 96.0, "x1": 178.0, "y2": 357.0}], [{"x2": 724.0, "y1": 87.0, "x1": 107.0, "y2": 407.0}], [{"x2": 401.0, "y1": 90.0, "x1": 99.0, "y2": 427.0}, {"x2": 401.0, "y1": 504.0, "x1": 99.0, "y2": 602.0}, {"x2": 398.0, "y1": 691.0, "x1": 102.0, "y2": 773.0}], [{"x2": 391.0, "y1": 539.0, "x1": 109.0, "y2": 759.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 255.3159942626953, "y1": 562.1705322265625, "x1": 106.9530029296875, "y2": 568.1729736328125}, "imageText": [], "regionBoundary": {"x2": 286.0, "y1": 387.8900146484375, "x1": 76.0, "y2": 549.8900146484375}, "caption": "Figure 4: The configuration of SNLI.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2002563476562, "y1": 260.5235290527344, "x1": 307.2760009765625, "y2": 362.1670227050781}, "imageText": ["Adversarial", "Training", "Single-task", "Knowledge", "Distillation", "Single-task", "Fine-tuning", "Natural", "Language", "Model", "Pre-training", "Multi-task", "Fine-tuning", "Multi-task", "Knowledge", "Distillation"], "regionBoundary": {"x2": 521.0, "y1": 63.8900146484375, "x1": 314.0, "y2": 238.8900146484375}, "caption": "Figure 1: The workflow of MT-DNN: train a neural language model on a large amount of unlabeled raw text to obtain general contextual representations; then finetune the learned contextual representation on downstream tasks, e.g. GLUE (Wang et al., 2018); lastly, distill this large model to a lighter one for online deployment. In the later two phrases, we can leverage powerful multi-task learning and adversarial training to further improve performance.", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.796142578125, "y1": 273.6545715332031, "x1": 71.99998474121094, "y2": 339.4330749511719}, "imageText": [], "regionBoundary": {"x2": 475.0, "y1": 61.8900146484375, "x1": 120.0, "y2": 269.8900146484375}, "caption": "Figure 2: Process of knowledge distillation for MTL. A set of tasks where there is task-specific labeled training data are picked. Then, for each task, an ensemble of different neural nets (teacher) is trained. The teacher is used to generate for each task-specific training sample a set of soft targets. Given the soft targets of the training datasets across multiple tasks, a single MT-DNN (student) shown in Figure 3 is trained using multi-task learning and back propagation, except that if task t has a teacher, the task-specific loss is the average of two objective functions, one for the correct targets and the other for the soft targets assigned by the teacher.", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.2866821289062, "y1": 315.7775573730469, "x1": 71.75099182128906, "y2": 405.4659423828125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 295.8900146484375}, "caption": "Figure 3: Overall System Architecture: The lower layers are shared across all tasks while the top layers are taskspecific. The input X (either a sentence or a set of sentences) is first represented as a sequence of embedding vectors, one for each word, in l1. Then the encoder, e.g a Transformer or recurrent neural network (LSTM) model, captures the contextual information for each word and generates the shared contextual embedding vectors in l2. Finally, for each task, additional task-specific layers generate task-specific representations, followed by operations necessary for classification, similarity scoring, or relevance ranking. In case of adversarial training, we perturb embeddings from the lexicon encoder and then add an extra loss term during the training. Note that for the inference phrase, it does not require perturbations.", "page": 3}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 291.5157775878906, "y1": 324.6015319824219, "x1": 71.69100189208984, "y2": 342.5589904785156}, "imageText": ["Corpus", "Task", "Formulation", "GLUE", "CoLA", "Acceptability", "Classi\ufb01cation", "SST", "Sentiment", "Classi\ufb01cation", "MNLI", "NLI", "Classi\ufb01cation", "RTE", "NLI", "Classi\ufb01cation", "WNLI", "NLI", "Classi\ufb01cation", "QQP", "Paraphrase", "Classi\ufb01cation", "MRPC", "Paraphrase", "Classi\ufb01cation", "QNLI", "QA/NLI", "Classi\ufb01cation", "QNLI", "v1.0", "QA/NLI", "Pairwise", "Ranking", "STS-B", "Similarity", "Regression", "Others", "SNLI", "NLI", "Classi\ufb01cation", "SciTail", "NLI", "Classi\ufb01cation", "ANLI", "NLI", "Classi\ufb01cation", "SQuAD", "MRC", "Span", "Classi\ufb01cation"], "regionBoundary": {"x2": 294.0, "y1": 63.8900146484375, "x1": 72.0, "y2": 307.8900146484375}, "caption": "Table 1: Summary of the four benchmarks: GLUE, SNLI, SciTail and ANLI.", "page": 4}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.5794372558594, "y1": 447.8745422363281, "x1": 71.69100189208984, "y2": 477.7869873046875}, "imageText": ["BERT", "84.5", "63.5", "91.1", "92.9", "89.0", "BERT", "+", "MTL", "85.3", "79.1", "91.5", "93.6", "89.2", "BERT", "+", "AdvTrain", "85.6", "71.2", "91.6", "93.0", "91.3", "Model", "MNLI", "RTE", "QNLI", "SST", "MRPC", "Acc", "Acc", "Acc", "Acc", "F1"], "regionBoundary": {"x2": 291.0, "y1": 361.8900146484375, "x1": 72.0, "y2": 435.8900146484375}, "caption": "Table 2: Comparison among single task, multi-Task and adversarial training on MNLI, RTE, QNLI, SST and MPRC in GLUE.", "page": 4}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 282.90277099609375, "y1": 567.8695678710938, "x1": 79.05799865722656, "y2": 573.8720092773438}, "imageText": ["Model", "Dev", "Test", "BERTLARGE", "(Nie", "et", "al.,", "2019)", "49.3", "44.2", "RoBERTaLARGE", "(Nie", "et", "al.,", "2019)", "53.7", "49.7", "RoBERTa-LARGE", "+", "AdvTrain", "57.1", "57.1"], "regionBoundary": {"x2": 294.0, "y1": 497.8900146484375, "x1": 72.0, "y2": 556.8900146484375}, "caption": "Table 3: Results in terms of accuracy on the ANLI.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 361.8382347954644, "x1": 426.772223578559, "y2": 503.0097537570529}, "name": "1", "caption_text": "Figure 1: The workflow of MT-DNN: train a neural language model on a large amount of unlabeled raw text to obtain general contextual representations; then finetune the learned contextual representation on downstream tasks, e.g. GLUE (Wang et al., 2018); lastly, distill this large model to a lighter one for online deployment. In the later two phrases, we can leverage powerful multi-task learning and adversarial training to further improve performance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 88.0, "x1": 435.0, "y2": 333.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.2724202473958, "y1": 380.0757937961154, "x1": 99.99997880723741, "y2": 471.434826321072}, "name": "2", "caption_text": "Figure 2: Process of knowledge distillation for MTL. A set of tasks where there is task-specific labeled training data are picked. Then, for each task, an ensemble of different neural nets (teacher) is trained. The teacher is used to generate for each task-specific training sample a set of soft targets. Given the soft targets of the training datasets across multiple tasks, a single MT-DNN (student) shown in Figure 3 is trained using multi-task learning and back propagation, except that if task t has a teacher, the task-specific loss is the average of two objective functions, one for the correct targets and the other for the soft targets assigned by the teacher.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 645.0, "y1": 96.0, "x1": 178.0, "y2": 361.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3426140679253, "y1": 438.57994079589844, "x1": 99.65415530734592, "y2": 563.1471421983507}, "name": "3", "caption_text": "Figure 3: Overall System Architecture: The lower layers are shared across all tasks while the top layers are taskspecific. The input X (either a sentence or a set of sentences) is first represented as a sequence of embedding vectors, one for each word, in l1. Then the encoder, e.g a Transformer or recurrent neural network (LSTM) model, captures the contextual information for each word and generates the shared contextual embedding vectors in l2. Finally, for each task, additional task-specific layers generate task-specific representations, followed by operations necessary for classification, similarity scoring, or relevance ranking. In case of adversarial training, we perturb embeddings from the lexicon encoder and then add an extra loss term during the training. Note that for the inference phrase, it does not require perturbations.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 87.0, "x1": 107.0, "y2": 410.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 404.88302442762586, "y1": 450.835461086697, "x1": 99.57083596123589, "y2": 475.77637566460504}, "name": "1", "caption_text": "Table 1: Summary of the four benchmarks: GLUE, SNLI, SciTail and ANLI.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 88.0, "x1": 99.0, "y2": 427.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.58255174424914, "y1": 622.0479753282335, "x1": 99.57083596123589, "y2": 663.593037923177}, "name": "2", "caption_text": "Table 2: Comparison among single task, multi-Task and adversarial training on MNLI, RTE, QNLI, SST and MPRC in GLUE.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 502.0, "x1": 99.0, "y2": 605.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 392.9205152723524, "y1": 788.7077331542969, "x1": 109.80277591281467, "y2": 797.044457329644}, "name": "3", "caption_text": "Table 3: Results in terms of accuracy on the ANLI.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 691.0, "x1": 99.0, "y2": 790.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 354.6055475870768, "y1": 780.7924058702257, "x1": 148.54583740234375, "y2": 789.1291300455729}, "name": "4", "caption_text": "Figure 4: The configuration of SNLI.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 539.0, "x1": 109.0, "y2": 759.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/3136da80c92bd9a3bd2e5e209c0acec1f1d8fa39/2020.acl-demos.16.pdf", "dpi": 100}