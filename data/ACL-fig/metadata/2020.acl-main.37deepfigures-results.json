{"raw_detected_boxes": [[], [], [{"x2": 398.0, "y1": 94.0, "x1": 102.0, "y2": 419.0}], [{"x2": 400.0, "y1": 99.0, "x1": 100.0, "y2": 625.0}], [{"x2": 640.0, "y1": 90.0, "x1": 189.0, "y2": 308.0}], [{"x2": 698.0, "y1": 86.0, "x1": 463.0, "y2": 197.0}], [{"x2": 662.0, "y1": 101.0, "x1": 164.0, "y2": 297.0}], [{"x2": 396.0, "y1": 87.0, "x1": 101.0, "y2": 285.0}, {"x2": 725.0, "y1": 88.0, "x1": 427.0, "y2": 282.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 510.9302062988281, "y1": 160.53353881835938, "x1": 321.58099365234375, "y2": 166.5360107421875}, "imageText": ["Transformer", "Big", "28.49", "41.36", "+PR", "29.60\u2020", "42.45\u2020", "Transformer", "Base", "27.38", "39.34", "+PR", "28.67\u2020", "40.71\u2020", "Models", "En-De", "En-Fr"], "regionBoundary": {"x2": 503.0, "y1": 62.8900146484375, "x1": 330.0, "y2": 147.8900146484375}, "caption": "Table 1: Results on WMT 14 En-De and En-Fr.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.20068359375, "y1": 225.66555786132812, "x1": 71.69100189208984, "y2": 255.57904052734375}, "imageText": ["Transformer", "Big", "28.49", "1.11", "264.1", "7.73x", "2.68x", "173.0", "1.74x", "1.52x", "+Max+Attn+TA", "28.67", "1.29", "1.75x", "1.53x", "+Max+Attn+TA+Parsing", "Phrase", "28.76", "1.38", "1.83x", "1.60x", "+Max+Attn", "28.52", "1.14", "+Mean", "27.99", "0.61", "129.0", "1.64x", "1.45x", "+Max", "28.13", "0.75", "1.60x", "1.40x", "Transformer", "Base", "27.38", "88.1", "1.00x", "1.00x", "Train", "Decode", "Models", "BLEU", "\u2206", "Para.", "(M)", "Time"], "regionBoundary": {"x2": 480.0, "y1": 62.8900146484375, "x1": 118.0, "y2": 213.8900146484375}, "caption": "Table 2: Ablation Study. \u2206 indicates the BLEU improvements compared to the Transformer Base. Time represents the time consumption compared to the Transformer Base (in training and decoding). The Transformer Big consumes 3 times training steps of the Transformer Base.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 291.9244079589844, "y1": 315.5715637207031, "x1": 72.0, "y2": 345.4850158691406}, "imageText": ["Classifier", "Output", "(Target)", "Source", "Shifted", "Target", "Positional", "Embedding", "Feed-Forward", "Self-Attention", "++", "Embedding", "6x", "Cross-Attention", "Feed-Forward", "Self-Attention", "Embedding", "6x"], "regionBoundary": {"x2": 289.0553283691406, "y1": 65.52366638183594, "x1": 73.22173309326172, "y2": 300.0589599609375}, "caption": "Figure 1: The Transformer Translation Model. Residual connection and Layer normalization are omitted for simplicity.", "page": 2}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5465087890625, "y1": 216.29556274414062, "x1": 307.2760009765625, "y2": 246.20806884765625}, "imageText": ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", ">15", "Transformer", "Base", "Base+PR", "Transformer", "Big", "Big+PR", "99.0", "98.5", "98.0", "97.5", "97.0", "96.5", "96.0", "95.5", "95.0"], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 204.8900146484375}, "caption": "Figure 4: Subject-Verb Agreement Analysis. X-axis and y-axis represent subject-verb distance in words and the accuracy respectively.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 290.2705993652344, "y1": 218.12655639648438, "x1": 72.0, "y2": 236.08404541015625}, "imageText": ["Transformer", "Base", "Base+PR", "Transformer", "Big", "Big+PR", "32", "31", "30", "29", "28", "27", "26", "25"], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 71.0, "y2": 205.8900146484375}, "caption": "Figure 3: BLEU scores with respect to various input sentence lengths.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5473022460938, "y1": 234.74954223632812, "x1": 72.0, "y2": 252.70703125}, "imageText": ["Encoder", "Layer", "Decoder", "Layer", "query", "key/value", "Encoder", "Representation", "Transparent", "Attentive", "Phrase", "Representation", "Output", "Input", "Attentive", "Combining", "Cross-", "Attention", "Feed-Forward", "Self-", "Attention", "Output", "Input", "key/value", "query", "Attentive", "Combining", "Attentive", "Phrase", "Representation", "Feed-", "Forward", "Self-", "Attention"], "regionBoundary": {"x2": 461.0, "y1": 66.46964263916016, "x1": 136.0, "y2": 219.7652587890625}, "caption": "Figure 2: The Encoder/Decoder Layer of the Transformer Model with Phrase Representation. Residual connection and Layer normalization are omitted for simplicity.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 405.4505666097005, "y1": 438.29383850097656, "x1": 100.0, "y2": 479.84029981825086}, "name": "1", "caption_text": "Figure 1: The Transformer Translation Model. Residual connection and Layer normalization are omitted for simplicity.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 88.0, "x1": 102.0, "y2": 419.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 326.04103088378906, "x1": 100.0, "y2": 350.98198784722223}, "name": "2", "caption_text": "Figure 2: The Encoder/Decoder Layer of the Transformer Model with Phrase Representation. Residual connection and Layer normalization are omitted for simplicity.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 648.0, "y1": 90.0, "x1": 179.0, "y2": 325.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 709.6252865261501, "y1": 222.96324835883246, "x1": 446.6402689615885, "y2": 231.30001491970486}, "name": "1", "caption_text": "Table 1: Results on WMT 14 En-De and En-Fr.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 698.0, "y1": 86.0, "x1": 459.0, "y2": 206.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2231716579861, "y1": 313.4243859185113, "x1": 99.57083596123589, "y2": 354.97088962131073}, "name": "2", "caption_text": "Table 2: Ablation Study. \u2206 indicates the BLEU improvements compared to the Transformer Base. Time represents the time consumption compared to the Transformer Base (in training and decoding). The Transformer Big consumes 3 times training steps of the Transformer Base.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 677.0, "y1": 86.0, "x1": 154.0, "y2": 314.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 302.95355055067273, "x1": 100.0, "y2": 327.8945075141059}, "name": "3", "caption_text": "Figure 3: BLEU scores with respect to various input sentence lengths.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 87.0, "x1": 100.0, "y2": 302.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 300.4105038113064, "x1": 426.772223578559, "y2": 341.95565117730035}, "name": "4", "caption_text": "Figure 4: Subject-Verb Agreement Analysis. X-axis and y-axis represent subject-verb distance in words and the accuracy respectively.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 88.0, "x1": 427.0, "y2": 299.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/7ed5acb8097a5588d638db48735661769c1fb3fa/2020.acl-main.37.pdf", "dpi": 100}