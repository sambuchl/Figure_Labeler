{"raw_detected_boxes": [[], [], [], [], [{"x2": 724.0, "y1": 115.0, "x1": 134.0, "y2": 336.0}], [{"x2": 746.0, "y1": 107.0, "x1": 443.0, "y2": 249.0}, {"x2": 750.0, "y1": 320.0, "x1": 435.0, "y2": 549.0}], [{"x2": 401.0, "y1": 100.0, "x1": 109.0, "y2": 349.0}], [{"x2": 736.0, "y1": 107.0, "x1": 121.0, "y2": 529.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 493.4124450683594, "y1": 191.8733673095703, "x1": 359.7879943847656, "y2": 198.446044921875}, "imageText": ["Word", "vector", "size", "200", "300", "Hidden", "vector", "size", "200", "200", "Optimizer", "AdaDelta", "AdaGrad", "(Weight", "decay/learning", "rate)", "0.0001", "0.005", "Gradient", "clipping", "5", "5", "Parameter", "Value", "Japanese", "English"], "regionBoundary": {"x2": 537.0, "y1": 71.8900146484375, "x1": 316.0, "y2": 178.8900146484375}, "caption": "Table 1: The hyperparameters.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 539.9981079101562, "y1": 408.1113586425781, "x1": 313.20001220703125, "y2": 428.2330322265625}, "imageText": ["Tree-LSTM", "w/", "attn", "0.810", "Tree-LSTM", "w/", "dict", "0.829", "Tree-LSTM", "w/", "attn,", "dict", "0.844", "RvNN", "0.517", "Reimplementation", "of", "Tai", "et", "al.", "(2015)", "0.709", "Reimplementation", "of", "K&P", "(2017)", "0.807", "MFS", "0.704", "LogRes", "0.771", "CNN", "(Kim,", "2014)", "0.803", "Tree-CRF", "(Nakagawa", "et", "al.,", "2010)", "0.826", "Method", "Accuracy"], "regionBoundary": {"x2": 544.0, "y1": 222.8900146484375, "x1": 313.0, "y2": 394.8900146484375}, "caption": "Table 2: Accuracy of each method on the Japanese sentiment classification task.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 446.7380676269531, "y1": 255.9163360595703, "x1": 165.26400756835938, "y2": 262.489013671875}, "imageText": ["(a)", "RvNN", "(b)", "RvNN", "with", "Attention"], "regionBoundary": {"x2": 523.0, "y1": 77.8900146484375, "x1": 89.0, "y2": 239.7550048828125}, "caption": "Figure 1: Sentiment classification by Tree-LSTM with attention.", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 539.9961547851562, "y1": 414.0123596191406, "x1": 71.99998474121094, "y2": 474.78106689453125}, "imageText": ["(c)", "Military", "confrontation", "was", "mitigated.", "(d)", "Anyway,", "it", "was", "able", "to", "avoid", "the", "worst-case", "scenario.", "(a)", "Consistency", "of", "policy", "cannot", "be", "found.", "(b)", "Apprehension", "about", "friendship."], "regionBoundary": {"x2": 536.0, "y1": 71.8900146484375, "x1": 76.0, "y2": 397.8500061035156}, "caption": "Figure 2: Examples of our attentional Tree-LSTM sentiment classification on the test set. The red square indicates a word or phrase to which great attention was paid in the softmax step, and the associated value indicates the attention weight. Root nodes are indicated by the (left) gold and (right) predicted labels (\u201cN\u201d indicates negative, whereas \u201cP\u201d indicates positive). We also show the labels for nodes that match an entry in the polar dictionary.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 298.7981262207031, "y1": 265.0963439941406, "x1": 72.0, "y2": 298.76702880859375}, "imageText": ["Tree-LSTM", "43.52", "Tree-LSTM", "w/", "attn", "44.97", "Tree-LSTM", "w/", "dict", "43.13", "Tree-LSTM", "w/", "attn,", "dict", "41.67", "(Kim,", "2014)", "\u2014", "CNN", "48.0", "(Tai", "et", "al.,", "2015)", "\u2014", "Tree-LSTM", "51.0", "(Kokkinos", "and", "Potamianos,", "2017)", "\u2014", "TreeGRU", "w/o", "attn", "50.5", "\u2014", "TreeGRU", "w/", "attn", "51.0", "Method", "Accuracy"], "regionBoundary": {"x2": 293.0, "y1": 71.8900146484375, "x1": 78.0, "y2": 251.8900146484375}, "caption": "Table 3: Accuracy of each method on the English sentiment classification task. Note that our model learns only from sentence-level annotation.", "page": 6}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 620.4695383707682, "y1": 355.4393556382921, "x1": 229.53334384494357, "y2": 364.5680745442708}, "name": "1", "caption_text": "Figure 1: Sentiment classification by Tree-LSTM with attention.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 112.0, "x1": 131.0, "y2": 336.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 685.2950625949436, "y1": 266.49078792995874, "x1": 499.7055477566189, "y2": 275.6195068359375}, "name": "1", "caption_text": "Table 1: The hyperparameters.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 746.0, "y1": 99.0, "x1": 439.0, "y2": 266.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9973720974392, "y1": 566.8213314480251, "x1": 435.0000169542101, "y2": 594.7681003146702}, "name": "2", "caption_text": "Table 2: Accuracy of each method on the Japanese sentiment classification task.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 755.0, "y1": 309.0, "x1": 435.0, "y2": 566.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.99739752875433, "y1": 368.1893666585286, "x1": 100.0, "y2": 414.9542066786024}, "name": "3", "caption_text": "Table 3: Accuracy of each method on the English sentiment classification task. Note that our model learns only from sentence-level annotation.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 407.0, "y1": 99.0, "x1": 108.0, "y2": 351.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9946594238281, "y1": 575.0171661376953, "x1": 99.99997880723741, "y2": 659.4181484646267}, "name": "2", "caption_text": "Figure 2: Examples of our attentional Tree-LSTM sentiment classification on the test set. The red square indicates a word or phrase to which great attention was paid in the softmax step, and the associated value indicates the attention weight. Root nodes are indicated by the (left) gold and (right) predicted labels (\u201cN\u201d indicates negative, whereas \u201cP\u201d indicates positive). We also show the labels for nodes that match an entry in the polar dictionary.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 736.0, "y1": 106.0, "x1": 109.0, "y2": 546.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/21d8dd716868ae1c5f293dffca9ba0ecc771afd4/Y18-1054.pdf", "dpi": 100}