{"raw_detected_boxes": [[], [{"x2": 712.0, "y1": 398.0, "x1": 446.0, "y2": 529.0}], [{"x2": 723.0, "y1": 86.0, "x1": 115.0, "y2": 239.0}], [{"x2": 716.0, "y1": 296.0, "x1": 441.0, "y2": 484.0}], [{"x2": 319.0, "y1": 86.0, "x1": 184.0, "y2": 136.0}], [{"x2": 730.0, "y1": 92.0, "x1": 426.0, "y2": 249.0}, {"x2": 392.0, "y1": 92.0, "x1": 108.0, "y2": 309.0}], [{"x2": 648.0, "y1": 91.0, "x1": 176.0, "y2": 211.0}, {"x2": 360.0, "y1": 302.0, "x1": 140.0, "y2": 450.0}], [{"x2": 385.0, "y1": 90.0, "x1": 111.0, "y2": 311.0}, {"x2": 358.0, "y1": 398.0, "x1": 145.0, "y2": 465.0}], [{"x2": 704.0, "y1": 91.0, "x1": 126.0, "y2": 204.0}, {"x2": 397.0, "y1": 375.0, "x1": 110.0, "y2": 521.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5465087890625, "y1": 198.60653686523438, "x1": 307.2760009765625, "y2": 252.4300537109375}, "imageText": ["SCOREEDGE(_and_c\u2192", "_discussion_n_1)", "c4", "c6", "BIAFFINE", "_topic_n_of", "_and_c", "_then_a_1", "_discussion_n_1", "arg", "max", "encoder", "encoder", "encoder", "encoder", "r4", "r6", "topic", "and", "then", "discussion"], "regionBoundary": {"x2": 526.0, "y1": 66.861083984375, "x1": 307.0, "y2": 177.09844970703125}, "caption": "Figure 4: The network architecture for the factorization-based parser. Textual embeddings (in red) are used to identify concepts and also to determine dependency relations together with the resulted conceptual embeddings (in yellow).", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 290.2706298828125, "y1": 237.98153686523438, "x1": 71.9999771118164, "y2": 363.5360412597656}, "imageText": ["NP", "CONJ", "NP", "R-INDEX", "=\u21d2", "and", "then", "ARG1CONJ", "and", "then", "discussion", "about", "it", "NP", "BV", "ARG1", "ARG2", "BV", "pronoun", "about", "pron", "udef", "discussion", "NP", "and", "then", "ARG1", "R-INDEX", "BV", "ARG1", "ARG2", "BV", "udef", "pronoun", "about", "pron", "discussion"], "regionBoundary": {"x2": 282.0, "y1": 64.8900146484375, "x1": 78.0, "y2": 223.03509521484375}, "caption": "Figure 3: An SHRG-based syntactico-semantic derivation from the composition-based parser. Each phrase in the syntactic tree (\u201cand then\u201d and \u201cdiscussion about it\u201d) is assigned with a sub-graph of the final semantic structure, as illustrated in the boxes. Some particular nodes (filled nodes) in a sub-graph are marked as communication channels to other meaning parts. According to the construction rule (shown in double-framed box), we glue the two sub-parts via the filled nodes, forming a larger graph with the syntactic label \u201cNP\u201d. More details are illustrated in Chen et al. (2019)", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5423583984375, "y1": 396.3585510253906, "x1": 307.27496337890625, "y2": 438.22698974609375}, "imageText": ["V", "give", "N", "topic", "D", "a", "CONJ", "and", "then", "NP", "N", "discussion", "NP", "NP", "VP", "P", "about", "PN", "it", "NP", "PP", "VP"], "regionBoundary": {"x2": 511.8360595703125, "y1": 287.3078918457031, "x1": 320.9805908203125, "y2": 378.9356689453125}, "caption": "Figure 1: A plausible syntactic analysis of give a topic and then discussion about it. The example is from the TLE corpus. The corrected counterpart of this fragment in TLE is Give a topic and then discuss it.", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 290.2721862792969, "y1": 336.08154296875, "x1": 71.99996948242188, "y2": 391.3989562988281}, "imageText": ["FAC", "X", "90.96", "84.48", "87.86", "\u00d7", "73.55", "80.27", "77.75", "CXG", "X", "89.04", "82.14", "85.75", "\u00d7", "71.46", "79.77", "76.66", "LEX", "X", "86.31", "81.95", "84.23", "\u00d7", "68.94", "79.81", "75.74", "Model", "Data", "Node", "Edge", "All"], "regionBoundary": {"x2": 264.0, "y1": 217.8900146484375, "x1": 98.0, "y2": 323.8900146484375}, "caption": "Table 4: X refers to error-ignored (\u03c3k = 0 when the kth triple in Gg is involved with errors, \u03c3k = 1 otherwise) SMATCH scores while \u00d7 refers to error-oriented (\u03c3k = 1 when the kth triple in Gg is involved with errors, \u03c3k = 0 otherwise) SMATCH scores.", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5451049804688, "y1": 164.17056274414062, "x1": 72.0, "y2": 194.08306884765625}, "imageText": ["L1", "88.41", "86.44", "87.41", "90.32", "86.04", "88.14", "92.28", "89.12", "90.91", "L2", "84.38", "82.23", "83.29", "86.47", "81.70", "84.04", "88.68", "84.45", "86.91", "\u2206", "4.03", "4.21", "4.12", "3.85", "4.34", "4.10", "3.60", "4.67", "4.00", "DeepBank", "94.05", "92.96", "93.50", "95.83", "92.87", "94.34", "96.85", "95.19", "96.01", "Node", "Edge", "All", "Node", "Edge", "All", "Node", "Edge", "All", "Data", "LEX", "CXG", "FAC"], "regionBoundary": {"x2": 473.0, "y1": 62.8900146484375, "x1": 124.0, "y2": 151.8900146484375}, "caption": "Table 3: SMATCH scores of semantic parsing on different test data. Henceforth, LEX, CXG and FAC refer to lexicalized and constructional composition-based parsers and the factorization-based parser, respectively. \u2206 refers to the gap between L1 and L2.", "page": 6}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.54736328125, "y1": 191.12759399414062, "x1": 72.0, "y2": 244.95111083984375}, "imageText": ["(b)", "Intended", "meaning", "BV", "ARG2", "R-INDEX", "BV", "L-INDEX", "ARG1", "ARG2", "BV", "pron", "pronoun_q", "_discuss_v_1", "_and+then_c", "_a_q", "_topic_n_of", "_give_v_1", "pron", "pronoun_q", "(a)", "Literal", "meaning", "BV", "ARG2", "ARG1", "R-INDEX", "BV", "BV", "L-INDEX", "ARG1", "ARG2", "BV", "pron", "pronoun_q", "_about_p", "udef_q", "_discussion_n_1", "_a_q", "_topic_n_of", "_and+then_c", "pronoun_q", "pron", "_give_v_1"], "regionBoundary": {"x2": 525.0, "y1": 62.8900146484375, "x1": 82.0, "y2": 171.87603759765625}, "caption": "Figure 2: Semantic analysis of the fragment give a topic and then discussion about it, where the contrastive parts are colored. The analysis is based on English Resource Semantics. Nodes represent concepts, while edges represent semantic dependencies. Following morphosyntax, \u201cdiscussion\u201d acts as the conjunct of the previous noun \u201ctopic\u201d. However, according to discourse, it should be juxtaposed with the verb \u201cgive\u201d because these are two successive actions.", "page": 2}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 290.2705993652344, "y1": 239.72756958007812, "x1": 72.0, "y2": 269.64105224609375}, "imageText": ["LEX", "CXG", "FAC", "ArtOrDet", "Nn", "Pform", "Wform", "Others", "WOinc", "WOadv", "40", "60", "80"], "regionBoundary": {"x2": 284.0, "y1": 62.8900146484375, "x1": 75.63600158691406, "y2": 223.76300048828125}, "caption": "Figure 5: Overall SMATCH scores with regard to different grammatical error types. Detailed descriptions of errors are provided in Ng et al. (2014).", "page": 7}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 290.2705993652344, "y1": 346.8825378417969, "x1": 72.0, "y2": 364.8399963378906}, "imageText": ["Chollampatt", "and", "Ng", "(2018)", "45.36", "Zhao", "et", "al.", "(2019)", "61.15", "Model", "F0.5"], "regionBoundary": {"x2": 258.0, "y1": 286.8900146484375, "x1": 105.0, "y2": 334.8900146484375}, "caption": "Table 5: Performances of the two GEC models on CoNLL-2014 test set.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5465698242188, "y1": 362.8995361328125, "x1": 307.2760009765625, "y2": 440.6329345703125}, "imageText": ["\u2013", "\u2013", "\u2013", "94-95", "Inter-Annotator", "Agreement", "Oracle", "(50)", "97.6", "96.9", "97.2", "95.6", "Oracle", "(500)", "98.7", "98.5", "98.6", "97.6", "Rerank", "(50)", "94.7", "93.4", "94.1", "92.0", "Rerank", "(500)", "95.1", "93.9", "94.5", "92.7", "Top-1", "92.8", "90.0", "91.4", "87.8", "Node", "Edge", "All", "All", "SMATCH", "EDM"], "regionBoundary": {"x2": 516.0, "y1": 209.8900146484375, "x1": 317.0, "y2": 350.8900146484375}, "caption": "Table 1: Results of reranking. \u201cTop-1\u201d means the most preferable graph generated by the ACE parser. \u201cRerank (50)\u201d and \u201cRerank (500)\u201d means thatK is set to 50 and 500 during reranking respectively. \u201cOracle\u201d means directly selecting the best-performing graph for each sentence from the K-best list. The inter-annotator agreement of EDM is reported in Bender et al. (2015).", "page": 3}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.5472412109375, "y1": 159.24154663085938, "x1": 71.99998474121094, "y2": 201.10906982421875}, "imageText": ["L2", "sentence", "83.91", "84.86", "84.39", "45.91", "78.93", "66.73", "57.18", "78.45", "70.59", "Chollampatt", "and", "Ng", "(2018)", "84.98", "85.13", "85.06", "53.06", "80.06", "70.08", "62.05", "79.26", "72.90", "Zhao", "et", "al.", "(2019)", "86.10", "85.85", "85.98", "58.73", "80.56", "72.49", "65.39", "80.09", "74.66", "L1", "sentence", "92.28", "89.60", "90.92", "86.08", "85.72", "85.85", "89.64", "85.48", "87.02", "Node", "Edge", "All", "Node", "Edge", "All", "Node", "Edge", "All", "Test", "Data", "Standard", "Error-oriented", "Node-relaxed"], "regionBoundary": {"x2": 507.0, "y1": 65.8900146484375, "x1": 90.0, "y2": 146.8900146484375}, "caption": "Table 6: Results of SMATCH scores compared to I-silver. Chollampatt and Ng (2018) and Zhao et al. (2019) mean the revised sentences with GEC models introduced in the two studies. \u201cError-oriented\u201d means only focusing on the parts aligned to grammatical errors in I-silver. \u201cNode-relaxed\u201d is an error-oriented metric that relax the standards of matching nodes.", "page": 8}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 290.2710266113281, "y1": 391.1535339355469, "x1": 72.0, "y2": 444.9769592285156}, "imageText": ["L-silver", "vs.", "I-silver", "L2-predicted", "vs.", "I-silver", "L2-predicted", "vs.", "L-silver", "95", "90", "1", "2", "3", "4-6", "7-10", "11-15", ">", "15"], "regionBoundary": {"x2": 286.0, "y1": 269.8900146484375, "x1": 79.11799621582031, "y2": 374.7320251464844}, "caption": "Figure 6: Overall SMATCH scores with regard to the distance from errors. L-silver and I-silver mean the silver standards of literal and intended meanings, respectively. L2-predicted refers to the predicted semantic graphs produced by neural parsers on L2 sentences.", "page": 8}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.2642822265625, "y1": 110.4645767211914, "x1": 72.0, "y2": 128.42205810546875}, "imageText": ["86.27", "86.68", "86.48", "Node", "Edge", "All"], "regionBoundary": {"x2": 232.0, "y1": 62.8900146484375, "x1": 133.0, "y2": 97.8900146484375}, "caption": "Table 2: SMATCH scores between the parallel meaning representations.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.919942220052, "y1": 550.4979875352648, "x1": 426.7707824707031, "y2": 608.6485968695746}, "name": "1", "caption_text": "Figure 1: A plausible syntactic analysis of give a topic and then discussion about it. The example is from the TLE corpus. The corrected counterpart of this fragment in TLE is Give a topic and then discuss it.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 398.0, "x1": 446.0, "y2": 529.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268934461805, "y1": 265.4549916585286, "x1": 100.0, "y2": 340.20987616644965}, "name": "2", "caption_text": "Figure 2: Semantic analysis of the fragment give a topic and then discussion about it, where the contrastive parts are colored. The analysis is based on English Resource Semantics. Nodes represent concepts, while edges represent semantic dependencies. Following morphosyntax, \u201cdiscussion\u201d acts as the conjunct of the previous noun \u201ctopic\u201d. However, according to discourse, it should be juxtaposed with the verb \u201cgive\u201d because these are two successive actions.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 114.0, "y2": 241.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 504.0271335177951, "x1": 426.772223578559, "y2": 611.9901869032118}, "name": "1", "caption_text": "Table 1: Results of reranking. \u201cTop-1\u201d means the most preferable graph generated by the ACE parser. \u201cRerank (50)\u201d and \u201cRerank (500)\u201d means thatK is set to 50 and 500 during reranking respectively. \u201cOracle\u201d means directly selecting the best-performing graph for each sentence from the K-best list. The inter-annotator agreement of EDM is reported in Bender et al. (2015).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 291.0, "x1": 441.0, "y2": 487.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.14483642578125, "y1": 153.42302322387695, "x1": 100.0, "y2": 178.3639695909288}, "name": "2", "caption_text": "Table 2: SMATCH scores between the parallel meaning representations.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 336.0, "y1": 86.0, "x1": 184.0, "y2": 153.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 275.8424123128255, "x1": 426.772223578559, "y2": 350.5972968207465}, "name": "4", "caption_text": "Figure 4: The network architecture for the factorization-based parser. Textual embeddings (in red) are used to identify concepts and also to determine dependency relations together with the resulted conceptual embeddings (in yellow).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 92.0, "x1": 426.0, "y2": 249.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15365261501734, "y1": 330.5299123128255, "x1": 99.99996821085611, "y2": 504.9111684163411}, "name": "3", "caption_text": "Figure 3: An SHRG-based syntactico-semantic derivation from the composition-based parser. Each phrase in the syntactic tree (\u201cand then\u201d and \u201cdiscussion about it\u201d) is assigned with a sub-graph of the final semantic structure, as illustrated in the boxes. Some particular nodes (filled nodes) in a sub-graph are marked as communication channels to other meaning parts. According to the construction rule (shown in double-framed box), we glue the two sub-parts via the filled nodes, forming a larger graph with the syntactic label \u201cNP\u201d. More details are illustrated in Chen et al. (2019)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 392.0, "y1": 90.0, "x1": 108.0, "y2": 309.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9237569173176, "y1": 228.01467047797308, "x1": 100.0, "y2": 269.559817843967}, "name": "3", "caption_text": "Table 3: SMATCH scores of semantic parsing on different test data. Henceforth, LEX, CXG and FAC refer to lexicalized and constructional composition-based parsers and the factorization-based parser, respectively. \u2206 refers to the gap between L1 and L2.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 665.0, "y1": 86.0, "x1": 173.0, "y2": 228.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1558142768012, "y1": 466.77992078993054, "x1": 99.99995761447482, "y2": 543.6096615261501}, "name": "4", "caption_text": "Table 4: X refers to error-ignored (\u03c3k = 0 when the kth triple in Gg is involved with errors, \u03c3k = 1 otherwise) SMATCH scores while \u00d7 refers to error-oriented (\u03c3k = 1 when the kth triple in Gg is involved with errors, \u03c3k = 0 otherwise) SMATCH scores.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 367.0, "y1": 301.0, "x1": 137.0, "y2": 467.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 332.9549577501085, "x1": 100.0, "y2": 374.50146145290796}, "name": "5", "caption_text": "Figure 5: Overall SMATCH scores with regard to different grammatical error types. Detailed descriptions of errors are provided in Ng et al. (2014).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 394.0, "y1": 87.0, "x1": 104.0, "y2": 311.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 481.7813025580512, "x1": 100.0, "y2": 506.72221713595917}, "name": "5", "caption_text": "Table 5: Performances of the two GEC models on CoNLL-2014 test set.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 375.0, "y1": 398.0, "x1": 139.0, "y2": 482.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 221.16881476508246, "x1": 99.99997880723741, "y2": 279.31815253363715}, "name": "6", "caption_text": "Table 6: Results of SMATCH scores compared to I-silver. Chollampatt and Ng (2018) and Zhao et al. (2019) mean the revised sentences with GEC models introduced in the two studies. \u201cError-oriented\u201d means only focusing on the parts aligned to grammatical errors in I-silver. \u201cNode-relaxed\u201d is an error-oriented metric that relax the standards of matching nodes.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 86.0, "x1": 113.0, "y2": 221.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1542036268446, "y1": 543.268797132704, "x1": 100.0, "y2": 618.0235544840494}, "name": "6", "caption_text": "Figure 6: Overall SMATCH scores with regard to the distance from errors. L-silver and I-silver mean the silver standards of literal and intended meanings, respectively. L2-predicted refers to the predicted semantic graphs produced by neural parsers on L2 sentences.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 374.0, "x1": 110.0, "y2": 521.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/cfe2d6fb0fc27bb8705e37bf1cf9f56903371fd8/2020.acl-main.606.pdf", "dpi": 100}