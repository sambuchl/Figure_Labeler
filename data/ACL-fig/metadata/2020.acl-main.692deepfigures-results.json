{"raw_detected_boxes": [[{"x2": 710.0, "y1": 308.0, "x1": 446.0, "y2": 567.0}], [], [{"x2": 704.0, "y1": 90.0, "x1": 124.0, "y2": 374.0}], [{"x2": 390.0, "y1": 92.0, "x1": 112.0, "y2": 363.0}, {"x2": 707.0, "y1": 757.0, "x1": 450.0, "y2": 1011.0}], [{"x2": 721.0, "y1": 86.0, "x1": 106.0, "y2": 373.0}], [{"x2": 352.0, "y1": 86.0, "x1": 148.0, "y2": 171.0}, {"x2": 727.0, "y1": 86.0, "x1": 430.0, "y2": 186.0}], [{"x2": 398.0, "y1": 101.0, "x1": 105.0, "y2": 295.0}, {"x2": 731.0, "y1": 911.0, "x1": 429.0, "y2": 1002.0}], [{"x2": 644.0, "y1": 86.0, "x1": 192.0, "y2": 196.0}, {"x2": 711.0, "y1": 247.0, "x1": 430.0, "y2": 341.0}], [], [], [], [], [], [{"x2": 689.0, "y1": 86.0, "x1": 431.0, "y2": 327.0}], [{"x2": 640.0, "y1": 477.0, "x1": 190.0, "y2": 631.0}], [{"x2": 608.0, "y1": 176.0, "x1": 218.0, "y2": 967.0}], [{"x2": 612.0, "y1": 168.0, "x1": 218.0, "y2": 957.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.8552856445312, "y1": 422.39654541015625, "x1": 307.2760009765625, "y2": 452.3089904785156}, "imageText": ["it", "koran", "subtitles", "medical", "law"], "regionBoundary": {"x2": 512.0, "y1": 221.8900146484375, "x1": 321.0, "y2": 409.8900146484375}, "caption": "Figure 1: A 2D visualization of average-pooled BERT hidden-state sentence representations using PCA. The colors represent the domain for each sentence.", "page": 0}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.2001342773438, "y1": 141.19552612304688, "x1": 306.9670104980469, "y2": 183.06402587890625}, "imageText": ["All", "53.3", "57.2", "20.9", "42.1", "27.6", "IT", "14.9", "9.6", "2.8", "43", "8.6", "Subtitles", "7.9", "5.5", "6.4", "8.5", "27.3", "Law", "21.7", "59", "2.7", "13.1", "5.4", "Koran", "0.1", "0.2", "15.9", "0.2", "0.5", "Medical", "Law", "Koran", "IT", "Subtitles", "Medical", "56.5", "18.3", "1.9", "11.4", "4.3"], "regionBoundary": {"x2": 523.0, "y1": 61.8900146484375, "x1": 309.0, "y2": 133.8900146484375}, "caption": "Table 4: SacreBLEU (Post, 2018) scores of our baseline systems on the test sets of the new data split. Each row represents the results from one model on each test set. The best result in each column is marked in bold.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 290.27044677734375, "y1": 137.30355834960938, "x1": 71.69100189208984, "y2": 155.26202392578125}, "imageText": ["Koran", "533,128", "17,982", "Subtitles", "22,508,639", "14,458,058", "Law", "715,372", "467,309", "IT", "378,477", "222,927", "Original", "New", "Split", "Medical", "1,104,752", "248,099"], "regionBoundary": {"x2": 256.0, "y1": 61.8900146484375, "x1": 107.0, "y2": 124.8900146484375}, "caption": "Table 3: Number of training examples for each domain in the original split (Mu\u0308ller et al., 2019) and in our split.", "page": 5}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 448.0926513671875, "y1": 467.1585388183594, "x1": 149.14500427246094, "y2": 473.1610107421875}, "imageText": ["Medical", "571/2000", "(28.55%)", "516/1691", "(30.51%)", "0/2000", "Koran", "0/2000", "1949/2000", "(97.45%)", "0/2000", "Subtitles", "451/5000", "(9.02%)", "478/2000", "(23.9%)", "0/2000", "Law", "649/2000", "(32.45%)", "966/2000", "(48.3%)", "0/2000", "IT", "945/1856", "(50.92%)", "1036/2000", "(51.8%)", "0/2000", "%", "test", "in", "train", "Medical", "1090/2000", "(54.5%)", "1204/2000", "(60.2%)", "0/2000", "Koran", "0/2000", "1926/2000", "(96.3)", "0/2000", "Subtitles", "1183/5000", "(23.66%)", "638/2000", "(31.9%)", "0/2000", "Law", "595/2000", "(29.75%)", "1000/2000", "(50%)", "0/2000", "IT", "2496/2526", "(98.81%)", "783/2000", "(39.15%)", "0/2000", "%", "dev", "in", "train", "Koehn", "and", "Knowles", "(2017)", "Mu\u0308ller", "et", "al.", "(2019)", "New", "Split"], "regionBoundary": {"x2": 462.0, "y1": 343.8900146484375, "x1": 135.0, "y2": 454.8900146484375}, "caption": "Table 8: Details about the different data splits for the multi-domain corpus.", "page": 14}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 292.0140686035156, "y1": 223.46255493164062, "x1": 72.0, "y2": 253.37506103515625}, "imageText": [], "regionBoundary": {"x2": 288.0, "y1": 65.8900146484375, "x1": 75.0, "y2": 212.8900146484375}, "caption": "Figure 4: The cosine similarity between the centroids of the BERT representations for each domain pair vs. the corresponding cross-domain BLEU.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.54638671875, "y1": 729.466552734375, "x1": 306.947021484375, "y2": 759.3790283203125}, "imageText": ["Koran", "0.966", "0.958", "0.962", "0.994", "0.974", "0.984", "Subtitles", "0.722", "0.984", "0.833", "0.964", "0.978", "0.971", "Law", "0.761", "0.94", "0.841", "0.944", "0.94", "0.942", "Medical", "0.821", "0.916", "0.866", "0.929", "0.92", "0.925", "IT", "0.848", "0.956", "0.898", "0.955", "0.98", "0.967", "without", "pre-ranking", "with", "pre-ranking", "p", "r", "F1", "p", "r", "F1"], "regionBoundary": {"x2": 527.0, "y1": 653.8900146484375, "x1": 309.0, "y2": 721.8900146484375}, "caption": "Table 5: Ablation analysis showing precision (p) recall (r) and F1 for the binary classification accuracy on a held-out set, with and without pre-ranking.", "page": 6}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 526.7918090820312, "y1": 245.22256469726562, "x1": 307.2760009765625, "y2": 275.13507080078125}, "imageText": ["--arch", "transformer_wmt_en_de", "\\", "--share-all-embeddings", "\\", "--optimizer", "adam", "\\", "--adam-betas", "\u2019(0.9,", "0.98)\u2019", "\\", "--clip-norm", "1.0", "\\", "--lr", "0.0005", "\\", "--lr-scheduler", "inverse_sqrt", "\\", "--warmup-updates", "4000", "\\", "--warmup-init-lr", "1e-07", "\\", "--dropout", "0.2", "\\", "--weight-decay", "0.0", "\\", "--criterion", "label_smoothed_cross_entropy", "\\", "--label-smoothing", "0.1", "\\", "--max-tokens", "4096", "\\", "--update-freq", "5", "\\", "--attention-dropout", "0.2", "\\", "--activation-dropout", "0.2", "\\", "--max-epoch", "200", "\\", "--seed", "17", "\\", "-s", "$src", "\\", "-t", "$tgt", "\\", "--save-dir", "$MODEL_PATH", "\\", "--save-interval-updates", "10000", "\\", "--validate-interval", "1"], "regionBoundary": {"x2": 465.0840148925781, "y1": 77.40771484375, "x1": 314.4490051269531, "y2": 240.93902587890625}, "caption": "Figure 5: The hyperparameter configuration we used for NMT model training using Fairseq (Ott et al., 2019).", "page": 13}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5472412109375, "y1": 264.3895568847656, "x1": 71.69100189208984, "y2": 282.3470458984375}, "imageText": ["word2vec", "53.65", "(\u00b10.79)", "68.14", "(\u00b12.58)", "73.44", "(\u00b10.68)", "45.93", "65.80", "76.26", "BERT-base", "87.66", "(\u00b10.24)", "88.02", "(\u00b11.10)", "88.37", "(\u00b10.66)", "85.74", "85.08", "86.37", "BERT-large", "85.64", "(\u00b16.13)", "87.61", "(\u00b10.26)", "89.07", "(\u00b10.53)", "68.56", "86.53", "86.99", "DistillBERT", "83.68", "(\u00b17.14)", "86.31", "(\u00b10.86)", "87.53", "(\u00b10.85)", "79.00", "86.42", "88.14", "RoBERTa-base", "79.05", "(\u00b10.10)", "86.39", "(\u00b10.90)", "86.51", "(\u00b10.28)", "70.21", "80.35", "81.49", "RoBERTa-large", "80.61", "(\u00b10.33)", "89.04", "(\u00b10.15)", "89.94", "(\u00b10.23)", "69.88", "81.07", "85.91", "GPT-2", "70.30", "(\u00b10.05)", "84.76", "(\u00b10.30)", "82.56", "(\u00b11.29)", "37.82", "39.02", "41.45", "XLNet", "55.72", "(\u00b10.69)", "68.17", "(\u00b13.93)", "72.65", "(\u00b11.92)", "30.36", "32.96", "48.55", "with", "PCA", "(n=50)", "without", "PCA", "k=5", "k=10", "k=15", "k=5", "k=10", "k=15", "k=5", "k=10", "k=15", "Random", "15.08", "(\u00b10.0)", "16.77", "(\u00b10.0)", "17.78", "(\u00b10.0)", "LDA", "24.31", "(\u00b10.99)", "26.73", "(\u00b12.19)", "30.79", "(\u00b12.97)"], "regionBoundary": {"x2": 506.0, "y1": 61.8900146484375, "x1": 92.0, "y2": 256.8900146484375}, "caption": "Table 1: Unsupervised domain clustering as measured by purity for the different models. Best results are marked in bold for each setting.", "page": 2}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 518.1001586914062, "y1": 157.62753295898438, "x1": 79.13800048828125, "y2": 163.6300048828125}, "imageText": ["Medical", "Law", "Koran", "IT", "Subtitles", "Average", "Random-500k", "49.8", "53.3", "18.5", "37.5", "25.5", "36.92", "Moore-Lewis-Top-500k", "55", "58", "21.4", "42.7", "27.3", "40.88", "Domain-Cosine-Top-500k", "52.7", "58", "22", "42.5", "27.1", "40.46", "Domain-Finetune-Top-500k", "54.8", "58.8", "21.8", "43.5", "27.4", "41.26", "Domain-Finetune-Positive", "55.3", "58.7", "19.2", "42.5", "27", "40.54", "Oracle", "56.5", "59", "15.9", "43", "27.3", "40.34", "All", "53.3", "57.2", "20.9", "42.1", "27.6", "40.22"], "regionBoundary": {"x2": 464.0, "y1": 61.8900146484375, "x1": 134.0, "y2": 145.8900146484375}, "caption": "Table 6: SacreBLEU scores for the data selection experiments. Highest scores per column are marked in bold.", "page": 7}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.5463256835938, "y1": 263.7115173339844, "x1": 306.9670104980469, "y2": 281.66998291015625}, "imageText": ["Koran", "0.35", "0.985", "0.36", "0.989", "0.36", "0.998", "IT", "0.441", "0.985", "0.382", "0.857", "0.447", "0.998", "Subtitles", "0.899", "0.899", "0.916", "0.916", "0.957", "0.957", "Average", "0.6", "0.944", "0.578", "0.89", "0.63", "0.979", "Medical", "0.476", "0.955", "0.391", "0.788", "0.485", "0.975", "Law", "0.836", "0.894", "0.841", "0.899", "0.902", "0.965", "Moore-Lewis", "D-Cosine", "D-Finetune", "p", "r", "p", "r", "p", "r"], "regionBoundary": {"x2": 523.0, "y1": 176.8900146484375, "x1": 310.0, "y2": 251.8900146484375}, "caption": "Table 7: Precision (p) and recall (r) for data selection of 500k sentences with respect to the oracle selection.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5465087890625, "y1": 741.4215698242188, "x1": 307.2760009765625, "y2": 759.3790283203125}, "imageText": ["bert-base-uncased", "it", "koran", "subtitles", "medical", "law"], "regionBoundary": {"x2": 509.0, "y1": 526.9840087890625, "x1": 324.0, "y2": 729.8900146484375}, "caption": "Figure 3: A 2D visualization of the unsupervised GMM clustering for the same sentences as in Figure 1.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.2705993652344, "y1": 274.9915466308594, "x1": 72.0, "y2": 292.94903564453125}, "imageText": ["206", "0", "10", "58", "1726", "340", "0", "82", "1413", "165", "47", "21", "1918", "9", "5", "l", "1927", "0", "55", "16", "2", "4", "1767", "225", "0", "4", "la", "be", "Tr", "ue", "law", "medical", "subtitles", "koran", "it", "Predicted", "label", "al", "law", "me", "dic", "es", "sub", "titl", "it", "kor", "an"], "regionBoundary": {"x2": 282.0, "y1": 66.8900146484375, "x1": 84.48231506347656, "y2": 262.1553955078125}, "caption": "Figure 2: A confusion matrix for clustering with k=5 using BERT-base.", "page": 3}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 525.5471801757812, "y1": 709.611572265625, "x1": 72.0, "y2": 727.5689697265625}, "imageText": ["gpt2", "it", "koran", "subtitles", "medical", "law", "xlnet-base-cased", "it", "koran", "subtitles", "medical", "law"], "regionBoundary": {"x2": 440.0, "y1": 116.07948303222656, "x1": 157.0, "y2": 690.8900146484375}, "caption": "Figure 7: 2D visualizations of the unsupervised GMM-based clustering for different pretrained auto-regressive LMs.", "page": 16}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 524.1417236328125, "y1": 280.7655334472656, "x1": 73.09500122070312, "y2": 286.76800537109375}, "imageText": ["Push", "it", "up", "to", "the", "front", "of", "the", "screen.", "Statutes,", "transcripts,", "redacted", "immunity", "agreements.", "Polyalloy", "requires", "programming", "to", "take", "permanent", "The", "Security", "Council", "therefore", "must", "press", "for", "his", "immediate", "form.", "referral", "to", "the", "International", "Criminal", "Court", "in", "The", "Hague.", "Law", "assigned", "to", "Medical", "Law", "assigned", "to", "IT", "-", "Viruses", "and", "virus-like", "organisms", "\u201dINFORMATION", "SOCIETY", "STATISTICS", "where", "the", "glucose", "content", "is", "equal", "to", "or", "less", "than", "This", "document", "must", "be", "attached", "to", "the", "certi\ufb01cate", "and", "\ufb01eld", "the", "fructose", "content.", "with", "it,", "except", "where", "there", "is", "a", "computerised", "checking", "system.", "Medical", "assigned", "to", "Law", "Medical", "assigned", "to", "IT", "This", "will", "be", "introduced", "by", "a", "Regulation", "adopted", "by", "the", "An", "updated", "and", "improved", "version", "of", "the", "CD-ROM", "was", "issued", "European", "Commission.", "to", "all", "subscribers", "during", "the", "\ufb01rst", "half", "of", "the", "year.", "The", "marketing", "authorisation", "was", "renewed", "on", "22", "May", "-", "All", "tables", "will", "be", "based", "on", "generic", "and", "not", "product-speci\ufb01c", "2002", "and", "22", "May", "2007.", "data.", "IT", "assigned", "to", "Medical", "IT", "assigned", "to", "Subtitles", "R65:", "Harmful:", "may", "cause", "lung", "damage", "if", "swallowed", "At", "the", "end", "we", "say", "good", "bye.", "Automatic", "Red-Eye", "Removal", "What", "would", "you", "like", "to", "do", "for", "your", "next", "shot?", "with", "this.", "Subtitles", "assigned", "to", "IT", "Subtitles", "assigned", "to", "Law", "Subtitles", "assigned", "to", "Koran", "Subtitles", "assigned", "to", "Medical", "I", "am", "Spa\u2019am,", "high", "priest", "of", "the", "boars.", "Oxygen", "supply", "at", "50%.", "Joseph,", "go", "in", "peace,", "and", "the", "Lord", "be", "with", "you.", "Or", "it", "can", "help", "her", "walk", "again", "if", "the", "virus", "is", "kept", "in", "check"], "regionBoundary": {"x2": 522.0, "y1": 63.8900146484375, "x1": 76.0, "y2": 268.8900146484375}, "caption": "Table 2: Sentences from one domain which were assigned to another domain by the BERT-based clustering, k=5.", "page": 4}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 504.11712646484375, "y1": 715.5885620117188, "x1": 93.42900085449219, "y2": 721.5910034179688}, "imageText": ["roberta-large", "it", "koran", "subtitles", "medical", "law", "bert-large-cased", "it", "koran", "subtitles", "medical", "law"], "regionBoundary": {"x2": 440.0, "y1": 122.05751037597656, "x1": 157.0, "y2": 696.8900146484375}, "caption": "Figure 6: 2D visualizations of the unsupervised GMM-based clustering for different pretrained MLMs.", "page": 15}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 730.3545633951823, "y1": 586.661868625217, "x1": 426.772223578559, "y2": 628.2069312201605}, "name": "1", "caption_text": "Figure 1: A 2D visualization of average-pooled BERT hidden-state sentence representations using PCA. The colors represent the domain for each sentence.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 308.0, "x1": 446.0, "y2": 570.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 367.2077178955078, "x1": 99.57083596123589, "y2": 392.148674858941}, "name": "1", "caption_text": "Table 1: Unsupervised domain clustering as measured by purity for the different models. Best results are marked in bold for each setting.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 86.0, "x1": 107.0, "y2": 391.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 381.9327036539713, "x1": 100.0, "y2": 406.8736606174045}, "name": "2", "caption_text": "Figure 2: A confusion matrix for clustering with k=5 using BERT-base.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 392.0, "y1": 92.0, "x1": 112.0, "y2": 365.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 1029.7521803114148, "x1": 426.772223578559, "y2": 1054.693094889323}, "name": "3", "caption_text": "Figure 3: A 2D visualization of the unsupervised GMM clustering for the same sentences as in Figure 1.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 707.0, "y1": 744.0, "x1": 450.0, "y2": 1013.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 727.974616156684, "y1": 389.9521297878689, "x1": 101.52083502875433, "y2": 398.28889634874133}, "name": "2", "caption_text": "Table 2: Sentences from one domain which were assigned to another domain by the BERT-based clustering, k=5.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 86.0, "x1": 102.0, "y2": 390.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15339830186633, "y1": 190.6993865966797, "x1": 99.57083596123589, "y2": 215.6416998969184}, "name": "3", "caption_text": "Table 3: Number of training examples for each domain in the original split (Mu\u0308ller et al., 2019) and in our split.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 355.0, "y1": 86.0, "x1": 148.0, "y2": 174.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.222408718533, "y1": 196.10489739312067, "x1": 426.3430701361762, "y2": 254.2555914984809}, "name": "4", "caption_text": "Table 4: SacreBLEU (Post, 2018) scores of our baseline systems on the test sets of the new data split. Each row represents the results from one model on each test set. The best result in each column is marked in bold.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 86.0, "x1": 426.0, "y2": 203.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.5750952826606, "y1": 310.3646596272786, "x1": 100.0, "y2": 351.9098069932726}, "name": "4", "caption_text": "Figure 4: The cosine similarity between the centroids of the BERT representations for each domain pair vs. the corresponding cross-domain BLEU.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 403.0, "y1": 99.0, "x1": 100.0, "y2": 312.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925537109375, "y1": 1013.1479899088541, "x1": 426.3153076171875, "y2": 1054.693094889323}, "name": "5", "caption_text": "Table 5: Ablation analysis showing precision (p) recall (r) and F1 for the binary classification accuracy on a held-out set, with and without pre-ranking.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 894.0, "x1": 426.0, "y2": 1019.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 719.5835537380642, "y1": 218.9271291097005, "x1": 109.91388956705728, "y2": 227.2638956705729}, "name": "6", "caption_text": "Table 6: SacreBLEU scores for the data selection experiments. Highest scores per column are marked in bold.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 644.0, "y1": 86.0, "x1": 186.0, "y2": 202.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9254523383246, "y1": 366.2659962972005, "x1": 426.3430701361762, "y2": 391.2083095974392}, "name": "7", "caption_text": "Table 7: Precision (p) and recall (r) for data selection of 500k sentences with respect to the oracle selection.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 245.0, "x1": 430.0, "y2": 349.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 731.6552903917101, "y1": 340.5868954128689, "x1": 426.772223578559, "y2": 382.13204277886285}, "name": "5", "caption_text": "Figure 5: The hyperparameter configuration we used for NMT model training using Fairseq (Ott et al., 2019).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 706.0, "y1": 86.0, "x1": 427.0, "y2": 344.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 622.3509046766493, "y1": 648.831303914388, "x1": 207.14583926730685, "y2": 657.1680704752604}, "name": "8", "caption_text": "Table 8: Details about the different data splits for the multi-domain corpus.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 642.0, "y1": 477.0, "x1": 188.0, "y2": 648.0}, "page": 14, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 700.1626756456163, "y1": 993.8730027940538, "x1": 129.7625011867947, "y2": 1002.209726969401}, "name": "6", "caption_text": "Figure 6: 2D visualizations of the unsupervised GMM-based clustering for different pretrained MLMs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 612.0, "y1": 169.0, "x1": 218.0, "y2": 968.0}, "page": 15, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9266391330295, "y1": 985.5716281467013, "x1": 100.0, "y2": 1010.512457953559}, "name": "7", "caption_text": "Figure 7: 2D visualizations of the unsupervised GMM-based clustering for different pretrained auto-regressive LMs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 612.0, "y1": 161.0, "x1": 218.0, "y2": 959.0}, "page": 16, "dpi": 0}], "error": null, "pdf": "/work/host-output/2549d261f537d30486dc8e86e086e201dde8e1ac/2020.acl-main.692.pdf", "dpi": 100}