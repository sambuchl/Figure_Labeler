{"raw_detected_boxes": [[], [], [], [{"x2": 396.0, "y1": 92.0, "x1": 105.0, "y2": 241.0}], [], [{"x2": 723.0, "y1": 90.0, "x1": 107.0, "y2": 330.0}, {"x2": 730.0, "y1": 401.0, "x1": 101.0, "y2": 621.0}], [{"x2": 397.0, "y1": 768.0, "x1": 106.0, "y2": 888.0}], [{"x2": 721.0, "y1": 86.0, "x1": 437.0, "y2": 304.0}, {"x2": 400.0, "y1": 95.0, "x1": 104.0, "y2": 387.0}, {"x2": 410.0, "y1": 501.0, "x1": 100.0, "y2": 636.0}], [{"x2": 699.0, "y1": 93.0, "x1": 129.0, "y2": 284.0}, {"x2": 396.0, "y1": 349.0, "x1": 104.0, "y2": 796.0}], [], [], [], [], [{"x2": 677.0, "y1": 385.0, "x1": 146.0, "y2": 725.0}]], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Table", "boundary": {"x2": 280.4909973144531, "y1": 473.66253662109375, "x1": 81.7770004272461, "y2": 479.6650085449219}, "text": "Table 4: Comparison between SMART and MTL.", "name": "4", "page": 7}], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5473022460938, "y1": 254.66354370117188, "x1": 72.0, "y2": 272.62103271484375}, "imageText": ["RoBERTaLARGE", "RoBERTa", "(Liu", "et", "al.,", "2019c)", "90.2/-", "92.2/-", "86.6", "94.7", "-/90.9", "68.0", "96.4", "92.4/-", "PGD", "(Zhu", "et", "al.,", "2020)", "90.5/-", "92.5/-", "87.4", "94.9", "-/90.9", "69.7", "96.4", "92.4/-", "FreeAT", "(Zhu", "et", "al.,", "2020)", "90.0/-", "92.5/-", "86.7", "94.7", "-/90.7", "68.8", "96.1", "92.4/-", "FreeLB", "(Zhu", "et", "al.,", "2020)", "90.6/-", "92.6/-", "88.1", "95.0", "-/91.4", "71.1", "96.7", "92.7/-", "SMARTRoBERTa", "91.1/91.3", "92.4/89.8", "92.0", "95.6", "89.2/92.1", "70.6", "96.9", "92.8/92.6", "BERTBASE", "BERT", "(Devlin", "et", "al.,", "2019)", "84.4/-", "-", "-", "88.4", "-/86.7", "-", "92.7", "-", "BERTReImp", "84.5/84.4", "90.9/88.3", "63.5", "91.1", "84.1/89.0", "54.7", "92.9", "89.2/88.8", "SMARTBERT", "85.6/86.0", "91.5/88.5", "71.2", "91.7", "87.7/91.3", "59.1", "93.0", "90.0/89.4", "Model", "MNLI-m/mm", "QQP", "RTE", "QNLI", "MRPC", "CoLA", "SST", "STS-B", "Acc", "Acc/F1", "Acc", "Acc", "Acc/F1", "Mcc", "Acc", "P/S", "Corr"], "regionBoundary": {"x2": 520.0, "y1": 63.8900146484375, "x1": 77.0, "y2": 237.8900146484375}, "caption": "Table 1: Main results on GLUE development set. The best result on each task produced by a single model is in bold and \u201c-\u201d denotes the missed result.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5472412109375, "y1": 465.18353271484375, "x1": 71.9999008178711, "y2": 542.91796875}, "imageText": ["Model", "/#Train", "CoLA", "SST", "MRPC", "STS-B", "QQP", "MNLI-m/mm", "QNLI", "RTE", "WNLI", "AX", "Score", "#param", "8.5k", "67k", "3.7k", "7k", "364k", "393k", "108k", "2.5k", "634", "Human", "Performance", "66.4", "97.8", "86.3/80.8", "92.7/92.6", "59.5/80.4", "92.0/92.8", "91.2", "93.6", "95.9", "-", "87.1", "-", "Ensemble", "Models", "RoBERTa1", "67.8", "96.7", "92.3/89.8", "92.2/91.9", "74.3/90.2", "90.8/90.2", "98.9", "88.2", "89.0", "48.7", "88.5", "356M", "FreeLB2", "68.0", "96.8", "93.1/90.8", "92.4/92.2", "74.8/90.3", "91.1/90.7", "98.8", "88.7", "89.0", "50.1", "88.8", "356M", "ALICE3", "69.2", "97.1", "93.6/91.5", "92.7/92.3", "74.4/90.7", "90.7/90.2", "99.2", "87.3", "89.7", "47.8", "89.0", "340M", "ALBERT4", "69.1", "97.1", "93.4/91.2", "92.5/92.0", "74.2/90.5", "91.3/91.0", "99.2", "89.2", "91.8", "50.2", "89.4", "235M\u2217", "MT-DNN-SMART\u2020", "69.5", "97.5", "93.7/91.6", "92.9/92.5", "73.9/90.2", "91.0/90.8", "99.2", "89.7", "94.5", "50.2", "89.9", "356M", "Single", "Model", "BERTLARGE5", "60.5", "94.9", "89.3/85.4", "87.6/86.5", "72.1/89.3", "86.7/85.9", "92.7", "70.1", "65.1", "39.6", "80.5", "335M", "MT-DNN6", "62.5", "95.6", "90.0/86.7", "88.3/87.7", "72.4/89.6", "86.7/86.0", "93.1", "75.5", "65.1", "40.3", "82.7", "335M", "T58", "70.8", "97.1", "91.9/89.2", "92.5/92.1", "74.6/90.4", "92.0/91.7", "96.7", "92.5", "93.2", "53.1", "89.7", "11,000M", "SMARTRoBERTa", "65.1", "97.5", "93.7/91.6", "92.9/92.5", "74.0/90.1", "91.0/90.8", "95.4", "87.9", "91.88", "50.2", "88.4", "356M"], "regionBoundary": {"x2": 527.0, "y1": 288.8900146484375, "x1": 72.0, "y2": 447.8900146484375}, "caption": "Table 2: GLUE test set results scored using the GLUE evaluation server. The state-of-the-art results are in bold. All the results were obtained from https://gluebenchmark.com/leaderboard on December 5, 2019. SMART uses the classification objective on QNLI. Model references: 1 Liu et al. (2019c); 2Zhu et al. (2020); 3Wang et al. (2019); 4Lan et al. (2019); 5 Devlin et al. (2019); 6 Liu et al. (2019b); 7 Raffel et al. (2019) and 8 He et al. (2019), Kocijan et al. (2019). \u2217 ALBERT uses a model similar in size, architecture and computation cost to a 3,000M BERT (though it has dramatically fewer parameters due to parameter sharing). \u2020 Mixed results from ensemble and single of MT-DNN-SMART and with data augmentation.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 290.2705383300781, "y1": 651.8446044921875, "x1": 72.0, "y2": 681.7579956054688}, "imageText": ["BERT", "84.5", "63.5", "91.1", "92.9", "89.0", "SMART", "85.6", "71.2", "91.7", "93.0", "91.3", "-Rs", "84.8", "70.8", "91.3", "92.8", "90.8", "-DBreg", "85.4", "71.2", "91.6", "92.9", "91.2", "Model", "MNLI", "RTE", "QNLI", "SST", "MRPC", "Acc", "Acc", "Acc", "Acc", "Acc"], "regionBoundary": {"x2": 286.0, "y1": 552.8900146484375, "x1": 76.0, "y2": 639.8900146484375}, "caption": "Table 3: Ablation study of SMART on 5 GLUE tasks. Note that all models used the BERTBASE model as their encoder.", "page": 6}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 452.4154968261719, "y1": 539.0885620117188, "x1": 145.12899780273438, "y2": 545.0910034179688}, "imageText": ["Text", "Similarity", "(GLUE)", "STS-B", "Similarity", "7k", "1.5k", "1.4k", "1", "Pearson/Spearman", "corr", "Pairwise", "Text", "Classi\ufb01cation", "SNLI", "NLI", "549k", "9.8k", "9.8k", "3", "Accuracy", "SciTail", "NLI", "23.5k", "1.3k", "2.1k", "2", "Accuracy", "ANLI", "NLI", "163k", "3.2k", "3.2k", "3", "Accuracy", "Pairwise", "Text", "Classi\ufb01cation", "(GLUE)", "MNLI", "NLI", "393k", "20k", "20k", "3", "Accuracy", "RTE", "NLI", "2.5k", "276", "3k", "2", "Accuracy", "WNLI", "NLI", "634", "71", "146", "2", "Accuracy", "QQP", "Paraphrase", "364k", "40k", "391k", "2", "Accuracy/F1", "MRPC", "Paraphrase", "3.7k", "408", "1.7k", "2", "Accuracy/F1", "QNLI", "QA/NLI", "108k", "5.7k", "5.7k", "2", "Accuracy", "Corpus", "Task", "#Train", "#Dev", "#Test", "#Label", "Metrics", "Single-Sentence", "Classi\ufb01cation", "(GLUE)", "CoLA", "Acceptability", "8.5k", "1k", "1k", "2", "Matthews", "corr", "SST", "Sentiment", "67k", "872", "1.8k", "2", "Accuracy"], "regionBoundary": {"x2": 493.0, "y1": 276.8900146484375, "x1": 105.0, "y2": 521.8900146484375}, "caption": "Table 8: Summary of the four benchmarks: GLUE, SNLI, SciTail and ANLI.", "page": 13}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 515.52783203125, "y1": 236.33255004882812, "x1": 317.2919921875, "y2": 242.33502197265625}, "imageText": ["SciTail", "Dataset", "(Dev", "Accuracy%)", "#Training", "Data", "23", "235", "2,359", "23,596", "BERT", "51.2", "82.2", "90.5", "94.3", "MT-DNN", "81.9", "88.3", "91.1", "95.8", "MT-DNN-SMART", "82.3", "88.6", "91.3", "96.1", "Model", "0.1%", "1%", "10%", "100%", "SNLI", "Dataset", "(Dev", "Accuracy%)", "#Training", "Data", "549", "5,493", "54,936", "549,367", "BERT", "52.5", "78.1", "86.7", "91.0", "MT-DNN", "82.1", "85.2", "88.4", "91.5", "MT-DNN-SMART", "82.7", "86.0", "88.7", "91.6"], "regionBoundary": {"x2": 521.0, "y1": 62.8900146484375, "x1": 312.0, "y2": 218.8900146484375}, "caption": "Table 5: Domain adaptation on SNLI and SciTail.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 284.7053527832031, "y1": 293.4005432128906, "x1": 77.56300354003906, "y2": 299.40301513671875}, "imageText": ["0.77", "0.64", "0.43", "0.08", "0.25", "1.15", "0.94", "0.62", "0.08", "0.35", "All", "5/0/0", "4/1/0", "3/2/0", "3/1/1", "0.76", "0.66", "0.41", "0.08", "0.26", "1.12", "0.97", "0.61", "0.08", "0.36", "ce", "e", "n", "e", "rg", "-D", "iv", "K", "L", "1.50", "1.25", "1.00", "0.75", "0.50", "0.25", "All", "5/0/0", "4/1/0", "3/2/0", "3/1/1", "0.00", "RoBERTa", "SMART", "MNLI", "Mismatch", "76.1", "65.4", "89.2", "97.9", "91.3", "72.1", "63.4", "87.1", "97.4", "90.1", "MNLI", "Match", "70.7", "67.4", "90.7", "97.7", "91.1", "68.0", "69.7", "95", "100", "A", "cc", "u", "ra", "cy", "90.6", "97.2", "89.5", "90", "85", "80", "75", "70", "65", "60"], "regionBoundary": {"x2": 288.0, "y1": 66.62004852294922, "x1": 76.18325805664062, "y2": 277.28326416015625}, "caption": "Figure 2: Score breakdown by degree of agreement.", "page": 7}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 290.27056884765625, "y1": 190.09555053710938, "x1": 72.0, "y2": 255.87408447265625}, "imageText": ["(a)", "(b)"], "regionBoundary": {"x2": 287.0, "y1": 66.8900146484375, "x1": 76.0, "y2": 171.342041015625}, "caption": "Figure 1: Decision boundaries learned without (a) and with (b) smoothness-inducing adversarial regularization, respectively. The red dotted line in (b) represents the decision boundary in (a). As can be seen, the output f in (b) does not change much within the neighborhood of training data points.", "page": 3}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 406.16864013671875, "y1": 217.00454711914062, "x1": 191.375, "y2": 223.00701904296875}, "imageText": ["SMARTRoBERTa-LARGE", "74.2", "49.5", "49.2", "57.1", "72.4", "50.3", "49.5", "56.9", "ANLI", "RoBERTaLARGE", "(Nie", "et", "al.,", "2019)", "71.3", "43.3", "43.0", "51.9", "-", "-", "-", "-", "BERTLARGE", "(Nie", "et", "al.,", "2019)", "57.4", "48.3", "43.5", "49.3", "-", "-", "-", "44.2", "XLNetLARGE", "(Nie", "et", "al.,", "2019)", "67.6", "50.7", "48.3", "55.1", "-", "-", "-", "52.0", "RoBERTaLARGE", "(Nie", "et", "al.,", "2019)", "73.8", "48.9", "44.4", "53.7", "-", "-", "-", "49.7", "SMARTRoBERTa-LARGE", "74.5", "50.9", "47.6", "57.1", "72.4", "49.8", "50.3", "57.1", "R1", "R2", "R3", "All", "R1", "R2", "R3", "All", "MNLI", "+", "SNLI", "+", "ANLI", "+", "FEVER", "Method", "Dev", "Test"], "regionBoundary": {"x2": 505.0, "y1": 62.8900146484375, "x1": 93.0, "y2": 204.8900146484375}, "caption": "Table 6: Experiment Result for Each Round of ANLI.", "page": 8}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 279.2860412597656, "y1": 581.6035766601562, "x1": 82.98300170898438, "y2": 587.6060180664062}, "imageText": ["Model", "Dev", "Test", "SNLI", "Dataset", "(Accuracy%)", "BERTBASE", "91.0", "90.8", "BERTBASE+SRL(Zhang", "et", "al.,", "2018)", "-", "90.3", "MT-DNNBASE", "91.4", "91.1", "SMARTBERT-BASE", "91.4", "91.1", "MT-DNN-SMARTBASEv0", "91.7", "91.4", "MT-DNN-SMARTBASE", "91.7", "91.5", "BERTLARGE+SRL(Zhang", "et", "al.,", "2018)", "-", "91.3", "BERTLARGE", "91.7", "91.0", "MT-DNNLARGE", "92.2", "91.6", "MT-DNN-SMARTLARGEv0", "92.6", "91.7", "SciTail", "Dataset", "(Accuracy%)", "GPT", "(Radford", "et", "al.,", "2018)", "-", "88.3", "BERTBASE", "94.3", "92.0", "MT-DNNBASE", "95.8", "94.1", "SMARTBERT-BASE", "94.8", "93.2", "MT-DNN-SMARTBASEv0", "96.0", "94.0", "MT-DNN-SMARTBASE", "96.1", "94.2", "BERTLARGE", "95.7", "94.4", "MT-DNNLARGE", "96.3", "95.0", "SMARTBERT-LARGE", "96.2", "94.7", "MT-DNN-SMARTLARGEv0", "96.6", "95.2"], "regionBoundary": {"x2": 288.0, "y1": 245.8900146484375, "x1": 75.0, "y2": 573.8900146484375}, "caption": "Table 7: Results on the SNLI and SciTail dataset.", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 403.153567843967, "y1": 264.02159796820746, "x1": 100.0, "y2": 355.3806728786892}, "name": "1", "caption_text": "Figure 1: Decision boundaries learned without (a) and with (b) smoothness-inducing adversarial regularization, respectively. The red dotted line in (b) represents the decision boundary in (a). As can be seen, the output f in (b) does not change much within the neighborhood of training data points.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 92.0, "x1": 105.0, "y2": 241.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 353.69936625162757, "x1": 100.0, "y2": 378.64032321506073}, "name": "1", "caption_text": "Table 1: Main results on GLUE development set. The best result on each task produced by a single model is in bold and \u201c-\u201d denotes the missed result.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 86.0, "x1": 107.0, "y2": 330.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 646.0882398817274, "x1": 99.99986224704318, "y2": 754.052734375}, "name": "2", "caption_text": "Table 2: GLUE test set results scored using the GLUE evaluation server. The state-of-the-art results are in bold. All the results were obtained from https://gluebenchmark.com/leaderboard on December 5, 2019. SMART uses the classification objective on QNLI. Model references: 1 Liu et al. (2019c); 2Zhu et al. (2020); 3Wang et al. (2019); 4Lan et al. (2019); 5 Devlin et al. (2019); 6 Liu et al. (2019b); 7 Raffel et al. (2019) and 8 He et al. (2019), Kocijan et al. (2019). \u2217 ALBERT uses a model similar in size, architecture and computation cost to a 3,000M BERT (though it has dramatically fewer parameters due to parameter sharing). \u2020 Mixed results from ensemble and single of MT-DNN-SMART and with data augmentation.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 401.0, "x1": 100.0, "y2": 622.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15352545844183, "y1": 905.3397284613715, "x1": 100.0, "y2": 946.8861050075955}, "name": "3", "caption_text": "Table 3: Ablation study of SMART on 5 GLUE tasks. Note that all models used the BERTBASE model as their encoder.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 397.0, "y1": 768.0, "x1": 100.0, "y2": 905.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 716.0108778211805, "y1": 328.2396528455946, "x1": 440.68332248263886, "y2": 336.576419406467}, "name": "5", "caption_text": "Table 5: Domain adaptation on SNLI and SciTail.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 86.0, "x1": 434.0, "y2": 304.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 395.4241010877821, "y1": 407.5007544623481, "x1": 107.7263938056098, "y2": 415.83752102322046}, "name": "2", "caption_text": "Figure 2: Score breakdown by degree of agreement.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 91.0, "x1": 104.0, "y2": 387.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 389.5708296034071, "y1": 657.8646341959635, "x1": 113.57916726006401, "y2": 666.2014007568359}, "name": "4", "caption_text": "Table 4: Comparison between SMART and MTL.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 418.0, "y1": 484.0, "x1": 100.0, "y2": 641.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 564.1231113009983, "y1": 301.39520433213977, "x1": 265.7986111111111, "y2": 309.73197089301215}, "name": "6", "caption_text": "Table 6: Experiment Result for Each Round of ANLI.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 86.0, "x1": 129.0, "y2": 301.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 387.89727952745227, "y1": 807.7827453613281, "x1": 115.25416904025607, "y2": 816.1194695366753}, "name": "7", "caption_text": "Table 7: Results on the SNLI and SciTail dataset.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 342.0, "x1": 104.0, "y2": 813.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 628.3548567030165, "y1": 748.7341139051649, "x1": 201.56805250379773, "y2": 757.0708380805121}, "name": "8", "caption_text": "Table 8: Summary of the four benchmarks: GLUE, SNLI, SciTail and ANLI.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 684.0, "y1": 384.0, "x1": 146.0, "y2": 725.0}, "page": 13, "dpi": 0}], "error": null, "pdf": "/work/host-output/4fabd172becd52740bee7cdaac00d094a7206e55/2020.acl-main.197.pdf", "dpi": 100}