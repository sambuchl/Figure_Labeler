{"raw_detected_boxes": [[], [{"x2": 726.0, "y1": 87.0, "x1": 101.0, "y2": 316.0}, {"x2": 686.0, "y1": 763.0, "x1": 470.0, "y2": 848.0}], [{"x2": 392.0, "y1": 497.0, "x1": 111.0, "y2": 597.0}], [], [], [{"x2": 401.0, "y1": 87.0, "x1": 102.0, "y2": 322.0}], [{"x2": 400.0, "y1": 86.0, "x1": 103.0, "y2": 203.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 291.9243469238281, "y1": 442.2605285644531, "x1": 71.69100189208984, "y2": 484.1279602050781}, "imageText": ["HEADLINE", "50", "LEAD", "42", "MAIN", "EVENTS", "60", "CONSEQUENCES", "19", "CIRCUMSTANCES", "103", "PREVIOUS", "EVENTS", "64", "HISTORY", "27", "VERBAL", "REACTIONS", "252", "EXPECTATIONS", "21", "EVALUATIONS", "56", "Label", "Count", "Label", "Count"], "regionBoundary": {"x2": 283.0, "y1": 357.8900146484375, "x1": 80.0, "y2": 429.8900146484375}, "caption": "Table 2: Distribution of the labels within the annotated corpus, with 644 labels total. The majority of paragraphs fall under the categories of verbal reactions or circumstances. From (Yarlott et al., 2018)", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 291.9244079589844, "y1": 247.68551635742188, "x1": 71.69100189208984, "y2": 385.19500732421875}, "imageText": ["CRF", "Yarlott", "et", "al.", "0.58", "0.60", "0.59", "CRF", "+Lexical", "0.61", "0.63", "0.62", "CRF", "+Positional", "0.62", "0.66", "0.64", "CRF", "+Syntactic", "0.65", "0.69", "0.67", "CRF", "+subevent", "relation", "0.65", "0.0.70", "0.67", "CRF", "+majority", "event", "tense", "0.67", "0.71", "0.68", "CRF", "+reported", "speech", "0.68", "0.72", "0.70", "CRF", "All", "(+Remaining", "Sem.)", "0.69", "0.73", "0.71", "DT", "Yarlott", "et", "al.", "0.41", "0.41", "0.41", "RDF", "Yarlott", "et", "al.", "0.43", "0.43", "0.43", "SVM", "Yarlott", "et", "al.", "0.54", "0.54", "0.54", "MFC", "-", "0.39", "0.39", "0.39", "HHMM", "Bigrams", "0.42", "0.45", "0.43", "SVM", "BoW", "0.46", "0.46", "0.46", "Model", "Features", "P", "R", "F1"], "regionBoundary": {"x2": 289.0, "y1": 62.8900146484375, "x1": 73.0, "y2": 235.8900146484375}, "caption": "Table 3: Experimental results for discourse label identification. All results are micro-averaged across instances, including precision (P ), recall (R), and balanced F-measure (F1). The Decision Tree, Random Forest, and SVM classifiers used the features outlined in (Yarlott et al., 2018). For the middle three lines of the CRF section, these indicate features groups added to the previous line\u2019s model. We present the results for the smenatic features individually. The CRF model in the last line (CRF with ALL features) includes all the features from the previous lines as well as all remaining semantic features.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2898559570312, "y1": 622.4725952148438, "x1": 306.9170227050781, "y2": 640.4300537109375}, "imageText": ["Total", "28,236", "644", "Average", "564.7", "12.9", "Std.", "Dev.", "322.1", "4.9", "Words", "Paragraphs"], "regionBoundary": {"x2": 494.0, "y1": 543.8900146484375, "x1": 339.0, "y2": 609.8900146484375}, "caption": "Table 1: Corpus-wide statistics for the annotated data. Adapted from Yarlott et al. (2018), Table 1.", "page": 1}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 526.7926635742188, "y1": 240.45352172851562, "x1": 72.0, "y2": 270.36602783203125}, "imageText": ["Expectations", "Evaluations", "Verbal", "Reactions", "History", "Circumstances", "Previous", "Events", "Main", "Events", "Consequences", "Headline", "Lead", "Context", "Conclusions", "Comments", "Episode", "Background", "Summary", "Situation", "Story", "News", "Report"], "regionBoundary": {"x2": 526.0, "y1": 62.27934265136719, "x1": 72.0, "y2": 227.8900146484375}, "caption": "Figure 1: The hierarchical discourse structure of news proposed by van Dijk (van Dijk, 1988). Boxes indicate labels that were directly annotated on the documents; other labels can be inferred. From Yarlott et al. (2018), Figure 1.", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.9243469238281, "y1": 162.50753784179688, "x1": 71.69100189208984, "y2": 204.37506103515625}, "imageText": ["Macro", "Average", "0.56", "HEADLINE", "-", "LEAD", "0.95", "MAIN", "EVENTS", "0.69", "CONSEQUENCES", "0.29", "CIRCUMSTANCES", "0.72", "PREVIOUS", "EVENTS", "0.51", "HISTORY", "0.24", "VERBAL", "REACTIONS", "0.91", "EXPECTATIONS", "0.26", "EVALUATIONS", "0.51", "Label", "Type", "F1", "Label", "Type", "F1"], "regionBoundary": {"x2": 288.0, "y1": 62.8900146484375, "x1": 74.0, "y2": 149.8900146484375}, "caption": "Table 4: Per-label F1 results. The last row shows the macro average over all label types. Best performance occurs for the LEAD, MAIN EVENTS, CIRCUMSTANCES, and VERBAL REACTIONS.", "page": 6}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 731.6564771864149, "y1": 333.96322462293836, "x1": 100.0, "y2": 375.50837198893225}, "name": "1", "caption_text": "Figure 1: The hierarchical discourse structure of news proposed by van Dijk (van Dijk, 1988). Boxes indicate labels that were directly annotated on the documents; other labels can be inferred. From Yarlott et al. (2018), Figure 1.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 87.0, "x1": 100.0, "y2": 333.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3470221625433, "y1": 864.5452711317274, "x1": 426.27364264594183, "y2": 889.4861857096354}, "name": "1", "caption_text": "Table 1: Corpus-wide statistics for the annotated data. Adapted from Yarlott et al. (2018), Table 1.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 700.0, "y1": 754.0, "x1": 462.0, "y2": 865.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 614.250734117296, "x1": 99.57083596123589, "y2": 672.3999447292751}, "name": "2", "caption_text": "Table 2: Distribution of the labels within the annotated corpus, with 644 labels total. The majority of paragraphs fall under the categories of verbal reactions or circumstances. From (Yarlott et al., 2018)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 496.0, "x1": 100.0, "y2": 614.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4505666097005, "y1": 344.0076616075304, "x1": 99.57083596123589, "y2": 534.9930657280815}, "name": "3", "caption_text": "Table 3: Experimental results for discourse label identification. All results are micro-averaged across instances, including precision (P ), recall (R), and balanced F-measure (F1). The Decision Tree, Random Forest, and SVM classifiers used the features outlined in (Yarlott et al., 2018). For the middle three lines of the CRF section, these indicate features groups added to the previous line\u2019s model. We present the results for the smenatic features individually. The CRF model in the last line (CRF with ALL features) includes all the features from the previous lines as well as all remaining semantic features.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 86.0, "x1": 102.0, "y2": 327.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 225.70491366916232, "x1": 99.57083596123589, "y2": 283.854251437717}, "name": "4", "caption_text": "Table 4: Per-label F1 results. The last row shows the macro average over all label types. Best performance occurs for the LEAD, MAIN EVENTS, CIRCUMSTANCES, and VERBAL REACTIONS.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 103.0, "y2": 209.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/e85b7bf0f5fe379b06f35e4f644590c10b8f1e97/2020.nuse-1.3.pdf", "dpi": 100}