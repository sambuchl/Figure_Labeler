{"raw_detected_boxes": [[], [{"x2": 725.0, "y1": 102.0, "x1": 126.0, "y2": 401.0}], [{"x2": 761.0, "y1": 647.0, "x1": 439.0, "y2": 899.0}], [{"x2": 413.0, "y1": 566.0, "x1": 101.0, "y2": 719.0}, {"x2": 705.0, "y1": 651.0, "x1": 480.0, "y2": 869.0}], [{"x2": 741.0, "y1": 101.0, "x1": 445.0, "y2": 608.0}, {"x2": 413.0, "y1": 854.0, "x1": 100.0, "y2": 912.0}], [{"x2": 413.0, "y1": 802.0, "x1": 100.0, "y2": 926.0}], [{"x2": 749.0, "y1": 101.0, "x1": 439.0, "y2": 225.0}, {"x2": 415.0, "y1": 441.0, "x1": 99.0, "y2": 650.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 296.3999938964844, "y1": 681.6000366210938, "x1": 72.83999633789062, "y2": 686.5800170898438}, "imageText": ["Answer", "David", "Morgan,", "the", "company's", "managing", "(kb-based", "director", "and", "inventor", "of", "the", "plastic", "methods)", "cone", "even", "collects", "them.", "removed", "a", "half", "-", "dozen", "plastic", "orange", "cones", "from", "the", "roadway", "and", "the", "rst", "cars", "passed", "Q52", "Who", "invented", "the", "road", "tra\u00c6c", "cone?", "Answer", "Smiling", "proudly", "for", "the", "cameras", ",", "Governor", "(shallow", "Pete", "Wilson,", "US", "Transportation", "Secretary", "methods)", "Federico", "Pena", "and", "Mayor", "Richard", "Riordan"], "regionBoundary": {"x2": 300.0, "y1": 577.0, "x1": 71.0, "y2": 669.0}, "caption": "Table 2: Examples of improved answer correctness.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 453.9599914550781, "y1": 311.2799987792969, "x1": 158.27999877929688, "y2": 316.260009765625}, "imageText": ["Shallow", "Document", "ProcessingKnowledge-Based", "Question", "Processing", "Transformation", "Logic", "Form", "Transformation", "Semantic", "AnswerAnswer", "Knowledge-Based", "Answer", "Processing", "False?R", "elax", "True?", "Answers", "Answer(s)", "Answer", "Extraction", "Documents", "Keywords", "1", "Keywords", "2", "IR", "Search", "Engine", "Expanded", "Question", "1", "Expanded", "Question", "n", "Expanded", "Question", "2", "Question", "Prover", "Parser", "Answer", "set", "n", "Answer", "set", "2", "Answer", "set", "1", "Combine", "/", "Rerank", "Answers", "Keywords", "1", "Paragrah", "Ordering", "Index", "Document", "Collection", "Recognition", "Class", "Question", "Expansion", "Question", "Question", "Logic", "Form", "Transformation", "Question", "Semantic", "Parser", "Transformation", "Word", "Classes", "Question", "Taxonomies", "Lexico-semantic", "Patterns", "Rules", "Abductive", "World", "Knowledge", "Axioms"], "regionBoundary": {"x2": 522.0, "y1": 73.0, "x1": 90.0, "y2": 289.8529968261719}, "caption": "Figure 1: An architecture for knowledge-based Question/Answering", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 490.3199462890625, "y1": 176.16001892089844, "x1": 364.79998779296875, "y2": 181.1400146484375}, "imageText": ["Correct", "answers", "127", "5", "96.2%", "(KB-based)", "Incorrect", "answers", "4", "38", "90.04%", "(KB-based)", "Incorrect", "answers", "3", "210", "98.5%", "(no", "knowledge)", "Proven", "Proven", "Precision", "correct", "incorrect"], "regionBoundary": {"x2": 539.0, "y1": 71.0, "x1": 316.0, "y2": 164.0}, "caption": "Table 4: Prover performance", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 253.2000274658203, "y1": 480.239990234375, "x1": 115.91999816894531, "y2": 485.2200012207031}, "imageText": ["Text-surface-based", "77.7%", "73%", "only", "with", "Answer", "Justi", "cation", "Knowledge-based", "89.5%", "84.75%", "Question", "Processing", "with", "Answer", "Justi", "cation", "(only)", "Text-surface-based", "77.7%", "64.5%", "Knowledge-based", "83.2%", "71.5%", "Question", "Processing", "Percentage", "of", "NIST", "score", "correct", "answers", "in", "top", "5", "returns"], "regionBoundary": {"x2": 302.0, "y1": 314.0, "x1": 71.0, "y2": 468.0}, "caption": "Table 3: Accuracy performance", "page": 6}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 523.5599975585938, "y1": 659.760009765625, "x1": 331.67999267578125, "y2": 664.739990234375}, "imageText": ["Question:", "Why", "did", "David", "Koresh", "ask", "the", "FBI", "for", "a", "word", "processor?", "Semantic", "representation:", "Parse:", "David", "FBIKoresh", "word", "processor", "REASON", "ask", "SBARQ", "VP", "SQ", "PP", "NPWHADVP", "NP", "NP", "WRB", "VBD", "NNP", "NNP", "VB", "NNDTIN", "NNNNPDT", "Why", "did", "David", "Koresh", "ask", "the", "FBI", "for", "a", "word", "processor"], "regionBoundary": {"x2": 551.0, "y1": 440.01947021484375, "x1": 316.0, "y2": 647.0}, "caption": "Figure 2: Question semantic transformation", "page": 2}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 540.2400512695312, "y1": 637.9200439453125, "x1": 315.0, "y2": 642.9000244140625}, "imageText": ["Location", "OrganizationCurrency", "DefinitionReason", "Location", "Name", "Artwork", "Name", "Author", "Name", "Person", "Product", "Name", "Instance", "Number", "Date"], "regionBoundary": {"x2": 510.0, "y1": 467.0, "x1": 346.0, "y2": 626.0}, "caption": "Figure 4: A snapshot of the top Question Taxonomy", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 248.87998962402344, "y1": 532.800048828125, "x1": 120.4800033569336, "y2": 537.780029296875}, "imageText": ["REASON", "FBIKoresh", "processor", "processor", "ask", "SBARQ", "VP", "SQ", "PP", "NPWHADVP", "NP", "NP", "WRB", "VBD", "NNP", "NNP", "VB", "NNDTIN", "NNNNPDT", "Why", "did", "David", "Koresh", "the", "FBI", "for", "a", "word", "processor", "ask", "ask", "ask"], "regionBoundary": {"x2": 306.17999267578125, "y1": 405.0, "x1": 73.0, "y2": 521.0}, "caption": "Figure 3: Parse tree traversal", "page": 3}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 297.1199951171875, "y1": 671.1600341796875, "x1": 71.99998474121094, "y2": 721.5}, "imageText": ["Value", "words", "\\monetary", "value\",", "\\money\",", "\\price\"", "Expenditure", "words", "\\spend\",", "\\buy\",", "\\rent\",", "\\invest\"", "Creation", "words", "\\author\",", "\\designer\",", "\\invent\"...", "Word", "Class", "Words"], "regionBoundary": {"x2": 304.0, "y1": 613.0, "x1": 71.0, "y2": 659.0}, "caption": "Table 1: Examples of word classes. The bootstrapping algorithm that learns new classi cation rules and new classes of questions is based on an information extraction measure: score(rulei)=Ai log2(Ni), where Ai stands for the", "page": 4}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 530.5199584960938, "y1": 450.0, "x1": 324.7200012207031, "y2": 454.9800109863281}, "imageText": ["author", "4", "semantic", "representation", "semantic", "representation", "2", "1", "es", "la", "ss", "su", "bc", "currency", "semantic", "representation", "semantic", "representation", "worm", "in", "the", "late", "1980s?", "Who", "released", "the", "Internet", "group", "leave?", "What", "debts", "did", "Qintex", "semantic", "representation", "How", "much", "did", "Manchester", "United", "spend", "on", "players", "in", "1993?", "semantic", "representation", "Rogers", "Award", "in", "1989?", "Who", "received", "the", "Will", "semantic", "representation", "semantic", "representation", "name", "person", "la", "ss", "es", "3", "su", "bc", "Class", "Name:", "Class", "Name:", "creation", "title", "creation", "word", "word", "create", "award", "name", "competition", "word", "?", "worm", "Internet", "released", "late", "1980s", "Q92:", "Award", "Will", "Rogers", "1989", "received", "Q7:", "players", "1993", "Manchester", "United", "spend", "?", "Q12:", "Q32:", "Class", "Name:", "?", "entity", "type", "specifier", "object", "possessing", "entity", "timestamp", "object", "with", "value", "value", "word", "action", "word", "expenditure", "author", "of", "action", "of", "action", "object", "timestamp", "?", "?", "timestamp", "?", "timestamp", "?", "leave", "?", "Qintex", "debts", "group"], "regionBoundary": {"x2": 535.0, "y1": 73.0, "x1": 321.0, "y2": 438.0}, "caption": "Figure 5: Mapping Questions in the Taxonomy", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 630.499988132053, "y1": 432.3333316379123, "x1": 219.83333163791232, "y2": 439.25001356336804}, "name": "1", "caption_text": "Figure 1: An architecture for knowledge-based Question/Answering", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 102.0, "x1": 126.0, "y2": 406.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 727.1666632758246, "y1": 916.3333468967013, "x1": 460.6666564941406, "y2": 923.249986436632}, "name": "2", "caption_text": "Figure 2: Question semantic transformation", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 766.0, "y1": 630.0, "x1": 439.0, "y2": 916.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 345.6666522555881, "y1": 740.0000678168402, "x1": 167.3333379957411, "y2": 746.9167073567708}, "name": "3", "caption_text": "Figure 3: Parse tree traversal", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 430.0, "y1": 549.0, "x1": 100.0, "y2": 723.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.3334045410156, "y1": 886.0000610351562, "x1": 437.5, "y2": 892.9167005750868}, "name": "4", "caption_text": "Figure 4: A snapshot of the top Question Taxonomy", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 722.0, "y1": 634.0, "x1": 463.0, "y2": 886.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 736.833275689019, "y1": 625.0, "x1": 451.00000169542096, "y2": 631.9166819254557}, "name": "5", "caption_text": "Figure 5: Mapping Questions in the Taxonomy", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 742.0, "y1": 101.0, "x1": 445.0, "y2": 625.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 412.6666598849826, "y1": 932.1667141384548, "x1": 99.99997880723741, "y2": 1002.0833333333333}, "name": "1", "caption_text": "Table 1: Examples of word classes. The bootstrapping algorithm that learns new classi cation rules and new classes of questions is based on an information extraction measure: score(rulei)=Ai log2(Ni), where Ai stands for the", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 421.0, "y1": 851.0, "x1": 99.0, "y2": 915.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 411.66665818956164, "y1": 946.6667175292969, "x1": 101.16666158040364, "y2": 953.5833570692274}, "name": "2", "caption_text": "Table 2: Examples of improved answer correctness.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 417.0, "y1": 785.0, "x1": 99.0, "y2": 929.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 680.9999254014757, "y1": 244.66669294569226, "x1": 506.6666497124566, "y2": 251.5833536783854}, "name": "4", "caption_text": "Table 4: Prover performance", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 749.0, "y1": 99.0, "x1": 439.0, "y2": 227.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 351.6667048136393, "y1": 666.999986436632, "x1": 160.99999745686847, "y2": 673.9166683620876}, "name": "3", "caption_text": "Table 3: Accuracy performance", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 419.0, "y1": 424.0, "x1": 99.0, "y2": 667.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/5a2f09f90a8fad0997f7cf454cbcbe79cab3bc0f/C00-1043.pdf", "dpi": 100}