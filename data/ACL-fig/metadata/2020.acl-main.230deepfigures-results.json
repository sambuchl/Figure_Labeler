{"raw_detected_boxes": [[{"x2": 728.0, "y1": 312.0, "x1": 430.0, "y2": 458.0}], [], [{"x2": 728.0, "y1": 88.0, "x1": 427.0, "y2": 186.0}, {"x2": 398.0, "y1": 86.0, "x1": 99.0, "y2": 352.0}, {"x2": 399.0, "y1": 762.0, "x1": 104.0, "y2": 813.0}], [{"x2": 724.0, "y1": 87.0, "x1": 103.0, "y2": 406.0}], [{"x2": 720.0, "y1": 88.0, "x1": 103.0, "y2": 384.0}], [], [{"x2": 723.0, "y1": 88.0, "x1": 104.0, "y2": 305.0}], [{"x2": 729.0, "y1": 295.0, "x1": 427.0, "y2": 418.0}, {"x2": 729.0, "y1": 495.0, "x1": 426.0, "y2": 656.0}, {"x2": 339.0, "y1": 578.0, "x1": 158.0, "y2": 693.0}], [{"x2": 401.0, "y1": 91.0, "x1": 103.0, "y2": 160.0}, {"x2": 400.0, "y1": 233.0, "x1": 100.0, "y2": 301.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 525.546630859375, "y1": 488.8733825683594, "x1": 307.2760009765625, "y2": 493.5010070800781}, "text": "Figure 6: Comparison with multimedia flat embedding.", "name": "6", "page": 7}, {"figType": "Figure", "boundary": {"x2": 525.5469360351562, "y1": 315.98138427734375, "x1": 307.2760009765625, "y2": 332.5649108886719}, "text": "Figure 5: Image helps textual event extraction, and surrounding sentence helps visual event extraction.", "name": "5", "page": 7}], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5469360351562, "y1": 344.9714050292969, "x1": 307.2760009765625, "y2": 385.46514892578125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 221.8900146484375, "x1": 307.0, "y2": 331.8900146484375}, "caption": "Figure 1: An example of Multimedia Event Extraction. An event mention and some event arguments (Agent and Person) are extracted from text, while the vehicle arguments can only be extracted from the image.", "page": 0}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.547607421875, "y1": 233.42340087890625, "x1": 72.0, "y2": 250.006103515625}, "imageText": ["Flatatt", "34.2", "63.2", "44.4", "20.1", "27.1", "23.1", "27.1", "57.3", "36.7", "4.3", "8.9", "5.8", "33.9", "59.8", "42.2", "12.9", "17.6", "14.9", "Flatobj", "38.3", "57.9", "46.1", "21.8", "26.6", "24.0", "26.4", "55.8", "35.8", "9.1", "6.5", "7.6", "34.1", "56.4", "42.5", "16.3", "15.9", "16.1", "WASEatt", "37.6", "66.8", "48.1", "27.5", "33.2", "30.1", "32.3", "63.4", "42.8", "9.7", "11.1", "10.3", "38.2", "67.1", "49.1", "18.6", "21.6", "19.9", "WASEobj", "42.8", "61.9", "50.6", "23.5", "30.3", "26.4", "43.1", "59.2", "49.9", "14.5", "10.1", "11.9", "43.0", "62.1", "50.8", "19.5", "18.9", "19.2", "VSE-C", "33.5", "47.8", "39.4", "16.6", "24.7", "19.8", "30.3", "48.9", "26.4", "5.6", "6.1", "5.7", "33.3", "48.2", "39.3", "11.1", "14.9", "12.8", "M", "u", "ltim", "ed", "ia", "WASEIobj", "-", "-", "-", "-", "-", "-", "28.6", "59.2", "38.7", "13.3", "9.8", "11.2", "26.1", "22.4", "24.1", "4.7", "5.0", "4.9", "JMEE", "42.5", "58.2", "48.7", "22.9", "28.3", "25.3", "-", "-", "-", "-", "-", "-", "42.1", "34.6", "38.1", "21.1", "12.6", "15.8", "GAIL", "43.4", "53.5", "47.9", "23.6", "29.2", "26.1", "-", "-", "-", "-", "-", "-", "44.0", "32.4", "37.3", "22.7", "12.8", "16.4", "WASET", "42.3", "58.4", "48.2", "21.4", "30.1", "24.9", "-", "-", "-", "-", "-", "-", "41.2", "33.1", "36.7", "20.1", "13.0", "15.7Im", "a", "g", "e", "WASEIatt", "-", "-", "-", "-", "-", "-", "29.7", "61.9", "40.1", "9.1", "10.2", "9.6", "28.3", "23.0", "25.4", "2.9", "6.1", "3.8", "T", "ex", "t", "P", "R", "F1", "P", "R", "F1", "P", "R", "F1", "P", "R", "F1", "P", "R", "F1", "P", "R", "F1", "Event", "Mention", "Argument", "Role", "Event", "Mention", "Argument", "Role", "Event", "Mention", "Argument", "Role", "Text-Only", "Evaluation", "Image-Only", "Evaluation", "Multimedia", "Evaluation", "Model", "T", "ra", "in", "in", "g"], "regionBoundary": {"x2": 523.0, "y1": 60.338104248046875, "x1": 74.0, "y2": 219.8900146484375}, "caption": "Table 3: Event and argument extraction results (%). We compare three categories of baselines in three evaluation settings. The main contribution of the paper is joint training and joint inference on multimedia data (bottom right).", "page": 6}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 290.27056884765625, "y1": 266.8013916015625, "x1": 72.0, "y2": 295.33880615234375}, "imageText": ["Con\ufb02ict.Demonstrate", "(151|69)", "Entity", "(102|184),", "Police", "(3|26),", "In-", "strument", "(0|118),", "Place", "(86|25)", "Justice.ArrestJail", "(160|56)", "Agent", "(64|119),", "Person", "(147|99),", "Instrument", "(0|11),", "Place", "(43|0)", "Contact.PhoneWrite", "(33|37)", "Entity", "(33|46),", "Instrument", "(0|43),", "Place", "(8|0)", "Contact.Meet", "(127|79)", "Participant", "(119|321),", "Place", "(68|0)", "Life.Die", "(244|64)", "Agent", "(39|0),", "Instrument", "(4|2),", "Victim", "(165|155),", "Place", "(54|0)", "Transaction.", "TransferMoney", "(33|6)", "Giver", "(19|3),", "Recipient", "(19|5),", "Money", "(0|8)", "Attacker", "(192|12),", "Target", "(207|19),", "Instrument", "(37|15),", "Place", "(121|0)", "Con\ufb02ict.Attack", "(326|27)", "Agent", "(46|64),", "Artifact", "(179|103),", "Vehicle", "(24|51),", "Destination", "(120|0),", "Origin", "(66|0)", "Event", "Type", "Argument", "Role", "Movement.Transport", "(223|53)"], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 253.8900146484375}, "caption": "Table 1: Event types and argument roles in M2E2, with expanded ones in bold. Numbers in parentheses represent the counts of textual and visual events/arguments.", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 239.39500427246094, "y1": 598.5653686523438, "x1": 122.87300109863281, "y2": 603.1929931640625}, "imageText": ["sentence", "image", "textual", "visual", "textual", "visual", "6,167", "1,014", "1,297", "391", "1,965", "1,429", "Source", "Event", "Mention", "Argument", "Role"], "regionBoundary": {"x2": 292.0, "y1": 547.8900146484375, "x1": 72.0, "y2": 584.8900146484375}, "caption": "Table 2: M2E2 data statistics.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 493.28607177734375, "y1": 147.61236572265625, "x1": 339.5329895019531, "y2": 152.239990234375}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 134.8900146484375}, "caption": "Figure 2: Example of bounding boxes.", "page": 2}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 287.89349365234375, "y1": 514.8723754882812, "x1": 74.375, "y2": 519.5}, "imageText": ["VSE", "31.2", "74.5", "44.0", "Flatatt", "33.1", "73.5", "45.6", "Flatobj", "34.3", "76.4", "47.3", "WASEatt", "39.5", "73.5", "51.5", "WASEobj", "40.1", "75.4", "52.4", "rule", "based", "10.1", "100", "18.2", "Model", "P", "(%)", "R", "(%)", "F1", "(%)"], "regionBoundary": {"x2": 249.0, "y1": 415.8900146484375, "x1": 113.0, "y2": 501.8900146484375}, "caption": "Table 4: Cross-media event coreference performance.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5472412109375, "y1": 311.359375, "x1": 72.0, "y2": 327.94329833984375}, "imageText": ["ACE", "Text", "Event", "Cross-media", "Shared", "Event", "Classi\ufb01er", "Alignment", "Con\ufb02ict.Attack", "Cross-media", "Shared", "Argument", "Classi\ufb01er", "Cross-media", "Structured", "Common", "Representation", "Encoder", "Training", "Phase", "Testing", "Phase", "Con\ufb02ict.Attack", "Attacker", "Con\ufb02ict.Attack", "Instrument", "Con\ufb02ict.Attack", "Instrument", "Contact.Meet", "Participant", "Contact.Meet", "Con\ufb02ict.Attack", "resistance", "imSitu", "Image", "Event", "Multimedia", "News", "insurgents", "trigger", "image", "entity", "region", "...", "...", "Liana", "Owen", "Tool", "[Instrument]:", "bomb", "destroying\u00a0[Con\ufb02ict.Attack]", "Item", "[Target]:", "ship", "...", "...", "Pairs", "Liana", "Owen\u00a0[Participant]", "drove", "from", "Pennsylvania", "to", "attend\u00a0[Contact.Meet]", "the", "rally", "in", "Manhattan", "with", "her", "parents", "[Participant].", "VOA", "Image-Caption", "attend", "trigger", "imageentity", "region", "For", "the", "rebels,", "bravado", "goes", "hand-in-", "hand", "with", "the", "desperate", "resistance", "the", "insurgents", "have", "mounted....."], "regionBoundary": {"x2": 526.0, "y1": 62.8900146484375, "x1": 72.0, "y2": 292.8900146484375}, "caption": "Figure 3: Approach overview. During training (left), we jointly train three tasks to establish a cross-media structured embedding space. During test (right), we jointly extract events and arguments from multimedia articles.", "page": 3}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 290.2707214355469, "y1": 232.785400390625, "x1": 72.0, "y2": 249.36810302734375}, "imageText": ["Entity:", "people", "Place:", "street", "Entity:", "dissent"], "regionBoundary": {"x2": 290.0, "y1": 167.24595642089844, "x1": 72.0, "y2": 217.8900146484375}, "caption": "Figure 8: Attention heatmaps lose focus due to large instance candidate number.", "page": 8}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 290.27020263671875, "y1": 129.46337890625, "x1": 72.0, "y2": 146.04571533203125}, "imageText": ["Entity:", "people", "Entity:", "troopsPlace:", "street"], "regionBoundary": {"x2": 290.0, "y1": 65.18141174316406, "x1": 74.0, "y2": 115.8900146484375}, "caption": "Figure 7: Argument labeling error examples: correct entity name but wrong localization.", "page": 8}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 502.4040222167969, "y1": 300.76336669921875, "x1": 95.14299774169922, "y2": 305.3909912109375}, "imageText": ["Object-based", "Graph", "GCNor", "Situation", "Graph", "Encoder", "AM", "R", "Parser", "Thai", "opposition", "protesters\u00a0[Attacker]", "attack\u00a0[Con\ufb02ict.Attack]", "a", "bus\u00a0[Target]\u00a0carrying", "pro-", "government", "Red", "Shirt", "supporters", "on", "their", "way", "to", "a", "rally", "at", "a", "stadium", "in", "Bangkok", "[Place].", "throwing", ":location", ":mod", ":ARG0", ":ARG1", "...", "...", "man", "car", "stone", "GCN", "Role-driven", "Attention", "...", ":agent", ":destination", "Bangkok", "rally-01", "bus", "...", "protest-01", "attack-01", ":ARG0-of", ":mod", ":ARG1", ":ARG0", "support-01", "pro-government", "Red", "Shirt", "person", "Bangkok", ":location", "oppose-01", ":ARG0-of", ":name", "rally-01", ":mod", "Thailand", "Context", "protest-01", "bus", ":ARG0", ":ARG1", "Bi-LSTM", "attack-01", ":agent", ":destination", ":item", ":item", "...", "...", "Attention-based", "GraphImage", "Structured", "Multimedia", "Common", "Space", "Caption", "AMR", "Graph"], "regionBoundary": {"x2": 523.0, "y1": 62.8900146484375, "x1": 72.0, "y2": 279.8900146484375}, "caption": "Figure 4: Multimedia structured common space construction. Red pixels stands for attention heatmap.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9263000488281, "y1": 479.126951429579, "x1": 426.772223578559, "y2": 535.3682623969183}, "name": "1", "caption_text": "Figure 1: An example of Multimedia Event Extraction. An event mention and some event arguments (Agent and Person) are extracted from text, while the vehicle arguments can only be extracted from the image.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 309.0, "x1": 427.0, "y2": 460.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 685.1195441351996, "y1": 205.01717461480035, "x1": 471.5735965304904, "y2": 211.44443088107639}, "name": "2", "caption_text": "Figure 2: Example of bounding boxes.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 87.0, "x1": 427.0, "y2": 203.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.153567843967, "y1": 370.5574883355035, "x1": 100.0, "y2": 410.19278632269965}, "name": "1", "caption_text": "Table 1: Event types and argument roles in M2E2, with expanded ones in bold. Numbers in parentheses represent the counts of textual and visual events/arguments.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 86.0, "x1": 99.0, "y2": 369.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 332.49306148952905, "y1": 831.3407897949219, "x1": 170.65694597032333, "y2": 837.7680460611979}, "name": "2", "caption_text": "Table 2: M2E2 data statistics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 405.0, "y1": 760.0, "x1": 99.0, "y2": 830.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 432.44357638888886, "x1": 100.0, "y2": 455.47680324978296}, "name": "3", "caption_text": "Figure 3: Approach overview. During training (left), we jointly train three tasks to establish a cross-media structured embedding space. During test (right), we jointly extract events and arguments from multimedia articles.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 87.0, "x1": 100.0, "y2": 406.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 697.7833641899956, "y1": 417.7268981933594, "x1": 132.1430524190267, "y2": 424.1541544596354}, "name": "4", "caption_text": "Figure 4: Multimedia structured common space construction. Red pixels stands for attention heatmap.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 87.0, "x1": 100.0, "y2": 390.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.927232530382, "y1": 324.19916788736975, "x1": 100.0, "y2": 347.23069932725696}, "name": "3", "caption_text": "Table 3: Event and argument extraction results (%). We compare three categories of baselines in three evaluation settings. The main contribution of the paper is joint training and joint inference on multimedia data (bottom right).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 86.0, "x1": 100.0, "y2": 322.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9263000488281, "y1": 438.86303371853296, "x1": 426.772223578559, "y2": 461.8957095675998}, "name": "5", "caption_text": "Figure 5: Image helps textual event extraction, and surrounding sentence helps visual event extraction.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 289.0, "x1": 427.0, "y2": 418.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 678.9908091227213, "x1": 426.772223578559, "y2": 685.4180653889973}, "name": "6", "caption_text": "Figure 6: Comparison with multimedia flat embedding.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 495.0, "x1": 426.0, "y2": 659.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 399.8520745171441, "y1": 715.1005215115017, "x1": 103.29861111111111, "y2": 721.5277777777777}, "name": "4", "caption_text": "Table 4: Cross-media event coreference performance.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 345.0, "y1": 561.0, "x1": 158.0, "y2": 696.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1530592176649, "y1": 179.81024848090277, "x1": 100.0, "y2": 202.84127129448785}, "name": "7", "caption_text": "Figure 7: Argument labeling error examples: correct entity name but wrong localization.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 91.0, "x1": 100.0, "y2": 177.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1537797715929, "y1": 323.31305609809027, "x1": 100.0, "y2": 346.3445875379774}, "name": "8", "caption_text": "Figure 8: Attention heatmaps lose focus due to large instance candidate number.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 233.0, "x1": 100.0, "y2": 301.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/d5a600d47df3dfd115427a7ce3b0ac25fb35a8b4/2020.acl-main.230.pdf", "dpi": 100}