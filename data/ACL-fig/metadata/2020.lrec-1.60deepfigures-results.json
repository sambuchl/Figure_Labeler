{"raw_detected_boxes": [[{"x2": 686.0, "y1": 498.0, "x1": 487.0, "y2": 685.0}], [{"x2": 749.0, "y1": 100.0, "x1": 426.0, "y2": 337.0}], [{"x2": 674.0, "y1": 104.0, "x1": 148.0, "y2": 235.0}, {"x2": 717.0, "y1": 278.0, "x1": 105.0, "y2": 494.0}], [], [{"x2": 735.0, "y1": 194.0, "x1": 438.0, "y2": 302.0}, {"x2": 710.0, "y1": 600.0, "x1": 462.0, "y2": 907.0}], [{"x2": 682.0, "y1": 95.0, "x1": 141.0, "y2": 235.0}, {"x2": 707.0, "y1": 393.0, "x1": 461.0, "y2": 480.0}, {"x2": 388.0, "y1": 798.0, "x1": 83.0, "y2": 907.0}], [{"x2": 731.0, "y1": 95.0, "x1": 91.0, "y2": 326.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 539.71435546875, "y1": 509.7755432128906, "x1": 304.8659973144531, "y2": 539.68798828125}, "imageText": [], "regionBoundary": {"x2": 494.0, "y1": 358.8900146484375, "x1": 350.0, "y2": 493.8900146484375}, "caption": "Figure 1: A screenshot from one of the video clips in the Margarita Dialogue Corpus, named after co-author and avatar maker Margarita Bicec.", "page": 0}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 539.7175903320312, "y1": 180.74154663085938, "x1": 52.15800094604492, "y2": 222.61004638671875}, "imageText": ["...", "...", "...", "...", "...", "...", "0.7", "108", "0", "0.269", "0.000", "0.269", "0.75", "108", "1", "0.339", "0.018", "0.272", "0.8", "107", "11", "0.335", "0.193", "0.294", "0.85", "103", "20", "0.323", "0.351", "0.307", "0.9", "91", "42", "0.285", "0.737", "0.332", "0.95", "72", "56", "0.226", "0.982", "0.319", "Threshold", "#", "Correct", "Answer", "#", "Correct", "Non-Answer", "TPR-ans", "TPR-non-ans", "Recall@1", "0.05", "108", "0", "0.269", "0.000", "0.269"], "regionBoundary": {"x2": 491.0, "y1": 68.8900146484375, "x1": 101.0, "y2": 168.8900146484375}, "caption": "Table 6: Thresholding considerations for the BERT model. The table shows, for each threshold level imposed to cosine similarities, the number of correct answers predicted, the number of correct non-answers predicted by the model, hence the true positive rate for answers (TPR-ans), the true positive rate for non-answers (TPR-non-ans) and the Recall@1 metric. The automatic choice of threshold for this setup is highlighted in bold face.", "page": 5}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 287.00640869140625, "y1": 664.7805786132812, "x1": 52.15800094604492, "y2": 694.6929931640625}, "imageText": ["TF-IDF", "InferSent", "BERT", "Similarity", "Threshold", "0.8", "0.9", "0.9", "Recall@1", "0.194", "0.169", "0.201", "Recall@2", "0.207", "0.169", "0.207", "Recall@5", "0.210", "0.169", "0.210", "Recall@10", "0.210", "0.169", "0.213", "Recall@20", "0.210", "0.169", "0.213"], "regionBoundary": {"x2": 280.0, "y1": 574.8900146484375, "x1": 60.0, "y2": 652.8900146484375}, "caption": "Table 7: Results for each baseline on the test set. For each model and threshold selection, the Recall@k metric is shown for different levels of k on the test set.", "page": 5}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 539.71435546875, "y1": 357.8255310058594, "x1": 304.8659973144531, "y2": 399.6929626464844}, "imageText": ["TF-IDF", "InferSent", "BERT", "Recall@1", "0.103", "0.046", "0.111", "Recall@2", "0.168", "0.084", "0.153", "Recall@5", "0.240", "0.126", "0.221", "Recall@10", "0.282", "0.164", "0.302", "Recall@20", "0.363", "0.210", "0.420"], "regionBoundary": {"x2": 513.0, "y1": 278.8900146484375, "x1": 332.0, "y2": 345.8900146484375}, "caption": "Table 8: Recall@k only for answers (i.e., ignoring questions in the test set that did not have and answer in the KB) for each baseline. For each model Recall@k metric is shown for different levels of k on the test set.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 539.7144775390625, "y1": 254.46554565429688, "x1": 304.8659973144531, "y2": 272.42303466796875}, "imageText": ["\u201cI", "never", "asked", "about", "your", "ma-", "jor?\u201d", "\u201cI", "studied", "music", "and", "economics.", "I\u2019m", "a", "music", "major,", "economics", "minor", "and", "in", "mu-", "sic", "I", "do", "mostly", "composition", "and", "sound", "en-", "gineering.\u201d", "\u201cHow", "do", "you", "make", "money", "with", "music?\u201d", "\u201cBy", "being", "good", "at", "what", "you", "do", "and", "know-", "ing", "people.", "That\u2019s", "how", "you", "get", "a", "job", "in", "the", "music", "industry", "and", "you", "grow", "from", "there.\u201d", "\u201cI", "used", "to", "more", "then,", "but", "now", "I", "got", "so", "used", "to", "just", "changing", "my", "diet", "depending", "on", "where", "I", "am", "at", "that", "time.", "And", "also", "I", "found", "some", "place", "where", "we", "can", "eat", "Rus-", "sian", "food", "and", "the", "dining", "hall", "is", "also", "mak-", "ing", "Russian", "food", "from", "time", "to", "time...", "so", "I", "don\u2019t", "miss", "it", "that", "much.\u201d", "Question", "Answer", "\u201cDo", "you", "miss", "the", "food,", "the", "Moldovan", "cui-", "sine?\u201d"], "regionBoundary": {"x2": 542.0, "y1": 68.8900146484375, "x1": 307.0, "y2": 242.8900146484375}, "caption": "Table 1: Three examples of pairs in the Margarita Dialogue Corpus KB data resource.", "page": 1}, {"figType": "Table", "name": "9", "captionBoundary": {"x2": 509.7606201171875, "y1": 246.29556274414062, "x1": 82.11599731445312, "y2": 252.29803466796875}, "imageText": ["\u201cWhen", "are", "you", "heading", "back", "home?\u201d", "\u201cAre", "most", "people", "back", "home", "Orthodox?\u201d", "(0.566)", "\u201cWhere", "are", "you", "from?\u201d", "(0.774)", "\u201cHow", "far", "are", "you", "guys", "from", "the", "city?\u201d", "(0.822)", "\u201cOh", "my", "God.", "That", "could", "have", "been.", "That\u2019s", "wild.", "And", "do", "you", "miss", "home", "when", "you\u2019re", "here", "in", "Abu", "Dhabi?\u201d", "\u201cDo", "you", "miss", "home", "a", "lot?\u201d", "(0.424)", "\u201cWhat", "can", "I", "do", "for", "fun", "in", "Abu", "Dhabi?\u201d", "(0.815)", "\u201cDo", "you", "have", "siblings", "who", "study", "in", "New", "York", "or", "Abu", "Dhabi?\u201d", "(0.803)", "\u201cSo", "where", "were", "you", "raised?\u201d", "\u201cWhere", "are", "you", "from?\u201d", "(0.458)", "\u201cWhen", "did", "you", "graduate?\u201d", "(0.761)", "\u201cWhere", "are", "you", "from?\u201d", "(0.825)", "Test", "Question", "TF-IDF", "InferSent", "BERT", "\u201cSo", "is", "this", "your", "natural", "hair", "color?\u201d", "\u201cIs", "this", "your", "natural", "hair", "color?\u201d", "(0.972)", "\u201cIs", "this", "your", "natural", "hair", "color?\u201d", "(0.847)", "\u201cIs", "this", "your", "natural", "hair", "color?\u201d", "(0.965)", "Top", "Ranked", "Similar", "Question", "in", "the", "KB\u2019", "(Cosine", "Similarity)"], "regionBoundary": {"x2": 526.0, "y1": 68.8900146484375, "x1": 66.0, "y2": 234.8900146484375}, "caption": "Table 9: Top ranked question similarity for some meaningful examples in the test set for all three baselines.", "page": 6}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 539.1500854492188, "y1": 180.74154663085938, "x1": 52.72600173950195, "y2": 186.7440185546875}, "imageText": ["Total", "Frequency", "892", "Pleasantries", "&", "Short", "Answers", "Greetings,", "yes/no", "answers,", "compliments.", "159", "18%", "Personal", "Information", "Family,", "country,", "past,", "future,", "love,", "etc.", "362", "41%", "New", "York", "University", "Abu", "Dhabi", "University", "life,", "admissions,", "courses,", "and", "life", "in", "the", "United", "Arab", "Emirates.", "309", "35%", "62", "7%", "Meta-interactions", "Hinting", "to", "user", "what", "to", "ask", "about", "or", "providing", "diversions.", "Category", "Class", "Examples", "Frequencyin", "KB", "(in", "%)"], "regionBoundary": {"x2": 486.0, "y1": 68.8900146484375, "x1": 106.0, "y2": 169.8900146484375}, "caption": "Table 2: Summary of the categories in the Margarita Dialogue Corpus Knowledge Base (KB) defined by the avatar maker.", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 539.7176513671875, "y1": 367.2275390625, "x1": 52.15800094604492, "y2": 397.1399841308594}, "imageText": ["PER", "Mode", "#", "dialogues", "NA", "20", "10", "10", "10", "10", "#", "q-a", "pairs", "(in", "total)", "892", "659", "340", "319", "296", "363", "#", "unique", "questions", "758", "NA", "NA", "NA", "NA", "NA", "#", "unique", "answers", "431", "NA", "NA", "NA", "NA", "NA", "#", "annotated", "answers", "NA", "888", "472", "416", "421", "467", "#", "no-answers", "NA", "49", "0", "49", "25", "32", "(in", "%)", "(NA)", "(15%)", "(0%)", "(15%)", "(8%)", "(9%)", "#", "words", "(in", "total)", "20,303", "40,557", "20,230", "20,327", "20,084", "20,473", "Min.", "#", "turns", "per", "dialogue", "NA", "22", "22", "26", "22", "24", "Avg.", "#", "turns", "per", "dialogue", "NA", "33", "34", "32", "30", "36", "Avg.", "#", "words", "per", "question", "7.75", "14.5", "14.5", "14.6", "16.3", "13.1", "Avg.", "#", "words", "per", "answer", "15.0", "47.0", "45.0", "49.1", "51.5", "43.3", "Statistics", "Knowledge", "Base", "Dialogues(All)", "Dialogues", "Train", "Dialogues", "Test", "Dialogues", "EDU", "Mode", "Dialogues"], "regionBoundary": {"x2": 517.0, "y1": 200.8900146484375, "x1": 75.0, "y2": 355.8900146484375}, "caption": "Table 3: Summary statistics on the two main data sets in the Margarita Dialogue Corpus: Knowledge Base (KB) and Dialogues. Statistics for the dialogues are also shown for the train portion vs. test and university mode (EDU) vs. personal mode (PER).", "page": 2}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 539.7142944335938, "y1": 229.03152465820312, "x1": 304.8659973144531, "y2": 270.8990478515625}, "imageText": ["Dialogues", "#", "q-a", "pairs", "(in", "total)", "776", "401", "319", "#", "unique", "questions", "698", "NA", "NA", "#", "unique", "answers", "398", "NA", "NA", "#", "no-answers", "NA", "61", "57", "(in", "%)", "(NA)", "(15%)", "(18%)", "Statistics", "KB\u2019", "TrainDialogues", "Test"], "regionBoundary": {"x2": 529.0, "y1": 138.8900146484375, "x1": 316.0, "y2": 217.8900146484375}, "caption": "Table 4: Summary statistics after sampling non-answers for the train set: down-sampled KB (KB\u2019) and up-sampled train dialogues. The train set remained the same with minor changes due to answers no longer present in the KB\u2019.", "page": 4}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 539.7144165039062, "y1": 664.6865844726562, "x1": 304.8659973144531, "y2": 694.5989990234375}, "imageText": ["0.15", "0.277", "0.234", "0.269", "0.2", "0.277", "0.234", "0.269", "0.25", "0.277", "0.234", "0.269", "0.3", "0.277", "0.234", "0.269", "0.35", "0.282", "0.234", "0.269", "0.4", "0.287", "0.234", "0.269", "0.45", "0.307", "0.234", "0.269", "0.5", "0.317", "0.234", "0.269", "0.55", "0.342", "0.234", "0.269", "0.6", "0.352", "0.239", "0.269", "0.65", "0.357", "0.242", "0.269", "0.7", "0.362", "0.252", "0.269", "0.75", "0.362", "0.267", "0.272", "0.8", "0.369", "0.282", "0.294", "0.85", "0.357", "0.289", "0.307", "0.9", "0.339", "0.302", "0.332", "0.95", "0.312", "0.284", "0.319", "Threshold", "TF-IDF", "InferSent", "BERT", "0.05", "0.277", "0.234", "0.269", "0.1", "0.277", "0.234", "0.269"], "regionBoundary": {"x2": 512.0, "y1": 431.8900146484375, "x1": 333.0, "y2": 652.8900146484375}, "caption": "Table 5: Recall@1 statistics for each baseline evaluated on the train set. The metrics corresponding to the thresholds that were automatically selected are bolded.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 749.603271484375, "y1": 708.0215877956814, "x1": 423.4249962700738, "y2": 749.566650390625}, "name": "1", "caption_text": "Figure 1: A screenshot from one of the video clips in the Margarita Dialogue Corpus, named after co-author and avatar maker Margarita Bicec.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 686.0, "y1": 498.0, "x1": 487.0, "y2": 686.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6034410264757, "y1": 353.4243689643012, "x1": 423.4249962700738, "y2": 378.3653259277344}, "name": "1", "caption_text": "Table 1: Three examples of pairs in the Margarita Dialogue Corpus KB data resource.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 752.0, "y1": 95.0, "x1": 423.0, "y2": 354.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 748.8195631239149, "y1": 251.02992587619357, "x1": 73.23055797153049, "y2": 259.366692437066}, "name": "2", "caption_text": "Table 2: Summary of the categories in the Margarita Dialogue Corpus Knowledge Base (KB) defined by the avatar maker.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 674.0, "y1": 95.0, "x1": 148.0, "y2": 252.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6078491210938, "y1": 510.03824869791663, "x1": 72.44166798061795, "y2": 551.5833112928602}, "name": "3", "caption_text": "Table 3: Summary statistics on the two main data sets in the Margarita Dialogue Corpus: Knowledge Base (KB) and Dialogues. Statistics for the dialogues are also shown for the train portion vs. test and university mode (EDU) vs. personal mode (PER).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 261.0, "x1": 93.0, "y2": 511.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031867133246, "y1": 318.0993398030599, "x1": 423.4249962700738, "y2": 376.24867757161456}, "name": "4", "caption_text": "Table 4: Summary statistics after sampling non-answers for the train set: down-sampled KB (KB\u2019) and up-sampled train dialogues. The train set remained the same with minor changes due to answers no longer present in the KB\u2019.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 735.0, "y1": 193.0, "x1": 423.0, "y2": 319.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6033562554253, "y1": 923.1758117675781, "x1": 423.4249962700738, "y2": 964.7208319769965}, "name": "5", "caption_text": "Table 5: Recall@1 statistics for each baseline evaluated on the train set. The metrics corresponding to the thresholds that were automatically selected are bolded.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 718.0, "y1": 600.0, "x1": 445.0, "y2": 924.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6077643500433, "y1": 251.02992587619357, "x1": 72.44166798061795, "y2": 309.18061998155383}, "name": "6", "caption_text": "Table 6: Thresholding considerations for the BERT model. The table shows, for each threshold level imposed to cosine similarities, the number of correct answers predicted, the number of correct non-answers predicted by the model, hence the true positive rate for answers (TPR-ans), the true positive rate for non-answers (TPR-non-ans) and the Recall@1 metric. The automatic choice of threshold for this setup is highlighted in bold face.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 694.0, "y1": 95.0, "x1": 124.0, "y2": 252.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.603271484375, "y1": 496.9799041748047, "x1": 423.4249962700738, "y2": 555.1291147867838}, "name": "8", "caption_text": "Table 8: Recall@k only for answers (i.e., ignoring questions in the test set that did not have and answer in the KB) for each baseline. For each model Recall@k metric is shown for different levels of k on the test set.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 387.0, "x1": 444.0, "y2": 497.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6200120713976, "y1": 923.3063591851128, "x1": 72.44166798061795, "y2": 964.8513793945312}, "name": "7", "caption_text": "Table 7: Results for each baseline on the test set. For each model and threshold selection, the Recall@k metric is shown for different levels of k on the test set.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 388.0, "y1": 798.0, "x1": 72.0, "y2": 924.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 708.0008612738715, "y1": 342.0771704779731, "x1": 114.04999627007378, "y2": 350.41393703884546}, "name": "9", "caption_text": "Table 9: Top ranked question similarity for some meaningful examples in the test set for all three baselines.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 95.0, "x1": 91.0, "y2": 343.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/bb23b86a494f5853d5219714422028f8b2b6c244/2020.lrec-1.60.pdf", "dpi": 100}