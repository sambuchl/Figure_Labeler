{"raw_detected_boxes": [[{"x2": 728.0, "y1": 309.0, "x1": 427.0, "y2": 511.0}], [{"x2": 707.0, "y1": 95.0, "x1": 127.0, "y2": 223.0}], [{"x2": 724.0, "y1": 799.0, "x1": 429.0, "y2": 906.0}], [{"x2": 405.0, "y1": 97.0, "x1": 103.0, "y2": 209.0}, {"x2": 717.0, "y1": 89.0, "x1": 439.0, "y2": 344.0}, {"x2": 393.0, "y1": 565.0, "x1": 103.0, "y2": 742.0}, {"x2": 631.0, "y1": 713.0, "x1": 438.0, "y2": 766.0}], [{"x2": 728.0, "y1": 95.0, "x1": 109.0, "y2": 419.0}], [{"x2": 396.0, "y1": 86.0, "x1": 103.0, "y2": 338.0}, {"x2": 721.0, "y1": 94.0, "x1": 435.0, "y2": 160.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2871704101562, "y1": 380.34954833984375, "x1": 307.2760009765625, "y2": 434.1729736328125}, "imageText": ["Native", "Python", "Objects", "\u3053\u3093\u306b\u3061\u306f\uff01", "JA", "Hallo!", "NL", "xin", "ch\u00e0o!", "VI", "\u0928\u092e\u0938\u094d\u0915\u093e\u0930!", "HI", "WORDS", "LEMMA", "RU", "\u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435!", "\uc548\ub155\ud558\uc138\uc694!", "KO", "\u00a1Hola!", "ES", "\ufe8e\ufe91\ufea3\u0631\ufee3!", "AR", "Hallo!", "DE", "\u4f60\u597d!", "ZH", "Bonjour!", "FR", "Hello!", "EN", "Named", "Entity", "Recognition", "NER", "Dependency", "Parsing", "DEPPARSE", "POS", "&", "Morphological", "Tagging", "POS", "Lemmatization", "LEMMA", "Multi-word", "Token", "Expansion", "MWT", "TOKENIZE", "Fully", "Neural:", "Language-agnostic", "Multilingual:", "66", "Languages", "RAW", "TEXT", "PROCESSORS", "HEAD", "DEPREL", "...", "TOKEN", "WORD", "POS", "SENTENCE", "DOCUMENT", "Tokenization", "&", "Sentence", "Split"], "regionBoundary": {"x2": 525.0, "y1": 222.8900146484375, "x1": 307.0, "y2": 367.8900146484375}, "caption": "Figure 1: Overview of Sta n z a \u2019s neural NLP pipeline. Sta n z a takes multilingual text as input, and produces annotations accessible as native Python objects. Besides this neural pipeline, Sta n z a also features a Python client interface to the Java CoreNLP software.", "page": 0}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.2005004882812, "y1": 127.71756744384766, "x1": 306.9670104980469, "y2": 181.54107666015625}, "imageText": ["UD", "10.3\u00d7", "3.22\u00d7", "4.30\u00d7", "\u2013", "\u2013", "NER", "17.7\u00d7", "1.08\u00d7", "\u2013", "51.8\u00d7", "1.17\u00d7", "Task", "Sta", "n", "z", "a", "UDPipe", "FLAIR", "CPU", "GPU", "CPU", "CPU", "GPU"], "regionBoundary": {"x2": 520.0, "y1": 62.8900146484375, "x1": 313.0, "y2": 115.8900146484375}, "caption": "Table 4: Annotation runtime of various toolkits relative to spaCy (CPU) on the English EWT treebank and OntoNotes NER test sets. For reference, on the compared UD and NER tasks, spaCy is able to process 8140 and 5912 tokens per second, respectively.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 291.9244384765625, "y1": 255.72256469726562, "x1": 71.69100189208984, "y2": 321.5010986328125}, "imageText": ["Spanish", "CoNLL02", "4", "88.1", "87.3", "77.5", "AnCora", "4", "88.6", "88.4", "76.1", "Russian", "WikiNER", "4", "92.9", "\u2013", "\u2013", "German", "CoNLL03", "4", "81.9", "82.5", "63.9", "GermEval14", "4", "85.2", "85.4", "68.4", "French", "WikiNER", "4", "92.9", "92.5", "88.8\u2217", "English", "CoNLL03", "4", "92.1", "92.7", "81.0", "OntoNotes", "18", "88.8", "89.0", "85.4\u2217", "Dutch", "CoNLL02", "4", "89.2", "90.3", "73.8", "WikiNER", "4", "94.8", "94.8", "90.9", "Chinese", "OntoNotes", "18", "79.2", "\u2013", "\u2013", "Arabic", "AQMAR", "4", "74.3", "74.0", "\u2013", "Language", "Corpus", "#", "Types", "Sta", "n", "z", "a", "FLAIR", "spaCy"], "regionBoundary": {"x2": 288.0, "y1": 62.8900146484375, "x1": 74.0, "y2": 243.8900146484375}, "caption": "Table 3: NER performance across different languages and corpora. All scores reported are entity microaveraged test F1. For each corpus we also list the number of entity types. \u2217 marks results from publicly available pretrained models on the same dataset, while others are from models retrained on our datasets.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 496.324462890625, "y1": 177.45455932617188, "x1": 100.91100311279297, "y2": 183.45703125}, "imageText": ["Sta", "n", "z", "a", "66", "Python", "!", "!", "!", "!", "CoreNLP", "6", "Java", "!", "!", "FLAIR", "12", "Python", "!", "!", "!", "spaCy", "10", "Python", "!", "!", "UDPipe", "61", "C++", "!", "!", "!", "State-of-the-art", "Performance", "Pretrained", "Models", "Fully", "Neural", "Raw", "Text", "Processing", "Programming", "Language", "System", "#", "Human", "Languages"], "regionBoundary": {"x2": 510.0, "y1": 69.70076751708984, "x1": 88.0, "y2": 164.8900146484375}, "caption": "Table 1: Feature comparisons of Sta n z a against other popular natural language processing toolkits.", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2899780273438, "y1": 251.97451782226562, "x1": 306.9670104980469, "y2": 281.88702392578125}, "imageText": ["(fr)", "L\u2019Association", "des", "H\u00f4tels", "(en)", "The", "Association", "of", "Hotels", "(fr)", "Il", "y", "a", "des", "h\u00f4tels", "en", "bas", "de", "la", "rue", "(en)", "There", "are", "hotels", "down", "the", "street"], "regionBoundary": {"x2": 522.0, "y1": 198.8900146484375, "x1": 310.0, "y2": 239.8900146484375}, "caption": "Figure 2: An example of multi-word tokens in French. The des in the first sentence corresponds to two syntactic words, de and les; the second des is a single word.", "page": 1}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.2017211914062, "y1": 261.9435729980469, "x1": 307.2760009765625, "y2": 303.81109619140625}, "imageText": [], "regionBoundary": {"x2": 519.0, "y1": 61.8900146484375, "x1": 314.0, "y2": 249.8900146484375}, "caption": "Figure 3: Sta n z a annotates a German sentence, as visualized by our interactive demo. Note am is expanded into syntactic words an and dem before downstream analyses are performed.", "page": 3}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.7164916992188, "y1": 294.0045471191406, "x1": 71.69100189208984, "y2": 337.3670349121094}, "imageText": ["Spanish-AnCora", "Sta", "n", "z", "a", "99.98", "99.07", "99.98", "98.78", "98.67", "98.59", "99.19", "92.21", "90.01", "UDPipe", "99.97", "98.32", "99.95", "98.32", "98.13", "98.13", "98.48", "88.22", "85.10", "spaCy", "99.47", "97.59", "98.95", "94.04", "\u2013", "\u2013", "79.63", "86.63", "84.13", "French-GSD", "Sta", "n", "z", "a", "99.68", "94.92", "99.48", "97.30", "\u2013", "96.72", "97.64", "91.38", "89.05", "UDPipe", "99.68", "93.59", "98.81", "95.85", "\u2013", "95.55", "96.61", "87.14", "84.26", "spaCy", "98.34", "77.30", "94.15", "86.82", "\u2013", "\u2013", "87.29", "67.46", "60.60", "English-EWT", "Sta", "n", "z", "a", "99.01", "81.13", "99.01", "95.40", "95.12", "96.11", "97.21", "86.22", "83.59", "UDPipe", "98.90", "77.40", "98.90", "93.26", "92.75", "94.23", "95.45", "80.22", "77.03", "spaCy", "97.30", "61.19", "97.30", "86.72", "90.83", "\u2013", "87.05", "\u2013", "\u2013", "Chinese-GSD", "Sta", "n", "z", "a", "92.83", "98.80", "92.83", "89.12", "88.93", "92.11", "92.83", "72.88", "69.82", "UDPipe", "90.27", "99.10", "90.27", "84.13", "84.04", "89.05", "90.26", "61.60", "57.81", "Arabic-PADT", "Sta", "n", "z", "a", "99.98", "80.43", "97.88", "94.89", "91.75", "91.86", "93.27", "83.27", "79.33", "UDPipe", "99.98", "82.09", "94.58", "90.36", "84.00", "84.16", "88.46", "72.67", "68.14", "Overall", "(100", "treebanks)", "Sta", "n", "z", "a", "99.09", "86.05", "98.63", "92.49", "91.80", "89.93", "92.78", "80.45", "75.68", "Treebank", "System", "Tokens", "Sents.", "Words", "UPOS", "XPOS", "UFeats", "Lemmas", "UAS", "LAS"], "regionBoundary": {"x2": 524.0, "y1": 69.70076751708984, "x1": 74.0, "y2": 281.8900146484375}, "caption": "Table 2: Neural pipeline performance comparisons on the Universal Dependencies (v2.5) test treebanks. For our system we show macro-averaged results over all 100 treebanks. We also compare our system against UDPipe and spaCy on treebanks of five major languages where the corresponding pretrained models are publicly available. All results are F1 scores produced by the 2018 UD Shared Task official evaluation script.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.3432922363281, "y1": 528.2632615831163, "x1": 426.772223578559, "y2": 603.0180189344618}, "name": "1", "caption_text": "Figure 1: Overview of Sta n z a \u2019s neural NLP pipeline. Sta n z a takes multilingual text as input, and produces annotations accessible as native Python objects. Besides this neural pipeline, Sta n z a also features a Python client interface to the Java CoreNLP software.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 309.0, "x1": 427.0, "y2": 528.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 689.3395317925347, "y1": 246.46466573079425, "x1": 140.15417098999023, "y2": 254.80143229166666}, "name": "1", "caption_text": "Table 1: Feature comparisons of Sta n z a against other popular natural language processing toolkits.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 708.0, "y1": 86.0, "x1": 122.0, "y2": 230.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.224612765842, "y1": 363.8105180528429, "x1": 426.772223578559, "y2": 421.9598558213976}, "name": "3", "caption_text": "Figure 3: Sta n z a annotates a German sentence, as visualized by our interactive demo. Note am is expanded into syntactic words an and dem before downstream analyses are performed.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 717.0, "y1": 89.0, "x1": 439.0, "y2": 344.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.1617940266926, "y1": 408.33964877658417, "x1": 99.57083596123589, "y2": 468.56532626681854}, "name": "2", "caption_text": "Table 2: Neural pipeline performance comparisons on the Universal Dependencies (v2.5) test treebanks. For our system we show macro-averaged results over all 100 treebanks. We also compare our system against UDPipe and spaCy on treebanks of five major languages where the corresponding pretrained models are publicly available. All results are F1 scores produced by the 2018 UD Shared Task official evaluation script.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 86.0, "x1": 100.0, "y2": 436.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4506089952257, "y1": 355.17022874620227, "x1": 99.57083596123589, "y2": 446.529303656684}, "name": "3", "caption_text": "Table 3: NER performance across different languages and corpora. All scores reported are entity microaveraged test F1. For each corpus we also list the number of entity types. \u2217 marks results from publicly available pretrained models on the same dataset, while others are from models retrained on our datasets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 100.0, "y2": 355.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2229173448351, "y1": 177.3855103386773, "x1": 426.3430701361762, "y2": 252.140384250217}, "name": "4", "caption_text": "Table 4: Annotation runtime of various toolkits relative to spaCy (CPU) on the English EWT treebank and OntoNotes NER test sets. For reference, on the compared UD and NER tasks, spaCy is able to process 8140 and 5912 tokens per second, respectively.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 722.0, "y1": 86.0, "x1": 426.0, "y2": 177.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/f5f4bd8a5cf3e69bbc5fbb37a5d8b3f6c708a9b7/2020.acl-demos.14.pdf", "dpi": 100}