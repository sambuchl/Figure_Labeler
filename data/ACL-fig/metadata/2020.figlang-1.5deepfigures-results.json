{"raw_detected_boxes": [[], [{"x2": 705.0, "y1": 127.0, "x1": 121.0, "y2": 348.0}], [], [], [{"x2": 394.0, "y1": 732.0, "x1": 127.0, "y2": 904.0}], [], [], [], [], [{"x2": 687.0, "y1": 652.0, "x1": 451.0, "y2": 761.0}], [{"x2": 392.0, "y1": 363.0, "x1": 131.0, "y2": 671.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 292.2255554199219, "y1": 505.574951171875, "x1": 84.9959945678711, "y2": 544.960693359375}, "imageText": [], "regionBoundary": {"x2": 292.0, "y1": 255.0, "x1": 85.0, "y2": 494.0}, "caption": "Figure 4: A satirical headline generated by our model was published in the Brown Noser Satirical Newspaper, and accompanied by an article written by a human satirical writer. The article can be found here.", "page": 10}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 513.6426391601562, "y1": 267.0514221191406, "x1": 84.89290618896484, "y2": 317.68292236328125}, "imageText": [], "regionBoundary": {"x2": 509.0, "y1": 84.0, "x1": 85.0, "y2": 256.0}, "caption": "Figure 1: Pipeline for retrieving real-world textual context for a satirical headline. The extracted context is combined into a synthetic document, which is used as the input to a pretrained abstractive summarization model. The pipeline extracts named entities from the lede of the satirical article. These named entities are queried onWikipedia and CNN. The results are then ranked by comparing their similarity to the original article across several metrics. We task the model with decoding the original satirical headline.", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 512.0028076171875, "y1": 687.3202514648438, "x1": 85.3333969116211, "y2": 749.1973876953125}, "imageText": ["Input:", "a", "2014", "study", "of", "the", "effects", "of", "the", "oil", "spill", "on", "blue\ufb01n", "tuna", "funded", "by", "national", "oceanic", "and", "atmospheric", "administration...found", "that", "tuna", "and", "amberjack", "that", "were", "exposed", "to", "oil", "from", "the", "spill", "developed", "deformities", "of", "the", "heart", "and", "other", "organs", "that", "would", "be", "expected", "to", "be", "fatal", "or", "at", "least", "life-shortening", ".", "the", "scientists", "said", "that", "their", "\ufb01ndings", "would", "most", "likely", "apply", "to", "other", "large", "predator", "\ufb01sh", "and", "even", "to", "humans..", "bp", "was", "guilty", "of", "gross", "negligence", "and", "willful", "misconduct", ".", "he", "described", "bp\u2019s", "actions", "as", "\u2019reckless", "...", "E-Context:", "study", "\ufb01nds", "majority", "of", "americans", "still", "in", "oil", "spill", "/", "study", "\ufb01nds", "majority", "of", "tuna", "spills", "now", "in", "danger", "of", "human", "suffering", "D-Context:", "scientists", "discover", "that", "oil", "spills", "caused", "by", "natural", "causes", "A-Context:", "report", ":", "blue\ufb01n", "\ufb01sh", "may", "have", "been", "killed", "by", "\ufb01sh", "Onion:", "Shrimp", "Boat", "Captain", "Worn", "Out", "From", "Long", "Day", "Of", "Putting", "Human", "Face", "On", "Crisis", "GPT-2", "Satire:", "shrimp", "boat", "to", "be", "built", "in", "new", "york", "GPT-2", "News:", "shrimp", "boat", "sinks", "in", "gulf", "Input:", "the", "boston", "globe", "called", "for", "a", "nationwide", "refutation", "of", "trump\u2019s", "\u2019dirty", "war\u2019", "against", "the", "news", "media,", "with", "the", "hashtag", "enemy", "of", "none.", "more", "than", "300", "news", "outlets", "joined", "the", "campaign.", "the", "new", "york", "times", "called", "trump\u2019s", "attacks", "\u2019dangerous", "to", "the", "lifeblood", "of", "democracy...", "E-Context:", "trump", "vows", "to", "destroy", "all", "his", "words", "/", "trump:", "\u2019", "i", "\u2019m", "not", "the", "best", "guy", "in", "the", "world", "\u2019", "D-Context:", "trump", "vows", "to", "destroy", "all", "the", "things", "he", "\u2019s", "doing", "A-Context:", "trump", ":", "\u2018", "we", "\u2019re", "not", "going", "to", "let", "people", "know", "what", "it", "is", "\u2019", "Onion:", "Trump\u2019s", "Attacks", "On", "The", "Press", "GPT-2", "Satire:", "trump\u2019sick", "and", "tired", "of", "hearing\u2019", "trump", "say", "GPT-2", "News:", "trump\u2019sick", "of", "being", "in", "the", "middle", "of", "a", "\ufb01ght\u2019", "Input:", "the", "jet", "propulsion", "laboratory", "is", "a", "federally", "funded", "research", "and", "development", "center", "and", "nasa", "\ufb01eld", "center...on", "26", "november", "2011", ",", "nasa\u2019s", "mars", "science", "laboratory", "mission", "was", "successfully", "launched", "for", "mars", "...", "the", "rover", "is", "currently", "helping", "to", "determine", "whether", "mars", "could", "ever", "have", "supported", "life", ",", "and", "search", "for", "evidence", "of", "past", "or", "present", "life", "on", "mars", "...", "E-Context:", "nasa", "announces", "plan", "to", "put", "down", "mars", "/", "nasa", "announces", "plan", "to", "hunt", "mars", "D-Context:", "nasa", "launches", "new", "mission", "to", "\ufb01nd", "out", "what", "life", "is", "doing", "A-Context:", "mars", "scientists", "successfully", "successfully", "successfully", "successfully", "Onion:", "Coke-Sponsored", "Rover", "Finds", "Evidence", "Of", "Dasani", "On", "Mars", "GPT-2", "Satire:", "coke", "-", "a", "little", "too", "much", "GPT-2", "News:", "coke", "-", "the", "new", "\u2019dancing", "with", "the", "stars\u2019", "Input:", "a", "creator", "deity", "or", "creator", "god", "[", "often", "called", "the", "creator", "]", "is", "a", "deity", "or", "god", "responsible", "for", "the", "creation", "of", "the", "earth", ",", "world", ",", "and", "universe", "in", "human", "religion", "and", "mythology", ".", "in", "monotheism", ",", "the", "single", "god", "is", "often", "also", "the", "creator", ".", "a", "number", "of", "monolatristic", "traditions", "separate", "a", "secondary", "creator", "from", "a", "primary", "transcendent", "being", ",", "identi\ufb01ed", "as", "a", "primary", "creator...", "E-Context:", "god", "\u2019s", "name", "a", "big", "hit", "/", "god", "admits", "he", "\u2019s", "not", "the", "creator", "D-Context:", "god", "\u2019s", "god", "calls", "for", "greater", "understanding", "of", "all", "the", "things", "A-Context:", "god", "admits", "he", "\u2019s", "not", "a", "good", "person", "Onion:", "Biologists", "Con\ufb01rm", "God", "Evolved", "From", "Chimpanzee", "Deity", "GPT-2", "Satire:", "biologists", "con\ufb01rm", "GPT-2", "News:", "biologists", "con\ufb01rm", "human", "ancestor"], "regionBoundary": {"x2": 510.0, "y1": 84.0, "x1": 85.0, "y2": 676.0}, "caption": "Figure 2: A sample of documents (abbreviated) and resulting generations. These generations incorporate entities from the context while maintaining Onion-like language. This includes irreverent, observational tone, and the addition of frequently Onion corpus terms like \u201cstudy\u201d and \u201cannounces.\u201d We also observed that generations could invert facts expressed within the context (e.g. God admitting he is not the creator, or oil spills result from natural causes). We observe the decoder-weighted model resorting to more casual, repetitive language (e.g. \u201call the things...\u201d).", "page": 6}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 275.4613952636719, "y1": 599.2740478515625, "x1": 100.24819946289062, "y2": 604.9207763671875}, "imageText": ["\u2265", "1", "86.7%", "96.3%", "97.7%", "98.5%", "99.0%", "Majority", "48.3%", "61.5%", "69.1%", "74.5%", "80.7%", "Consensus", "Top", "1", "Top", "2", "Top", "3", "Top", "4", "Top", "5"], "regionBoundary": {"x2": 282.0, "y1": 611.0, "x1": 94.0, "y2": 663.974365234375}, "caption": "Table 2: Top 5 Retrieved Document Relevance", "page": 9}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 488.03173828125, "y1": 453.4768371582031, "x1": 330.3446044921875, "y2": 459.12359619140625}, "imageText": ["Onion", "5.0", "Summarizer", "9.9", "D-Context", "6.2", "E-Context", "6.7", "A-Context", "6.0", "Model", "Normalized", "Jaccard", "(Avg.)"], "regionBoundary": {"x2": 495.0, "y1": 470.0, "x1": 324.0, "y2": 553.0}, "caption": "Table 3: Generation-to-Context Similarity", "page": 9}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 292.2256164550781, "y1": 651.645263671875, "x1": 85.3333969116211, "y2": 691.031005859375}, "imageText": ["\u2022", "world", "health", "organization", "unveils", "new", "\u201c", "\u2019", "plan", "to", "cover", "up", "coronavirus", "Input:", "president", "donald", "trump", "announced", "tues-", "day", "he", "is", "halting", "funding", "to", "the", "world", "health", "organization", "while", "a", "review", "is", "conducted", ".", "trump", "said", "the", "review", "would", "cover", "the", "\u201d", "role", "in", "severely", "mismanaging", "and", "covering", "up", "the", "spread", "of", "coro-", "navirus", "\u201d", ".", "trump", "has", "sought", "to", "assign", "blame", "elsewhere", ",", "including", "at", "the", "who", "and", "in", "the", "news", "media", "\u2022", "nation", "\u2019s", "love", "of", "coronavirus", "now", "a", "little", "more", "complex", "Input:", "questions", "over", "whether", "downing", "street", "was", "fully", "transparent", "about", "the", "prime", "minister\u2019s", "health", ".", "but", "important", "issues", "risk", "overshadowing", "the", "true", "picture", "of", "the", "uk\u2019s", "struggle", "against", "coro-", "navirus", ".", "the", "uk", "is", "on", "a", "similar,", "grim", "trajectory", "as", "the", "uk", "is", "\u2022", "trump", "doubles", "down", "on", "prescription", "drug", "that", "can", "cause", "coronavirus", "Input:", "president", "donald", "trump", "doubled", "down", "on", "an", "unproven", "therapy", "for", "the", "novel", "coronavirus", ".", "without", "citing", "evidence", ",", "he", "said", "it\u2019s", "a", "\u201dgreat", "\u201d", "and", "\u201dpowerful\u201d", "anti-malaria", "drug", "\u201d", ".", "trump", "said", "it", "\u2019", "s"], "regionBoundary": {"x2": 290.0, "y1": 261.0, "x1": 86.0, "y2": 639.0}, "caption": "Figure 3: We preprocessed CNN articles from April using the pretrained abstractive summarization model provided by Liu and Lapata (2019). Our approach appears to generalize to these novel news contexts.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 240.7375030517578, "y1": 508.8610534667969, "x1": 134.97230529785156, "y2": 514.5078125}, "imageText": ["A-Context", "85.3%", "54.9%", "8.8", "%", "10.3%", "E-Context", "80.2%", "57.8%", "8.7%", "10.8%", "D-Context", "88.4%", "58.8%", "9.4%", "10.4%", "News", "GPT-2", "89.2%", "36.9%", "2.4%", "2.7%", "Satire", "GPT-2", "86.5%", "57.7%", "6.9%", "7.9%", "Model", "Coherence", "Onion", "Funny", "F", "|", "C", "Onion", "(Gold)", "99.5%", "86.6%38.2%", "38.4%"], "regionBoundary": {"x2": 285.0, "y1": 520.0, "x1": 85.0, "y2": 677.0}, "caption": "Table 1: Model Comparison", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 713.3925543891058, "y1": 370.90475294325086, "x1": 117.90681415134006, "y2": 441.22628106011285}, "name": "1", "caption_text": "Figure 1: Pipeline for retrieving real-world textual context for a satirical headline. The extracted context is combined into a synthetic document, which is used as the input to a pretrained abstractive summarization model. The pipeline extracts named entities from the lede of the satirical article. These named entities are queried onWikipedia and CNN. The results are then ranked by comparing their similarity to the original article across several metrics. We task the model with decoding the original satirical headline.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 707.0, "y1": 118.0, "x1": 120.0, "y2": 352.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 334.3576431274414, "y1": 706.751463148329, "x1": 187.46153513590494, "y2": 714.5941840277777}, "name": "1", "caption_text": "Table 1: Model Comparison", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 715.0, "x1": 126.0, "y2": 904.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 677.8218587239583, "y1": 629.8289404975043, "x1": 458.81195068359375, "y2": 637.6716613769531}, "name": "3", "caption_text": "Table 3: Generation-to-Context Similarity", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 687.0, "y1": 635.0, "x1": 450.0, "y2": 767.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.8688269721137, "y1": 702.1874321831597, "x1": 118.04999245537651, "y2": 756.8898518880208}, "name": "4", "caption_text": "Figure 4: A satirical headline generated by our model was published in the Brown Noser Satirical Newspaper, and accompanied by an article written by a human satirical writer. The article can be found here.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 406.0, "y1": 354.0, "x1": 118.0, "y2": 686.0}, "page": 10, "dpi": 0}], "error": null, "pdf": "/work/host-output/550e51b724411e46a5b27ce41aecdf5172041472/2020.figlang-1.5.pdf", "dpi": 100}