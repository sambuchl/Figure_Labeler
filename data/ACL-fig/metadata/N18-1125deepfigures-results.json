{"raw_detected_boxes": [[{"x2": 711.0, "y1": 320.0, "x1": 444.0, "y2": 563.0}], [], [{"x2": 358.0, "y1": 316.0, "x1": 143.0, "y2": 496.0}], [{"x2": 701.0, "y1": 110.0, "x1": 119.0, "y2": 248.0}], [{"x2": 361.0, "y1": 86.0, "x1": 131.0, "y2": 269.0}], [{"x2": 621.0, "y1": 87.0, "x1": 208.0, "y2": 231.0}], [{"x2": 713.0, "y1": 87.0, "x1": 445.0, "y2": 169.0}, {"x2": 398.0, "y1": 88.0, "x1": 105.0, "y2": 297.0}], [], [{"x2": 682.0, "y1": 86.0, "x1": 148.0, "y2": 222.0}, {"x2": 409.0, "y1": 287.0, "x1": 106.0, "y2": 378.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5455932617188, "y1": 460.4505310058594, "x1": 307.2749938964844, "y2": 563.14990234375}, "imageText": ["(c)", "Reference", "French", "unemployment", "rises", "again", "</S>", "(b)", "TFA-NMT", "French", "unemployment", "rises", "again", "</S>", "JJ", "NN", "VBZ", "RB", "EOS", "f\u0103", "gu\u00f3", "sh\u012b", "y\u00e8", "r\u00e9n", "sh\u00f9", "z\u00e0i", "d\u00f9", "hu\u00ed", "sh\u0113ng", "</S>", "\u6cd5\u56fd", "\u5931\u4e1a", "\u4eba\u6570", "\u518d\u5ea6", "\u56de\u5347", "</S>", "(a)", "Baseline", "French", "unemployment", "rate", "rises", "again", "</S>", "f\u0103", "gu\u00f3", "sh\u012b", "y\u00e8", "r\u00e9n", "sh\u00f9", "z\u00e0i", "d\u00f9", "hu\u00ed", "sh\u0113ng", "</S>", "\u6cd5\u56fd", "\u5931\u4e1a", "\u4eba\u6570", "\u518d\u5ea6", "\u56de\u5347", "</S>"], "regionBoundary": {"x2": 513.694580078125, "y1": 231.17068481445312, "x1": 319.1231689453125, "y2": 443.28436279296875}, "caption": "Figure 1: A running example to motivate the proposed model. (a) The baseline obtains a translation error due to the incorrect attention. (b) With the help of the target foresight information \u201cVBZ\u201d, TFA-NMT is likely to figure out the exact translation as the reference in (c). The light font denotes the target words to be translated in future. Both dashed or solid arrowed lines denote the alignments and solid one denotes the 1-best alignment.", "page": 0}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5364990234375, "y1": 179.30551147460938, "x1": 71.9990005493164, "y2": 222.22998046875}, "imageText": ["Nematus", "105M", "2858.8", "86.6", "38.65", "\u2013", "+2-Layer", "+6M", "2522.5", "84.1", "38.57", "\u2013", "+Model1", "+2M", "1844.9", "72.0", "38.83", "69.03", "+Model2", "+12M", "1666.1", "70.1", "39.26", "69.95", "+Model3", "+27M", "1485.2", "59.1", "40.63", "71.91", "Model", "#", "Para.", "Speed", "Performance", "Train", "Decode", "BLEU", "FPA"], "regionBoundary": {"x2": 448.0, "y1": 61.8900146484375, "x1": 149.0, "y2": 168.8900146484375}, "caption": "Table 1: Speeds and performances of the proposed models. \u201cSpeed\u201d is measured in words/second for both training and decoding, and performances are measured in terms of BLEU scores (\u201cBLEU\u201d) and foresight prediction accuracy (\u201cFPA\u201d) on the development set. Higher BLEU and FPA scores denote better performance.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.2662048339844, "y1": 224.36654663085938, "x1": 71.9990005493164, "y2": 255.33599853515625}, "imageText": ["Noun", "30.13%", "77.49", "28.97", "26.50", "Verb", "12.39%", "71.94", "37.06", "33.93", "Adj.", "9.43%", "55.99", "34.67", "31.86", "Prep.", "14.66%", "79.40", "84.04", "76.95", "Dete.", "10.08%", "72.06", "80.15", "76.51", "Punc.", "8.01%", "74.89", "91.74", "66.51", "Others", "15.30%", "81.22", "53.64", "39.11", "All", "100%", "74.87", "49.67", "42.56", "Type", "Perc.", "FPA", "AER", "Ours", "Base", "Ours"], "regionBoundary": {"x2": 287.0, "y1": 61.8900146484375, "x1": 75.0, "y2": 213.8900146484375}, "caption": "Table 2: Performances on syntactic categories. \u201cBase\u201d denotes \u201cNematus\u201d, and Ours denotes the proposed model.", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.54150390625, "y1": 133.74655151367188, "x1": 307.2749938964844, "y2": 176.6700439453125}, "imageText": ["Train", "(\u03bb)", "Decode", "BLEU", "\u25bd", "1", "Exp", "40.63", "\u2013", "0", "Exp", "39.36", "-1.27", "1", "Map", "40.34", "-0.29"], "regionBoundary": {"x2": 516.0, "y1": 61.8900146484375, "x1": 317.0, "y2": 122.8900146484375}, "caption": "Table 3: Effect of foresight supervision signal in training (i.e., \u03bb) and foresight representations in decoding: Exp for expectation and Map for maximum a posteriori.", "page": 6}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.26959228515625, "y1": 373.7865295410156, "x1": 71.9990005493164, "y2": 392.8000183105469}, "imageText": ["x", "yiyi\u22121", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "h", "ci\u03b1i", "sisi\u22121"], "regionBoundary": {"x2": 270.0, "y1": 227.8900146484375, "x1": 92.0, "y2": 358.8900146484375}, "caption": "Figure 2: One slice of the architecture of Neural Machine Translation based on a generic attention.", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5401611328125, "y1": 195.18649291992188, "x1": 71.9990005493164, "y2": 238.1099853515625}, "imageText": ["(c)", "model", "3", "yi\u22121", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "c\u2032i", "\u03b2i", "titi\u22121", "(b)", "model", "2", "yi\u22121", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u03b2i", "titi\u22121", "(a)", "model", "1", "\u03b2isi\u22121"], "regionBoundary": {"x2": 512.0, "y1": 67.8900146484375, "x1": 86.0, "y2": 176.60003662109375}, "caption": "Figure 3: The prediction coarse-to-fine models for target foresight information: (a) Model 1 using only the decoding hidden state si\u22121. (b) Model 2 using a hidden state ti from a specialized RNN. (c) Models using a hidden state from a specialized RNN enhanced by the representation vector c\u2032i of x similar to Eq.(5).", "page": 3}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 462.9040832519531, "y1": 174.87155151367188, "x1": 134.63600158691406, "y2": 181.9300537109375}, "imageText": ["This", "work", "Nematus", "38.65", "36.32", "36.10", "28.24", "33.55", "TFA-NMT", "40.63", "37.70", "38.01", "30.12", "35.28", "(Liu", "et", "al.,", "2016a)", "SA-NMT", "40.0", "37.8", "37.6", "29.9", "35.10", "(Liu", "et", "al.,", "2016b)", "Moses", "\u2013", "35.4", "33.7", "25.0", "31.37", "NMT-J", "\u2013", "36.8", "36.9", "28.5", "34.07", "System", "Model", "Dev", "MT05", "MT06", "MT08", "Ave."], "regionBoundary": {"x2": 491.0, "y1": 61.8900146484375, "x1": 107.0, "y2": 164.8900146484375}, "caption": "Table 4: Evaluation of translation performance on Chinese-to-English task.", "page": 8}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 290.2621765136719, "y1": 285.7655334472656, "x1": 71.9990005493164, "y2": 304.779052734375}, "imageText": ["This", "work", "Nematus", "33.92", "35.01TFA-Nmt", "35.14", "36.32", "System", "Model", "Dev", "Test", "(Liu", "et", "al.,", "2016b)", "Moses", "28.6", "30.2", "NMT-J", "33.0", "34.1"], "regionBoundary": {"x2": 295.0, "y1": 203.8900146484375, "x1": 71.0, "y2": 274.8900146484375}, "caption": "Table 5: Evaluation of translation performance on Japanese-to-English task.", "page": 8}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.2638244628906, "y1": 208.45455932617188, "x1": 71.99898529052734, "y2": 251.3790283203125}, "imageText": ["\u03b2i", "xz", "yiyi\u22121", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "\u00b7", "h", "ci\u03b1izi", "sisi\u22121"], "regionBoundary": {"x2": 270.0, "y1": 62.8900146484375, "x1": 92.0, "y2": 193.8900146484375}, "caption": "Figure 4: Neural machine translation with target Foresight attention. \u03b2i is derived from Figure 3, zi is from Eq.(10-11), and other nodes are similar to ones in Figure 2.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9244350857205, "y1": 639.5146263970269, "x1": 426.7708248562283, "y2": 782.1526421440972}, "name": "1", "caption_text": "Figure 1: A running example to motivate the proposed model. (a) The baseline obtains a translation error due to the incorrect attention. (b) With the help of the target foresight information \u201cVBZ\u201d, TFA-NMT is likely to figure out the exact translation as the reference in (c). The light font denotes the target words to be translated in future. Both dashed or solid arrowed lines denote the alignments and solid one denotes the 1-best alignment.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 320.0, "x1": 443.0, "y2": 563.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15221150716144, "y1": 519.147957695855, "x1": 99.99861187405057, "y2": 545.5555809868706}, "name": "2", "caption_text": "Figure 2: One slice of the architecture of Neural Machine Translation based on a generic attention.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 362.0, "y1": 316.0, "x1": 138.0, "y2": 499.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9168904622395, "y1": 271.09235127766925, "x1": 99.99861187405057, "y2": 330.70831298828125}, "name": "3", "caption_text": "Figure 3: The prediction coarse-to-fine models for target foresight information: (a) Model 1 using only the decoding hidden state si\u22121. (b) Model 2 using a hidden state ti from a specialized RNN. (c) Models using a hidden state from a specialized RNN enhanced by the representation vector c\u2032i of x similar to Eq.(5).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 93.0, "x1": 119.0, "y2": 248.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1442006429036, "y1": 289.5202212863498, "x1": 99.99859068128798, "y2": 349.13753933376734}, "name": "4", "caption_text": "Figure 4: Neural machine translation with target Foresight attention. \u03b2i is derived from Figure 3, zi is from Eq.(10-11), and other nodes are similar to ones in Figure 2.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 362.0, "y1": 86.0, "x1": 131.0, "y2": 269.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9118041992188, "y1": 249.03543260362412, "x1": 99.99861187405057, "y2": 308.65275065104163}, "name": "1", "caption_text": "Table 1: Speeds and performances of the proposed models. \u201cSpeed\u201d is measured in words/second for both training and decoding, and performances are measured in terms of BLEU scores (\u201cBLEU\u201d) and foresight prediction accuracy (\u201cFPA\u201d) on the development set. Higher BLEU and FPA scores denote better performance.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 622.0, "y1": 86.0, "x1": 208.0, "y2": 233.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9187554253472, "y1": 185.75909932454425, "x1": 426.7708248562283, "y2": 245.37506103515625}, "name": "3", "caption_text": "Table 3: Effect of foresight supervision signal in training (i.e., \u03bb) and foresight representations in decoding: Exp for expectation and Map for maximum a posteriori.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 86.0, "x1": 428.0, "y2": 186.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1475067138672, "y1": 311.6202036539713, "x1": 99.99861187405057, "y2": 354.6333312988281}, "name": "2", "caption_text": "Table 2: Performances on syntactic categories. \u201cBase\u201d denotes \u201cNematus\u201d, and Ours denotes the proposed model.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 86.0, "x1": 100.0, "y2": 314.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 642.9223378499348, "y1": 242.87715488009982, "x1": 186.99444664849176, "y2": 252.68063015407986}, "name": "4", "caption_text": "Table 4: Evaluation of translation performance on Chinese-to-English task.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 682.0, "y1": 86.0, "x1": 148.0, "y2": 228.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.14191182454425, "y1": 396.89657423231336, "x1": 99.99861187405057, "y2": 423.30423990885413}, "name": "5", "caption_text": "Table 5: Evaluation of translation performance on Japanese-to-English task.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 282.0, "x1": 100.0, "y2": 382.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/c0fa436f64d856e927fb95c89e6d3cf117c8ea6e/N18-1125.pdf", "dpi": 100}