{"raw_detected_boxes": [[], [{"x2": 404.0, "y1": 87.0, "x1": 108.0, "y2": 335.0}], [{"x2": 742.0, "y1": 87.0, "x1": 444.0, "y2": 549.0}], [{"x2": 407.0, "y1": 437.0, "x1": 110.0, "y2": 964.0}], [{"x2": 411.0, "y1": 85.0, "x1": 104.0, "y2": 226.0}], [{"x2": 733.0, "y1": 84.0, "x1": 450.0, "y2": 270.0}, {"x2": 734.0, "y1": 327.0, "x1": 452.0, "y2": 417.0}], [{"x2": 411.0, "y1": 84.0, "x1": 101.0, "y2": 255.0}, {"x2": 746.0, "y1": 84.0, "x1": 439.0, "y2": 209.0}], [{"x2": 413.0, "y1": 84.0, "x1": 101.0, "y2": 180.0}, {"x2": 745.0, "y1": 84.0, "x1": 438.0, "y2": 180.0}], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 298.79937744140625, "y1": 259.0489807128906, "x1": 72.00080108642578, "y2": 312.8721618652344}, "text": "Figure 1: An example translation forest encoding two synchronous derivations for a Spanish sentence: one solid and one dotted. Nodes are annotated with their left and right unigram contexts, and hyperedges are annotated with scores \u03b8 \u00b7 \u03c6(r) and the bigrams they introduce.", "name": "1", "page": 1}, {"figType": "Figure", "boundary": {"x2": 298.79937744140625, "y1": 182.70144653320312, "x1": 72.00080108642578, "y2": 236.52459716796875}, "text": "Figure 3: Hypergraph expansion ensures n-gram locality without affecting the distribution over derivations. In the left example, trigrams \u201cgreen witch was\u201d and \u201cblue witch was\u201d are non-local due to language model back-off. On the right, states are split to enforce trigram locality.", "name": "3", "page": 4}], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 510.8899841308594, "y1": 205.91091918945312, "x1": 342.3127746582031, "y2": 211.91339111328125}, "imageText": ["Sys", "Base", "dev", "nist08", "dev", "nist08", "PB", "MAX", "51.6", "43.9", "37.7", "25.4", "PB", "MBR", "52.4\u2217", "44.6\u2217", "38.6\u2217", "27.3\u2217", "PB", "CON", "52.4\u2217", "44.6\u2217", "38.7\u2217", "27.2\u2217", "Hiero", "MAX", "50.9", "43.3", "40.0", "27.2", "Hiero", "MBR", "51.4\u2217", "43.8\u2217", "40.6\u2217", "27.8", "Hiero", "CON", "51.5\u2217", "43.8\u2217", "40.5\u2217", "28.2", "SAMT", "MAX", "51.7", "43.8", "40.8\u2217", "28.4", "SAMT", "MBR", "52.7\u2217", "44.5\u2217", "41.1\u2217", "28.8\u2217", "SAMT", "CON", "52.6\u2217", "44.4\u2217", "41.1\u2217", "28.7\u2217", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 529.0, "y1": 60.0, "x1": 324.0, "y2": 194.0}, "caption": "Table 1: Performance of baseline systems.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 540.0006103515625, "y1": 316.76458740234375, "x1": 313.2003173828125, "y2": 370.5877685546875}, "imageText": ["MC", "Conjoin/SI", "53.5", "45.3", "41.6", "29.0\u2217", "Approach", "dev", "nist08", "dev", "nist08", "Best", "MAX", "system", "51.7", "43.9", "40.8", "28.4", "Best", "MBR", "system", "52.7", "44.5", "41.1", "28.8\u2217", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 529.0, "y1": 233.0, "x1": 324.0, "y2": 300.0}, "caption": "Table 2: Performance from the best single system for each language pair without consensus decoding (Best MAX system), the best system with minimum Bayes risk decoding (Best MBR system), and model combination across three systems.", "page": 5}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 539.9993896484375, "y1": 166.65817260742188, "x1": 313.2007751464844, "y2": 232.4365234375}, "imageText": ["Approach", "Base", "dev", "nist08", "dev", "nist08", "Sent-level", "MAX", "51.8\u2217", "44.4\u2217", "40.8\u2217", "28.2\u2217", "Word-level", "MAX", "52.0\u2217", "44.4\u2217", "40.8\u2217", "28.1\u2217", "Sent-level", "MBR", "52.7+", "44.6\u2217", "41.2", "28.8+", "Word-level", "MBR", "52.5+", "44.7\u2217", "40.9", "28.8+", "MC-conjoin-SI", "53.5", "45.3", "41.6", "29.0+", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 537.0, "y1": 60.0, "x1": 316.0, "y2": 150.0}, "caption": "Table 4: BLEU performance for different system and model combination approaches. Sentence-level and word-level system combination operate over the sentence output of the base systems, which are either decoded to maximize derivation score (MAX) or to minimize Bayes risk (MBR).", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 268.4994812011719, "y1": 200.33175659179688, "x1": 99.21499633789062, "y2": 206.334228515625}, "imageText": ["Strategy", "dev", "nist08", "dev", "nist08", "Best", "MBR", "system", "52.7", "44.5", "41.1", "28.8", "MBR", "Conjoin", "52.3", "44.5", "40.5", "28.3", "MBR", "Conjoin/feats-best", "52.7", "44.9", "41.2", "28.8", "MBR", "Conjoin/SI", "53.1", "44.9", "41.2", "28.9", "MC", "1-best", "HG", "52.7", "44.6", "41.1", "28.7", "MC", "Conjoin", "52.9", "44.6", "40.3", "28.1", "MC", "Conjoin/base/SI", "53.5", "45.1", "41.2", "28.9", "MC", "Conjoin/SI", "53.5", "45.3", "41.6", "29.0", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 298.0, "y1": 60.0, "x1": 72.0, "y2": 184.0}, "caption": "Table 3: Model Combination experiments.", "page": 6}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 539.9999389648438, "y1": 416.79241943359375, "x1": 313.20068359375, "y2": 506.4811096191406}, "imageText": ["\u201csaw", "the\u201d:", "[", "v2pb", "=", "0.9,", "v", "2", "h", "=", "0.7", "]", "v2h(\u201csaw", "the\u201d)", "=", "0.7v", "2", "pb(\u201csaw", "the\u201d)", "=", "0.9", "d\u2217", "=", "arg", "max", "d\u2208D", "sw(d)", "w", "=", "arg", "max", "w", "BLEU", "({", "arg", "max", "d\u2208D(f)", "sw(d)", "}", ";", "e", ")", "[\u03b1pb", "=", "1]", "[\u03b1h", "=", "1]", "Rpb", "Rh", "R", "......", "Phrase-based", "model", "Hierarchical", "model", "Step", "4:", "Model", "Training", "and", "Inference", "Step", "3:", "Add", "Features", "for", "the", "Combination", "Model", "Step", "2:", "Construct", "a", "Search", "Space", "\u201cI", "saw", "with", "the", "telescope", "the", "man\u201d", "Step", "1:", "Compute", "Combination", "Features", "\u201cI", "saw", "the", "man", "with", "the", "telescope\u201d", "\u201csaw", "with\u201d", "I", "...", "telescope", "0.3", "\u201ctelescope", "the\u201d", "0.4", "I", "...", "man", "\u201cman", "with\u201d", "1.0", "\u201csaw", "the\u201d", "the", "...", "telescope", "0.6", "I", "...", "saw", "the", "...", "man", "with", "...", "telescope", "Yo", "vi", "al", "hombre", "con", "el", "telescopio", "I", "...", "telescope", "Rpb", "Rh", "R"], "regionBoundary": {"x2": 775.1793212890625, "y1": 60.0, "x1": 318.0, "y2": 401.0}, "caption": "Figure 2: Model combination applied to a phrase-based (pb) and a hierarchical model (h) includes four steps. (1) shows an excerpt of the bigram feature function for each component, (2) depicts the result of conjoining a phrase lattice with a hierarchical forest, (3) shows example hyperedge features of the combination model, including bigram features vni and system indicators \u03b1i, and (4) gives training and decoding objectives.", "page": 2}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 539.9991455078125, "y1": 146.33407592773438, "x1": 313.2006530761719, "y2": 164.291748046875}, "imageText": ["Posteriors", "dev", "nist08", "dev", "nist08", "Exact", "52.4\u2217", "44.6\u2217", "38.6\u2217", "27.3\u2217", "Approximate", "52.5\u2217", "44.6\u2217", "38.6\u2217", "27.2\u2217", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 537.0, "y1": 60.0, "x1": 316.0, "y2": 130.0}, "caption": "Table 6: MBR decoding on the phrase-based system with either exact or approximate posteriors.", "page": 7}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 298.79937744140625, "y1": 146.33407592773438, "x1": 72.0008316040039, "y2": 164.291748046875}, "imageText": ["Approach", "dev", "nist08", "dev", "nist08", "HG-expand", "52.7\u2217", "44.5\u2217", "41.1\u2217", "28.8\u2217", "HG-noexpand", "52.7\u2217", "44.5\u2217", "41.1\u2217", "28.8\u2217", "BLEU", "(%)", "ar-en", "zh-en"], "regionBoundary": {"x2": 298.0, "y1": 60.0, "x1": 72.0, "y2": 130.0}, "caption": "Table 5: MBR decoding on the syntax augmented system, with and without hypergraph expansion.", "page": 7}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 414.99913533528644, "y1": 359.79025099012586, "x1": 100.0011126200358, "y2": 434.54466925726996}, "name": "1", "caption_text": "Figure 1: An example translation forest encoding two synchronous derivations for a Spanish sentence: one solid and one dotted. Nodes are annotated with their left and right unigram contexts, and hyperedges are annotated with scores \u03b8 \u00b7 \u03c6(r) and the bigrams they introduce.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 407.0, "y1": 87.0, "x1": 108.0, "y2": 335.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9999152289496, "y1": 578.8783603244358, "x1": 435.00094943576386, "y2": 703.4459855821398}, "name": "2", "caption_text": "Figure 2: Model combination applied to a phrase-based (pb) and a hierarchical model (h) includes four steps. (1) shows an excerpt of the bigram feature function for each component, (2) depicts the result of conjoining a phrase lattice with a hierarchical forest, (3) shows example hyperedge features of the combination model, including bigram features vni and system indicators \u03b1i, and (4) gives training and decoding objectives.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 742.0, "y1": 87.0, "x1": 444.0, "y2": 556.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.99913533528644, "y1": 253.75200907389322, "x1": 100.0011126200358, "y2": 328.50638495551215}, "name": "3", "caption_text": "Figure 3: Hypergraph expansion ensures n-gram locality without affecting the distribution over derivations. In the left example, trigrams \u201cgreen witch was\u201d and \u201cblue witch was\u201d are non-local due to language model back-off. On the right, states are split to enforce trigram locality.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 411.0, "y1": 85.0, "x1": 104.0, "y2": 228.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 709.5694224039713, "y1": 285.98738776312933, "x1": 475.43440924750433, "y2": 294.3241543240017}, "name": "1", "caption_text": "Table 1: Performance of baseline systems.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 735.0, "y1": 84.0, "x1": 450.0, "y2": 287.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0008477105034, "y1": 439.9508158365885, "x1": 435.0004408094618, "y2": 514.7052341037327}, "name": "2", "caption_text": "Table 2: Performance from the best single system for each language pair without consensus decoding (Best MAX system), the best system with minimum Bayes risk decoding (Best MBR system), and model combination across three systems.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 734.0, "y1": 323.0, "x1": 451.0, "y2": 417.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 372.9159461127387, "y1": 278.23855082194007, "x1": 137.79860602484808, "y2": 286.5753173828125}, "name": "3", "caption_text": "Table 3: Model Combination experiments.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 414.0, "y1": 84.0, "x1": 101.0, "y2": 255.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9991522894965, "y1": 231.46968417697482, "x1": 435.0010765923394, "y2": 322.82850477430554}, "name": "4", "caption_text": "Table 4: BLEU performance for different system and model combination approaches. Sentence-level and word-level system combination operate over the sentence output of the base systems, which are either decoded to maximize derivation score (MAX) or to minimize Bayes risk (MBR).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 746.0, "y1": 84.0, "x1": 439.0, "y2": 209.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.99913533528644, "y1": 203.2417721218533, "x1": 100.00115500556097, "y2": 228.1829833984375}, "name": "5", "caption_text": "Table 5: MBR decoding on the syntax augmented system, with and without hypergraph expansion.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 414.0, "y1": 84.0, "x1": 101.0, "y2": 180.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9988132052952, "y1": 203.2417721218533, "x1": 435.0009070502387, "y2": 228.1829833984375}, "name": "6", "caption_text": "Table 6: MBR decoding on the phrase-based system with either exact or approximate posteriors.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 747.0, "y1": 84.0, "x1": 438.0, "y2": 180.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/c108531fbf3218787cc9d779d3c06ec9e92c0e10/N10-1141.pdf", "dpi": 100}