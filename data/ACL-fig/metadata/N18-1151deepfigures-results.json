{"raw_detected_boxes": [[], [{"x2": 723.0, "y1": 90.0, "x1": 422.0, "y2": 254.0}, {"x2": 726.0, "y1": 352.0, "x1": 432.0, "y2": 433.0}], [{"x2": 401.0, "y1": 93.0, "x1": 108.0, "y2": 269.0}, {"x2": 722.0, "y1": 90.0, "x1": 431.0, "y2": 256.0}], [{"x2": 728.0, "y1": 86.0, "x1": 429.0, "y2": 236.0}], [{"x2": 711.0, "y1": 86.0, "x1": 120.0, "y2": 259.0}], [{"x2": 711.0, "y1": 86.0, "x1": 119.0, "y2": 258.0}], [{"x2": 400.0, "y1": 86.0, "x1": 103.0, "y2": 246.0}, {"x2": 703.0, "y1": 92.0, "x1": 426.0, "y2": 255.0}], [{"x2": 373.0, "y1": 86.0, "x1": 127.0, "y2": 211.0}, {"x2": 728.0, "y1": 87.0, "x1": 420.0, "y2": 334.0}], [{"x2": 401.0, "y1": 86.0, "x1": 100.0, "y2": 230.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5494384765625, "y1": 320.7295837402344, "x1": 307.2769470214844, "y2": 394.4780578613281}, "imageText": ["Target", "post", "for", "keyphrase", "extraction:", "\u201dI", "will", "curse", "you", "in", "that", "forum\u201d", "is", "the", "lowest", "of", "low.", "You", "are", "an", "embarrassment", "president", "Duterte.", "Childish!", "Messages", "forming", "a", "conversation:", "[R1]:", "any", "head", "of", "state", "will", "be", "irked", "if", "asked", "to", "report", "to", "another", "head", "of", "state", "[R2]:", "Really?", "Did", "Obama", "really", "asked", "Duterte", "to", "report", "to", "him?", "LOL"], "regionBoundary": {"x2": 522.0, "y1": 221.8900146484375, "x1": 310.0, "y2": 307.8900146484375}, "caption": "Table 1: An example conversation about \u201cpresident Duterte\u201d on Twitter. [Ri]: The i-th message in conversation ordered by their positing time. president Duterte: keyphrase to be detected; Italic words: words that are related to the main topic in conversations and can indicate the keyphrase.", "page": 0}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.548828125, "y1": 199.78854370117188, "x1": 72.0009994506836, "y2": 205.791015625}, "imageText": ["No", "encoder", "58.8\u00b11.4", "66.2\u00b10.8", "67.3\u00b11.6", "74.8\u00b10.7", "55.5\u00b10.5", "64.1\u00b10.7", "64.9\u00b10.6", "76.8\u00b10.5", "Context", "Encoder", "Avg", "Emb", "63.3\u00b10.9", "68.2\u00b10.7", "69.4\u00b10.4", "76.6\u00b10.9", "61.1\u00b11.2", "69.7\u00b11.3", "69.3\u00b10.7", "79.8\u00b10.6", "RNN", "58.2\u00b11.6", "64.9\u00b10.6", "65.3\u00b10.8", "73.1\u00b10.1", "60.9\u00b10.5", "67.1\u00b10.6", "66.7\u00b10.5", "71.2\u00b10.7", "GRU", "56.5\u00b10.8", "67.0\u00b10.6", "67.4\u00b11.1", "73.8\u00b10.7", "58.4\u00b11.1", "65.5\u00b10.8", "67.1\u00b10.4", "76.2\u00b10.7", "LSTM", "59.4\u00b12.0", "67.6\u00b10.8", "68.1\u00b10.5", "75.5\u00b10.2", "61.1\u00b11.9", "68.4\u00b11.1", "69.5\u00b10.7", "78.1\u00b11.0", "BILSTM", "60.8\u00b11.7", "68.6\u00b11.0", "68.4\u00b10.7", "75.9\u00b10.7", "61.6\u00b11.8", "69.3\u00b11.0", "69.6\u00b10.3", "78.2\u00b10.8", "Att", "(LSTM)", "62.4\u00b11.8", "67.6\u00b11.1", "69.0\u00b10.7", "75.8\u00b11.2", "63.1\u00b11.3", "70.2\u00b10.8", "70.8\u00b11.3", "79.3\u00b10.5", "Att", "(BiLSTM)", "59.6\u00b11.4", "68.6\u00b10.6", "70.4\u00b11.0", "76.5\u00b10.8", "61.5\u00b12.2", "70.5\u00b10.6", "71.0\u00b10.5", "80.5\u00b11.7", "MemNN", "61.1\u00b10.4", "69.3\u00b10.5", "69.9\u00b10.7", "79.1\u00b11.1", "61.8\u00b11.4", "68.7\u00b10.9", "69.3\u00b10.4", "79.6\u00b11.4", "Single-layer", "Taggers", "Joint-layer", "Taggers", "RNN", "GRU", "LSTM", "BiLSTM", "RNN", "GRU", "LSTM", "BiLSTM"], "regionBoundary": {"x2": 512.0, "y1": 63.8900146484375, "x1": 86.0, "y2": 186.8900146484375}, "caption": "Table 5: Comparisons of F1 scores on Weibo. The abbreviations are defined the same as those in Table 4.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.546142578125, "y1": 196.76559448242188, "x1": 307.2770080566406, "y2": 243.41607666015625}, "imageText": ["\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "\u2026", "+", "+", "+", "\ud835\udc86\ud835\udc56", "\ud835\udc50", "\ud835\udc3c\ud835\udc3c\ud835\udc50", "\ud835\udc3c\ud835\udc50", "\ud835\udc3c\ud835\udc50", "Conversation", "context", "\ud835\udc99\ud835\udc56", "\ud835\udc50", "Target", "post", "\ud835\udc99\ud835\udc56", "\ud835\udc65\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc65\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc65\ud835\udc56,\ud835\udc60+1", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc60+1", "\ud835\udc50", "\ud835\udc3c", "\ud835\udc3c", "\ud835\udc89\ud835\udc61\u22121", "\ud835\udc89\ud835\udc61", "\ud835\udc89\ud835\udc61+1", "Keyphrase", "Tagger", "\ud835\udc66\ud835\udc56,\ud835\udc61\u22121", "\ud835\udc66\ud835\udc56,\ud835\udc61", "\ud835\udc66\ud835\udc56,\ud835\udc61+1", "Context", "Encoder", "\ud835\udc97\ud835\udc56,\ud835\udc61\u22121", "\ud835\udc97\ud835\udc56,\ud835\udc61", "\ud835\udc97\ud835\udc56,\ud835\udc61+1", "\ud835\udc65\ud835\udc56,\ud835\udc61\u22121", "\ud835\udc65\ud835\udc56,\ud835\udc61", "\ud835\udc65\ud835\udc56,\ud835\udc61+1"], "regionBoundary": {"x2": 520.0, "y1": 63.8900146484375, "x1": 304.0, "y2": 182.70330810546875}, "caption": "Figure 1: The overall structure of our keyphrase extraction framework with context encoder. Grey dotted array refer to the inputs of target posts that are also used in context encoding.", "page": 1}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 494.2542724609375, "y1": 324.8665771484375, "x1": 338.5670166015625, "y2": 332.5050354003906}, "imageText": ["SINGLE", "xi,t", "is", "a", "one-word", "keyphrase", "(keyword).", "BEGIN", "xi,t", "is", "the", "\ufb01rst", "word", "of", "a", "keyphrase.", "MIDDLE", "xi,t", "is", "part", "of", "a", "keyphrase", "but", "it", "is", "neitherthe", "\ufb01rst", "nor", "the", "last", "word", "of", "the", "keyphrase.", "END", "xi,t", "is", "the", "last", "word", "of", "a", "keyphrase", "NOT", "xi,t", "is", "not", "a", "keyword", "or", "part", "of", "a", "keyphrase."], "regionBoundary": {"x2": 525.0, "y1": 247.8900146484375, "x1": 308.0, "y2": 311.8900146484375}, "caption": "Table 2: Definitions of different yi,t.", "page": 1}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 290.2702941894531, "y1": 197.19857788085938, "x1": 72.0009994506836, "y2": 270.94708251953125}, "imageText": ["No", "encoder", "60.8", "74.8", "62.5", "76.8", "Avg", "Emb", "61.0", "75.7", "63.3", "79.2", "RNN", "58.8", "72.7", "63.1", "71.1", "GRU", "56.4", "73.1", "62.7", "76.0", "LSTM", "61.3", "75.2", "63.9", "77.8", "BiLSTM", "62.0", "75.4", "62.3", "78.0", "Att", "(LSTM)", "62.6", "75.6", "63.7", "79.2", "Att", "(BiLSTM)", "62.0", "76.5", "63.9", "79.9", "MemNN", "61.6", "77.4", "65.1", "79.2", "SL", "BiLSTM", "JL", "BiLSTM", "Twitter", "Weibo", "Twitter", "Weibo"], "regionBoundary": {"x2": 288.0, "y1": 62.8900146484375, "x1": 74.0, "y2": 178.8900146484375}, "caption": "Table 6: The F1 scores of BiLSTM taggers measured on test instances without conversation context (%). SL BiLSTM and JL BiLSTM denote keyphrase tagger as single-layer and joint-layer BiLSTM, respectively. The other abbreviations are defined the same as those in Table 4.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5462646484375, "y1": 197.44155883789062, "x1": 307.2770080566406, "y2": 271.1900634765625}, "imageText": [], "regionBoundary": {"x2": 538.0, "y1": 61.8900146484375, "x1": 293.0, "y2": 189.8900146484375}, "caption": "Figure 4: The heatmap of the context representation generated by MemNN (see Eq. 8). The horizontal axis refers to words in the conversation context, while the vertical axis refers to words in the target post. Darker colors indicate higher weights. The red box indicates the keyphrase to be detected.", "page": 6}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5482177734375, "y1": 198.26254272460938, "x1": 307.2770080566406, "y2": 217.81402587890625}, "imageText": ["\u2026", "\u2026", "\u2026", "\u2026", "\ud835\udc96\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc96\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc96\ud835\udc56,\ud835\udc60+1", "\ud835\udc50", "|\ud835\udc99\ud835\udc56|", "\ud835\udc6a\ud835\udc56", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc61+1", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc61+1", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60+1", "\ud835\udc50\ud835\udc97\ud835\udc56,\ud835\udc61+1", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc61", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc61", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60+1", "\ud835\udc50\ud835\udc97\ud835\udc56,\ud835\udc61", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc61\u22121", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc61\u22121", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60+1", "\ud835\udc50\ud835\udc97\ud835\udc56,\ud835\udc61\u22121", "\u22c5", "\ud835\udc97\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\ud835\udc74\ud835\udc56", "\ud835\udc97\ud835\udc56,\ud835\udc61", "\ud835\udc97\ud835\udc56,\ud835\udc61+1\ud835\udc97\ud835\udc56,\ud835\udc61\u22121", "\ud835\udc97\ud835\udc56,\ud835\udc60", "\ud835\udc50", "\ud835\udc97\ud835\udc56,\ud835\udc60+1", "\ud835\udc50\ud835\udc97\ud835\udc56,\ud835\udc60\u22121", "\ud835\udc50", "\u03a3", "\ud835\udc86\ud835\udc56", "\ud835\udc50", "Softmax", "\ud835\udc77\ud835\udc56"], "regionBoundary": {"x2": 523.39111328125, "y1": 63.69483947753906, "x1": 306.6571044921875, "y2": 184.8900146484375}, "caption": "Figure 3: The structure of the conversation context encoder based on memory networks.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.2687683105469, "y1": 209.69955444335938, "x1": 72.0009994506836, "y2": 229.25103759765625}, "imageText": ["\u2026", "\u2026"], "regionBoundary": {"x2": 290.0212707519531, "y1": 64.8900146484375, "x1": 73.21150970458984, "y2": 195.8900146484375}, "caption": "Figure 2: The structure of attention-based conversation context encoder.", "page": 2}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 290.2738952636719, "y1": 170.09957885742188, "x1": 72.0009994506836, "y2": 216.75006103515625}, "imageText": ["Extracted", "keyphrase", "Gold-standard", "president", "duterte", "No", "encoder", "duterte", "childish", "Context", "Encoder", "Avg", "Emb", "NULL", "BiLSTM", "duterte", "childish", "Att", "(BiLSTM)", "president", "duterte", "childish", "MemNN", "president", "duterte"], "regionBoundary": {"x2": 272.0, "y1": 62.8900146484375, "x1": 90.0, "y2": 151.8900146484375}, "caption": "Table 7: Outputs of joint-layer BiLSTM combined with various context encoders given the example illustrated in Table1. \u201cNULL\u201d: Avg Emb did not produce any keyphrase.", "page": 7}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5462646484375, "y1": 262.4255676269531, "x1": 307.2770080566406, "y2": 363.2730712890625}, "imageText": ["(c)", "SL", "BiLSTM", "on", "Weibo", "(d)", "JL", "BiLSTM", "on", "Weibo", "(a)", "SL", "BiLSTM", "on", "Twitter", "(b)", "JL", "BiLSTM", "on", "Twitter"], "regionBoundary": {"x2": 527.0, "y1": 61.8900146484375, "x1": 300.0, "y2": 245.9930419921875}, "caption": "Figure 5: Histograms of F1 scores on extracting keyphrases with various lengths. SL BiLSTM: tagger based on single-layer BiLSTM. JL BiLSTM: tagger based on joint-layer BiLSTM. Length: count of words in keyphrases. For each length range, histograms from left to right show the results of No encoder, Avg Emb, LSTM, BiLSTM, Att (LSTM), ATT (BiLSTM), and MemNN.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5462646484375, "y1": 189.22854614257812, "x1": 307.2770080566406, "y2": 290.0750732421875}, "imageText": ["Weibo", "Train", "13,816", "1.97", "55.77", "25,259", "Dev", "1,727", "2.01", "45.00", "9,106", "Test", "1,727", "1.82", "51.95", "9,305", "Dataset", "#", "of", "an-not.", "msgs", "#", "of", "msgs", "in", "context", "Context", "length", "Vocab", "Twitter", "Train", "3,976", "3.38", "49.74", "34,412", "Dev", "497", "3.19", "46.44", "7,186", "Test", "497", "3.30", "48.09", "8,779"], "regionBoundary": {"x2": 525.0, "y1": 62.8900146484375, "x1": 308.0, "y2": 170.8900146484375}, "caption": "Table 3: Statistics of two datasets. Train, Dev, and Test denotes training, development, and test set, respectively. # of annot. msgs: number of messages with keyphrase annotation, each containing conversation context. # of msgs in context: average count of message in conversation context. Context length: average count of words in conversation context. Vocab: vocabulary size.", "page": 3}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 290.2705078125, "y1": 187.23556518554688, "x1": 72.0009994506836, "y2": 247.43505859375}, "imageText": ["w/o", "context", "TF-IDF", "6.3", "48.8", "11.1", "1.9", "7.3", "3.0", "TextRank", "6.6", "18.8", "9.7", "1.0", "8.6", "1.7", "KEA", "3.5", "0.8", "1.3", "0.1", "0.2", "0.1", "w/", "context", "TF-IDF", "7.9", "45.6", "13.4", "2.1", "8.3", "3.4", "TextRank", "4.8", "20.8", "7.8", "1.0", "9.5", "1.8", "KEA", "15.4", "12.9", "14.0", "2.2", "12.3", "3.7", "Twitter", "Weibo", "Pre", "Rec", "F1", "Pre", "Rec", "F1"], "regionBoundary": {"x2": 290.0, "y1": 62.8900146484375, "x1": 72.0, "y2": 168.8900146484375}, "caption": "Table 8: Precision, recall, and F1 scores of ranking-based baselines (%). w/o context: each target post is treated as a document; w/ context: each conversation and its corresponding target post is treated as a document.", "page": 8}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.5505981445312, "y1": 199.78854370117188, "x1": 72.0009994506836, "y2": 273.53704833984375}, "imageText": ["No", "Encoder", "44.9\u00b11.4", "53.9\u00b14.7", "54.9\u00b13.8", "60.8\u00b13.6", "51.0\u00b13.3", "56.1\u00b13.4", "55.1\u00b12.6", "62.5\u00b10.9", "Context", "Encoder", "Avg", "Emb", "50.4\u00b10.9", "58.8\u00b12.9", "56.0\u00b10.7", "62.2\u00b13.0", "51.5\u00b11.7", "59.0\u00b13.5", "58.7\u00b13.7", "64.5\u00b10.4", "RNN", "46.4\u00b11.6", "56.4\u00b11.9", "55.6\u00b12.5", "59.0\u00b12.4", "52.2\u00b12.8", "54.4\u00b12.8", "58.3\u00b11.8", "63.7\u00b11.3", "GRU", "50.3\u00b10.8", "53.7\u00b11.0", "58.0\u00b10.9", "56.8\u00b12.3", "50.8\u00b14.8", "52.3\u00b13.8", "57.0\u00b12.1", "63.0\u00b11.3", "LSTM", "51.6\u00b12.0", "56.4\u00b11.4", "57.9\u00b12.3", "64.0\u00b13.1", "50.8\u00b13.1", "57.9\u00b12.3", "58.3\u00b14.0", "64.2\u00b10.6", "BiLSTM", "49.2\u00b11.7", "58.3\u00b11.1", "56.0\u00b12.0", "62.6\u00b13.2", "52.7\u00b13.4", "56.8\u00b11.0", "56.5\u00b13.6", "63.7\u00b12.3", "Att", "(LSTM)", "48.7\u00b11.7", "58.1\u00b11.7", "58.1\u00b13.1", "64.0\u00b11.8", "51.7\u00b14.8", "57.4\u00b12.3", "58.0\u00b12.4", "63.8\u00b11.5", "Att", "(BiLSTM)", "51.7\u00b11.4", "58.3\u00b11.5", "57.0\u00b13.6", "62.8\u00b12.5", "52.3\u00b14.3", "58.0\u00b11.8", "59.0\u00b13.9", "64.2\u00b13.4", "MemNN", "53.6\u00b10.3", "59.4\u00b13.1", "59.5\u00b14.1", "62.4\u00b14.8", "53.7\u00b13.5", "59.4\u00b12.1", "62.3\u00b13.3", "65.5\u00b11.6", "Single-layer", "Taggers", "Joint-layer", "Taggers", "RNN", "GRU", "LSTM", "BiLSTM", "RNN", "GRU", "LSTM", "BiLSTM"], "regionBoundary": {"x2": 512.0, "y1": 63.8900146484375, "x1": 86.0, "y2": 186.8900146484375}, "caption": "Table 4: Comparisons of the average F1 scores (%) and their standard deviations measured on Twitter over the results of models with 5 sets of parameters for random initialization. The left half reports results of single-layer taggers; The right half reports results of joint-layer taggers. Each column: results of the same tagger with different encoders. Each row: results of different taggers with the same encoder. No Encoder: taggers without encoding context. Abbreviations for context encoders: Avg Emb \u2013 averaged embedding; Att (LSTM) \u2013 attention on LSTM; Att (BiLSTM) \u2013 attention on BiLSTM; MemNN \u2013 memory networks.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9251980251736, "y1": 273.28554789225257, "x1": 426.77362230088977, "y2": 338.077884250217}, "name": "1", "caption_text": "Figure 1: The overall structure of our keyphrase extraction framework with context encoder. Grey dotted array refer to the inputs of target posts that are also used in context encoding.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 89.0, "x1": 422.0, "y2": 271.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 686.4642673068577, "y1": 451.20357937282984, "x1": 470.2319675021701, "y2": 461.81254916720917}, "name": "2", "caption_text": "Table 2: Definitions of different yi,t.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 335.0, "x1": 427.0, "y2": 450.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15106709798175, "y1": 291.24938117133246, "x1": 100.00138812594943, "y2": 318.40421888563367}, "name": "2", "caption_text": "Figure 2: The structure of attention-based conversation context encoder.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 93.0, "x1": 103.0, "y2": 271.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9280802408854, "y1": 275.36464267306854, "x1": 426.77362230088977, "y2": 302.51948038736975}, "name": "3", "caption_text": "Figure 3: The structure of the conversation context encoder based on memory networks.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 88.0, "x1": 427.0, "y2": 273.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9253675672743, "y1": 262.81742519802515, "x1": 426.77362230088977, "y2": 402.88204616970484}, "name": "3", "caption_text": "Table 3: Statistics of two datasets. Train, Dev, and Test denotes training, development, and test set, respectively. # of annot. msgs: number of messages with keyphrase annotation, each containing conversation context. # of msgs in context: average count of message in conversation context. Context length: average count of words in conversation context. Vocab: vocabulary size.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 86.0, "x1": 428.0, "y2": 237.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9313863118489, "y1": 277.4840884738498, "x1": 100.00138812594943, "y2": 379.9125671386719}, "name": "4", "caption_text": "Table 4: Comparisons of the average F1 scores (%) and their standard deviations measured on Twitter over the results of models with 5 sets of parameters for random initialization. The left half reports results of single-layer taggers; The right half reports results of joint-layer taggers. Each column: results of the same tagger with different encoders. Each row: results of different taggers with the same encoder. No Encoder: taggers without encoding context. Abbreviations for context encoders: Avg Emb \u2013 averaged embedding; Att (LSTM) \u2013 attention on LSTM; Att (BiLSTM) \u2013 attention on BiLSTM; MemNN \u2013 memory networks.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 711.0, "y1": 86.0, "x1": 119.0, "y2": 276.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9289279513889, "y1": 277.4840884738498, "x1": 100.00138812594943, "y2": 285.82085503472223}, "name": "5", "caption_text": "Table 5: Comparisons of F1 scores on Weibo. The abbreviations are defined the same as those in Table 4.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 711.0, "y1": 86.0, "x1": 119.0, "y2": 259.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1531863742404, "y1": 273.8869137234158, "x1": 100.00138812594943, "y2": 376.31539238823785}, "name": "6", "caption_text": "Table 6: The F1 scores of BiLSTM taggers measured on test instances without conversation context (%). SL BiLSTM and JL BiLSTM denote keyphrase tagger as single-layer and joint-layer BiLSTM, respectively. The other abbreviations are defined the same as those in Table 4.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 103.0, "y2": 248.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9253675672743, "y1": 274.2243872748481, "x1": 426.77362230088977, "y2": 376.6528659396701}, "name": "4", "caption_text": "Figure 4: The heatmap of the context representation generated by MemNN (see Eq. 8). The horizontal axis refers to words in the conversation context, while the vertical axis refers to words in the target post. Darker colors indicate higher weights. The red box indicates the keyphrase to be detected.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 703.0, "y1": 92.0, "x1": 420.0, "y2": 272.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15818786621094, "y1": 236.2494150797526, "x1": 100.00138812594943, "y2": 301.041751437717}, "name": "7", "caption_text": "Table 7: Outputs of joint-layer BiLSTM combined with various context encoders given the example illustrated in Table1. \u201cNULL\u201d: Avg Emb did not produce any keyphrase.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 378.0, "y1": 86.0, "x1": 125.0, "y2": 211.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9253675672743, "y1": 364.4799550374349, "x1": 426.77362230088977, "y2": 504.5459323459201}, "name": "5", "caption_text": "Figure 5: Histograms of F1 scores on extracting keyphrases with various lengths. SL BiLSTM: tagger based on single-layer BiLSTM. JL BiLSTM: tagger based on joint-layer BiLSTM. Length: count of words in keyphrases. For each length range, histograms from left to right show the results of No encoder, Avg Emb, LSTM, BiLSTM, Att (LSTM), ATT (BiLSTM), and MemNN.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 87.0, "x1": 403.0, "y2": 344.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15348307291663, "y1": 260.0493960910373, "x1": 100.00138812594943, "y2": 343.65980360243054}, "name": "8", "caption_text": "Table 8: Precision, recall, and F1 scores of ranking-based baselines (%). w/o context: each target post is treated as a document; w/ context: each conversation and its corresponding target post is treated as a document.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 403.0, "y1": 86.0, "x1": 100.0, "y2": 235.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/0f14f93af2dd1a50ab74d4cb600c4d3ac9c880df/N18-1151.pdf", "dpi": 100}