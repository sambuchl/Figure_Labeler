{"raw_detected_boxes": [[], [], [{"x2": 723.0, "y1": 93.0, "x1": 432.0, "y2": 436.0}], [{"x2": 715.0, "y1": 95.0, "x1": 119.0, "y2": 422.0}], [{"x2": 723.0, "y1": 87.0, "x1": 428.0, "y2": 217.0}, {"x2": 714.0, "y1": 282.0, "x1": 446.0, "y2": 395.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5464477539062, "y1": 326.1925354003906, "x1": 306.9670104980469, "y2": 344.1499938964844}, "imageText": ["Model", "Architecture", "BERT-Base", "(cased)", "Number", "of", "epochs", "3", "Batch", "size", "32", "Max", "sentence", "length", "128", "Optimizer", "Adam", "(\u03b21", "=", "0.9,", "\u03b22", "=", "0.999,", "=", "1\u00d7", "10\u22128)", "Learning", "rate", "4e\u2212", "5", "Dropout", "0.1", "GED", "model", "Dropout", "0.3", "Gradient", "Clipping", "0.1", "Beam", "search", "5", "(", "ls", "=", "0.1)", "(Szegedy", "et", "al.,", "2016)", "Model", "Architecture", "Transformer", "(big)", "Number", "of", "epochs", "30", "Max", "tokens", "4096", "Optimizer", "Adam", "(\u03b21", "=", "0.9,", "\u03b22", "=", "0.98,", "=", "1\u00d7", "10\u22128)", "Learning", "rate", "3\u00d7", "10\u22125", "Min", "learning", "rate", "1\u00d7", "10\u22126", "Loss", "function", "label", "smoothed", "cross-entropy", "GEC", "model"], "regionBoundary": {"x2": 522.0, "y1": 62.8900146484375, "x1": 311.0, "y2": 313.8900146484375}, "caption": "Table 1: Hyperparameters values of GEC model and Fine-tuned BERT.", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 527.2002563476562, "y1": 296.6205139160156, "x1": 306.9170227050781, "y2": 338.4880065917969}, "imageText": ["PUNCT", "40.2", "36.8", "OTHER", "20.4", "19.1", "DET", "48.8", "45.4", "PREP", "36.7", "34.8", "VERB:TENSE", "36.0", "34.1", "Error", "type", "BERT-fuse", "GED", "w/o", "BERT"], "regionBoundary": {"x2": 514.0, "y1": 202.8900146484375, "x1": 321.0, "y2": 284.8900146484375}, "caption": "Table 3: The result of single Fine-tuned BERT-fuse and w/o BERT models without using pseudo-data on most error types including all the top-5 frequent types of error in W&I-dev", "page": 4}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2002563476562, "y1": 171.57754516601562, "x1": 307.2760009765625, "y2": 189.5350341796875}, "imageText": ["(a)", "BERT", "(b)", "Fine-tuned", "BERT"], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 156.260009765625}, "caption": "Figure 1: Hidden representation visualization for encoded grammatically correct and incorrect words.", "page": 4}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.2008666992188, "y1": 320.7715148925781, "x1": 71.69100189208984, "y2": 374.59393310546875}, "imageText": ["BERT-fuse", "GED", "+", "R2L", "72.3", "61.4", "69.8", "72.6", "46.4", "65.2", "62.8", "48.8", "59.4", "62.0", "Lichtarge", "et", "al.", "(2019)", "-", "-", "-", "66.7", "43.9", "60.4", "-", "-", "-", "63.3", "Grundkiewicz", "et", "al.", "(2019)", "72.3", "60.1", "69.5", "-", "-", "64.2", "-", "-", "-", "61.2", "Kiyono", "et", "al.", "(2019)\u2217", "74.7", "56.7", "70.2", "72.4", "46.1", "65.0", "-", "-", "-", "61.4", "w/o", "BERT", "66.1", "59.9", "64.8", "68.5", "44.8", "61.9", "56.5", "48.1", "54.9", "61.0", "BERT-fuse", "66.6", "60.0", "65.2", "68.3", "45.7", "62.1", "59.7", "48.5", "57.0", "61.2", "BERT-fuse", "mask", "67.0", "60.0", "65.4", "68.8", "45.3", "62.3", "59.7", "47.1", "56.6", "61.2", "BERT-fuse", "GED", "67.1", "60.1", "65.6", "69.2", "45.6", "62.6", "59.8", "46.9", "56.7", "61.3", "Lichtarge", "et", "al.", "(2019)", "-", "-", "-", "65.5", "37.1", "56.8", "-", "-", "-", "61.6", "Awasthi", "et", "al.", "(2019)", "-", "-", "-", "66.1", "43.0", "59.7", "-", "-", "-", "60.3", "Kiyono", "et", "al.", "(2019)", "65.5", "59.4", "64.2", "67.9", "44.1", "61.3", "-", "-", "-", "59.7", "w/o", "BERT", "51.5", "43.2", "49.6", "59.2", "31.2", "50.2", "61.7", "46.4", "57.9", "52.7", "BERT-init", "55.1", "43.7", "52.4", "61.3", "31.5", "51.4", "62.4", "46.9", "58.5", "53.0", "BERT-fuse", "57.5", "44.9", "54.4", "62.3", "31.3", "52.0", "64.0", "47.6", "59.8", "54.1", "BERT-fuse", "mask", "57.1", "44.7", "54.1", "62.9", "32.2", "52.8", "64.3", "48.1", "60.2", "54.2", "BERT-fuse", "GED", "58.1", "44.8", "54.8", "63.6", "33.0", "53.6", "65.0", "49.6", "61.2", "54.4", "BEA-test", "(ERRANT)", "CoNLL-14", "(M2)", "FCE-test", "(M2)", "JFLEG", "P", "R", "F0.5", "P", "R", "F0.5", "P", "R", "F0.5", "GLEU"], "regionBoundary": {"x2": 516.0, "y1": 67.83753967285156, "x1": 84.0, "y2": 308.8900146484375}, "caption": "Table 2: Results of our GEC models. The top group shows the results of the single models without using pseudodata and/or ensemble. The second group shows the results of the single models using pseudo-data. The third group shows ensemble models using pseudo-data. Bold indicates the highest score in each column. * reports the state-of-the-art scores for BEA test and CoNLL 2014 for two separate models: models with and without SED. We filled out a single line with the results from such two separate models.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9256218804253, "y1": 453.0451880560981, "x1": 426.3430701361762, "y2": 477.98610263400604}, "name": "1", "caption_text": "Table 1: Hyperparameters values of GEC model and Fine-tuned BERT.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 426.0, "y2": 453.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2234259711371, "y1": 445.51599290635846, "x1": 99.57083596123589, "y2": 520.2693515353733}, "name": "2", "caption_text": "Table 2: Results of our GEC models. The top group shows the results of the single models without using pseudodata and/or ensemble. The second group shows the results of the single models using pseudo-data. The third group shows ensemble models using pseudo-data. Bold indicates the highest score in each column. * reports the state-of-the-art scores for BEA test and CoNLL 2014 for two separate models: models with and without SED. We filled out a single line with the results from such two separate models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 87.0, "x1": 117.0, "y2": 429.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 238.30214606391058, "x1": 426.772223578559, "y2": 263.24310302734375}, "name": "1", "caption_text": "Figure 1: Hidden representation visualization for encoded grammatically correct and incorrect words.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 87.0, "x1": 427.0, "y2": 220.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 411.9729359944661, "x1": 426.27364264594183, "y2": 470.12223137749567}, "name": "3", "caption_text": "Table 3: The result of single Fine-tuned BERT-fuse and w/o BERT models without using pseudo-data on most error types including all the top-5 frequent types of error in W&I-dev", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 265.0, "x1": 429.0, "y2": 412.0}, "page": 4, "dpi": 0}], "error": null, "pdf": "/work/host-output/ac0964105377880de76cfa4dadec311242ce8567/2020.acl-main.391.pdf", "dpi": 100}