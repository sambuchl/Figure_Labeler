{"raw_detected_boxes": [[], [], [{"x2": 328.0, "y1": 101.0, "x1": 143.0, "y2": 241.0}], [{"x2": 395.0, "y1": 96.0, "x1": 75.0, "y2": 284.0}, {"x2": 739.0, "y1": 113.0, "x1": 429.0, "y2": 283.0}, {"x2": 399.0, "y1": 826.0, "x1": 72.0, "y2": 1012.0}], [{"x2": 325.0, "y1": 107.0, "x1": 145.0, "y2": 289.0}, {"x2": 320.0, "y1": 415.0, "x1": 145.0, "y2": 595.0}, {"x2": 698.0, "y1": 318.0, "x1": 471.0, "y2": 518.0}], [{"x2": 678.0, "y1": 95.0, "x1": 139.0, "y2": 328.0}, {"x2": 366.0, "y1": 425.0, "x1": 105.0, "y2": 665.0}, {"x2": 731.0, "y1": 1035.0, "x1": 431.0, "y2": 1084.0}], [{"x2": 743.0, "y1": 95.0, "x1": 78.0, "y2": 239.0}, {"x2": 730.0, "y1": 380.0, "x1": 439.0, "y2": 714.0}, {"x2": 337.0, "y1": 768.0, "x1": 129.0, "y2": 848.0}], [{"x2": 379.0, "y1": 95.0, "x1": 88.0, "y2": 258.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 539.7175903320312, "y1": 251.16555786132812, "x1": 52.157958984375, "y2": 281.07806396484375}, "imageText": ["\u00e1", "\u00d3", "(who", "is", "the", "one)", "2", "\u00e9<\u00cb", "@", "B@", "(except", "God)", "9", "\u00fa", "\u00ce\u00cb@", "\u00e1", "\u00d3", "\u00f0", "(and", "who)", "2", "I", "J\u00bb", "A", "K", "@", "(I", "was)", "9", "Q", "\u00d2m", "\u00cc'@", "I.", "J", "\u00cag", "(Donkey\u2019s", "milk)", "4", "i.", "J", "\u00ca", "m\u00cc'@", "\u00c8\u00f0X", "(Gulf", "countries)", "10", "\u00d5\u00baJ", "\u00ca\u00ab", "\u00e9<\u00cb", "@", "\u00e9", "J\u00aa\u00cb", "(God\u2019", "curse", "on", "you", "all)", "4", "\u00e9<\u00cbAK.", "B@", "\u00e8\u00f1", "\u00af", "(power", "except", "with", "God)", "17", "HA\u00a2\u00a2", "m\u00d7", "\u00a9J", "\u00d2m.", "'", ".", "(with", "all", "plots)", "4", "\u00e9<\u00cb", "@", "Z", "A", "A\u00d3", "(God\u2019s", "willing)", "14", "\u00a9J", "\u00d2m.", "'", ".", "\u00e9kA\u00a3B@", "(downing", "all)", "4", "\u00e9J", "K.", "Q\u00aa\u00cb@", "\u00c8\u00f0Y\u00cb@", "(Arab", "countries)", "15", "\u00e9kA\u00a3B@", "\u00d5\u00e7", "'", "(was", "downed)", "4", "\u00e8\u00f1", "\u00af", "\u00c8\u00f1k", "(will", "power)", "17", "\u00d5\u00ba", "\u00a2J", "\u00aaK.", "@\u00f1", "K\u00f1\u00d3", "(die", "with", "your", "rage)", "4", "@Yg.", "@Yg.", "(many", "many)", "17", "\u00e8QK", "Q", "m\u00cc'@", "\u00e8A", "J", "\u00af", "(piglet", "channel)", "5", "\u00e9<\u00cb", "@", "\u00c8\u00f1", "P", "(Messenger", "of", "God)", "27", "Highly", "OFF", "Highly", "NOT", "Ngrams", "Freq.", "Ngrams", "Freq."], "regionBoundary": {"x2": 492.0, "y1": 68.8900146484375, "x1": 100.0, "y2": 238.8900146484375}, "caption": "Table 2: List of top most frequent n-grams (n=2,3) for both offensive (OFF) and non-offensive (NOT) comments, using valence score, are as follows. (.) are the translation in English. Freq. represents frequency of the ngram in the corresponding class.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 287.0063171386719, "y1": 491.03955078125, "x1": 52.15800094604492, "y2": 508.99700927734375}, "imageText": ["HA\u00a2\u00a2", "m\u00d7", "(Plots)", "4", "\u00ad", "K", "@", "(Nose)", "4", "H.", "C\u00bf", "AK", "(O", "Dogs)", "5", "'", "(\ufb01lthy)", "5", "m.", "\u00d5\u00ba", "\u00a2J", "\u00aaK.", "(With", "your", "envy/rage)", "5", "iJ.", "K", "(Bark)", "6", "\u00e9", "\u00af", "Q", "KQ\u00d6\u00cf", "@", "(Mercenaries)", "7", "P", "Y", "\u00af", "(Dirty)", "8", "I.", "\u00ca\u00be\u00cb@", "(Dog)", "8", "Tokens", "Frequency", "\u00e8QK", "Q", "m\u00cc'@", "(Piglet)", "21"], "regionBoundary": {"x2": 264.0, "y1": 303.8900146484375, "x1": 75.0, "y2": 478.8900146484375}, "caption": "Table 3: List of top 10 most highly offensive unigrams, with \u03d1(word) = 1.0. (.) are the translation in English.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 539.7144165039062, "y1": 525.95361328125, "x1": 304.865966796875, "y2": 627.5969848632812}, "imageText": ["TW", "0.37", "0.39", "0.34", "FB", "0.21", "0.31", "0.10", "YT", "0.29", "0.26", "0.32", "FB", "+", "YT", "+", "TW", "0.40", "0.35", "0.45", "DCD", "DCD", "0.44", "0.67", "0.22", "FB", "0.53", "0.96", "0.10", "TW", "0.60", "0.94", "0.27", "TW", "+", "FB", "0.63", "0.95", "0.31", "TW", "+", "FB", "+", "DCD", "0.82", "0.97", "0.67", "YT", "DCD", "0.52", "0.51", "0.53", "FB", "0.51", "0.83", "0.19", "YT", "0.54", "0.82", "0.25", "FB", "+", "YT", "0.59", "0.84", "0.35", "FB", "+", "YT", "+", "DCD", "0.84", "0.90", "0.78", "TW", "DCD", "0.34", "0.43", "0.25", "TW", "0.62", "0.90", "0.34", "YT", "0.62", "0.92", "0.31", "TW", "+", "YT", "0.68", "0.93", "0.44", "TW", "+", "YT", "+", "DCD", "0.78", "0.94", "0.63", "FB", "Testset", "Trained", "on", "Fm", "NOT", "OFF"], "regionBoundary": {"x2": 526.0, "y1": 272.8900146484375, "x1": 316.0, "y2": 513.8900146484375}, "caption": "Table 6: F-measure performances based on platform wise dataset. The test sets presented here are a subset of MPOLD data. For instance TW \u2208 MPOLD, is the dataset extracted from Twitter. Similarly, YT represents YouTube data, FB represents comments from Facebook. DCD - Deleted comments dataset. NOT = Not-offensive, OFF = offensive instances. The blue rows presents the results when the platform-wise data present in our dataset is modelled along with online-news-platform data, DCD.", "page": 6}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 539.7176513671875, "y1": 184.40853881835938, "x1": 52.15800094604492, "y2": 250.18707275390625}, "imageText": ["a", "news", "website", "OBs,", "OFF-OBs,", "NOT", "31692", "(\u2248", "82%)", "17.4", "train/", "test", "L-HSAB*", "Levantine", "tweets", "Abs,", "HS,", "NOT", "5846", "(\u2248", "37.6%)", "12.0", "test", "DCD**", "Deleted", "comments", "from", "and", "corresponding", "comments", "OBs,", "OFF-OBs,", "NOT", "1100", "(\u2248", "59.0%)", "13.5", "test", "ETCD*", "100", "Egyptian", "tweets", "MPOLD*", "News", "comments", "fromTW,", "FB,", "and", "YT", "OFF,", "NOT", "4000", "(16.9%)", "22.8", "train/testV,", "HS,", "Oth", "18.0/18.5/41.7", "Abbr.", "Dataset", "Description", "Labels", "#I", "(#OFF%)", "avg.", "len", "Used", "for"], "regionBoundary": {"x2": 539.0, "y1": 69.8900146484375, "x1": 53.0, "y2": 171.8900146484375}, "caption": "Table 4: Details of the datasets used for the study. * represent the out-of-domain dataset and ** represent the different platforms. #I represent the number of instances, whereas #OFF% represents the number of offensive labels used in this study. In the case of ETCD and DCD, we merged the offensive comments \u2013 obscene (OBs) and other offensive comments (OFF-OBs), as OFF for matching with our labels. Similarly, we merged HS and Abs (abusive) for the L-HSAB dataset to OFF. avg. len represents the average length of the corresponding content in terms of the number of words. V - Vulgar, HS - Hatespeech Oth-Other offensive categories.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 287.0063171386719, "y1": 623.091552734375, "x1": 52.15800094604492, "y2": 641.0490112304688}, "imageText": ["Fm", "NOT", "OFF", "Chance", "0.49", "0.83", "0.14", "Lex", "0.53", "0.84", "0.21", "SVM", "0.74", "0.92", "0.56"], "regionBoundary": {"x2": 246.0, "y1": 549.8900146484375, "x1": 93.0, "y2": 610.8900146484375}, "caption": "Table 5: Reported performance on MPOLD dataset using 5-fold cross validation (with SVM and Chance baseline)", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 287.00634765625, "y1": 190.33151245117188, "x1": 52.15800094604492, "y2": 208.28900146484375}, "imageText": [], "regionBoundary": {"x2": 241.0, "y1": 68.8900146484375, "x1": 99.0, "y2": 178.8900146484375}, "caption": "Figure 1: Platform wise distribution of the comments in the dataset.", "page": 2}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 287.0063171386719, "y1": 201.25253295898438, "x1": 52.15800094604492, "y2": 267.03106689453125}, "imageText": ["L-HSAB", "Lex", "0.46", "0.74", "0.18", "DCD", "0.59", "0.60", "0.58", "MPOLD", "0.64", "0.77", "0.51", "MPOLD+", "0.62", "0.64", "0.59", "Lex", "0.51", "0.58", "0.44", "DCD", "0.64", "0.76", "0.53", "MPOLD", "0.61", "0.66", "0.56", "MPOLD+", "0.68", "0.61", "0.75", "ETCD", "Testset", "Model", "Fm", "NOT", "OFF"], "regionBoundary": {"x2": 273.0, "y1": 68.8900146484375, "x1": 63.0, "y2": 188.8900146484375}, "caption": "Table 7: Reported F-measures of the models trained using DCD, MPOLD (MPOLD) and MPOLD + DCD (MPOLD+) and tested on out-of-domain test sets. The test sets includes: (a) ETCD - controversial Egyptian tweets and comments dataset; and (b) L-HSAB Levantine tweets datasets. Lex is lexicon-based baseline for the test sets.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 287.00640869140625, "y1": 216.58755493164062, "x1": 52.15800094604492, "y2": 258.4560546875}, "imageText": ["No.", "of", "Comments", "4000", "Cost", "per", "Comment", "1", "cent", "Comments/HIT", "25", "Gold/HIT", "5", "Gold", "Review", "Policy", "dynamic", "Assignments/HIT", "3", "Task", "duration", "7", "days", "Assignment", "Duration", "1", "hour", "Avg.", "Annotator/Comment", "3.23", "Max.", "Annotator/Comment", "5*", "No.", "Comment", "with", "more", "than", "3", "annotation", "787"], "regionBoundary": {"x2": 285.0, "y1": 68.8900146484375, "x1": 54.0, "y2": 204.8900146484375}, "caption": "Table 1: Crowdsourcing annotation task details. *In this case one or two annotators could not pass the quality evaluation. Thus their annotations were rejected and the task was extended to a new annotator.", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 539.7142944335938, "y1": 219.32553100585938, "x1": 304.8659973144531, "y2": 249.239013671875}, "imageText": [], "regionBoundary": {"x2": 540.0, "y1": 68.8900146484375, "x1": 304.0, "y2": 207.8900146484375}, "caption": "Figure 3: Platform wise annotation label distribution for types of offensive comments present in the annotated dataset.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 287.0063781738281, "y1": 742.0255737304688, "x1": 52.15800094604492, "y2": 771.9390258789062}, "imageText": [], "regionBoundary": {"x2": 288.0, "y1": 589.8900146484375, "x1": 52.0, "y2": 729.8900146484375}, "caption": "Figure 2: Platform wise annotation label distribution. \u201cAll\u201d represents the total % of instances for offensive and notoffensive comments in the annotated dataset.", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 287.0116882324219, "y1": 222.40054321289062, "x1": 52.15800094604492, "y2": 276.22308349609375}, "imageText": [], "regionBoundary": {"x2": 264.0, "y1": 68.8900146484375, "x1": 75.0, "y2": 210.8900146484375}, "caption": "Figure 4: Word-cloud for highly non offensive (NOT) tokens, with valence score, \u03d1(.) = 1, in comments. Some of the most frequent words include \u2018thank you\u2019, \u2018important\u2019 along with other conversation fillers and reaction like \u2018hahah\u2019.", "page": 4}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 287.00628662109375, "y1": 445.93353271484375, "x1": 52.15800094604492, "y2": 475.8459777832031}, "imageText": [], "regionBoundary": {"x2": 264.0, "y1": 291.8900146484375, "x1": 75.0, "y2": 433.8900146484375}, "caption": "Figure 5: Word-cloud for highly offensive tokens, with valence score, \u03d1(.) = 1, in comments. Corresponding English examples can be found in Table 3.", "page": 4}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 539.718994140625, "y1": 388.65753173828125, "x1": 304.86590576171875, "y2": 442.48095703125}, "imageText": [], "regionBoundary": {"x2": 504.0, "y1": 221.8900146484375, "x1": 338.0, "y2": 376.8900146484375}, "caption": "Figure 6: Reported analysis on use of emojis in offensive comments. Figure (a) \u2013 lists the 10 most highly offensive emojis with valence score, \u03d1 = 1.0. Figure (b) \u2013 Top 3 groups of emojis with \u03d1 = 1.0. For each group, \u03c9 is reported in percentage.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 398.61992730034723, "y1": 264.3493228488498, "x1": 72.44166798061795, "y2": 289.29027981228296}, "name": "1", "caption_text": "Figure 1: Platform wise distribution of the comments in the dataset.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 329.0, "y1": 101.0, "x1": 143.0, "y2": 244.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6200120713976, "y1": 300.81604851616754, "x1": 72.44166798061795, "y2": 358.96674262152777}, "name": "1", "caption_text": "Table 1: Crowdsourcing annotation task details. *In this case one or two annotators could not pass the quality evaluation. Thus their annotations were rejected and the task was extended to a new annotator.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 95.0, "x1": 72.0, "y2": 301.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031867133246, "y1": 304.61879306369354, "x1": 423.4249962700738, "y2": 346.16529676649304}, "name": "3", "caption_text": "Figure 3: Platform wise annotation label distribution for types of offensive comments present in the annotated dataset.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 750.0, "y1": 96.0, "x1": 424.0, "y2": 283.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6199696858724, "y1": 1030.5910746256511, "x1": 72.44166798061795, "y2": 1072.1375359429253}, "name": "2", "caption_text": "Figure 2: Platform wise annotation label distribution. \u201cAll\u201d represents the total % of instances for offensive and notoffensive comments in the annotated dataset.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 820.0, "x1": 72.0, "y2": 1013.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.62734476725257, "y1": 308.88964335123694, "x1": 72.44166798061795, "y2": 383.6431715223524}, "name": "4", "caption_text": "Figure 4: Word-cloud for highly non offensive (NOT) tokens, with valence score, \u03d1(.) = 1, in comments. Some of the most frequent words include \u2018thank you\u2019, \u2018important\u2019 along with other conversation fillers and reaction like \u2018hahah\u2019.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 328.0, "y1": 104.0, "x1": 145.0, "y2": 289.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6198425292969, "y1": 619.3521287706163, "x1": 72.44166798061795, "y2": 660.8971913655598}, "name": "5", "caption_text": "Figure 5: Word-cloud for highly offensive tokens, with valence score, \u03d1(.) = 1, in comments. Corresponding English examples can be found in Table 3.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 327.0, "y1": 415.0, "x1": 144.0, "y2": 599.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6097140842014, "y1": 539.8021274142795, "x1": 423.42486911349823, "y2": 614.556884765625}, "name": "6", "caption_text": "Figure 6: Reported analysis on use of emojis in offensive comments. Figure (a) \u2013 lists the 10 most highly offensive emojis with valence score, \u03d1 = 1.0. Figure (b) \u2013 Top 3 groups of emojis with \u03d1 = 1.0. For each group, \u03c9 is reported in percentage.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 699.0, "y1": 313.0, "x1": 471.0, "y2": 518.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6077643500433, "y1": 348.8410525851779, "x1": 72.44160970052083, "y2": 390.3861999511719}, "name": "2", "caption_text": "Table 2: List of top most frequent n-grams (n=2,3) for both offensive (OFF) and non-offensive (NOT) comments, using valence score, are as follows. (.) are the translation in English. Freq. represents frequency of the ngram in the corresponding class.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 683.0, "y1": 95.0, "x1": 139.0, "y2": 332.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.619884914822, "y1": 681.9993760850695, "x1": 72.44166798061795, "y2": 706.9402906629774}, "name": "3", "caption_text": "Table 3: List of top 10 most highly offensive unigrams, with \u03d1(word) = 1.0. (.) are the translation in English.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 366.0, "y1": 422.0, "x1": 93.0, "y2": 682.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6078491210938, "y1": 256.1229705810547, "x1": 72.44166798061795, "y2": 347.48204549153644}, "name": "4", "caption_text": "Table 4: Details of the datasets used for the study. * represent the out-of-domain dataset and ** represent the different platforms. #I represent the number of instances, whereas #OFF% represents the number of offensive labels used in this study. In the case of ETCD and DCD, we merged the offensive comments \u2013 obscene (OBs) and other offensive comments (OFF-OBs), as OFF for matching with our labels. Similarly, we merged HS and Abs (abusive) for the L-HSAB dataset to OFF. avg. len represents the average length of the corresponding content in terms of the number of words. V - Vulgar, HS - Hatespeech Oth-Other offensive categories.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 748.0, "y1": 95.0, "x1": 72.0, "y2": 256.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6033562554253, "y1": 730.4911295572916, "x1": 423.4249538845486, "y2": 871.6624789767795}, "name": "6", "caption_text": "Table 6: F-measure performances based on platform wise dataset. The test sets presented here are a subset of MPOLD data. For instance TW \u2208 MPOLD, is the dataset extracted from Twitter. Similarly, YT represents YouTube data, FB represents comments from Facebook. DCD - Deleted comments dataset. NOT = Not-offensive, OFF = offensive instances. The blue rows presents the results when the platform-wise data present in our dataset is modelled along with online-news-platform data, DCD.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 737.0, "y1": 379.0, "x1": 423.0, "y2": 731.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.619884914822, "y1": 865.4049343532986, "x1": 72.44166798061795, "y2": 890.3458489312065}, "name": "5", "caption_text": "Table 5: Reported performance on MPOLD dataset using 5-fold cross validation (with SVM and Chance baseline)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 342.0, "y1": 764.0, "x1": 112.0, "y2": 865.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.619884914822, "y1": 279.5174068874783, "x1": 72.44166798061795, "y2": 370.8764817979601}, "name": "7", "caption_text": "Table 7: Reported F-measures of the models trained using DCD, MPOLD (MPOLD) and MPOLD + DCD (MPOLD+) and tested on out-of-domain test sets. The test sets includes: (a) ETCD - controversial Egyptian tweets and comments dataset; and (b) L-HSAB Levantine tweets datasets. Lex is lexicon-based baseline for the test sets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 379.0, "y1": 95.0, "x1": 88.0, "y2": 263.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/1ddb2883fa50542ae3be983d71e01090e47580d8/2020.lrec-1.761.pdf", "dpi": 100}