{"raw_detected_boxes": [[], [{"x2": 738.0, "y1": 221.0, "x1": 426.0, "y2": 392.0}], [{"x2": 392.0, "y1": 685.0, "x1": 101.0, "y2": 922.0}, {"x2": 736.0, "y1": 623.0, "x1": 428.0, "y2": 832.0}], [{"x2": 697.0, "y1": 86.0, "x1": 134.0, "y2": 385.0}, {"x2": 384.0, "y1": 774.0, "x1": 105.0, "y2": 882.0}, {"x2": 729.0, "y1": 831.0, "x1": 429.0, "y2": 957.0}, {"x2": 709.0, "y1": 478.0, "x1": 428.0, "y2": 569.0}], [{"x2": 736.0, "y1": 93.0, "x1": 433.0, "y2": 361.0}, {"x2": 400.0, "y1": 373.0, "x1": 107.0, "y2": 639.0}, {"x2": 392.0, "y1": 719.0, "x1": 106.0, "y2": 986.0}], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 274.5535583496094, "y1": 480.34454345703125, "x1": 87.71499633789062, "y2": 486.3470153808594}, "text": "Figure 2: Sub-task A, Ensemble of LR-NB-RF", "name": "2", "page": 4}, {"figType": "Figure", "boundary": {"x2": 271.30596923828125, "y1": 729.7235717773438, "x1": 90.96299743652344, "y2": 747.6810302734375}, "text": "Figure 3: Sub-task B, Naive Bayes - TFIDF - Lemmatization", "name": "3", "page": 4}], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 518.3277587890625, "y1": 611.402587890625, "x1": 314.4930114746094, "y2": 641.3150024414062}, "imageText": [], "regionBoundary": {"x2": 535.0, "y1": 444.8900146484375, "x1": 307.0, "y2": 599.8900146484375}, "caption": "Figure 1: F1-scores of logistic regression model on subtask A, each bar is a model with it\u2019s own pre-processing, vectorizer and parameters.", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.06011962890625, "y1": 676.2745361328125, "x1": 72.20800018310547, "y2": 694.2319946289062}, "imageText": ["solver:", "[sgd,adam,", "lbfgs]", "MLP", "activation:[tanh,", "relu]", "penalty", ":", "[l2]", "solver:", "[sag,", "lbfgs,", "newton]", "Logistic", "Regression", "Random", "Forest", "n", "estimators:", "[10", "-", "200]", "Decision", "Trees", "criterion:", "[gini,", "entropy]", "kernel:", "[rbf,", "poly]", "SVM", "C:", "[0.1,10,100]", "Naive", "Bayes", "\ufb01t", "prior:", "[True,", "False]", "Model", "Parameters", "Grid", "KNN", "n", "neighbours:", "[1,", "3,", "5,", "7]"], "regionBoundary": {"x2": 286.0, "y1": 492.8900146484375, "x1": 72.0, "y2": 663.8900146484375}, "caption": "Table 2: Classification models and their corresponding parameters to tune.", "page": 2}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 519.4434204101562, "y1": 279.1825256347656, "x1": 313.37701416015625, "y2": 297.1400146484375}, "imageText": ["0.7", "0.6", "0.5", "0.4", "0.3", "0.2", "0.1", "0.0", "Confusion", "Matrix", "16", "13", "6", "18", "76", "6", "47", "25", "6", "l", "la", "be", "Tr", "ue", "OTH", "IND", "GRP", "Predicted", "label", "OT", "H", "IN", "D", "GR", "P"], "regionBoundary": {"x2": 529.5320434570312, "y1": 66.65818786621094, "x1": 314.53717041015625, "y2": 261.04571533203125}, "caption": "Figure 4: Sub-task C, Logistic Regression - Count - Stopwords Removal", "page": 4}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 513.9942626953125, "y1": 294.4205627441406, "x1": 318.8269958496094, "y2": 312.3780517578125}, "imageText": ["Classi\ufb01cation", "KNN", "-", "Naive", "Bayes", "-", "Decision", "Trees", "-", "SVM", "-Random", "Forest", "Logistic", "Regression", "-", "MLP", "TFIDF", "-", "Count", "-", "Word", "Embedding", "Feature", "Extraction", "Lemmatization", "-", "Stemming", "Pre-processing", "Stopwords", "Removal", "Phase", "Implemented", "Techniques"], "regionBoundary": {"x2": 536.0, "y1": 155.8900146484375, "x1": 307.0, "y2": 282.8900146484375}, "caption": "Table 1: Multiple techniques implemented in our system.", "page": 1}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 524.2305297851562, "y1": 703.987548828125, "x1": 308.5899963378906, "y2": 721.9450073242188}, "imageText": ["System", "F1", "(macro)", "Accuracy", "All", "GRP", "baseline", "0.1787", "0.3662", "All", "IND", "baseline", "0.2130", "0.4695", "All", "OTH", "baseline", "0.0941", "0.1643", "Ensemble", "0.4973", "0.6479", "Random", "Forest", "0.4763", "0.6432", "Logistic", "Regression", "0.5093", "0.6056"], "regionBoundary": {"x2": 530.0, "y1": 594.8900146484375, "x1": 307.0, "y2": 691.8900146484375}, "caption": "Table 6: Results for Sub-task C. The ensemble got the best accuracy but, LR got a better F1-score.", "page": 3}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 274.28460693359375, "y1": 647.1775512695312, "x1": 87.98400115966797, "y2": 665.135009765625}, "imageText": ["System", "F1", "(macro)", "Accuracy", "All", "NOT", "baseline", "0.4189", "0.7209", "All", "OFF", "baseline", "0.2182", "0.2790", "Ensemble", "0.7289", "0.8151", "Random", "Forest", "0.7143", "0.8128", "1D-CNN", "0.5506", "0.6977"], "regionBoundary": {"x2": 281.0, "y1": 551.8900146484375, "x1": 72.0, "y2": 634.8900146484375}, "caption": "Table 4: Results for Sub-task A. The ensemble approach gave the best results.", "page": 3}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 512.7047729492188, "y1": 289.6325378417969, "x1": 84.84100341796875, "y2": 295.635009765625}, "imageText": ["Classi\ufb01cation", "Random", "Forest", "Logistic", "Regression", "Naive", "Bayes", "Pre-processing", "Lemmatization", "Stopwords", "Removal", "Stemming", "C", "Vectorization", "Count", "Count", "Count", "Classi\ufb01action", "Naive", "Bayes", "Random", "Forest", "MLP", "B", "Vectorization", "TFIDF", "TFIDF", "GloVe-", "Embeddings", "Pre-processing", "Lemmatization", "Lemmatization", "Stopwords-", "Removal", "A", "Vectorization", "Count", "Count", "Count", "Classi\ufb01cation", "Logistic", "Regression", "Naive", "Bayes", "Random", "Forest", "Pre-processing", "Stopwords", "Removal", "&", "Lemmatization", "Stopwords", "Removal", "&", "Stemming", "Lemmatization", "Subtask", "Phase", "1st", "2nd", "3rd"], "regionBoundary": {"x2": 502.0, "y1": 62.8900146484375, "x1": 96.0, "y2": 277.8900146484375}, "caption": "Table 3: Top 3 models for each subtask, these 3 models will form an ensemble to enhance the performance.", "page": 3}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 519.6578369140625, "y1": 424.22454833984375, "x1": 313.1629943847656, "y2": 442.1820068359375}, "imageText": ["System", "F1", "(macro)", "Accuracy", "All", "TIN", "baseline", "0.4702", "0.8875", "All", "UNT", "baseline", "0.1011", "0.1125", "1D-CNN", "0.4436", "0.5542", "Naive", "Bayes", "0.6161", "0.8542"], "regionBoundary": {"x2": 517.0, "y1": 341.8900146484375, "x1": 307.0, "y2": 411.8900146484375}, "caption": "Table 5: Results for Sub-task B. The best performer was a simple TFIDF - Naive Bayes model.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 713.8809204101562, "y1": 408.91744825575086, "x1": 442.8152720133463, "y2": 433.858405219184}, "name": "1", "caption_text": "Table 1: Multiple techniques implemented in our system.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 745.0, "y1": 216.0, "x1": 426.0, "y2": 409.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 402.86127726236975, "y1": 939.2701890733507, "x1": 100.28888914320204, "y2": 964.2111036512587}, "name": "2", "caption_text": "Table 2: Classification models and their corresponding parameters to tune.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 668.0, "x1": 99.0, "y2": 939.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 719.899664984809, "y1": 849.1702609592014, "x1": 436.7958492702908, "y2": 890.7152811686198}, "name": "1", "caption_text": "Figure 1: F1-scores of logistic regression model on subtask A, each bar is a model with it\u2019s own pre-processing, vectorizer and parameters.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 741.0, "y1": 618.0, "x1": 428.0, "y2": 849.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 712.0899624294705, "y1": 402.2674136691623, "x1": 117.83472696940103, "y2": 410.60418023003473}, "name": "3", "caption_text": "Table 3: Top 3 models for each subtask, these 3 models will form an ensemble to enhance the performance.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 697.0, "y1": 86.0, "x1": 118.0, "y2": 402.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 380.95084296332465, "y1": 898.8577100965712, "x1": 122.20000161064995, "y2": 923.7986246744791}, "name": "4", "caption_text": "Table 4: Results for Sub-task A. The ensemble approach gave the best results.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 391.0, "y1": 766.0, "x1": 99.0, "y2": 899.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 728.0979580349392, "y1": 977.760484483507, "x1": 428.59721713595917, "y2": 1002.7013990614149}, "name": "6", "caption_text": "Table 6: Results for Sub-task C. The ensemble got the best accuracy but, LR got a better F1-score.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 736.0, "y1": 826.0, "x1": 426.0, "y2": 961.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 721.7469957139757, "y1": 589.2007615831163, "x1": 434.94860331217444, "y2": 614.1416761610243}, "name": "5", "caption_text": "Table 5: Results for Sub-task B. The best performer was a simple TFIDF - Naive Bayes model.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 718.0, "y1": 475.0, "x1": 426.0, "y2": 572.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 721.4491950141058, "y1": 387.75350782606336, "x1": 435.245853000217, "y2": 412.6944647894965}, "name": "4", "caption_text": "Figure 4: Sub-task C, Logistic Regression - Count - Stopwords Removal", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 736.0, "y1": 93.0, "x1": 433.0, "y2": 363.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 381.3243865966797, "y1": 667.1451992458767, "x1": 121.82638380262587, "y2": 675.4819658067491}, "name": "2", "caption_text": "Figure 2: Sub-task A, Ensemble of LR-NB-RF", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 373.0, "x1": 106.0, "y2": 643.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 376.8138461642795, "y1": 1013.5049608018663, "x1": 126.33749643961588, "y2": 1038.4458753797742}, "name": "3", "caption_text": "Figure 3: Sub-task B, Naive Bayes - TFIDF - Lemmatization", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 719.0, "x1": 106.0, "y2": 989.0}, "page": 4, "dpi": 0}], "error": null, "pdf": "/work/host-output/19c21c5ee5d391505310c7b7c961ee405109717e/S19-2144.pdf", "dpi": 100}