{"raw_detected_boxes": [[{"x2": 688.0, "y1": 309.0, "x1": 469.0, "y2": 457.0}], [], [{"x2": 390.0, "y1": 98.0, "x1": 103.0, "y2": 403.0}], [{"x2": 718.0, "y1": 87.0, "x1": 106.0, "y2": 428.0}], [{"x2": 364.0, "y1": 86.0, "x1": 137.0, "y2": 162.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "2", "captionBoundary": {"x2": 270.4444274902344, "y1": 310.7285461425781, "x1": 91.82499694824219, "y2": 316.73101806640625}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 298.8900146484375}, "caption": "Figure 2: BERT Sentence-Pair Classification", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.2705078125, "y1": 136.30752563476562, "x1": 71.69100189208984, "y2": 154.2650146484375}, "imageText": ["ST", "2.31%", "0", "33.36%", "C", "4.02%", "8.50%", "0", "ST+C", "ST", "C", "ST+C", "0", "7.76%", "34.33%"], "regionBoundary": {"x2": 264.0, "y1": 62.8900146484375, "x1": 99.0, "y2": 118.8900146484375}, "caption": "Table 2: Cell-(i, j): % of test set images that were misses by model j, converted to hits by model i", "page": 4}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.200927734375, "y1": 321.0425720214844, "x1": 71.69100189208984, "y2": 398.7760009765625}, "imageText": ["Method", "Image", "TEST", "Data", "VAL", "Data**", "Input", "Accu", "Rank", "Rank", "Recall", "Accu", "Rank", "Rank", "Recall", "-racy", "Avg", "@3", "-racy", "Avg", "@3", "VSE++", "O", "62%\u2020", "-", "-", "-", "66.6%\u2021", "-", "3.858\u2021", "-", "Symvise*", "O", "57.11%", "1.998", "4.227", "1.601", "59.73%", "1.931", "4.049", "1.683", "LXMERT", "O", "50.00%", "2.262", "5.000", "1.410", "53.22%", "2.159", "4.860", "1.470", "VilBERT", "O", "61.76%", "1.860", "4.19", "1.710", "64.13%", "1.760", "4.028", "1.790", "ADVISE", "O", "+", "K", "69%\u2020", "-", "-", "-", "72.84%\u2021", "-", "3.552\u2021", "-", "cyberagent", "\u2020", "ST", "+", "O", "82%", "-", "-", "-", "-", "-", "-", "VS", "(v1)", "ST", "+", "O", "-", "-", "-", "-", "88.70%", "-", "-", "-", "VS", "(v1)*", "ST", "+", "O", "86.84%", "1.264", "3.072", "2.259", "89.28%", "1.213", "2.889", "2.356", "VS", "(v3)", "ST", "+", "O", "-", "-", "-", "-", "90.90%", "-", "3.090", "-", "SBERT", "FE", "ST", "+", "C", "37.31", "%", "2.870", "6.515", "1.024", "37.59", "%", "2.847", "6.472", "1.025", "BERT", "FE", "ST", "+", "C", "81.94%", "1.496", "3.854", "2.078", "84.10%", "1.423", "3.744", "2.141", "SBERT", "FT", "ST", "+", "C", "84.54%", "1.334", "3.123", "2.310", "87.87%", "1.269", "2.993", "2.413", "BERT", "FT", "C", "60.09", "%", "2.175", "4.489", "1.667", "62.81%", "2.012", "4.284", "1.743", "BERT", "FT", "ST", "84.95%", "1.884", "3.622", "2.271", "87.53%", "1.774", "3.502", "2.353", "BERT", "FT", "ST", "+", "C", "89.69%", "1.230", "2.982", "2.411", "91.56%", "1.189", "2.830", "2.487"], "regionBoundary": {"x2": 522.0, "y1": 63.8900146484375, "x1": 75.0, "y2": 308.8900146484375}, "caption": "Table 1: Results on CVPR 2018 Challenge Data (FE: Feature Extractor, FT: Fine-Tuned, ST: Scene-Text, C: Densecap Captions, O: Object-Proposals, K: Knowledge) Symvise (Doshi and Hinthorn, 2018), VS(v1):Visual Semantics version 1 (Dey et al., 2019a), VS(v3): Visual Semantics version 3 (Dey et al., 2019b), LXMERT (Tan and Bansal, 2019), VilBERT (Lu et al., 2019), BERT (Devlin et al., 2019), SBERT: Siamese BERT (Reimers and Gurevych, 2019), * Our implementation , ** Results on their respective VAL splits, our results are on 5-fold train-val split, \u2020 Results from challenge leaderboard (https://evalai.cloudcv.org/web/challenges/challenge-page/86/evaluation), \u2021 Results from ADVISE github page (https://github.com/yekeren/ADVISE-Image ads understanding) - April 2020.", "page": 3}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 511.6131896972656, "y1": 343.7285461425781, "x1": 321.2080078125, "y2": 349.73101806640625}, "imageText": [], "regionBoundary": {"x2": 496.0, "y1": 221.8900146484375, "x1": 337.0, "y2": 331.8900146484375}, "caption": "Figure 1: Ads Dataset: Textual and Visual Cues", "page": 0}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 710.5738745795355, "y1": 477.40075853135846, "x1": 446.12223307291663, "y2": 485.7375250922309}, "name": "1", "caption_text": "Figure 1: Ads Dataset: Textual and Visual Cues", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 688.0, "y1": 309.0, "x1": 469.0, "y2": 460.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 375.6172604031033, "y1": 431.56742519802515, "x1": 127.5347179836697, "y2": 439.9041917588976}, "name": "2", "caption_text": "Figure 2: BERT Sentence-Pair Classification", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 87.0, "x1": 100.0, "y2": 403.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2235107421875, "y1": 445.8924611409505, "x1": 99.57083596123589, "y2": 553.8555569118923}, "name": "1", "caption_text": "Table 1: Results on CVPR 2018 Challenge Data (FE: Feature Extractor, FT: Fine-Tuned, ST: Scene-Text, C: Densecap Captions, O: Object-Proposals, K: Knowledge) Symvise (Doshi and Hinthorn, 2018), VS(v1):Visual Semantics version 1 (Dey et al., 2019a), VS(v3): Visual Semantics version 3 (Dey et al., 2019b), LXMERT (Tan and Bansal, 2019), VilBERT (Lu et al., 2019), BERT (Devlin et al., 2019), SBERT: Siamese BERT (Reimers and Gurevych, 2019), * Our implementation , ** Results on their respective VAL splits, our results are on 5-fold train-val split, \u2020 Results from challenge leaderboard (https://evalai.cloudcv.org/web/challenges/challenge-page/86/evaluation), \u2021 Results from ADVISE github page (https://github.com/yekeren/ADVISE-Image ads understanding) - April 2020.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 86.0, "x1": 100.0, "y2": 445.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15348307291663, "y1": 189.31600782606336, "x1": 99.57083596123589, "y2": 214.25696478949652}, "name": "2", "caption_text": "Table 2: Cell-(i, j): % of test set images that were misses by model j, converted to hits by model i", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 366.0, "y1": 86.0, "x1": 137.0, "y2": 165.0}, "page": 4, "dpi": 0}], "error": null, "pdf": "/work/host-output/695dcafa0ae45f36e9a5a451b1fa88bd0b06aec2/2020.acl-main.674.pdf", "dpi": 100}