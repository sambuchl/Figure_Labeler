{"raw_detected_boxes": [[], [], [{"x2": 398.0, "y1": 91.0, "x1": 106.0, "y2": 282.0}], [{"x2": 395.0, "y1": 92.0, "x1": 106.0, "y2": 288.0}], [{"x2": 644.0, "y1": 87.0, "x1": 185.0, "y2": 180.0}], [{"x2": 687.0, "y1": 92.0, "x1": 140.0, "y2": 394.0}, {"x2": 702.0, "y1": 479.0, "x1": 134.0, "y2": 620.0}, {"x2": 693.0, "y1": 699.0, "x1": 461.0, "y2": 792.0}], [{"x2": 706.0, "y1": 86.0, "x1": 124.0, "y2": 708.0}, {"x2": 719.0, "y1": 789.0, "x1": 434.0, "y2": 876.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.5475463867188, "y1": 581.8565673828125, "x1": 307.2770080566406, "y2": 611.76904296875}, "imageText": ["BPE", "28.41", "23.05", "Char-att", "29.80", "23.87", "+0.82", "+Multi-att", "30.52", "24.48", "+1.43", "System", "Dev", "Test", "\u2206"], "regionBoundary": {"x2": 501.0, "y1": 503.8900146484375, "x1": 331.0, "y2": 569.8900146484375}, "caption": "Table 4: Case-sensitive BLEU on the English-German translation tasks. Our systems improve over a baseline BPE system.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.548095703125, "y1": 295.4325866699219, "x1": 72.00099182128906, "y2": 325.3460693359375}, "imageText": ["En-Zh", "1\u2032", "NMT", "31.58", "22.20", "23.47", "22.50", "21.47", "22.41", "2\u2032", "RNN-Char", "28.78", "21.03", "21.70", "19.81", "20.98", "20.88", "\u22121.53", "3\u2032", "CNN-Char", "31.36", "23.60", "24.71", "22.75", "23.05", "23.53", "+1.12", "4\u2032", "Hybrid", "31.31", "24.45", "24.65", "23.10", "23.62", "23.96", "+1.55", "5\u2032", "Char-att", "30.93", "23.63", "24.42", "21.92", "23.6", "23.39", "+0.98", "6\u2032", "Multi-att", "30.17", "22.09", "24.09", "22.29", "23.8", "23.07", "+0.66", "7\u2032", "5\u2032+6\u2032", "32.91", "25.02", "25.69", "24.03", "25.20", "24.99", "+2.58", "Zh-En", "1", "NMT", "33.76", "31.88", "33.15", "30.55", "27.47", "30.76", "2", "RNN-Char", "32.22", "31.05", "31.41", "28.85", "25.99", "29.32", "\u22121.44", "3", "CNN-Char", "33.69", "32.06", "33.10", "30.40", "27.67", "30.81", "+0.05", "4", "Hybrid", "34.33", "33.10", "33.41", "30.96", "28.00", "31.37", "+0.60", "5", "Char-att", "34.85", "33.71", "34.91", "32.08", "28.66", "32.34", "+1.58", "6", "Multi-att", "34.61", "33.26", "34.42", "31.06", "28.24", "31.75", "+0.98", "7", "5+6", "35.42", "33.9", "35.23", "32.62", "29.36", "32.68", "+2.02", "Task", "#", "System", "MT02", "MT03", "MT04", "MT05", "MT06", "Mean", "\u2206"], "regionBoundary": {"x2": 500.0, "y1": 62.8900146484375, "x1": 98.0, "y2": 283.8900146484375}, "caption": "Table 2: Performance of different systems on the Chinese-English and English-Chinese translation tasks. Our encoder with character attention (Char-att) improves over all other models on Zh-En and over the word-based baseline on En-Zh. Adding our decoder with multi-scale attention (Multi-att) outperforms all other models.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5383911132812, "y1": 463.69952392578125, "x1": 72.0009994506836, "y2": 481.656982421875}, "imageText": ["En-Zh", "8\u2032", "BPE", "30.17", "22.09", "24.09", "22.29", "23.80", "23.07", "+0.66", "9\u2032", "Char-att", "30.95", "23.07", "25.19", "22.74", "24.27", "23.82", "+1.41", "10\u2032", "9\u2032+Multi-att", "32.36", "24.91", "25.79", "23.42", "24.88", "24.75", "+2.34", "Zh-En", "8", "BPE", "34.66", "33.65", "34.69", "30.80", "27.66", "31.70", "+0.94", "9", "Char-att", "35.20", "34.93", "35.39", "31.62", "28.56", "32.63", "+1.86", "10", "9+Multi-att", "36.68", "35.39", "35.93", "32.08", "29.74", "33.29", "+2.52", "Task", "#", "System", "MT02", "MT03", "MT04", "MT05", "MT06", "Mean", "\u2206"], "regionBoundary": {"x2": 506.0, "y1": 339.8900146484375, "x1": 92.0, "y2": 451.8900146484375}, "caption": "Table 3: Comparison of our models on top of the BPE-based NMT model and the original BPE-based model on the Chinese-English and English-Chinese translation tasks. Our models improve over the BPE baselines.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.5474243164062, "y1": 642.66357421875, "x1": 307.2770080566406, "y2": 672.5770263671875}, "imageText": ["NMT", "28.47", "38.21", "Hybrid", "29.83", "+1.36", "37.79", "\u22120.43", "Ours", "30.80", "+2.33", "39.39", "+1.18", "System", "with", "OOV", "\u2206", "no", "OOV", "\u2206"], "regionBoundary": {"x2": 521.0, "y1": 564.8900146484375, "x1": 312.0, "y2": 630.8900146484375}, "caption": "Table 6: Translation performance on source sentences with and without OOV words. \u201cOurs\u201d means our model with both Char-att and Multi-att.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.54833984375, "y1": 526.53955078125, "x1": 72.0009994506836, "y2": 544.4970092773438}, "imageText": ["Ours", "[...]", "presented", "the", "un", "on", "the", "4th", "of", "the", "three", "wall", "UNK", "of", "the", "eastern", "and", "west-", "ern", "cold", "war", ".", "CNN-Char", "[...]", "sent", "three", "pieces", "of", "UNK", "to", "the", "united", "nations,", "which", "was", "the", "cold", "war", "in", "eastern", "china", ".", "NMT", "[...]", "sent", "the", "three", "pieces", "of", "UNK", "UNK", "to", "the", "un", "to", "the", "un", "Reference", "[...]", "presented", "the", "united", "nations", "with", "three", "pieces", "of", "the", "berlin", "wall", ",", "a", "symbol", "of", "the", "cold", "war", "between", "the", "east", "and", "the", "west", ".", "Source", "[...]\u5c06\u4e1c\u897f\u65b9\u51b7\u6218\u7684\u8c61\u5f81\u67cf\u6797\u5899\u7684\u4e09\u5757\u5899\u4f53\u8d60\u9001\u5230\u4e86\u8054\u5408\u56fd", "Ours", "[...]", "not", "the", "root", "of", "the", "current", "incidents", "that", "took", "place", "in", "the", "palestinian", "occu-", "pied", "territories", "[...]", "CNN-Char", "[...]", "not", "the", "only", "source", "of", "events", "that", "took", "place", "in", "the", "palestinian", "occupation", "[...]", "NMT", "[...]", "such", "actions", "were", "not", "the", "source", "of", "the", "incidents", "of", "the", "current", "palestinian", "occupation", "[...]", "Reference", "[...]", "not", "the", "source", "of", "what", "happened", "on", "the", "palestinian", "territory", "occupied", "by", "israel", "[...]", "Source", "[...]\u4e0d\u662f\u76ee\u524d\u5728\u5df4\u52d2\u65af\u5766\u88ab\u5360\u9886\u571f\u6240\u53d1\u751f\u7684\u4e8b\u4ef6\u7684\u6839\u6e90", "[...]", "(b)", "Frequent", "words", "Ours", "internet", "business", "will", "continue", "to", "be", "the", "fastest", "growing", "business", "of", "china", "\u2019s", "telecommunications", "industry", "[...]", "Hybrid", "the", "internet", "will", "remain", "the", "fastest", "of", "china", "\u2019s", "communications", "growth", "speed", "[...]", "NMT", "internet", "business", "will", "remain", "the", "fastest", "growing", "business", "in", "china", ".", "[...]", "Reference", "internet", "will", "remain", "the", "business", "with", "the", "fastest", "growth", "in", "china", "\u2019s", "telecommu-", "nication", "industry", "[...]", "Source", "\u4e92\u8054\u7f51\u4e1a\u52a1\u4ecd\u5c06\u662f\u4e2d\u56fd\u901a\u4fe1\u4e1a\u589e\u957f\u901f\u5ea6\u6700\u5feb\u7684\u4e1a\u52a1", "[...]", "(a)", "OOV", "words"], "regionBoundary": {"x2": 508.0, "y1": 63.52480697631836, "x1": 89.0, "y2": 509.8900146484375}, "caption": "Table 5: Sample translations. For each example, we show the source, the reference and the translation from our best model. \u201cOurs\u201d means our model with both Char-att and Multi-att.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 290.2716369628906, "y1": 220.66055297851562, "x1": 72.0009994506836, "y2": 274.48406982421875}, "imageText": ["sl", "llllll", "l", "l", "lllll", "l", "\u03b1l,q+2O", "Oq+2", "\u03b1l,p-1O", "Op-2", "\u03b1l,p+1I", "Op+1", "\u03b1l,q+1O", "Oq+1", "\u03b1l,p-2O", "\u03b1l,pI", "\u03b1l,qI", "Embeddings", "Op-1", "OqOp", "Character", "hl-1", "Attention", "Mechanism", "cl", "O", "cl", "I", "Annotations", "sl+1", "\u2032", "hl+1\u2032", "hl", "hl", "Word", "Embeddings"], "regionBoundary": {"x2": 287.0, "y1": 65.8900146484375, "x1": 77.0, "y2": 202.8900146484375}, "caption": "Figure 1: Forward encoder with character attention at time step l. The encoder alternates between reading word embeddings and character context vectors. cl I and clO denotes the inside and outside character-level context vectors of the l-th word, respectively.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 290.2715759277344, "y1": 224.66659545898438, "x1": 72.0009994506836, "y2": 242.62408447265625}, "imageText": ["cj", "c", "cj", "w", "Word", "Embeddings", "\u03b1j,1", "c", "\u03b1j,k", "c", "\u03b1j,K", "c", "Embeddings", "O1", "OKOk", "Character", "\u03b1j,1", "\u03b1j,l", "\u03b1j,L", "Encoder", "sls1", "sL", "hL", "hL", "h1", "h1", "hl", "hl", "Decoder", "Initial", "State", "dj-1", "yj", "d0", "dj"], "regionBoundary": {"x2": 286.0, "y1": 63.71769332885742, "x1": 76.0, "y2": 206.8900146484375}, "caption": "Figure 2: Illustration of the decoder with our multiscale attention mechanism.", "page": 3}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5481567382812, "y1": 140.91458129882812, "x1": 72.0009994506836, "y2": 158.8720703125}, "imageText": ["NMT", "33.76", "31.88", "33.15", "30.55", "27.47", "30.76", "Word-att", "34.28", "32.26", "33.82", "31.02", "27.93", "31.26", "+0.50", "Char-att", "34.85", "33.71", "34.91", "32.08", "28.66", "32.34", "+1.58", "System", "MT02", "MT03", "MT04", "MT05", "MT06", "Mean", "\u2206"], "regionBoundary": {"x2": 464.0, "y1": 62.8900146484375, "x1": 133.0, "y2": 128.8900146484375}, "caption": "Table 1: Performance of the encoder with character attention and the encoder with word attention. Char-att and Word-att denotes the encoder with character attention and the encoder with word attention, respectively.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 403.1550513373481, "y1": 306.47299024793836, "x1": 100.00138812594943, "y2": 381.2278747558594}, "name": "1", "caption_text": "Figure 1: Forward encoder with character attention at time step l. The encoder alternates between reading word embeddings and character context vectors. cl I and clO denotes the inside and outside character-level context vectors of the l-th word, respectively.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 91.0, "x1": 106.0, "y2": 282.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15496656629773, "y1": 312.0369381374783, "x1": 100.00138812594943, "y2": 336.97789510091144}, "name": "2", "caption_text": "Figure 2: Illustration of the decoder with our multiscale attention mechanism.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 398.0, "y1": 90.0, "x1": 106.0, "y2": 288.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9279954698351, "y1": 195.71469624837238, "x1": 100.00138812594943, "y2": 220.65565321180554}, "name": "1", "caption_text": "Table 1: Performance of the encoder with character attention and the encoder with word attention. Char-att and Word-att denotes the encoder with character attention and the encoder with word attention, respectively.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 645.0, "y1": 86.0, "x1": 170.0, "y2": 197.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9279106987847, "y1": 410.32303704155817, "x1": 100.00137752956815, "y2": 451.8695407443576}, "name": "2", "caption_text": "Table 2: Performance of different systems on the Chinese-English and English-Chinese translation tasks. Our encoder with character attention (Char-att) improves over all other models on Zh-En and over the word-based baseline on En-Zh. Adding our decoder with multi-scale attention (Multi-att) outperforms all other models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 694.0, "y1": 86.0, "x1": 136.0, "y2": 411.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9144321017795, "y1": 644.0271165635851, "x1": 100.00138812594943, "y2": 668.968031141493}, "name": "3", "caption_text": "Table 3: Comparison of our models on top of the BPE-based NMT model and the original BPE-based model on the Chinese-English and English-Chinese translation tasks. Our models improve over the BPE baselines.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 702.0, "y1": 471.0, "x1": 128.0, "y2": 628.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9271477593315, "y1": 808.1341213650173, "x1": 426.77362230088977, "y2": 849.6792263454861}, "name": "4", "caption_text": "Table 4: Case-sensitive BLEU on the English-German translation tasks. Our systems improve over a baseline BPE system.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 696.0, "y1": 699.0, "x1": 447.0, "y2": 809.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9282497829861, "y1": 731.304931640625, "x1": 100.00138812594943, "y2": 756.245846218533}, "name": "5", "caption_text": "Table 5: Sample translations. For each example, we show the source, the reference and the translation from our best model. \u201cOurs\u201d means our model with both Char-att and Multi-att.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 706.0, "y1": 86.0, "x1": 124.0, "y2": 708.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9269782172308, "y1": 892.5882975260416, "x1": 426.77362230088977, "y2": 934.1347588433159}, "name": "6", "caption_text": "Table 6: Translation performance on source sentences with and without OOV words. \u201cOurs\u201d means our model with both Char-att and Multi-att.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 783.0, "x1": 427.0, "y2": 893.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/9ac5ada0654dc1892bf8022fddf5ba528d85b04a/N18-1116.pdf", "dpi": 100}