{"raw_detected_boxes": [[], [{"x2": 396.0, "y1": 100.0, "x1": 128.0, "y2": 143.0}, {"x2": 722.0, "y1": 99.0, "x1": 457.0, "y2": 273.0}, {"x2": 347.0, "y1": 205.0, "x1": 161.0, "y2": 315.0}], [{"x2": 360.0, "y1": 96.0, "x1": 148.0, "y2": 339.0}], [{"x2": 407.0, "y1": 103.0, "x1": 105.0, "y2": 347.0}], [], [], [{"x2": 751.0, "y1": 82.0, "x1": 438.0, "y2": 220.0}], [{"x2": 416.0, "y1": 83.0, "x1": 103.0, "y2": 213.0}, {"x2": 750.0, "y1": 82.0, "x1": 440.0, "y2": 320.0}, {"x2": 406.0, "y1": 354.0, "x1": 112.0, "y2": 501.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 298.8006896972656, "y1": 126.75455474853516, "x1": 72.0009994506836, "y2": 132.75701904296875}, "imageText": ["3210", "s", "a", "y"], "regionBoundary": {"x2": 291.0, "y1": 72.0, "x1": 78.0, "y2": 104.0}, "caption": "Figure 1: An automaton encoding the English word say.", "page": 1}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 540.006103515625, "y1": 209.42752075195312, "x1": 313.2009582519531, "y2": 312.23199462890625}, "imageText": ["s:s", "s:a", "\u03b5:a", "\u03b5:s", "y:s", "0,", "$", "y:a", "a:s", "a:a", "s:s", "\u03b5:a", "\u03b5:s", "\u03b5:a", "\u03b5:s", "\u03b5:a", "\u03b5:s", "\u03b5:a", "s:a", "\u03b5:a\u03b5:a\u03b5:a\u03b5:a", "s:a", "a:a", "y:a", "\u03b5:s", "s:\u03b5", "a:\u03b5", "y:\u03b5", "s:\u03b5", "a:\u03b5", "y:\u03b5", "\u03b5:s\u03b5:s\u03b5:s\u03b5:s", "s:s", "a:s", "y:s", "3,", "s", "2,", "a", "3,", "a", "2,", "s", "1,", "a", "1,", "s", "0,", "a", "0,", "s"], "regionBoundary": {"x2": 520.0, "y1": 69.94706726074219, "x1": 328.0, "y2": 196.37152099609375}, "caption": "Figure 3: An example of the transducer G, which pairs the string x=say with infinitely many possible strings y. ThisGwas created as the composition of the straight-line input automaton (Figure 1) and the transducer F (Figure 2). Thus, the state of G tracks the states of those two machines: the position in x and the most recent output character. To avoid a tangled diagram, this figure shows only a few of the states (the start state plus all states of the form i,s\u00a9 or i,a\u00a9), with all arcs among them.", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 298.80194091796875, "y1": 240.53549194335938, "x1": 72.00098419189453, "y2": 295.8529357910156}, "imageText": ["?:a\u03a3:\u03b5", "?:s", "\u03a3:\u03b5", "?:a", "\u03a3:\u03b5", "?:s", "a", "?:s", "s", "?:a", "$"], "regionBoundary": {"x2": 252.46177673339844, "y1": 147.0, "x1": 117.0, "y2": 228.0}, "caption": "Figure 2: An example transducer F , whose state remembers the most recent output character (or $ if none). Only a few of the states are shown, with all arcs among them. The \u03a3 wildcard matches any symbol in \u03a3x; the \u201c?\u201d wildcard matches the empty string \u03b5 or any symbol in \u03a3x.", "page": 1}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 540.005615234375, "y1": 167.77951049804688, "x1": 313.2010192871094, "y2": 365.0649719238281}, "imageText": ["BiLSTM-WFST", "(2", "\u00d7", "Data)", "87.6", "94.8", "88.1", "85.7", "Model", "Ensemble", "85.8", "94.6", "86.0", "83.8", "BiLSTM-WFST", "85.1", "94.4", "85.5", "83.0", "Model", "13SIA", "2PIE", "2PKE", "rP", "Moses15", "85.3", "94.0", "82.8", "70.8", "Dreyer", "(Backoff)", "82.8", "88.7", "74.7", "69.9", "Dreyer", "(Lat-Class)", "84.8", "93.6", "75.7", "81.8", "Dreyer", "(Lat-Region)", "87.5", "93.4", "87.4", "84.9"], "regionBoundary": {"x2": 541.0, "y1": 59.728084564208984, "x1": 315.0, "y2": 163.0}, "caption": "Table 1: Exact match accuracy on the morphological reinflection task. All the results in the first half of the table are taken from Dreyer (2011), whose experimental setup we copied exactly. The Moses15 result is obtained by applying the SMT toolkit Moses (Koehn et al., 2007) over letter strings with 15-character context windows. Dreyer (Backoff) refers to the ngrams+x model which has access to all the \u201cbackoff features.\u201d Dreyer (Lat-Class) is the ngrams+x+latent class model, and Dreyer (Lat Region) refers to the ngrams+x+latent class + latent change region model. The \u201cModel Ensemble\u201d row displays the performance of an ensemble including our full model and the 7 models that we performed ablation on. In each column, we boldfaced the highest result and those that were not significantly worse (sign test, p < 0.05). Finally, the last row reports the performance of our BiLSTM-WFST when trained on twice the training data.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 298.8056335449219, "y1": 261.6285095214844, "x1": 72.00098419189453, "y2": 363.2718811035156}, "imageText": ["s:d", "s:i", "s:a", "y:d", "y:s", "y:a", "a:s", "a:d", "y:ia:i", "a:a", "s:s", "s:\u03b5", "a:\u03b5", "y:\u03b5", "s:\u03b5", "a:\u03b5", "y:\u03b5", "s:\u03b5", "a:\u03b5", "y:\u03b5", "s:\u03b5", "a:\u03b5", "y:\u03b5", "s:\u03b5", "a:\u03b5", "y:\u03b5", "\u03b5:d", "\u03b5:d", "\u03b5:i", "\u03b5:i", "\u03b5:a", "\u03b5:a", "\u03b5:s", "\u03b5:s", "\u03b5:i", "\u03b5:d", "\u03b5:a", "\u03b5:s", "\u03b5:i", "\u03b5:d", "\u03b5:a", "\u03b5:s", "3,i,3", "3,a,2", "3,s,1", "3,$,0", "0,d,4", "1,d,4", "2,d,4", "3,d,4", "0,i,3", "1,i,3", "2,i,3", "0,a,2", "1,a,2", "2,a,2", "2,s,1", "2,$,0", "1,s,1", "1,$,0", "0,s,1", "0,$,0"], "regionBoundary": {"x2": 259.0, "y1": 68.0, "x1": 106.0, "y2": 246.0}, "caption": "Figure 4: A compact lattice of the exponentially many paths in the transducer G of Figure 3 that align input string x=say with output string y=said. To find p(y | x), we must sum over these paths (i.e., alignments). The lattice is created by composing G with y, which selects all paths in G that output y. Note that horizontal movement makes progress through x; vertical movement makes progress through y. The lattice\u2019s states specialize states in G so that they also record a position in y.", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 298.7995910644531, "y1": 161.48348999023438, "x1": 72.0009994506836, "y2": 239.217041015625}, "imageText": ["BiLSTM-WFST", "91.5", "94.5", "97.9", "97.4", "ngrams", "+", "x", "(D)", "91.1", "93.4", "97.0", "83.0", "ngrams", "+", "x", "+", "l", "(D)", "93.6", "96.9", "97.9", "88.6", "Model", "Basque", "English", "Irish", "Tagalog", "Base", "(W)", "85.3", "91.0", "43.3", "0.3", "WFAf\ufb01x", "(W)", "80.1", "93.1", "70.8", "81.7", "ngrams", "(D)", "91.0", "92.4", "96.8", "80.5"], "regionBoundary": {"x2": 299.0, "y1": 59.87340545654297, "x1": 74.0, "y2": 152.79736328125}, "caption": "Table 2: Lemmatization results on Basque, English, Irish and Tagalog. Comparison systems marked with (W) are taken from Wicentowski (2002) and systems marked with a (D) are taken from Dreyer (2011). We outperform baselines on all languages and are competitive with the latentvariable approach (ngrams + x + l), beating it in two cases: Irish and Tagalog.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 539.999755859375, "y1": 235.23049926757812, "x1": 313.2010192871094, "y2": 265.14300537109375}, "imageText": ["Seq2Seq-Att-4Layer", "76.0", "91.4", "81.2", "79.3", "Seq2Seq-Att-1Layer", "77.2", "89.6", "82.1", "79.1", "Seq2Seq-4Layer", "2.5", "5.2", "11.5", "6.4", "Seq2Seq-1Layer", "9.1", "11.1", "14.1", "11.9", "Deep", "BiLSTM", "(No", "Context)", "86.5", "94.3", "87.8", "78.8", "Deep", "BiLSTMs", "w/o", "Copying", "86.5", "94.6", "86.5", "80.7", "Shallow", "BiLSTM", "86.4", "94.7", "86.1", "80.6", "Bi-Deep", "LSTM", "86.1", "94.2", "86.5", "78.6", "Deep", "MonoLSTM", "84.0", "93.8", "85.6", "67.3", "Shallow", "MonoLSTM", "84.2", "94.5", "84.9", "68.2", "No", "LSTM", "(Local", "Context)", "83.6", "88.5", "83.2", "68.0", "Deep", "BiLSTM", "w/o", "Tying", "69.7", "78.5", "77.9", "66.7", "No", "LSTM", "(No", "Context)", "70.7", "84.9", "72.4", "64.1", "Systems", "13SIA", "2PIE", "2PKE", "rP", "Deep", "BiLSTM", "w/", "Tying", "86.8", "94.8", "87.9", "81.1"], "regionBoundary": {"x2": 541.0, "y1": 59.688438415527344, "x1": 315.0, "y2": 230.0}, "caption": "Table 3: Ablation experiments: Exact-match accuracy of the different systems averaged on 5 folds of validation portions of the morphological induction dataset.", "page": 7}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 238.3375244140625, "y1": 370.5145263671875, "x1": 132.46499633789062, "y2": 376.5169982910156}, "imageText": ["BiLSTM-WFST", "Dreyer", "(Lat-Region)", "Dreyer", "(Backoff)", "Moses15", "88", "13SIA", "86", "84", "82", "80", "78", "76", "74", "50100", "300", "500", "1000", "72", "2PKE", "cy", "u", "ra", "A", "cc", "90", "85", "80", "75", "70", "65", "60", "50100", "300", "500", "1000", "55"], "regionBoundary": {"x2": 294.3782043457031, "y1": 256.66973876953125, "x1": 82.56539916992188, "y2": 360.1224060058594}, "caption": "Figure 7: Learning Curves", "page": 7}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 295.023681640625, "y1": 151.22750854492188, "x1": 75.77799987792969, "y2": 157.22998046875}, "imageText": ["1", "2", "3", "0", "\u21b50", "3", "\u21b53\u21b52\u21b51", "s", "a", "y", "1", "2"], "regionBoundary": {"x2": 290.0, "y1": 64.0, "x1": 78.0, "y2": 139.883056640625}, "caption": "Figure 5: A level-1 BiLSTM reading the word x=say.", "page": 3}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 298.8007507324219, "y1": 261.1795349121094, "x1": 72.0009994506836, "y2": 279.136962890625}, "imageText": ["(k)", "3", "(k", "1)", "3", "(k", "1)", "2", "(k", "1)", "1", "(k)", "2", "(k)", "1", "(k)", "3", "(k)", "2", "(k)", "1", "(k)", "0", "\u21b5", "(k)", "0", "\u21b5", "(k)", "1", "\u21b5", "(k)", "2", "\u21b5", "(k)", "3"], "regionBoundary": {"x2": 295.0, "y1": 169.0, "x1": 78.0, "y2": 250.47821044921875}, "caption": "Figure 6: Level k > 1 of a deep BiLSTM. (We augment the shown input vectors with level k\u2212 1\u2019s input vectors.)", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 415.0009579128689, "y1": 176.04799270629883, "x1": 100.00138812594943, "y2": 184.38474867078992}, "name": "1", "caption_text": "Figure 1: An automaton encoding the English word say.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 100.0, "x1": 111.0, "y2": 143.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0084771050347, "y1": 290.8715565999349, "x1": 435.0013309054904, "y2": 433.6555480957031}, "name": "3", "caption_text": "Figure 3: An example of the transducer G, which pairs the string x=say with infinitely many possible strings y. ThisGwas created as the composition of the straight-line input automaton (Figure 1) and the transducer F (Figure 2). Thus, the state of G tracks the states of those two machines: the position in x and the most recent output character. To avoid a tangled diagram, this figure shows only a few of the states (the start state plus all states of the form i,s\u00a9 or i,a\u00a9), with all arcs among them.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 739.0, "y1": 99.0, "x1": 440.0, "y2": 290.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.002695719401, "y1": 334.0770721435547, "x1": 100.00136693318684, "y2": 410.90685526529944}, "name": "2", "caption_text": "Figure 2: An example transducer F , whose state remembers the most recent output character (or $ if none). Only a few of the states are shown, with all arcs among them. The \u03a3 wildcard matches any symbol in \u03a3x; the \u201c?\u201d wildcard matches the empty string \u03b5 or any symbol in \u03a3x.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 350.0, "y1": 204.0, "x1": 161.0, "y2": 315.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.007824367947, "y1": 363.3729298909505, "x1": 100.00136693318684, "y2": 504.54427931043836}, "name": "4", "caption_text": "Figure 4: A compact lattice of the exponentially many paths in the transducer G of Figure 3 that align input string x=say with output string y=said. To find p(y | x), we must sum over these paths (i.e., alignments). The lattice is created by composing G with y, which selects all paths in G that output y. Note that horizontal movement makes progress through x; vertical movement makes progress through y. The lattice\u2019s states specialize states in G so that they also record a position in y.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 360.0, "y1": 96.0, "x1": 148.0, "y2": 341.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 409.75511338975696, "y1": 210.03820631239148, "x1": 105.24722205268012, "y2": 218.37497287326389}, "name": "5", "caption_text": "Figure 5: A level-1 BiLSTM reading the word x=say.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 414.0, "y1": 88.0, "x1": 100.0, "y2": 364.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.007798936632, "y1": 233.02709791395398, "x1": 435.0014156765408, "y2": 507.03468322753906}, "name": "1", "caption_text": "Table 1: Exact match accuracy on the morphological reinflection task. All the results in the first half of the table are taken from Dreyer (2011), whose experimental setup we copied exactly. The Moses15 result is obtained by applying the SMT toolkit Moses (Koehn et al., 2007) over letter strings with 15-character context windows. Dreyer (Backoff) refers to the ngrams+x model which has access to all the \u201cbackoff features.\u201d Dreyer (Lat-Class) is the ngrams+x+latent class model, and Dreyer (Lat Region) refers to the ngrams+x+latent class + latent change region model. The \u201cModel Ensemble\u201d row displays the performance of an ensemble including our full model and the 7 models that we performed ablation on. In each column, we boldfaced the highest result and those that were not significantly worse (sign test, p < 0.05). Finally, the last row reports the performance of our BiLSTM-WFST when trained on twice the training data.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 751.0, "y1": 82.0, "x1": 435.0, "y2": 237.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.99943203396265, "y1": 224.28262498643662, "x1": 100.00138812594943, "y2": 332.24589029947913}, "name": "2", "caption_text": "Table 2: Lemmatization results on Basque, English, Irish and Tagalog. Comparison systems marked with (W) are taken from Wicentowski (2002) and systems marked with a (D) are taken from Dreyer (2011). We outperform baselines on all languages and are competitive with the latentvariable approach (ngrams + x + l), beating it in two cases: Irish and Tagalog.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 416.0, "y1": 83.0, "x1": 100.0, "y2": 230.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9996609157986, "y1": 326.70902676052515, "x1": 435.0014156765408, "y2": 368.2541741265191}, "name": "3", "caption_text": "Table 3: Ablation experiments: Exact-match accuracy of the different systems averaged on 5 folds of validation portions of the morphological induction dataset.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 751.0, "y1": 82.0, "x1": 435.0, "y2": 337.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 331.0243394639757, "y1": 514.6035088433159, "x1": 183.97916158040363, "y2": 522.9402754041884}, "name": "7", "caption_text": "Figure 7: Learning Curves", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 409.0, "y1": 354.0, "x1": 112.0, "y2": 518.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/261e841c8e0175586fb193b1a199cefaa8ecf169/N16-1076.pdf", "dpi": 100}