{"raw_detected_boxes": [[{"x2": 717.0, "y1": 310.0, "x1": 435.0, "y2": 462.0}], [{"x2": 719.0, "y1": 88.0, "x1": 436.0, "y2": 241.0}], [], [{"x2": 711.0, "y1": 95.0, "x1": 445.0, "y2": 262.0}], [], [], [], [{"x2": 663.0, "y1": 86.0, "x1": 164.0, "y2": 359.0}, {"x2": 695.0, "y1": 471.0, "x1": 461.0, "y2": 623.0}], [{"x2": 368.0, "y1": 90.0, "x1": 134.0, "y2": 263.0}], [], [{"x2": 725.0, "y1": 587.0, "x1": 426.0, "y2": 848.0}, {"x2": 722.0, "y1": 323.0, "x1": 426.0, "y2": 503.0}], [], [{"x2": 391.0, "y1": 138.0, "x1": 112.0, "y2": 355.0}, {"x2": 377.0, "y1": 540.0, "x1": 122.0, "y2": 934.0}], [{"x2": 608.0, "y1": 268.0, "x1": 222.0, "y2": 316.0}, {"x2": 662.0, "y1": 720.0, "x1": 168.0, "y2": 815.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2000732421875, "y1": 349.9785461425781, "x1": 306.9169921875, "y2": 439.66693115234375}, "imageText": ["Sentences", "Encodings", "Predictions", "Inspikred", "ating", "Complete", "flop", "Inspired", "acting", "Negative", "Irnspired", "atcing", "Copmlete", "fljop", "Complete", "flop", "Inspikred", "ating", "Inspired", "acting", "Positive", "Positive"], "regionBoundary": {"x2": 517.0842895507812, "y1": 223.69729614257812, "x1": 313.0, "y2": 336.8900146484375}, "caption": "Figure 1: Example of a defense using RobEn. An adversary can perturb sentences (blue, underlined) to many different perturbations (red, not-underlined) within the attack surface (red, ovals). We define an encoding function \u03b1 such that each perturbation of the input sentences maps to one of a few encodings (grey, rounded rectangles). We can then use any model g to make predictions given the encodings.", "page": 0}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2916870117188, "y1": 187.20651245117188, "x1": 307.2760009765625, "y2": 264.9400634765625}, "imageText": ["BERT", "Perturbation", "x", "BERT", "Perturbation", "set", "Input", "x", "Neg", "Pos", "x", "Tihs", "dlightful", "fllm", "\u2026", "dlightful", "deliightful", "\u2026", "delirhtful", "This", "delightful", "film", "\u2026", "fulm", "fllm", "\u2026", "fim", "This", "Thus", "\u2026", "Tihs"], "regionBoundary": {"x2": 518.105224609375, "y1": 62.8900146484375, "x1": 314.0, "y2": 174.8900146484375}, "caption": "Figure 2: Attack model allowing independent perturbations of each token. The original input, x is classified by the model as positive while the perturbation x\u0303 =, obtained by choosing perturbations of \u201cThis\u201d, \u201cdelightful\u201d, and \u201cfilm\u201d independently, is classified as negative. Independent perturbations of each word results in an exponentially large perturbation space B(x).", "page": 1}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 441.9570007324219, "y1": 239.83651733398438, "x1": 155.2779998779297, "y2": 247.333984375}, "imageText": ["Encodings", "SST-2", "MRPC", "QQP", "MNLI", "QNLI", "RTE", "Avg", "Con.", "Comp.", "86.9", "71.6", "72.7", "45.3", "54.6", "40.4", "61.9", "Agg.", "Clust.", "65.6", "50.0", "62.7", "35.4", "36.6", "25.2", "45.9"], "regionBoundary": {"x2": 442.0, "y1": 192.8900146484375, "x1": 156.0, "y2": 227.8900146484375}, "caption": "Table 2: Percentage of test examples with |B\u03b1(x)| = 1 for each dataset.", "page": 13}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.547119140625, "y1": 598.7265625, "x1": 71.69100189208984, "y2": 628.6390380859375}, "imageText": ["Standard", "BERT", "93.8", "87.7", "91.2", "84.3", "88.9", "71.1", "86.2Con.", "Comp.", "+", "BERT", "93.2", "87.7", "86.9", "75.9", "83.4", "61.4", "81.4", "Attack", "BERT", "28.1", "15.9", "33.0", "4.9", "6.2", "5.8", "15.7Con.", "Comp.", "+", "BERT", "93.2", "87.7", "86.9", "75.9", "83.4", "61.4", "81.4", "Robust", "Con.", "Comp.", "+", "BERT", "93.2", "87.7", "86.9", "75.9", "83.4", "61.4", "81.4", "Accuracy", "System", "SST-2", "MRPC", "QQP", "MNLI", "QNLI", "RTE", "Avg"], "regionBoundary": {"x2": 479.0, "y1": 518.8900146484375, "x1": 118.0, "y2": 586.8900146484375}, "caption": "Table 3: Results from internal permutation attacks. Internal permutation attacks bring the average performance for BERT across the six listed tasks from 86.2 to 15.7. Our CONNCOMP encodings, generated using the internal permutation attack surface, achieve a robust accuracy of 81.4, which is only 4.8 points below standard accuracy.", "page": 13}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 291.92169189453125, "y1": 271.2595520019531, "x1": 71.99998474121094, "y2": 313.1270751953125}, "imageText": ["Robust", "Accuracy", "for", "Constrained", "Adversaries", "ac", "y", "cc", "ur", "us", "ta", "R", "oc", "0.76", "0.75", "0.74", "0.73", "0.72", "0.71", "0", "1", "2", "3", "4", "Allowable", "token", "perturbations", "(b)"], "regionBoundary": {"x2": 281.359375, "y1": 98.45149993896484, "x1": 85.02857208251953, "y2": 253.65020751953125}, "caption": "Figure 6: Robust accuracy averaged across all tasks based on different adversarial budgets b. b = 0 corresponds to clean performance, and robust performance is reached at b = 4", "page": 12}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 291.5094909667969, "y1": 710.1885986328125, "x1": 72.00000762939453, "y2": 728.14599609375}, "imageText": ["(b)", "Size", "of", "B\u03b1", "over", "MNLI", "and", "QNLI", "CONNCOMP", "AGGCLUST", "Sizes", "of", "B\u03b1", "on", "QNLI", "0.8", "0.6", "0.4", "0.2", "1", "2", "3\u20134", "5\u20138", "9+", "Sizes", "of", "B\u03b1", "on", "MNLI", "1", "2", "3\u20134", "5\u20138", "9+", "pl", "es", "xa", "m", "of", "E", "tio", "n", "Fr", "ac", "1.0", "0.8", "0.6", "0.4", "0.2", "0", "Size", "of", "B\u03b1", "(a)", "Size", "of", "B\u03b1", "over", "MRPC", "and", "QQP", "CONNCOMP", "AGGCLUST", "Sizes", "of", "B\u03b1", "on", "QQP", "0.8", "0.6", "0.4", "0.2", "1", "2", "3\u20134", "5\u20138", "9+", "Sizes", "of", "B\u03b1", "on", "MRPC", "1", "2", "3\u20134", "5\u20138", "9+", "pl", "es", "xa", "m", "of", "E", "tio", "n", "Fr", "ac", "1.0", "0.8", "0.6", "0.4", "0.2", "0", "Size", "of", "B\u03b1"], "regionBoundary": {"x2": 273.0, "y1": 389.8015441894531, "x1": 91.46421813964844, "y2": 692.2830200195312}, "caption": "Figure 7: Histograms showing sizes of B\u03b1 for MRPC, QQP, MNLI, and QNLI.", "page": 12}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.8956298828125, "y1": 270.8375549316406, "x1": 71.64099884033203, "y2": 312.705078125}, "imageText": ["Robust", "RobEn", "Con.", "Comp.", "+", "BERT", "80.1", "79.4", "82.2", "61.4", "70.5", "46.6", "70.0", "Agg.", "Clust.", "+", "BERT", "80.7", "80.9", "81.4", "62.8", "71.9", "49.8", "71.3", "Baselines", "BERT", "8.7", "10.0", "17.4", "0.7", "0.7", "1.8", "6.6", "Data", "Aug.", "+", "BERT", "17.1", "1.0", "27.6", "15.4", "10.7", "1.4", "12.2", "Typo", "Corr.", "+", "BERT", "53.2", "30.1", "52.0", "23.0", "32.3", "21.3", "35.3", "RobEn", "Con.", "Comp.", "+", "BERT", "80.3", "79.4", "82.7", "62.6", "71.5", "47.3", "70.6", "Agg.", "Clust.", "+", "BERT", "82.1", "82.8", "83.2", "65.3", "74.5", "52.7", "73.4", "Attack", "Standard", "Baselines", "BERT", "93.8", "87.7", "91.3", "84.6", "88.6", "71.1", "86.2", "Data", "Aug.", "+", "BERT", "92.2", "84.3", "88.7", "83.0", "87.4", "63.5", "83.1", "Typo", "Corr.", "+", "BERT", "89.6", "80.9", "87.6", "75.9", "80.5", "54.9", "78.2", "RobEn", "Con.", "Comp.", "+", "BERT", "80.6", "79.9", "84.2", "65.7", "73.3", "52.7", "72.7", "Agg.", "Clust.", "+", "BERT", "83.1", "83.8", "85.0", "69.1", "76.6", "59.2", "76.1", "Accuracy", "System", "SST-2", "MRPC", "QQP", "MNLI", "QNLI", "RTE", "Avg"], "regionBoundary": {"x2": 482.0, "y1": 62.8900146484375, "x1": 116.0, "y2": 258.8900146484375}, "caption": "Table 1: Standard, attack, and robust accuracy on six GLUE tasks against ED1 perturbations. For baseline models we only compute attack accuracy, an upper bound on robust accuracy, since robust accuracy cannot be tractably computed. Using RobEn, we get robustness guarantees by computing robust accuracy, which we find outperforms a the typo corrector in (Pruthi et al., 2019) by at least 36 points.", "page": 7}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 527.28857421875, "y1": 465.4095458984375, "x1": 307.2760009765625, "y2": 519.2329711914062}, "imageText": ["CONNCOMP", "AGGCLUST", "Size", "of", "B\u03b1", "on", "RTE", "0.8", "0.6", "0.4", "0.2", "1", "2", "3\u20134", "5\u20138", "9+", "Size", "of", "B\u03b1", "on", "SST-2", "1", "2", "3\u20134", "5\u20138", "9+", "pl", "es", "xa", "m", "of", "E", "tio", "n", "Fr", "ac", "1.0", "0.8", "0.6", "0.4", "0.2", "0", "Size", "of", "B\u03b1"], "regionBoundary": {"x2": 500.0, "y1": 338.5841369628906, "x1": 335.581787109375, "y2": 448.6224670410156}, "caption": "Figure 4: Histogram of |B\u03b1(x)| for SST-2 and RTE. SST-2 has the highest percentage of inputs x where |B\u03b1(x)| = 1, while RTE has the least. On both datasets, |B\u03b1(x)| < 9 for most x, and |B\u03b1(x)| = 1 on a plurality of inputs.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.2899780273438, "y1": 203.58255004882812, "x1": 306.9169921875, "y2": 281.31610107421875}, "imageText": ["Maximal", "stability", "Maximal", "fidelity", "Balanced", "aboupt", "abot", "auet", "aet", "aut", "about", "abrupt", "abet", "aunt", "at"], "regionBoundary": {"x2": 512.0, "y1": 66.8900146484375, "x1": 321.0, "y2": 188.8900146484375}, "caption": "Figure 3: Visualization of three different encodings. Vocabulary words (large font, blue) share an edge if they share a common perturbation (small font, red). The maximal stability cluster (thick solid line) clusters identically, the maximal fidelity clusters (thin dotted line) encodes all words separately, while the balanced clusters (thin solid line) trade off the two.", "page": 3}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.9244079589844, "y1": 203.80252075195312, "x1": 71.86100006103516, "y2": 245.6710205078125}, "imageText": ["Standard", "accuracy", "Robust", "accuracy", "SST-2", "Standard", "and", "Robust", "Accuracies", "y", "ur", "ac", "A", "cc", "0.9", "0.8", "0.7", "0.0", "0.2", "0.4", "0.6", "Fidelity", "Objective", "Weight", "(\u03b3)"], "regionBoundary": {"x2": 265.0, "y1": 66.30233764648438, "x1": 100.07632446289062, "y2": 187.06134033203125}, "caption": "Figure 5: Standard and robust accuracies on SST-2 with AGGCLUST using different values of \u03b3. While the gap between standard and robust accuracy increases monotonically, robust accuracy increases before decreasing.", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2223239474827, "y1": 486.08131408691406, "x1": 426.27360026041663, "y2": 610.6485154893663}, "name": "1", "caption_text": "Figure 1: Example of a defense using RobEn. An adversary can perturb sentences (blue, underlined) to many different perturbations (red, not-underlined) within the attack surface (red, ovals). We define an encoding function \u03b1 such that each perturbation of the input sentences maps to one of a few encodings (grey, rounded rectangles). We can then use any model g to make predictions given the encodings.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 718.0, "y1": 310.0, "x1": 435.0, "y2": 468.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3495652940538, "y1": 260.009045071072, "x1": 426.772223578559, "y2": 367.97231038411456}, "name": "2", "caption_text": "Figure 2: Attack model allowing independent perturbations of each token. The original input, x is classified by the model as positive while the perturbation x\u0303 =, obtained by choosing perturbations of \u201cThis\u201d, \u201cdelightful\u201d, and \u201cfilm\u201d independently, is classified as negative. Independent perturbations of each word results in an exponentially large perturbation space B(x).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 719.0, "y1": 87.0, "x1": 436.0, "y2": 242.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.347191704644, "y1": 282.7535417344835, "x1": 426.27360026041663, "y2": 390.716807047526}, "name": "3", "caption_text": "Figure 3: Visualization of three different encodings. Vocabulary words (large font, blue) share an edge if they share a common perturbation (small font, red). The maximal stability cluster (thick solid line) clusters identically, the maximal fidelity clusters (thin dotted line) encodes all words separately, while the balanced clusters (thin solid line) trade off the two.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 91.0, "x1": 445.0, "y2": 262.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.4105970594618, "y1": 376.16327073838977, "x1": 99.50138727823892, "y2": 434.31260850694446}, "name": "1", "caption_text": "Table 1: Standard, attack, and robust accuracy on six GLUE tasks against ED1 perturbations. For baseline models we only compute attack accuracy, an upper bound on robust accuracy, since robust accuracy cannot be tractably computed. Using RobEn, we get robustness guarantees by computing robust accuracy, which we find outperforms a the typo corrector in (Pruthi et al., 2019) by at least 36 points.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 672.0, "y1": 86.0, "x1": 149.0, "y2": 376.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3452419704861, "y1": 646.4021470811632, "x1": 426.772223578559, "y2": 721.1569044325087}, "name": "4", "caption_text": "Figure 4: Histogram of |B\u03b1(x)| for SST-2 and RTE. SST-2 has the highest percentage of inputs x where |B\u03b1(x)| = 1, while RTE has the least. On both datasets, |B\u03b1(x)| < 9 for most x, and |B\u03b1(x)| = 1 on a plurality of inputs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 695.0, "y1": 469.0, "x1": 461.0, "y2": 623.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4505666097005, "y1": 283.0590565999349, "x1": 99.80694452921549, "y2": 341.2097507052951}, "name": "5", "caption_text": "Figure 5: Standard and robust accuracies on SST-2 with AGGCLUST using different values of \u03b3. While the gap between standard and robust accuracy increases monotonically, robust accuracy increases before decreasing.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 368.0, "y1": 90.0, "x1": 134.0, "y2": 263.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4467942979601, "y1": 376.7493777804904, "x1": 99.99997880723741, "y2": 434.8987155490451}, "name": "6", "caption_text": "Figure 6: Robust accuracy averaged across all tasks based on different adversarial budgets b. b = 0 corresponds to clean performance, and robust performance is reached at b = 4", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 391.0, "y1": 135.0, "x1": 112.0, "y2": 355.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 404.87429300944007, "y1": 986.373053656684, "x1": 100.00001059638129, "y2": 1011.3138834635416}, "name": "7", "caption_text": "Figure 7: Histograms showing sizes of B\u03b1 for MRPC, QQP, MNLI, and QNLI.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 380.0, "y1": 540.0, "x1": 122.0, "y2": 934.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 613.8291676839192, "y1": 333.1062740749783, "x1": 215.66388871934677, "y2": 343.51942274305554}, "name": "2", "caption_text": "Table 2: Percentage of test examples with |B\u03b1(x)| = 1 for each dataset.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 613.0, "y1": 268.0, "x1": 216.0, "y2": 333.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9265543619791, "y1": 831.5646701388889, "x1": 99.57083596123589, "y2": 873.1097751193577}, "name": "3", "caption_text": "Table 3: Results from internal permutation attacks. Internal permutation attacks bring the average performance for BERT across the six listed tasks from 86.2 to 15.7. Our CONNCOMP encodings, generated using the internal permutation attack surface, achieve a robust accuracy of 81.4, which is only 4.8 points below standard accuracy.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 679.0, "y1": 720.0, "x1": 152.0, "y2": 832.0}, "page": 13, "dpi": 0}], "error": null, "pdf": "/work/host-output/bd7301d92538e9f822972e4acee33effc3775054/2020.acl-main.245.pdf", "dpi": 100}