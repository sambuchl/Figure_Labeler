{"raw_detected_boxes": [[], [{"x2": 723.0, "y1": 100.0, "x1": 89.0, "y2": 252.0}, {"x2": 735.0, "y1": 315.0, "x1": 78.0, "y2": 597.0}], [{"x2": 352.0, "y1": 98.0, "x1": 118.0, "y2": 523.0}], [{"x2": 681.0, "y1": 102.0, "x1": 141.0, "y2": 363.0}, {"x2": 386.0, "y1": 425.0, "x1": 83.0, "y2": 607.0}, {"x2": 392.0, "y1": 690.0, "x1": 78.0, "y2": 884.0}], [{"x2": 743.0, "y1": 99.0, "x1": 84.0, "y2": 290.0}, {"x2": 749.0, "y1": 387.0, "x1": 428.0, "y2": 590.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "2", "captionBoundary": {"x2": 287.0063781738281, "y1": 395.8785400390625, "x1": 52.15800094604492, "y2": 413.83599853515625}, "imageText": ["opinion", "provoke", "memory", "greeting", "complement", "paraphrasing", "echoic", "response", "evaluation", "thinking", "process", "start", "thinking", "surprise", "with", "doubt", "surprise", "satisfaction", "disapproval", "approval", "admiration", "back-channel", "Level", "5", "Level", "3", "Level", "4", "Level", "2", "Level", "1"], "regionBoundary": {"x2": 253.0, "y1": 68.8900146484375, "x1": 85.0, "y2": 376.8900146484375}, "caption": "Figure 2: Classification of types of attentive listening responses", "page": 2}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 539.7177124023438, "y1": 223.64456176757812, "x1": 52.157928466796875, "y2": 255.05206298828125}, "imageText": ["(1)", "Fhai(u)", "=", "2", "(u", "=", "ee),", "1", "(u", "\u2208", "{un,", "a,", "haihai,", "kitsuke,", "a\u2019,", "he,", "un,", "hee}),", "0", "(otherwise)", "(2)", "ent(hai)", "=", "\u2212", "210", "log2", "2", "10", "\u2212", "8(", "1", "10", "log2", "1", "10", ")", "=", "3.12", "[narrative]", "I", "do", "not", "continue", "now,", "but", "my", "hobbies", "are", "dressing,", "knitting", "and", "!\"", "\"", "!"], "regionBoundary": {"x2": 535.0, "y1": 68.8900146484375, "x1": 57.0, "y2": 208.28900146484375}, "caption": "Figure 6: Example of measuring ent(r), versatility of the attentive listening response r. This example shows how to measure ent(hai), versatility of the response hai: (1) calculate Fhai(u), a co-occurrence frequency between hai and another response u (6= hai); (2) measure ent(hai) using Fhai(u).", "page": 4}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 525.0562744140625, "y1": 443.68353271484375, "x1": 319.52801513671875, "y2": 449.6860046386719}, "imageText": [], "regionBoundary": {"x2": 540.0, "y1": 281.8900146484375, "x1": 342.0, "y2": 400.8900146484375}, "caption": "Figure 7: Versatility of attentive listening responses", "page": 4}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 417.6808776855469, "y1": 443.54254150390625, "x1": 174.19500732421875, "y2": 449.5450134277344}, "imageText": ["Types", "of", "response", "Roles,", "ie.", "what", "does", "the", "response", "show?", "back-channel", "hearing", "success", "admiration", "attitude", "of", "admiration,", "surprise,", "or", "attention", "to", "the", "content", "of", "the", "speaker\u2019s", "utterance", "evaluation", "attitude", "toward", "the", "situation", "described", "by", "speaker\u2019s", "utterance", "approval", "attitude", "of", "approval", "of", "the", "content", "of", "the", "speaker\u2019s", "utterance", "disapproval", "attitude", "of", "disapproval", "of", "the", "content", "of", "the", "speaker\u2019s", "utterance", "echoic", "response", "comprehension", "of", "the", "content", "of", "the", "speaker\u2019s", "utterance", "and", "a", "sense", "of", "security", "paraphrasing", "attitude", "of", "trying", "to", "understand", "and", "share", "the", "content", "of", "the", "speaker\u2019s", "utterance", "satisfaction", "listener\u2019s", "attitude", "that", "the", "content", "of", "the", "speaker\u2019s", "utterance", "is", "satisfactory", "for", "him/her", "surprise", "attitude", "of", "strong", "surprise", "at", "the", "content", "of", "the", "speaker\u2019s", "utterance", "surprise", "with", "doubt", "attitude", "of", "surprise", "or", "doubt", "toward", "the", "content", "of", "the", "speaker\u2019s", "utterance", "opinion", "listener\u2019s", "personal", "experiences,", "opinions,", "or", "feelings", "complement", "listener\u2019s", "status", "that", "he/she", "is", "eagerly", "listening", "to", "the", "speaker\u2019s", "utterance", "greeting", "acknowledgement", "of", "the", "speaker\u2019s", "presence", "and", "willingness", "to", "favorably", "interact", "with", "the", "speaker", "provoke", "memory", "listener\u2019s", "reaction", "that", "his/her", "memory", "is", "provoked", "by", "the", "content", "of", "the", "speaker\u2019s", "utterance", "start", "thinking", "listener\u2019s", "reaction", "that", "he/she", "is", "starting", "to", "think", "about", "the", "content", "of", "the", "speaker\u2019s", "utterance", "thinking", "process", "listener\u2019s", "status", "that", "he/she", "is", "thinking", "about", "the", "content", "of", "the", "speaker\u2019s", "utterance"], "regionBoundary": {"x2": 540.0, "y1": 226.8900146484375, "x1": 52.0, "y2": 431.8900146484375}, "caption": "Table 1: Types of attentive listening responses and their roles", "page": 1}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 435.9824523925781, "y1": 197.28152465820312, "x1": 155.8939971923828, "y2": 203.28399658203125}, "imageText": ["!", "\"", "#", "*", "\"", "!", "#", "$%&", "'(", ")", ")", "!", "!", "!"], "regionBoundary": {"x2": 528.0, "y1": 74.95292663574219, "x1": 64.0, "y2": 181.8900146484375}, "caption": "Figure 1: Example of narrative speech and attentive listening response", "page": 1}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 274.5141296386719, "y1": 462.0595397949219, "x1": 64.6520004272461, "y2": 468.06201171875}, "imageText": ["Level", "5", "0.58%", "(222", "/", "37,995)", "Level", "4", "7.46%", "(2,833", "/", "37,995)", "Level", "3", "6.20%", "(2,355", "/", "37,995)", "Level", "2", "17.78%", "(6,757", "/", "37,995)", "(25,828", "/", "37,995)", "Level", "1", "67.98%"], "regionBoundary": {"x2": 278.2918701171875, "y1": 306.8900146484375, "x1": 59.45499801635742, "y2": 439.8900146484375}, "caption": "Figure 4: Breakdown of responses in evaluation data", "page": 3}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 278.4298095703125, "y1": 655.0445556640625, "x1": 60.73699951171875, "y2": 661.0469970703125}, "imageText": [], "regionBoundary": {"x2": 258.0, "y1": 497.8900146484375, "x1": 91.0, "y2": 613.8900146484375}, "caption": "Figure 5: Concreteness of attentive listening responses", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 403.5390625, "y1": 275.2345886230469, "x1": 188.33700561523438, "y2": 281.237060546875}, "imageText": ["[narrative]", "My", "hobby", "is", "ballroom", "dancing", "$", "#", "%", "#", "!", "!", "\"", "!", "!", "#", "!", "!"], "regionBoundary": {"x2": 490.0, "y1": 75.93408966064453, "x1": 101.0, "y2": 259.31903076171875}, "caption": "Figure 3: Example of attentive listening response data", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 605.5311838785807, "y1": 274.00211758083765, "x1": 216.51944054497613, "y2": 282.3388841417101}, "name": "1", "caption_text": "Figure 1: Example of narrative speech and attentive listening response", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 733.0, "y1": 100.0, "x1": 89.0, "y2": 252.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 580.1123301188151, "y1": 616.0313076443142, "x1": 241.93751017252603, "y2": 624.3680742051866}, "name": "1", "caption_text": "Table 1: Types of attentive listening responses and their roles", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 750.0, "y1": 315.0, "x1": 72.0, "y2": 600.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6199696858724, "y1": 549.831305609809, "x1": 72.44166798061795, "y2": 574.772220187717}, "name": "2", "caption_text": "Figure 2: Classification of types of attentive listening responses", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 352.0, "y1": 95.0, "x1": 118.0, "y2": 523.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 560.4709201388889, "y1": 382.270261976454, "x1": 261.5791744656033, "y2": 390.60702853732636}, "name": "3", "caption_text": "Figure 3: Example of attentive listening response data", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 681.0, "y1": 102.0, "x1": 141.0, "y2": 363.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 381.2696244981554, "y1": 641.7493608262804, "x1": 89.7944450378418, "y2": 650.0861273871527}, "name": "4", "caption_text": "Figure 4: Breakdown of responses in evaluation data", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 386.0, "y1": 425.0, "x1": 83.0, "y2": 610.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 386.70806884765625, "y1": 909.7841050889757, "x1": 84.35694376627603, "y2": 918.1208292643229}, "name": "5", "caption_text": "Figure 5: Concreteness of attentive listening responses", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 392.0, "y1": 690.0, "x1": 78.0, "y2": 884.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.607933892144, "y1": 310.61744689941406, "x1": 72.44156731499565, "y2": 354.23897637261285}, "name": "6", "caption_text": "Figure 6: Example of measuring ent(r), versatility of the attentive listening response r. This example shows how to measure ent(hai), versatility of the response hai: (1) calculate Fhai(u), a co-occurrence frequency between hai and another response u (6= hai); (2) measure ent(hai) using Fhai(u).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 743.0, "y1": 96.0, "x1": 79.0, "y2": 290.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2448255750868, "y1": 616.2271287706163, "x1": 443.7889099121094, "y2": 624.5638953314887}, "name": "7", "caption_text": "Figure 7: Versatility of attentive listening responses", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 750.0, "y1": 387.0, "x1": 428.0, "y2": 590.0}, "page": 4, "dpi": 0}], "error": null, "pdf": "/work/host-output/33c2c50752d0ecd06854db9b2aff1e523f3f125c/2020.lrec-1.87.pdf", "dpi": 100}