{"raw_detected_boxes": [[], [], [{"x2": 722.0, "y1": 96.0, "x1": 105.0, "y2": 383.0}], [{"x2": 715.0, "y1": 86.0, "x1": 102.0, "y2": 142.0}, {"x2": 724.0, "y1": 792.0, "x1": 433.0, "y2": 916.0}], [{"x2": 718.0, "y1": 98.0, "x1": 436.0, "y2": 271.0}], [{"x2": 391.0, "y1": 129.0, "x1": 110.0, "y2": 260.0}, {"x2": 721.0, "y1": 96.0, "x1": 436.0, "y2": 289.0}], [{"x2": 721.0, "y1": 96.0, "x1": 436.0, "y2": 348.0}, {"x2": 392.0, "y1": 535.0, "x1": 111.0, "y2": 728.0}], [], [], [], [{"x2": 649.0, "y1": 208.0, "x1": 103.0, "y2": 463.0}, {"x2": 389.0, "y1": 622.0, "x1": 110.0, "y2": 876.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.2002563476562, "y1": 227.52651977539062, "x1": 306.96697998046875, "y2": 269.39404296875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 215.8900146484375}, "caption": "Figure 3: Attention density ratio R(p) for NMT and TTS tasks under different p with and without knowledge distillation, where \u201cKD\u201d means knowledge distillation.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 290.2703857421875, "y1": 199.15457153320312, "x1": 71.69100189208984, "y2": 217.112060546875}, "imageText": ["FastSpeech", "3.79", "\u00b1", "0.12", "FastSpeech", "w/o", "KD", "3.58", "\u00b1", "0.13", "TTS", "(MOS)", "Transformer", "TTS", "3.82", "\u00b1", "0.08", "NAT", "27.12", "NAT", "w/o", "KD", "21.79", "NMT", "(BLEU)", "Transformer", "33.90", "Task", "Model", "Accuracy"], "regionBoundary": {"x2": 283.0, "y1": 88.8900146484375, "x1": 79.0, "y2": 186.8900146484375}, "caption": "Table 3: The comparison between NAR models with and without knowledge distillation.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 259.04193115234375, "y1": 643.1975708007812, "x1": 102.91799926757812, "y2": 649.2000122070312}, "imageText": ["Name", "Hyperparameter", "Embedding", "Dimension", "512", "Encoder", "Layers", "6", "Encoder", "Hidden", "512", "Encoder", "Filter", "Size", "1024", "Encoder", "Heads", "4", "Decoder", "Layers", "6", "Decoder", "Hidden", "Size", "512", "Decoder", "Filter", "Size", "1024", "Decoder", "Heads", "4", "Dropout", "0.1", "Batch", "Size", "64", "Base", "Learning", "Rate", "1e-3"], "regionBoundary": {"x2": 283.0, "y1": 446.8900146484375, "x1": 79.0, "y2": 630.8900146484375}, "caption": "Table 6: Hyperparameters of CoMMA.", "page": 10}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 290.2705383300781, "y1": 345.6845397949219, "x1": 71.69100189208984, "y2": 363.6419982910156}, "imageText": ["Transformer", "Hyperparameter", "NMT", "/", "NAT", "ASR", "/", "NAR-ASR", "TTS", "/", "FastSpeech", "Embedding", "Dimension", "512", "512", "512", "Encoder", "Layers", "6", "6", "6", "Encoder", "Hidden", "512", "512", "512", "Encoder", "Filter", "Size", "1024", "1024", "1024", "Encoder", "Heads", "4", "4", "4", "Decoder", "Layers", "6", "6", "6", "Decoder", "Hidden", "Size", "512", "512", "512", "Decoder", "Filter", "Size", "1024", "1024", "1024", "Decoder", "Heads", "4", "4", "4", "Dropout", "0.2", "0.1", "0.2", "Batch", "Size", "64", "32", "32", "Base", "Learning", "Rate", "1e-3", "1e-3", "1e-3"], "regionBoundary": {"x2": 478.0, "y1": 148.8900146484375, "x1": 72.0, "y2": 333.8900146484375}, "caption": "Table 5: Hyperparameters of transformer-based AR and NAR models.", "page": 10}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 290.2703857421875, "y1": 536.5235595703125, "x1": 71.69100189208984, "y2": 554.48095703125}, "imageText": ["FastSpeech", "3.79", "\u00b1", "0.12", "FastSpeech", "w/o", "AC", "1.97", "\u00b1", "0.16", "TTS", "(MOS)", "Transformer", "TTS", "3.82", "\u00b1", "0.08", "NAR-ASR", "33.1", "NAR-ASR", "w/o", "AC", "39.23", "ASR", "(WER)", "Transformer", "ASR", "20.1", "NAT", "27.12", "NAT", "w/o", "AC", "25.03", "NMT", "(BLEU)", "Transformer", "33.90", "Task", "Model", "Accuracy"], "regionBoundary": {"x2": 283.0, "y1": 385.8900146484375, "x1": 80.0, "y2": 523.8900146484375}, "caption": "Table 4: The comparison between NAR models with and without alignment constraint.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 527.1954345703125, "y1": 271.0665588378906, "x1": 307.2760009765625, "y2": 300.97906494140625}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 258.8900146484375}, "caption": "Figure 4: Attention density ratio R(p) for NMT, ASR and TTS tasks under different p with and without alignment constraint (AC).", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 493.825439453125, "y1": 296.6825256347656, "x1": 103.72001647949219, "y2": 302.68499755859375}, "imageText": ["(b)", "The", "input", "module", "of", "CoMMA.", "Positional", "Embedding", "CoMMA", "model", "E1", "E2", "E3", "E4", "E5", "E6", "E1", "E2", "E3", "E4", "E5", "E6", "Token", "Embedding", "Input", "Tokens", "Ex1", "Ex2", "Ex3", "Ex4", "Ex5", "Eeos", "Ey1", "Em", "Ey3", "Em", "Ey5", "Ey6", "Es", "Es", "Es", "Es", "Es", "Es", "Et", "Et", "Et", "Et", "Et", "Et", "Source/Target", "Embedding", "Encoder", "Pre-Net", "Decoder", "Pre-Net", "Y2", "Y4", "Mixed", "Attention", "Source", "Token", "Target", "Token", "Softmax", "X1", "X2", "X3", "X4", "X5", "EOS", "Y1", "M", "Y3", "M", "Y5", "Y6", "Self-Attention", "Linear", "Add", "&", "Norm", "Feed", "Forward", "N", "\u00d7", "Add", "&", "Norm", "CoMMA", "model", "(a)", "The", "main", "structure", "of", "CoMMA.", "Positional", "Embedding", "CoMMA", "model", "E1", "E2", "E3", "E4", "E5", "E6", "E1", "E2", "E3", "E4", "E5", "E6", "Token", "Embedding", "Input", "Tokens", "Ex1", "Ex2", "Ex3", "Ex4", "Ex5", "Eeos", "Ey1", "Em", "Ey3", "Em", "Ey5", "Ey6", "Es", "Es", "Es", "Es", "Es", "Es", "Et", "Et", "Et", "Et", "Et", "Et", "Source/Target", "Embedding", "Encoder", "Pre-Net", "Decoder", "Pre-Net", "Y2", "Y4", "Mixed", "Attention", "Source", "Token", "Target", "Token", "Softmax", "X1", "X2", "X3", "X4", "X5", "EOS", "Y1", "M", "Y3", "M", "Y5", "Y6", "Self-Attention", "Linear", "Add", "&", "Norm", "Feed", "Forward", "N", "\u00d7", "Add", "&", "Norm", "CoMMA", "model"], "regionBoundary": {"x2": 522.0, "y1": 67.01614379882812, "x1": 71.8104248046875, "y2": 280.3690185546875}, "caption": "Figure 1: The architecture of conditional masked prediction model with mix-attention (CoMMA).", "page": 2}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5472412109375, "y1": 126.6795425415039, "x1": 71.69100189208984, "y2": 144.63702392578125}, "imageText": ["AR", "Transformer", "(Vaswani", "et", "al.,", "2017)", "Transformer", "ASR", "(Karita", "et", "al.,", "2019)", "Transformer", "TTS", "(Li", "et", "al.,", "2019a)", "NAR", "NAT", "(Gu", "et", "al.,", "2017)", "w/", "AC", "NAR-ASR", "(Chen", "et", "al.,", "2019)", "w/", "AC", "FastSpeech", "(Ren", "et", "al.,", "2019)", "Task", "NMT", "ASR", "TTS"], "regionBoundary": {"x2": 526.0, "y1": 65.8900146484375, "x1": 72.0, "y2": 104.8900146484375}, "caption": "Table 1: The AR and NAR model we consider in each task. \u201cAC\u201d means attention constraint we mentioned in Section 5.", "page": 3}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.2001953125, "y1": 671.7625732421875, "x1": 306.9670104980469, "y2": 689.7200317382812}, "imageText": ["TTS", "(MOS)", "Transformer", "TTS", "3.82", "\u00b1", "0.08FastSpeech", "3.79", "\u00b1", "0.12", "ASR", "(BLEU/WER)", "Transformer", "ASR", "66.60/20.10NAR-ASR", "39.23/36.20", "NMT", "(BLEU/WER)", "Transformer", "33.90/47.18NAT", "27.12/54.90", "Task", "Model", "Accuracy"], "regionBoundary": {"x2": 526.0, "y1": 566.8900146484375, "x1": 307.0, "y2": 659.8900146484375}, "caption": "Table 2: The accuracy gap between NAR and AR models.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5404663085938, "y1": 214.22256469726562, "x1": 307.2760009765625, "y2": 232.1800537109375}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 202.8900146484375}, "caption": "Figure 2: Attention density ratio R(p) under different p in different tasks for performance gap analysis.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 685.868665907118, "y1": 412.0590633816189, "x1": 144.05557844373914, "y2": 420.39582994249133}, "name": "1", "caption_text": "Figure 1: The architecture of conditional masked prediction model with mix-attention (CoMMA).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 92.0, "x1": 105.0, "y2": 392.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 175.9438090854221, "x1": 99.57083596123589, "y2": 200.88475545247394}, "name": "1", "caption_text": "Table 1: The AR and NAR model we consider in each task. \u201cAC\u201d means attention constraint we mentioned in Section 5.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 86.0, "x1": 100.0, "y2": 146.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2224934895833, "y1": 933.0035739474826, "x1": 426.3430701361762, "y2": 957.9444885253906}, "name": "2", "caption_text": "Table 2: The accuracy gap between NAR and AR models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 786.0, "x1": 426.0, "y2": 933.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9173143174913, "y1": 297.53133985731336, "x1": 426.772223578559, "y2": 322.4722968207465}, "name": "2", "caption_text": "Figure 2: Attention density ratio R(p) under different p in different tasks for performance gap analysis.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 96.0, "x1": 436.0, "y2": 272.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.153313530816, "y1": 276.6035715738932, "x1": 99.57083596123589, "y2": 301.54452853732636}, "name": "3", "caption_text": "Table 3: The comparison between NAR models with and without knowledge distillation.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 123.0, "x1": 100.0, "y2": 277.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 316.0090552435981, "x1": 426.343027750651, "y2": 374.15839301215277}, "name": "3", "caption_text": "Figure 3: Attention density ratio R(p) for NMT and TTS tasks under different p with and without knowledge distillation, where \u201cKD\u201d means knowledge distillation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 96.0, "x1": 436.0, "y2": 289.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2158813476562, "y1": 376.48133171929254, "x1": 426.772223578559, "y2": 418.02647908528644}, "name": "4", "caption_text": "Figure 4: Attention density ratio R(p) for NMT, ASR and TTS tasks under different p with and without alignment constraint (AC).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 96.0, "x1": 436.0, "y2": 350.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.153313530816, "y1": 745.1716105143229, "x1": 99.57083596123589, "y2": 770.1124403211805}, "name": "4", "caption_text": "Table 4: The comparison between NAR models with and without alignment constraint.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 518.0, "x1": 100.0, "y2": 745.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15352545844183, "y1": 480.11741638183594, "x1": 99.57083596123589, "y2": 505.0583309597439}, "name": "5", "caption_text": "Table 5: Hyperparameters of transformer-based AR and NAR models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 663.0, "y1": 191.0, "x1": 100.0, "y2": 480.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 359.78045993381073, "y1": 893.3299594455294, "x1": 142.94166564941406, "y2": 901.6666836208767}, "name": "6", "caption_text": "Table 6: Hyperparameters of CoMMA.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 393.0, "y1": 620.0, "x1": 110.0, "y2": 893.0}, "page": 10, "dpi": 0}], "error": null, "pdf": "/work/host-output/18451b65576668a15975c4d8a93f82921e5e46df/2020.acl-main.15.pdf", "dpi": 100}