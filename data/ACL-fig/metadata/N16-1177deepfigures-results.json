{"raw_detected_boxes": [[], [], [], [{"x2": 738.0, "y1": 256.0, "x1": 449.0, "y2": 476.0}], [{"x2": 407.0, "y1": 510.0, "x1": 106.0, "y2": 755.0}], [{"x2": 719.0, "y1": 88.0, "x1": 131.0, "y2": 483.0}], [{"x2": 740.0, "y1": 398.0, "x1": 457.0, "y2": 585.0}], [{"x2": 713.0, "y1": 95.0, "x1": 139.0, "y2": 394.0}, {"x2": 680.0, "y1": 488.0, "x1": 150.0, "y2": 705.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 540.0057373046875, "y1": 355.87628173828125, "x1": 72.00093841552734, "y2": 687.6300659179688}, "imageText": ["Method", "MR", "SST-2", "SST-5", "TREC", "SUBJ", "IMDB", "SVM", "(Socher", "et", "al.,", "2013)", "\u2014", "79.4", "40.7", "\u2014", "\u2014", "\u2014", "NB", "(Socher", "et", "al.,", "2013)", "\u2014", "81.8", "41.0", "\u2014", "\u2014", "\u2014", "NBSVM-bi", "(Wang", "and", "Manning,", "2012)", "79.4", "\u2014", "\u2014", "\u2014", "93.2", "91.2", "SVMS", "(Silva", "et", "al.,", "2011)", "\u2014", "\u2014", "\u2014", "95.0", "\u2014", "\u2014", "Standard-RNN", "(Socher", "et", "al.,", "2013)", "\u2014", "82.4", "43.2", "\u2014", "\u2014", "\u2014", "MV-RNN", "(Socher", "et", "al.,", "2012)", "79.0", "82.9", "44.4", "\u2014", "\u2014", "\u2014", "RNTN", "(Socher", "et", "al.,", "2013)", "\u2014", "85.4", "45.7", "\u2014", "\u2014", "\u2014", "DRNN", "(Irsoy", "and", "Cardie,", "2014)", "\u2014", "86.6", "49.8", "\u2014", "\u2014", "\u2014", "Standard-LSTM", "(Tai", "et", "al.,", "2015)", "\u2014", "86.7", "45.8", "\u2014", "\u2014", "\u2014", "bi-LSTM", "(Tai", "et", "al.,", "2015)", "\u2014", "86.8", "49.1", "\u2014", "\u2014", "\u2014", "Tree-LSTM", "(Tai", "et", "al.,", "2015)", "\u2014", "88.0", "51.0", "\u2014", "\u2014", "\u2014", "SA-LSTM", "(Dai", "and", "Le,", "2015)", "80.7", "\u2014", "\u2014", "\u2014", "\u2014", "92.8", "DCNN", "(Kalchbrenner", "et", "al.,", "2014)", "\u2014", "86.8", "48.5", "93.0", "\u2014", "\u2014", "CNN-MC", "(Kim,", "2014)", "81.1", "88.1", "47.4", "92.2", "93.2", "\u2014", "MVCNN", "(Yin", "and", "Schu\u0308tze,", "2015)", "\u2014", "89.4", "49.6", "\u2014", "93.9", "\u2014", "Dep-CNN", "(Ma", "et", "al.,", "2015)", "81.9", "\u2014", "49.5", "95.4", "\u2014", "\u2014", "Neural-BoW", "(Kalchbrenner", "et", "al.,", "2014)", "\u2014", "80.5", "42.4", "88.2", "\u2014", "\u2014", "DAN", "(Iyyer", "et", "al.,", "2015)", "80.3", "86.3", "47.7", "\u2014", "\u2014", "89.4", "Paragraph-Vector", "(Le", "and", "Mikolov,", "2014)", "\u2014", "87.8", "48.7", "\u2014", "\u2014", "92.6", "WRRBM+BoW(bnc)", "(Dahl", "et", "al.,", "2012)", "\u2014", "\u2014", "\u2014", "\u2014", "\u2014", "89.2", "Full+Unlabeled+BoW(bnc)", "(Maas", "et", "al.,", "2011)", "\u2014", "\u2014", "\u2014", "\u2014", "88.2", "88.9", "DSCNN", "81.5", "89.1", "49.7", "95.4", "93.2", "90.2", "DSCNN-Pretrain", "82.2", "88.7", "50.6", "95.6", "93.9", "90.7"], "regionBoundary": {"x2": 520.0, "y1": 60.0, "x1": 92.0, "y2": 350.0}, "caption": "Table 1: Experiment results of DSCNN compared with other models. Performance is measured in accuracy (%). Models are categorized into five classes. The first block is baseline methods including SVM and Naive Bayes and their variations. The second is the class of Recursive Neural Networks models. Constituent parsers and phrase-level supervision are needed. The third category is LSTMs. CNN models are fourth block, and the last category is a collection of other models achieving state-of-the-art results. SVM: Support Vector Machines with unigram features (Socher et al., 2013) NB: Naive Bayes with unigram features(Socher et al., 2013) NBSVM-bi: Naive Bayes SVM and Multinomial Naive Bayes with bigrams (Wang and Manning, 2012) SVMS : SVM with features including uni-bi-trigrams, POS, parser, and 60 hand-coded rules (Silva et al., 2011) Standard-RNN: Standard Recursive Neural Network (Socher et al., 2013) MV-RNN: Matrix-Vector Recursive Neural Network (Socher et al., 2012) RNTN:Recursive Neural Tensor Network (Socher et al., 2013) DRNN: Deep Recursive Neural Network (Irsoy and Cardie, 2014) Standard-LSTM: Standard Long Short-Term Memory Network (Tai et al., 2015) bi-LSTM: Bidirectional LSTM (Tai et al., 2015) Tree-LSTM: Tree-Structured LSTM (Tai et al., 2015) SA-LSTM: Sequence Autoencoder LSTM (Dai and Le, 2015). For fair comparison, we report the result on MR trained without unlabeled data from IMDB or Amazon reviews. DCNN: Dynamic Convolutional Neural Network with k-max pooling (Kalchbrenner et al., 2014) CNN-MC: Convolutional Neural Network with static pretrained and fine-tuned pretrained word-embeddings (Kim, 2014) MVCNN: Multichannel Variable-Size Convolution Neural Network (Yin and Schu\u0308tze, 2015) Dep-CNN: Dependency-based Convolutional Neural Network (Ma et al., 2015). Dependency parser is required. The result is for the combined model ancestor+sibling+sequential. Neural-BoW : Neural Bag-of-Words Models (Kalchbrenner et al., 2014) DAN: Deep Averaging Network (Iyyer et al., 2015) Paragraph-Vector: Logistic Regression on Paragraph-Vector (Le and Mikolov, 2014) WRRBM+BoW(bnc): word representation Restricted Boltzmann Machine combined with bag-of-words features (Dahl et al., 2012) Full+Unlabeled+BoW(bnc):word vector based model capturing both semantic and sentiment, trained on unlabeled examples, and with bag-of-words features concatenated (Maas et al., 2011)", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 540.0010986328125, "y1": 434.39227294921875, "x1": 313.2010192871094, "y2": 508.7110290527344}, "imageText": [], "regionBoundary": {"x2": 548.0, "y1": 271.0, "x1": 313.0, "y2": 429.0}, "caption": "Figure 3: Number of sentences in TREC, and classification performances of DSCNN-Pretrain/DepCNN/CNN-MC as functions of dependency lengths. DSCNN and Dep-CNN clearly outperforms CNNMC when the dependency length in the sentence grows.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 540.0035400390625, "y1": 292.8442687988281, "x1": 72.0009765625, "y2": 326.5150146484375}, "imageText": ["(d)", "entity\u2192", "human", "(c)", "entity\u2192", "location", "(a)", "description\u2192", "entity", "(b)", "numeric\u2192", "location"], "regionBoundary": {"x2": 517.0, "y1": 60.0, "x1": 95.0, "y2": 283.35699462890625}, "caption": "Figure 4: TREC examples that are misclassified by CNN-MC but correctly classified by DSCNN. For example, CNN-MC labels (a) as entity while the ground truth is description. Dependency Parsing is done by ClearNLP (Choi and Palmer, 2012).", "page": 7}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 540.0018310546875, "y1": 516.72119140625, "x1": 72.00102233886719, "y2": 536.843994140625}, "imageText": ["(c)", "location\u2192", "entity", "(a)", "numeric\u2192", "description", "(b)", "abbreviation\u2192", "description"], "regionBoundary": {"x2": 494.0, "y1": 342.0, "x1": 100.0, "y2": 507.2349853515625}, "caption": "Figure 5: TREC examples that are misclassified by DSCNN. For example, DSCNN labels (a) as description while the ground truth is numeric. Dependency Parsing is done by ClearNLP (Choi and Palmer, 2012).", "page": 7}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 540.0010986328125, "y1": 358.6242980957031, "x1": 313.2010192871094, "y2": 460.04107666015625}, "imageText": [], "regionBoundary": {"x2": 548.0, "y1": 178.0, "x1": 313.0, "y2": 353.0}, "caption": "Figure 1: An example for sentence modeling. The bottom LSTM layer processes the input sentence and feed-forwards hidden state vectors at each time step. The one-dimensional wide convolution layer and the max-over-time pooling operation extract features from the LSTM output. For brevity, only one version of word embedding is illustrated in this figure.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 298.80120849609375, "y1": 552.5382080078125, "x1": 72.0009994506836, "y2": 653.9549560546875}, "imageText": [], "regionBoundary": {"x2": 306.0, "y1": 363.0, "x1": 72.0, "y2": 547.0}, "caption": "Figure 2: A schematic for document modeling hierarchy, which can be viewed as a variant of the one for sentence modeling. Independent LSTM networks process subsentences separated by punctuation. Hidden states of LSTM networks are averaged as the sentence representations, from which the high-level LSTM layer creates the joint meaning of sentences.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 750.0015258789062, "y1": 498.0893029106988, "x1": 435.0014156765408, "y2": 638.9459398057726}, "name": "1", "caption_text": "Figure 1: An example for sentence modeling. The bottom LSTM layer processes the input sentence and feed-forwards hidden state vectors at each time step. The one-dimensional wide convolution layer and the max-over-time pooling operation extract features from the LSTM output. For brevity, only one version of word embedding is illustrated in this figure.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 738.0, "y1": 255.0, "x1": 444.0, "y2": 480.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.0016784667969, "y1": 767.4141777886284, "x1": 100.00138812594943, "y2": 908.270772298177}, "name": "2", "caption_text": "Figure 2: A schematic for document modeling hierarchy, which can be viewed as a variant of the one for sentence modeling. Independent LSTM networks process subsentences separated by punctuation. Hidden states of LSTM networks are averaged as the sentence representations, from which the high-level LSTM layer creates the joint meaning of sentences.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 411.0, "y1": 510.0, "x1": 100.0, "y2": 772.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0079684787327, "y1": 494.2726135253906, "x1": 100.00130335489908, "y2": 955.041758219401}, "name": "1", "caption_text": "Table 1: Experiment results of DSCNN compared with other models. Performance is measured in accuracy (%). Models are categorized into five classes. The first block is baseline methods including SVM and Naive Bayes and their variations. The second is the class of Recursive Neural Networks models. Constituent parsers and phrase-level supervision are needed. The third category is LSTMs. CNN models are fourth block, and the last category is a collection of other models achieving state-of-the-art results. SVM: Support Vector Machines with unigram features (Socher et al., 2013) NB: Naive Bayes with unigram features(Socher et al., 2013) NBSVM-bi: Naive Bayes SVM and Multinomial Naive Bayes with bigrams (Wang and Manning, 2012) SVMS : SVM with features including uni-bi-trigrams, POS, parser, and 60 hand-coded rules (Silva et al., 2011) Standard-RNN: Standard Recursive Neural Network (Socher et al., 2013) MV-RNN: Matrix-Vector Recursive Neural Network (Socher et al., 2012) RNTN:Recursive Neural Tensor Network (Socher et al., 2013) DRNN: Deep Recursive Neural Network (Irsoy and Cardie, 2014) Standard-LSTM: Standard Long Short-Term Memory Network (Tai et al., 2015) bi-LSTM: Bidirectional LSTM (Tai et al., 2015) Tree-LSTM: Tree-Structured LSTM (Tai et al., 2015) SA-LSTM: Sequence Autoencoder LSTM (Dai and Le, 2015). For fair comparison, we report the result on MR trained without unlabeled data from IMDB or Amazon reviews. DCNN: Dynamic Convolutional Neural Network with k-max pooling (Kalchbrenner et al., 2014) CNN-MC: Convolutional Neural Network with static pretrained and fine-tuned pretrained word-embeddings (Kim, 2014) MVCNN: Multichannel Variable-Size Convolution Neural Network (Yin and Schu\u0308tze, 2015) Dep-CNN: Dependency-based Convolutional Neural Network (Ma et al., 2015). Dependency parser is required. The result is for the combined model ancestor+sibling+sequential. Neural-BoW : Neural Bag-of-Words Models (Kalchbrenner et al., 2014) DAN: Deep Averaging Network (Iyyer et al., 2015) Paragraph-Vector: Logistic Regression on Paragraph-Vector (Le and Mikolov, 2014) WRRBM+BoW(bnc): word representation Restricted Boltzmann Machine combined with bag-of-words features (Dahl et al., 2012) Full+Unlabeled+BoW(bnc):word vector based model capturing both semantic and sentiment, trained on unlabeled examples, and with bag-of-words features concatenated (Maas et al., 2011)", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 735.0, "y1": 84.0, "x1": 115.0, "y2": 500.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0015258789062, "y1": 603.3226013183594, "x1": 435.0014156765408, "y2": 706.5430959065754}, "name": "3", "caption_text": "Figure 3: Number of sentences in TREC, and classification performances of DSCNN-Pretrain/DepCNN/CNN-MC as functions of dependency lengths. DSCNN and Dep-CNN clearly outperforms CNNMC when the dependency length in the sentence grows.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 744.0, "y1": 397.0, "x1": 444.0, "y2": 602.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0049167209202, "y1": 406.7281511094835, "x1": 100.00135633680556, "y2": 453.4930759006076}, "name": "4", "caption_text": "Figure 4: TREC examples that are misclassified by CNN-MC but correctly classified by DSCNN. For example, CNN-MC labels (a) as entity while the ground truth is description. Dependency Parsing is done by ClearNLP (Choi and Palmer, 2012).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 91.0, "x1": 122.0, "y2": 411.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0025431315104, "y1": 717.6683213975695, "x1": 100.00141991509331, "y2": 745.6166585286458}, "name": "5", "caption_text": "Figure 5: TREC examples that are misclassified by DSCNN. For example, DSCNN labels (a) as description while the ground truth is numeric. Dependency Parsing is done by ClearNLP (Choi and Palmer, 2012).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 696.0, "y1": 482.0, "x1": 133.0, "y2": 722.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/ec64f650fea9b49cbf7d8bddf458388c4b362475/N16-1177.pdf", "dpi": 100}