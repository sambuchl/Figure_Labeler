{"raw_detected_boxes": [[{"x2": 705.0, "y1": 332.0, "x1": 433.0, "y2": 505.0}], [{"x2": 720.0, "y1": 94.0, "x1": 107.0, "y2": 318.0}], [], [], [{"x2": 722.0, "y1": 93.0, "x1": 432.0, "y2": 181.0}, {"x2": 396.0, "y1": 95.0, "x1": 103.0, "y2": 319.0}, {"x2": 399.0, "y1": 432.0, "x1": 102.0, "y2": 580.0}], [{"x2": 384.0, "y1": 98.0, "x1": 106.0, "y2": 306.0}, {"x2": 712.0, "y1": 98.0, "x1": 433.0, "y2": 306.0}], [{"x2": 386.0, "y1": 99.0, "x1": 102.0, "y2": 309.0}, {"x2": 387.0, "y1": 376.0, "x1": 113.0, "y2": 488.0}], [{"x2": 697.0, "y1": 97.0, "x1": 119.0, "y2": 250.0}, {"x2": 402.0, "y1": 333.0, "x1": 101.0, "y2": 507.0}], [], [], [{"x2": 712.0, "y1": 145.0, "x1": 435.0, "y2": 341.0}, {"x2": 715.0, "y1": 484.0, "x1": 443.0, "y2": 540.0}, {"x2": 708.0, "y1": 905.0, "x1": 450.0, "y2": 952.0}, {"x2": 716.0, "y1": 700.0, "x1": 438.0, "y2": 745.0}], [{"x2": 396.0, "y1": 93.0, "x1": 103.0, "y2": 176.0}]], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Table", "boundary": {"x2": 483.6041564941406, "y1": 257.48309326171875, "x1": 348.5498046875, "y2": 263.48297119140625}, "text": "Table 5: Statistics of benchmarks.", "name": "5", "page": 10}, {"figType": "Table", "boundary": {"x2": 526.9736938476562, "y1": 400.99462890625, "x1": 306.8356018066406, "y2": 418.9444580078125}, "text": "Table 6: The distribution of nodes in terms of local difficulty.", "name": "6", "page": 10}], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 526.9739379882812, "y1": 378.6212158203125, "x1": 307.1445007324219, "y2": 456.32684326171875}, "imageText": [], "regionBoundary": {"x2": 468.0, "y1": 239.0, "x1": 320.0, "y2": 355.0}, "caption": "Figure 1: Illustration of the challenges of learning sentiment semantic compositionality. The blue nodes represent token nodes. The colors of phrase nodes in the binary constituency tree represent the sentiment of phrases. The red boxes show that the sentiment changes from the child node to the parent node due to negation and contrast.", "page": 0}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 526.9739379882812, "y1": 233.95623779296875, "x1": 307.1445007324219, "y2": 275.80694580078125}, "imageText": [], "regionBoundary": {"x2": 513.0, "y1": 71.0, "x1": 311.0, "y2": 221.0}, "caption": "Figure 4: Evaluation for global difficulty. The figure shows the accuracy difference on phrase node sentiment prediction with BERT w/ Mean pooling for different global difficulty.", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 291.79864501953125, "y1": 233.95623779296875, "x1": 71.96920013427734, "y2": 275.80694580078125}, "imageText": [], "regionBoundary": {"x2": 278.0, "y1": 71.0, "x1": 76.0, "y2": 221.0}, "caption": "Figure 3: Evaluation for local difficulty. The figure shows the accuracy difference on phrase node sentiment prediction with BERT w/ Mean pooling for different local difficulty.", "page": 5}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.3207397460938, "y1": 548.6083984375, "x1": 306.8356018066406, "y2": 566.5592651367188}, "imageText": ["Number", "930", "861", "326", "59", "8"], "regionBoundary": {"x2": 520.0, "y1": 520.0, "x1": 312.0, "y2": 536.0}, "caption": "Table 7: The distribution of nodes in terms of global difficulty.", "page": 10}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 525.3377685546875, "y1": 704.0699462890625, "x1": 306.7857971191406, "y2": 722.019775390625}, "imageText": ["Number", "1825", "325", "34", "#", "of", "Negation", "Words", "0", "1", "2-"], "regionBoundary": {"x2": 513.0, "y1": 652.0, "x1": 320.0, "y2": 692.0}, "caption": "Table 8: The distribution of nodes in terms of negation words.", "page": 10}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.3206787109375, "y1": 243.44610595703125, "x1": 71.96917724609375, "y2": 297.24676513671875}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 66.0, "x1": 77.0, "y2": 230.0}, "caption": "Figure 2: The architecture of SentiBERT. Module I is the BERT encoder; Module II denotes the semantic composition module based on an attention mechanism; Module III is a predictor for phrase-level sentiment. The semantic composition module is a two layer attention-based network (see Section 3.1) The first layer (Attention to Tokens) generates representation for each phrase based on the token it covers and the second layer (Attention to Children) refines the phrase representation obtained from the first layer based on its children.", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.88800048828125, "y1": 369.0364074707031, "x1": 71.61051177978516, "y2": 398.9361877441406}, "imageText": ["SentiBERT", "30.7", "BERT", "w/", "Tree-LSTM", "28.5", "BERT", "w/", "GCN", "29.4", "SentiBERT", "w/o", "Attention", "to", "Children", "29.8", "BERT", "w/", "Mean", "pooling", "26.1", "Models", "Accuracy"], "regionBoundary": {"x2": 281.0, "y1": 271.0, "x1": 81.0, "y2": 357.0}, "caption": "Table 4: Evaluation for contrastive relation (%). We show the accuracy for triple-lets (\u2018X but Y\u2019, \u2018X\u2019, \u2018Y\u2019). X and Y must be phrases in our experiments.", "page": 6}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.8175964355469, "y1": 236.43115234375, "x1": 71.96920013427734, "y2": 254.3809814453125}, "imageText": [], "regionBoundary": {"x2": 278.0, "y1": 71.0, "x1": 73.0, "y2": 223.0}, "caption": "Figure 5: Evaluation for negation. We show the accuracy difference with BERT w/ Mean pooling.", "page": 6}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 525.4859619140625, "y1": 193.50152587890625, "x1": 71.96920013427734, "y2": 211.45135498046875}, "imageText": ["(a)", "SST-5", "(b)", "SST-3", "(c)", "Twitter", "Sentiment", "Analysis"], "regionBoundary": {"x2": 502.0, "y1": 69.0, "x1": 86.0, "y2": 182.75848388671875}, "caption": "Figure 6: The results of SentiBERT trained with part of the phrase-level labels on SST-5, SST-3 and Twitter Sentiment Analysis. We show the averaged results of 5 runs.", "page": 7}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 291.79864501953125, "y1": 378.1344299316406, "x1": 71.96920013427734, "y2": 419.9841613769531}, "imageText": [], "regionBoundary": {"x2": 284.0, "y1": 237.0, "x1": 77.0, "y2": 360.0}, "caption": "Figure 7: Cases for interpretability of compositional sentiment semantics. The three color blocks between parents and children are the attention weights distributed to left child, the phrase itself and right child.", "page": 7}, {"figType": "Table", "name": "9", "captionBoundary": {"x2": 291.7984924316406, "y1": 139.2767333984375, "x1": 71.6603012084961, "y2": 157.2265625}, "imageText": ["SentiBERT", "68.31", "56.10", "SentiBERT", "w/", "RoBERTa", "68.98", "56.87", "SentiBERT", "w/", "token", "68.23", "56.02", "SentiBERT", "w/", "token", "and", "RoBERTa", "68.78", "56.91", "Models", "SST-phrase", "SST-5"], "regionBoundary": {"x2": 286.0, "y1": 63.0, "x1": 74.0, "y2": 127.0}, "caption": "Table 9: The results after incorporating token node prediction. \u2018Token\u2019 denotes token node prediction.", "page": 11}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 291.7984924316406, "y1": 242.32763671875, "x1": 71.6603012084961, "y2": 296.1273193359375}, "imageText": ["SentiBERT", "w/o", "BERT", "61.04", "50.31", "SentiBERT", "68.31", "56.10", "SentiBERT", "w/", "RoBERTa", "68.98", "56.87", "BERT", "w/", "Mean", "pooling", "64.53", "50.68", "BERT", "w/", "GCN", "65.23", "54.56", "BERT", "w/", "Tree-LSTM", "67.39", "55.89", "RoBERTa", "w/", "Mean", "pooling", "67.73", "56.34", "Recursive", "NN", "58.33", "46.53", "GCN", "60.89", "49.34", "Tree-LSTM", "61.71", "50.07", "BiLSTM", "w/", "Tree-LSTM", "61.89", "50.45", "Models", "SST-phrase", "SST-5"], "regionBoundary": {"x2": 289.0, "y1": 63.0, "x1": 74.0, "y2": 230.0}, "caption": "Table 1: The averaged accuracies on SST-phrase and SST-5 tasks (%) for 5 runs. For baselines vanilla BERT and RoBERTa, we use mean-pooling on token representation of top layer to get phrase and sentence representation.", "page": 4}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 291.79840087890625, "y1": 434.5013122558594, "x1": 71.6603012084961, "y2": 476.3510437011719}, "imageText": ["SentiBERT", "w/o", "BERT", "86.57", "68.32", "64.9", "SentiBERT", "w/o", "Masking", "92.48", "76.95", "70.7", "SentiBERT", "w/o", "Pre-training", "92.44", "76.78", "70.8", "SentiBERT", "92.78", "77.11", "70.9", "SentiBERT", "w/", "RoBERTa", "94.72", "78.69", "71.5", "BERT", "92.39", "73.78", "70.0", "BERT", "w/", "Mean", "pooling", "92.33", "74.35", "69.7", "XLNet", "93.23", "75.89", "70.7", "RoBERTa", "94.31", "78.04", "71.1", "Models", "SST-2", "(Dev)", "SST-3", "Twitter"], "regionBoundary": {"x2": 289.0, "y1": 312.0, "x1": 73.0, "y2": 422.0}, "caption": "Table 2: The averaged results on sentence-level sentiment classification (%) for 5 runs. For SST-2,3, the metric is accuracy; for Twitter Sentiment Analysis, we use averaged recall value.", "page": 4}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 527.0634155273438, "y1": 142.5113525390625, "x1": 306.78582763671875, "y2": 208.260986328125}, "imageText": ["SentiBERT", "w/o", "Pre-training", "66.0", "73.81", "SentiBERT", "66.5", "74.23", "SentiBERT", "w/", "RoBERTa", "67.2", "74.67", "BERT", "65.2", "73.49", "RoBERTa", "66.4", "74.20", "Models", "Emotion", "Intensity", "EmoContext"], "regionBoundary": {"x2": 523.0, "y1": 63.0, "x1": 310.0, "y2": 130.0}, "caption": "Table 3: The averaged results on several emotion classification tasks (%) for 5 runs. For Emotion Intensity Classification task, the metric is averaged Pearson Correlation value of the four subtasks; for EmoContext, we follow the standard metrics used in Chatterjee et al. (2019) and use F1 score as the evaluation metric.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 731.9082472059462, "y1": 525.862799750434, "x1": 426.58958435058594, "y2": 633.7872823079426}, "name": "1", "caption_text": "Figure 1: Illustration of the challenges of learning sentiment semantic compositionality. The blue nodes represent token nodes. The colors of phrase nodes in the binary constituency tree represent the sentiment of phrases. The red boxes show that the sentiment changes from the child node to the parent node due to negation and contrast.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 705.0, "y1": 332.0, "x1": 433.0, "y2": 507.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.6120537651909, "y1": 338.11959160698785, "x1": 99.95719061957465, "y2": 412.84272935655383}, "name": "2", "caption_text": "Figure 2: The architecture of SentiBERT. Module I is the BERT encoder; Module II denotes the semantic composition module based on an attention mechanism; Module III is a predictor for phrase-level sentiment. The semantic composition module is a two layer attention-based network (see Section 3.1) The first layer (Attention to Tokens) generates representation for each phrase based on the token it covers and the second layer (Attention to Children) refines the phrase representation obtained from the first layer based on its children.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 92.0, "x1": 107.0, "y2": 318.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.0325215657551, "y1": 197.93243408203125, "x1": 426.09142727322046, "y2": 289.2513699001736}, "name": "3", "caption_text": "Table 3: The averaged results on several emotion classification tasks (%) for 5 runs. For Emotion Intensity Classification task, the metric is averaged Pearson Correlation value of the four subtasks; for EmoContext, we follow the standard metrics used in Chatterjee et al. (2019) and use F1 score as the evaluation metric.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 87.0, "x1": 426.0, "y2": 198.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.27568393283417, "y1": 336.566162109375, "x1": 99.52819612291124, "y2": 411.2879435221354}, "name": "1", "caption_text": "Table 1: The averaged accuracies on SST-phrase and SST-5 tasks (%) for 5 runs. For baselines vanilla BERT and RoBERTa, we use mean-pooling on token representation of top layer to get phrase and sentence representation.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 87.0, "x1": 100.0, "y2": 336.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.27555677625867, "y1": 603.4740447998047, "x1": 99.52819612291124, "y2": 661.5986718071831}, "name": "2", "caption_text": "Table 2: The averaged results on sentence-level sentiment classification (%) for 5 runs. For SST-2,3, the metric is accuracy; for Twitter Sentiment Analysis, we use averaged recall value.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 432.0, "x1": 102.0, "y2": 586.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.2758958604601, "y1": 324.939219156901, "x1": 99.95722240871854, "y2": 383.0652025010851}, "name": "3", "caption_text": "Figure 3: Evaluation for local difficulty. The figure shows the accuracy difference on phrase node sentiment prediction with BERT w/ Mean pooling for different local difficulty.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 386.0, "y1": 98.0, "x1": 106.0, "y2": 306.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 731.9082472059462, "y1": 324.939219156901, "x1": 426.58958435058594, "y2": 383.0652025010851}, "name": "4", "caption_text": "Figure 4: Evaluation for global difficulty. The figure shows the accuracy difference on phrase node sentiment prediction with BERT w/ Mean pooling for different global difficulty.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 98.0, "x1": 433.0, "y2": 306.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.3022172715929, "y1": 328.37660047743054, "x1": 99.95722240871854, "y2": 353.3069186740451}, "name": "5", "caption_text": "Figure 5: Evaluation for negation. We show the accuracy difference with BERT w/ Mean pooling.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 386.0, "y1": 99.0, "x1": 102.0, "y2": 309.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4000006781684, "y1": 512.5505659315321, "x1": 99.45904413859049, "y2": 554.0780385335286}, "name": "4", "caption_text": "Table 4: Evaluation for contrastive relation (%). We show the accuracy for triple-lets (\u2018X but Y\u2019, \u2018X\u2019, \u2018Y\u2019). X and Y must be phrases in our experiments.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 390.0, "y1": 376.0, "x1": 113.0, "y2": 495.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.8416137695312, "y1": 268.75211927625867, "x1": 99.95722240871854, "y2": 293.68243747287323}, "name": "6", "caption_text": "Figure 6: The results of SentiBERT trained with part of the phrase-level labels on SST-5, SST-3 and Twitter Sentiment Analysis. We show the averaged results of 5 runs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 697.0, "y1": 96.0, "x1": 119.0, "y2": 256.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.2758958604601, "y1": 525.1867082383898, "x1": 99.95722240871854, "y2": 583.3113352457682}, "name": "7", "caption_text": "Figure 7: Cases for interpretability of compositional sentiment semantics. The three color blocks between parents and children are the attention weights distributed to left child, the phrase itself and right child.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 329.0, "x1": 100.0, "y2": 524.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 671.6724395751953, "y1": 357.6154073079427, "x1": 484.0969509548611, "y2": 365.94857109917535}, "name": "5", "caption_text": "Table 5: Statistics of benchmarks.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 138.0, "x1": 435.0, "y2": 358.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 731.9079081217448, "y1": 556.9369845920139, "x1": 426.1605580647786, "y2": 581.8673027886284}, "name": "6", "caption_text": "Table 6: The distribution of nodes in terms of local difficulty.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 484.0, "x1": 426.0, "y2": 557.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.6357896592882, "y1": 977.8749254014757, "x1": 426.0913848876953, "y2": 1002.8052435980902}, "name": "8", "caption_text": "Table 8: The distribution of nodes in terms of negation words.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 905.0, "x1": 444.0, "y2": 961.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.6121385362413, "y1": 761.9561089409722, "x1": 426.1605580647786, "y2": 786.8878682454426}, "name": "7", "caption_text": "Table 7: The distribution of nodes in terms of global difficulty.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 700.0, "x1": 426.0, "y2": 762.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.27568393283417, "y1": 193.43990749782986, "x1": 99.52819612291124, "y2": 218.37022569444443}, "name": "9", "caption_text": "Table 9: The results after incorporating token node prediction. \u2018Token\u2019 denotes token node prediction.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 86.0, "x1": 100.0, "y2": 193.0}, "page": 11, "dpi": 0}], "error": null, "pdf": "/work/host-output/bcbb132efed39ba1e3174cbb473a1facf32eaf27/2020.acl-main.341.pdf", "dpi": 100}