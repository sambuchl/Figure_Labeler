{"raw_detected_boxes": [[], [], [{"x2": 704.0, "y1": 86.0, "x1": 442.0, "y2": 459.0}], [{"x2": 718.0, "y1": 100.0, "x1": 106.0, "y2": 496.0}], [], [], [{"x2": 684.0, "y1": 93.0, "x1": 145.0, "y2": 216.0}, {"x2": 400.0, "y1": 312.0, "x1": 110.0, "y2": 497.0}], [{"x2": 730.0, "y1": 87.0, "x1": 431.0, "y2": 239.0}, {"x2": 396.0, "y1": 92.0, "x1": 103.0, "y2": 195.0}], [{"x2": 722.0, "y1": 89.0, "x1": 105.0, "y2": 315.0}, {"x2": 387.0, "y1": 416.0, "x1": 115.0, "y2": 767.0}], [], [], [{"x2": 723.0, "y1": 196.0, "x1": 101.0, "y2": 879.0}]], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 525.5473022460938, "y1": 244.67453002929688, "x1": 72.0, "y2": 274.5870361328125}, "text": "Figure 3: Qualitative examples. Red/bold indicates pronoun errors (inappropriate use of pronouns), blue/italic indicates repetitive patterns, underline indicates content errors. Compared to baselines, our model generates more coherent, less repeated paragraphs while maintaining relevance.", "name": "3", "page": 8}], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2899169921875, "y1": 167.76657104492188, "x1": 71.69100189208984, "y2": 197.6790771484375}, "imageText": ["Human", "-", "-", "-", "-", "0.98", "-", "-", "-", "1.27", "VTransformer", "(2018)", "7", "9.31", "15.54", "21.33", "7.45", "7.62", "15.65", "32.26", "7.83", "Transformer-XL", "(2019)", "3", "10.25", "14.91", "21.71", "8.79", "6.56", "14.76", "26.35", "6.30", "Transformer-XLRG", "3", "10.07", "14.58", "20.34", "9.37", "6.63", "14.74", "25.93", "6.03", "MART", "3", "9.78", "15.57", "22.16", "5.44", "8.00", "15.9", "35.74", "4.39", "B@4", "M", "C", "R@4", "\u2193", "B@4", "M", "C", "R@4", "\u2193", "Model", "Re.", "ActivityNet", "Captions", "(ae-test)", "YouCookII", "(val)"], "regionBoundary": {"x2": 493.0, "y1": 62.8900146484375, "x1": 104.0, "y2": 155.8900146484375}, "caption": "Table 1: Comparison with transformer baselines on ActivityNet Captions ae-test split and YouCookII val split. Re. indicates whether sentence-level recurrence is used. We report BLEU@4 (B@4), METEOR (M), CIDEr-D (C) and Repetition (R@4). VTransformer denotes vanilla transformer.", "page": 6}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 291.9243469238281, "y1": 374.6915283203125, "x1": 71.64097595214844, "y2": 452.4259338378906}, "imageText": ["Human", "-", "-", "-", "-", "-", "0.98", "Transformer", "based", "methods", "VTransformer", "(2018)", "7", "7", "9.75", "15.64", "22.16", "7.79", "Transformer-XL", "(2019)", "7", "3", "10.39", "15.09", "21.67", "8.54", "Transformer-XLRG", "7", "3", "10.17", "14.77", "20.40", "8.85", "(Ours)", "MART", "7", "3", "10.33", "15.68", "23.42", "5.18", "LSTM", "based", "methods", "with", "detection", "feature", "GVD", "(2019)", "3", "7", "11.04", "15.71", "21.95", "8.76", "GVDsup", "(2019)", "3", "7", "11.30", "16.41", "22.94", "7.04", "AdvInf", "(2019)", "3", "3", "10.04", "16.60", "20.97", "5.76", "LSTM", "based", "methods", "MFT", "(2018)", "7", "3", "10.29", "14.73", "19.12", "17.71", "HSE", "(2018)", "7", "3", "9.84", "13.78", "18.78", "13.22", "Det.", "Re.", "B@4", "M", "C", "R@4", "\u2193"], "regionBoundary": {"x2": 289.0, "y1": 220.8900146484375, "x1": 74.0, "y2": 362.8900146484375}, "caption": "Table 2: Comparison with baselines on ActivityNet Captions ae-val split. Det. indicates whether the model uses detection feature. Models that use detection features are shown in gray background to indicate they are not in fair comparison with the others. Re. indicates whether sentence-level recurrence is used. VTransformer denotes vanilla transformer.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2003784179688, "y1": 345.9315490722656, "x1": 307.2760009765625, "y2": 375.843994140625}, "imageText": ["PE", "The", "girl", "dances", "around", "the", "room.", "Outputs", "(shifted", "right)Video", "Segment", "Softmax", "Linear", "x\u00a0N", "x\u00a0N", "Add", "&", "Norm", "Feed", "Forward", "Add", "&", "Norm", "Multi-Head", "Attention", "Add", "&", "Norm", "PE", "Word", "Enbedding", "Masked", "Multi-Head", "Attention", "CNN", "Add", "&", "Norm", "Feed", "Forward", "Add", "&", "Norm", "Multi-Head", "Attention"], "regionBoundary": {"x2": 506.9718017578125, "y1": 62.8900146484375, "x1": 318.0, "y2": 329.5240478515625}, "caption": "Figure 1: Vanilla transformer video captioning model (Zhou et al., 2018). PE denotes Positional Encoding, TE denotes token Type Embedding.", "page": 2}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.2006225585938, "y1": 188.44155883789062, "x1": 306.9169616699219, "y2": 242.26507568359375}, "imageText": ["MART", "2", "1", "3", "10.33", "15.68", "23.42", "5.18", "recurrence", "MART", "w/o", "re.", "2", "-", "7", "9.91", "15.83", "22.78", "7.56", "mem.", "len.", "MART", "2", "2", "3", "10.30", "15.66", "22.93", "5.94", "MART", "2", "5", "3", "10.12", "15.48", "22.89", "6.83", "#hidden", "layers", "MART", "1", "1", "3", "10.42", "16.01", "22.87", "6.70", "MART", "5", "1", "3", "10.48", "16.03", "24.33", "6.74", "#hidden", "layers", "mem.", "len.", "Re.", "B@4", "M", "C", "R@4", "\u2193"], "regionBoundary": {"x2": 526.0, "y1": 62.8900146484375, "x1": 309.0, "y2": 175.8900146484375}, "caption": "Table 4: Model ablation on ActivityNet Captions aeval split. Re. indicates whether sentence-level recurrence is used. mem. len. indicates the length of the memory state. MART w/o re. denotes a MART variant without recurrence. Top two scores are highlighted.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 292.01153564453125, "y1": 152.66555786132812, "x1": 71.69100189208984, "y2": 194.5330810546875}, "imageText": ["relevance", "40.0", "39.5", "+0.5", "coherence", "39.2", "36.2", "+3.0", "MART", "wins", "(%)", "Transformer-XL", "wins", "(%)", "Delta", "relevance", "37", "29.5", "+7.5", "coherence", "42.8", "26.3", "+16.5", "MART", "wins", "(%)", "VTransformer", "wins", "(%)", "Delta"], "regionBoundary": {"x2": 288.0, "y1": 62.8900146484375, "x1": 74.0, "y2": 140.8900146484375}, "caption": "Table 3: Human evaluation on ActivityNet Captions aetest set w.r.t. relevance and coherence. Top: MART vs. vanilla transformer (VTransformer). Bottom: MART vs. Transformer-XL.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2833251953125, "y1": 372.88153076171875, "x1": 71.69099426269531, "y2": 402.7939758300781}, "imageText": ["Element-wise", "Addition", "Positional", "Encoding", "token", "Type", "Embedding", "PE", "TE", "The", "girl", "dances", "around", "the", "room.", "TE", "Linear", "&", "Norm", "Linear", "&", "Norm", "Concat", "Video", "Segment", "CNN", "Outputs", "(shifted", "right)", "Word", "Enbedding", "The", "girl", "dances", "around", "the", "room.", "TE", "Linear", "&", "Norm", "Linear", "&", "Norm", "Concat", "Video", "Segment", "PE", "CNN", "Outputs", "(shifted", "right)", "Word", "Enbedding", "Transformer-XL", "(at", "step", ")", "Add", "&", "Norm", "Concat", "Masked", "Multi-Head", "Attention", "with", "Relative", "PE", "x\u00a0N", "Add", "&", "Norm", "Feed", "Forward", "Softmax", "Linear", "Add", "sigmoid", "Add", "tanh", "Linear", "Linear", "Linear", "Linear", "Multi-Head", "Attention", "Feed", "Forward", "Memory", "Updater", "Concat", "Multi-Head", "Attention", "Memory-Augmented", "Recurrent", "Transformer", "(at", "step", ")", "x", "N", "Add", "&", "Norm", "Feed", "Forward", "Add", "&", "Norm", "Masked", "Multi-Head", "Attention", "Softmax", "Linear"], "regionBoundary": {"x2": 522.8340454101562, "y1": 67.9560546875, "x1": 73.0, "y2": 355.8900146484375}, "caption": "Figure 2: Left: Our proposed Memory-Augmented Recurrent Transformer (MART) for video paragraph captioning. Right: Transformer-XL (Dai et al., 2019) model for video paragraph captioning. Relative PE denotes Relative Positional Encoding (Dai et al., 2019). SG(\u00b7) denotes stop-gradient, denotes Hadamard product.", "page": 3}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 527.2008056640625, "y1": 650.799560546875, "x1": 72.0, "y2": 680.7130126953125}, "imageText": ["Vanilla", "Transformer", "The", "man", "then", "holds", "up", "a", "bottle", "of", "mouthwash", "and", "talks", "to", "the", "camera.", "The", "man", "then", "puts", "lotion", "on", "her", "face", "and", "begins", "rubbing", "it", "down.", "The", "man", "then", "begins", "to", "blow", "dry", "her", "face", "and", "shows", "off", "the", "camera.", "Transformer-XL", "A", "man", "is", "seen", "speaking", "to", "the", "camera", "while", "holding", "up", "a", "brush.", "He", "then", "rubs", "lotion", "all", "over", "his", "face", "and", "begins", "brushing", "his", "face.", "He", "then", "puts", "the", "lotion", "on", "the", "face", "and", "rubs", "it", "on", "the", "wall.", "MART", "(ours)", "A", "man", "is", "seen", "speaking", "to", "the", "camera", "and", "leads", "into", "him", "holding", "up", "a", "bottle", "of", "water.", "The", "man", "then", "holds", "up", "a", "can", "and", "begins", "to", "shave", "his", "face.", "He", "finishes", "putting", "the", "paper", "into", "the", "mirror", "and", "smiles", "to", "the", "camera.", "Ground-Truth", "A", "girl's", "face", "is", "shown", "in", "front", "of", "the", "camera.", "She", "showed", "an", "orange", "bottle,", "read", "the", "label", "and", "squirt", "the", "orange", "content", "on", "her", "palm,", "showed", "the", "cream", "on", "the", "camera,", "then", "rub", "the", "cream", "all", "over", "her", "face.", "She", "bend", "down", "and", "rinse", "her", "face,", "when", "her", "face", "is", "visible", "on", "the", "camera", "her", "face", "is", "clear.", "MART", "(ours)", "A", "young", "child", "is", "seen", "climbing", "across", "a", "set", "of", "monkey", "bars", "while", "speaking", "to", "the", "camera.", "She", "then", "climbs", "down", "across", "the", "bars", "and", "begins", "swinging", "herself", "around.", "She", "continues", "to", "swing", "down", "and", "ends", "by", "jumping", "down.", "Ground-Truth", "A", "boy", "goes", "across", "the", "monkey", "bars", "as", "a", "lady", "watches", "and", "cheers", "him", "on.", "At", "the", "end", "he", "begins", "to", "struggle", "bit,", "but", "finally", "finished.", "When", "he", "is", "done", "another", "little", "boy", "comes", "and", "stands", "by", "him.", "Vanilla", "Transformer", "A", "young", "girl", "is", "seen", "climbing", "across", "a", "set", "of", "monkey", "bars.", "A", "young", "child", "is", "seen", "climbing", "across", "a", "set", "of", "monkey", "bars.", "A", "little", "girl", "is", "standing", "on", "a", "platform", "in", "a", "playground.", "Transformer-XL", "A", "young", "child", "is", "seen", "standing", "before", "a", "set", "of", "monkey", "bars", "and", "begins", "climbing", "across", "monkey", "bars.", "The", "girl", "then", "climbs", "back", "and", "fourth", "on", "the", "bars.", "Ground-Truth", "A", "man", "is", "seen", "moving", "along", "the", "water", "on", "a", "surf", "board", "while", "another", "person", "watches", "on", "the", "side.", "The", "person", "continues", "riding", "around", "and", "slowing", "down", "to", "demonstrate", "how", "to", "play.", "Vanilla", "Transformer", "Several", "shots", "are", "shown", "of", "people", "riding", "on", "the", "surf", "board", "and", "the", "people", "riding", "along", "the", "water.", "Several", "shots", "are", "shown", "of", "people", "riding", "around", "on", "a", "surf", "board", "and", "leads", "into", "several", "clips", "of", "people", "riding.", "Transformer-XL", "A", "large", "wave", "is", "seen", "followed", "by", "several", "shots", "of", "people", "riding", "on", "a", "surf", "board", "and", "riding", "along", "the.", "The", "people", "continue", "riding", "along", "the", "water", "while", "the", "camera", "pans", "around", "the", "area", "and", "leads", "into", "several", "more", "shots.", "MART", "(ours)", "A", "man", "is", "seen", "riding", "on", "a", "surfboard", "and", "surfing", "on", "the", "waves.", "The", "man", "continues", "surfing", "while", "the", "camera", "captures", "him", "from", "several", "angles.", "Ground-Truth", "A", "woman", "is", "seen", "speaking", "to", "the", "camera", "and", "leads", "into", "her", "walking", "up", "and", "down", "the", "board.", "She", "then", "stands", "on", "top", "of", "the", "beam", "while", "speaking", "to", "the", "camera", "continuously.", "MART", "(ours)", "A", "woman", "is", "standing", "in", "a", "room", "talking.", "She", "starts", "working", "out", "on", "the", "equipment.", "Vanilla", "Transformer", "She", "continues", "moving", "around", "the", "room", "and", "leads", "into", "her", "speaking", "to", "the", "camera.", "She", "continues", "moving", "around", "on", "the", "step", "and", "ends", "by", "speaking", "to", "the", "camera.", "Transformer-XL", "A", "woman", "is", "standing", "in", "a", "gym.", "She", "begins", "to", "do", "a", "step.", "Vanilla", "Transformer", "He", "continues", "speaking", "while", "holding", "the", "violin", "and", "showing", "how", "to", "play", "his", "hands.", "He", "continues", "playing", "the", "instrument", "while", "looking", "down", "at", "the", "camera.", "He", "continues", "playing", "the", "violin", "and", "then", "stops", "to", "speak", "to", "the", "camera.", "Transformer-XL", "A", "man", "is", "seen", "speaking", "to", "the", "camera", "while", "holding", "a", "violin.", "The", "man", "continues", "playing", "the", "instrument", "while", "moving", "his", "hands", "up", "and", "down.", "The", "man", "continues", "playing", "the", "instrument", "and", "ends", "by", "looking", "back", "to", "the", "camera.", "MART", "(ours)", "A", "man", "is", "seen", "speaking", "to", "the", "camera", "while", "holding", "a", "violin", "and", "begins", "playing", "the", "instrument.", "The", "man", "continues", "to", "play", "the", "instrument", "while", "moving", "his", "hands", "up", "and", "down.", "He", "continues", "to", "play", "and", "ends", "by", "moving", "his", "hands", "up", "and", "down.", "Ground-Truth", "A", "man", "is", "seen", "looking", "to", "the", "camera", "while", "holding", "a", "violin.", "The", "man", "then", "begins", "playing", "the", "instrument", "while", "the", "camera", "zooms", "in", "on", "his", "fingers.", "The", "man", "continues", "to", "play", "and", "stops", "to", "speak", "to", "the", "camera.", "Vanilla", "Transformer", "He", "is", "skateboarding", "down", "a", "road.", "He", "goes", "through", "the", "streets", "and", "goes.", "He", "is", "skateboarding", "down", "a", "road.", "Transformer-XL", "A", "man", "is", "riding", "a", "skateboard", "down", "a", "road.", "He", "is", "skateboarding", "down", "a", "road.", "He", "is", "skateboarding", "down", "a", "road.", "MART", "(ours)", "A", "man", "is", "seen", "riding", "down", "a", "road", "with", "a", "person", "walking", "into", "frame", "and", "speaking", "to", "the", "camera.", "The", "man", "continues", "riding", "down", "the", "road", "while", "looking", "around", "to", "the", "camera", "and", "showing", "off", "his", "movements.", "The", "man", "continues", "to", "ride", "around", "while", "looking", "to", "the", "camera.", "Ground-Truth", "A", "camera", "pans", "all", "around", "an", "area", "and", "leads", "into", "a", "man", "speaking", "to", "the", "camera.", "Several", "shots", "of", "the", "area", "are", "shown", "as", "well", "as", "dogs", "and", "leads", "into", "a", "man", "riding", "down", "a", "hill.", "The", "man", "rides", "a", "skateboard", "continuously", "around", "the", "area", "and", "ends", "by", "meeting", "up", "with", "the", "first", "man."], "regionBoundary": {"x2": 524.0, "y1": 140.8900146484375, "x1": 72.0, "y2": 633.28759765625}, "caption": "Figure 5: Additional qualitative examples. Red/bold indicates pronoun errors (inappropriate use of pronouns or person mentions), blue/italic indicates repetitive patterns, underline indicates content errors. Compared to baselines, our model generates more coherent, less repeated paragraphs while maintaining relevance.", "page": 11}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.6192932128906, "y1": 566.4095458984375, "x1": 72.0, "y2": 596.322021484375}, "imageText": ["A", "little", "girl", "stands", "on", "a", "diving", "board.", "Then", "the", "little", "girl", "jumps,", "flip", "and", "dives", "in", "the", "swimming", "pool\u2026", "A", "young", "girl", "is", "seen", "walking", "to", "the", "end", "of", "a", "diving", "board", "with", "several", "other", "people", "around", "her\u2026", "A", "man", "on", "a", "diving", "board", "walks", "to", "the", "end.", "The", "man", "bounces", "on", "the", "board", "two", "times", "then", "dives", "into", "the", "water\u2026", "A", "girl", "is", "giving", "a", "small", "dog", "a", "bath.", "She", "has", "an", "orange", "bottle", "in", "her", "hand\u2026"], "regionBoundary": {"x2": 280.0, "y1": 297.8900146484375, "x1": 82.0, "y2": 551.8900146484375}, "caption": "Figure 4: Nearest neighbors retrieved using memory states. Top row shows the query, the 3 rows below it are the top-3 nearest neighbors.", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2227478027344, "y1": 480.4604848225911, "x1": 426.772223578559, "y2": 522.0055474175347}, "name": "1", "caption_text": "Figure 1: Vanilla transformer video captioning model (Zhou et al., 2018). PE denotes Positional Encoding, TE denotes token Type Embedding.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 86.0, "x1": 442.0, "y2": 459.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3379516601562, "y1": 517.8910149468315, "x1": 99.5708253648546, "y2": 559.4360775417751}, "name": "2", "caption_text": "Figure 2: Left: Our proposed Memory-Augmented Recurrent Transformer (MART) for video paragraph captioning. Right: Transformer-XL (Dai et al., 2019) model for video paragraph captioning. Relative PE denotes Relative Positional Encoding (Dai et al., 2019). SG(\u00b7) denotes stop-gradient, denotes Hadamard product.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 93.0, "x1": 103.0, "y2": 496.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3471069335938, "y1": 233.00912645128037, "x1": 99.57083596123589, "y2": 274.5542738172743}, "name": "1", "caption_text": "Table 1: Comparison with transformer baselines on ActivityNet Captions ae-test split and YouCookII val split. Re. indicates whether sentence-level recurrence is used. We report BLEU@4 (B@4), METEOR (M), CIDEr-D (C) and Repetition (R@4). VTransformer denotes vanilla transformer.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 86.0, "x1": 134.0, "y2": 233.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 520.4049004448784, "x1": 99.50135548909505, "y2": 628.3693525526259}, "name": "2", "caption_text": "Table 2: Comparison with baselines on ActivityNet Captions ae-val split. Det. indicates whether the model uses detection feature. Models that use detection features are shown in gray background to indicate they are not in fair comparison with the others. Re. indicates whether sentence-level recurrence is used. VTransformer denotes vanilla transformer.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 306.0, "x1": 103.0, "y2": 503.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2230868869358, "y1": 261.7243872748481, "x1": 426.2735578748915, "y2": 336.4792717827691}, "name": "4", "caption_text": "Table 4: Model ablation on ActivityNet Captions aeval split. Re. indicates whether sentence-level recurrence is used. mem. len. indicates the length of the memory state. MART w/o re. denotes a MART variant without recurrence. Top two scores are highlighted.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 86.0, "x1": 429.0, "y2": 245.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.57157728407117, "y1": 212.03549702962238, "x1": 99.57083596123589, "y2": 270.18483479817706}, "name": "3", "caption_text": "Table 3: Human evaluation on ActivityNet Captions aetest set w.r.t. relevance and coherence. Top: MART vs. vanilla transformer (VTransformer). Bottom: MART vs. Transformer-XL.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 100.0, "y2": 212.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 339.8257361518012, "x1": 100.0, "y2": 381.3708835177951}, "name": "3", "caption_text": "Figure 3: Qualitative examples. Red/bold indicates pronoun errors (inappropriate use of pronouns), blue/italic indicates repetitive patterns, underline indicates content errors. Compared to baselines, our model generates more coherent, less repeated paragraphs while maintaining relevance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 87.0, "x1": 104.0, "y2": 315.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.63790724012586, "y1": 786.6799248589409, "x1": 100.0, "y2": 828.2250298394097}, "name": "4", "caption_text": "Figure 4: Nearest neighbors retrieved using memory states. Top row shows the query, the 3 rows below it are the top-3 nearest neighbors.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 388.0, "y1": 413.0, "x1": 115.0, "y2": 767.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2233412000868, "y1": 903.8882785373263, "x1": 100.0, "y2": 945.4347398546007}, "name": "5", "caption_text": "Figure 5: Additional qualitative examples. Red/bold indicates pronoun errors (inappropriate use of pronouns or person mentions), blue/italic indicates repetitive patterns, underline indicates content errors. Compared to baselines, our model generates more coherent, less repeated paragraphs while maintaining relevance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 196.0, "x1": 101.0, "y2": 879.0}, "page": 11, "dpi": 0}], "error": null, "pdf": "/work/host-output/ad1af85753075b6c0df36e4eb98dfe83dd68b95e/2020.acl-main.233.pdf", "dpi": 100}