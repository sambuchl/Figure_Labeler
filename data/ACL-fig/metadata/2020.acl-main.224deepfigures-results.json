{"raw_detected_boxes": [[{"x2": 727.0, "y1": 314.0, "x1": 428.0, "y2": 499.0}], [], [{"x2": 647.0, "y1": 90.0, "x1": 180.0, "y2": 285.0}, {"x2": 661.0, "y1": 497.0, "x1": 492.0, "y2": 541.0}], [{"x2": 398.0, "y1": 90.0, "x1": 102.0, "y2": 180.0}], [], [{"x2": 668.0, "y1": 93.0, "x1": 154.0, "y2": 247.0}, {"x2": 402.0, "y1": 310.0, "x1": 111.0, "y2": 432.0}], [{"x2": 704.0, "y1": 95.0, "x1": 130.0, "y2": 309.0}, {"x2": 723.0, "y1": 413.0, "x1": 435.0, "y2": 515.0}], [{"x2": 392.0, "y1": 86.0, "x1": 109.0, "y2": 237.0}], [{"x2": 724.0, "y1": 92.0, "x1": 100.0, "y2": 323.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Table", "boundary": {"x2": 525.7155151367188, "y1": 249.48355102539062, "x1": 71.69100189208984, "y2": 279.39605712890625}, "text": "Table 5: Sample texts generated by our methods and baselines, compared with a human-provided reference. We highlight in different color the [missing], unfaithful, and unfluent parts of each text. Only the results of our DUALENC correctly mention all the input triples.", "name": "5", "page": 8}], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5465087890625, "y1": 372.2185363769531, "x1": 307.2760009765625, "y2": 402.1309814453125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 221.8900146484375, "x1": 307.0, "y2": 359.8900146484375}, "caption": "Figure 1: Illustration of the WebNLG challenge: the source data is an RDF graph and the target output is a text description of the graph.", "page": 0}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 456.1820373535156, "y1": 193.16854858398438, "x1": 141.05499267578125, "y2": 199.1710205078125}, "imageText": ["GCN", "0.63", "0.61", "0.62", "80.8", "79.3", "80.1", "Transformer", "(Ferreira", "et", "al.,", "2019)", "0.56", "0.09", "0.34", "74.3", "20.9", "49.3", "GRU", "(Ferreira", "et", "al.,", "2019)", "0.56", "0.10", "0.35", "75.8", "25.4", "52.2", "Step-By-Step", "II", "(Moryossef", "et", "al.,", "2019b)", "0.45", "0.44", "0.44", "67.7", "67.3", "67.5", "Step-By-Step", "(Moryossef", "et", "al.,", "2019a)", "0.49", "0.44", "0.47", "73.2", "68.0", "70.8", "Random", "0.28", "0.34", "0.31", "54.1", "62.1", "57.9", "Structure-random", "0.32", "0.38", "0.34", "56.6", "62.9", "59.5", "SEEN", "UNSEEN", "ALL", "SEEN", "UNSEEN", "ALL", "Accuracy", "BLEU-2"], "regionBoundary": {"x2": 485.0, "y1": 62.8900146484375, "x1": 111.0, "y2": 180.8900146484375}, "caption": "Table 1: Planning results of three test sets evaluated by accuracy and BLEU-2.", "page": 5}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.92437744140625, "y1": 323.8815612792969, "x1": 72.0, "y2": 353.79400634765625}, "imageText": ["Triple-set", "Size", "random_walk", "random_dfs", "random_bfs", "random", "-2", "BL", "EU", "100", "80", "60", "40", "20", "2", "3", "4", "5", "6", "7", "0", "GCN", "step-by-step", "step-by", "step", "II", "GRU", "Transformer", "ra", "cy", "Ac", "cu", "0.8", "0.6", "0.4", "0.2", "2", "3", "4", "5", "6", "7", "0.0"], "regionBoundary": {"x2": 290.0, "y1": 222.8900146484375, "x1": 73.49761962890625, "y2": 310.5469970703125}, "caption": "Figure 5: Fine-grained planning results for the ALL test set. Our method outperforms all the baselines regardless of the triple size.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5472412109375, "y1": 239.83554077148438, "x1": 71.69100189208984, "y2": 269.7490234375}, "imageText": ["TILB-SMT", "54.29", "29.88", "44.28", "0.42", "0.33", "0.38", "0.47", "0.61", "0.53", "ADAPT", "60.59", "10.53", "31.06", "0.44", "0.19", "0.31", "0.37", "1.40", "0.84", "MELBOURNE", "54.52", "33.27", "45.13", "0.41", "0.33", "0.37", "0.40", "0.55", "0.47", "GTR-LSTM", "(2018)", "54.00", "29.20", "37.10", "0.37", "0.28", "0.31", "0.45", "0.60", "0.55", "GCN-EC", "(2018)", "55.90", "-", "-", "0.39", "-", "-", "0.41", "-", "-", "GRU", "(2019)", "56.09", "25.12", "42.73", "0.42", "0.22", "0.33", "0.39", "0.64", "0.51", "Transformer", "(2019)", "56.28", "23.04", "42.41", "0.42", "0.21", "0.32", "0.39", "0.63", "0.50", "Step-By-Step", "(2019a)", "53.30", "34.41", "47.24", "0.44", "0.34", "0.39", "0.47", "0.56", "0.51", "PLANENC", "64.42", "38.23", "52.78", "0.45", "0.37", "0.41", "0.33", "0.53", "0.42", "DUALENC", "63.45", "36.73", "51.42", "0.46", "0.37", "0.41", "0.34", "0.55", "0.44", "SEEN", "UNSEEN", "ALL", "SEEN", "UNSEEN", "ALL", "SEEN", "UNSEEN", "ALL", "BLEU", "(\u2191)", "METEOR", "(\u2191)", "TER", "(\u2193)"], "regionBoundary": {"x2": 509.0, "y1": 68.97897338867188, "x1": 89.0, "y2": 222.8900146484375}, "caption": "Table 2: Generation results evaluated by BLEU, METEOR, and TER. We compare our methods with different generation systems (SMT, Sequential NMT, Graph NMT, Pipeline). Both of our methods outperform all the baselines on all three measures. We highlight both results if there is no significant difference.", "page": 6}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 492.76348876953125, "y1": 387.9785461425781, "x1": 339.74798583984375, "y2": 393.98101806640625}, "imageText": ["-plan", "57.81", "\u00b1", "0.82", "0.40", "\u00b1", "0.00", "0.40", "\u00b1", "0.01", "-copy", "61.64", "\u00b1", "0.53", "0.43", "\u00b1", "0.01", "0.36", "\u00b1", "0.01", "-mention", "61.49", "\u00b1", "0.35", "0.43", "\u00b1", "0.00", "0.36", "\u00b1", "0.00", "-delimiter", "63.26", "\u00b1", "0.33", "0.44", "\u00b1", "0.00", "0.34", "\u00b1", "0.00", "PLANENC", "64.42", "\u00b1", "0.17", "0.45", "\u00b1", "0.00", "0.33", "\u00b1", "0.00", "Methods", "BLEU", "(\u2191)", "METEOR", "(\u2191)", "TER", "(\u2193)"], "regionBoundary": {"x2": 522.0, "y1": 292.8900146484375, "x1": 311.0, "y2": 370.8900146484375}, "caption": "Table 3: Results of the ablation study.", "page": 6}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 515.6319580078125, "y1": 405.6615295410156, "x1": 317.18701171875, "y2": 411.66400146484375}, "imageText": [], "regionBoundary": {"x2": 482.0, "y1": 355.8900146484375, "x1": 350.0, "y2": 393.8900146484375}, "caption": "Figure 3: The graph obtained from an RDF triple.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5473022460938, "y1": 224.26351928710938, "x1": 71.99998474121094, "y2": 266.13104248046875}, "imageText": [], "regionBoundary": {"x2": 469.0, "y1": 61.8900146484375, "x1": 128.0, "y2": 212.8900146484375}, "caption": "Figure 2: The architecture of the proposed DUALENC model. The input triples are converted as a graph and then fed to two GCN encoders for plan and text generation (Planner and Graph Encoder, top center). The plan is then encoded by an LSTM network (Plan Encoder, bottom center). Finally an LSTM decoder combines the hidden states from both the encoders to generate the text (Text Decoder, middle right).", "page": 2}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.9217224121094, "y1": 188.18753051757812, "x1": 71.69100189208984, "y2": 206.14501953125}, "imageText": ["PLANENC", "92.3", "88.2", "-7.5", "-12.5", "-7.5", "-21.2", "DUALENC", "94.5", "91.8", "\u2013", "\u2013", "\u2013", "\u2013", "STEP", "96.1", "89.3", "5.0", "-3.7", "-45.0", "-55.0", "E2E-TRANS", "85.5", "78.0", "-21.2", "-32.5", "-21.2", "-46.3", "GCN", "79.8", "76.8", "-48.7", "-50.0", "-26.3", "-67.5", "MELBOURNE", "83.0", "75.2", "-35.0", "-42.5", "-38.8", "-68.8", "CVGE", "FAITH", "CVGE", "FAITH", "FLCY", "ALL", "Absolute(%)", "Pairwise(%)"], "regionBoundary": {"x2": 284.0, "y1": 62.8900146484375, "x1": 79.0, "y2": 170.8900146484375}, "caption": "Table 4: Results of human evaluation. DUALENC outperforms most of the baselines on all measures.", "page": 7}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.2705993652344, "y1": 145.73556518554688, "x1": 72.0, "y2": 163.69305419921875}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 133.8900146484375}, "caption": "Figure 4: The sequential decision-making process of the planning stage.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 516.9701894124349, "x1": 426.772223578559, "y2": 558.5152520073784}, "name": "1", "caption_text": "Figure 1: Illustration of the WebNLG challenge: the source data is an RDF graph and the target output is a text description of the graph.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 310.0, "x1": 427.0, "y2": 516.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 311.47711012098523, "x1": 99.99997880723741, "y2": 369.6264478895399}, "name": "2", "caption_text": "Figure 2: The architecture of the proposed DUALENC model. The input triples are converted as a graph and then fed to two GCN encoders for plan and text generation (Planner and Graph Encoder, top center). The plan is then encoded by an LSTM network (Plan Encoder, bottom center). Finally an LSTM decoder combines the hidden states from both the encoders to generate the text (Text Decoder, middle right).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 647.0, "y1": 90.0, "x1": 180.0, "y2": 285.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 716.1554972330729, "y1": 563.4187910291884, "x1": 440.53751627604163, "y2": 571.7555575900608}, "name": "3", "caption_text": "Figure 3: The graph obtained from an RDF triple.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 668.0, "y1": 496.0, "x1": 489.0, "y2": 545.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 202.41050720214844, "x1": 100.0, "y2": 227.35146416558158}, "name": "4", "caption_text": "Figure 4: The sequential decision-making process of the planning stage.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 90.0, "x1": 102.0, "y2": 180.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 633.5861629909939, "y1": 268.2896508110894, "x1": 195.90971204969617, "y2": 276.6264173719618}, "name": "1", "caption_text": "Table 1: Planning results of three test sets evaluated by accuracy and BLEU-2.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 673.0, "y1": 86.0, "x1": 154.0, "y2": 251.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45052422417535, "y1": 449.8355017768012, "x1": 100.0, "y2": 491.38056437174475}, "name": "5", "caption_text": "Figure 5: Fine-grained planning results for the ALL test set. Our method outperforms all the baselines regardless of the triple size.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 403.0, "y1": 309.0, "x1": 100.0, "y2": 449.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 333.10491773817273, "x1": 99.57083596123589, "y2": 374.65142144097223}, "name": "2", "caption_text": "Table 2: Generation results evaluated by BLEU, METEOR, and TER. We compare our methods with different generation systems (SMT, Sequential NMT, Graph NMT, Pipeline). Both of our methods outperform all the baselines on all three measures. We highlight both results if there is no significant difference.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 706.0, "y1": 86.0, "x1": 124.0, "y2": 309.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 684.3937344021267, "y1": 538.8590918646918, "x1": 471.8722025553385, "y2": 547.1958584255642}, "name": "3", "caption_text": "Table 3: Results of the ablation study.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 406.0, "x1": 432.0, "y2": 515.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.44683668348523, "y1": 261.3715701633029, "x1": 99.57083596123589, "y2": 286.3125271267361}, "name": "4", "caption_text": "Table 4: Results of human evaluation. DUALENC outperforms most of the baselines on all measures.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 394.0, "y1": 86.0, "x1": 109.0, "y2": 238.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.1604376898871, "y1": 346.50493197970917, "x1": 99.57083596123589, "y2": 388.0500793457031}, "name": "5", "caption_text": "Table 5: Sample texts generated by our methods and baselines, compared with a human-provided reference. We highlight in different color the [missing], unfaithful, and unfluent parts of each text. Only the results of our DUALENC correctly mention all the input triples.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 86.0, "x1": 100.0, "y2": 323.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/575157d9c2fe71eefe8265bdfed2ff1720008c7b/2020.acl-main.224.pdf", "dpi": 100}