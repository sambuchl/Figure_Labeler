{"raw_detected_boxes": [[], [], [], [], [{"x2": 403.0, "y1": 108.0, "x1": 225.0, "y2": 446.0}], [], [], [], [{"x2": 479.0, "y1": 94.0, "x1": 93.0, "y2": 306.0}], [{"x2": 504.0, "y1": 390.0, "x1": 104.0, "y2": 777.0}, {"x2": 417.0, "y1": 92.0, "x1": 112.0, "y2": 262.0}], [{"x2": 384.0, "y1": 136.0, "x1": 211.0, "y2": 287.0}, {"x2": 441.0, "y1": 456.0, "x1": 117.0, "y2": 674.0}], [{"x2": 446.0, "y1": 91.0, "x1": 153.0, "y2": 281.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 369.0024108886719, "y1": 227.32208251953125, "x1": 63.0, "y2": 255.6510009765625}, "imageText": ["benchmark", "best", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6"], "regionBoundary": {"x2": 277.82110595703125, "y1": 97.97185516357422, "x1": 151.68699645996094, "y2": 206.85101318359375}, "caption": "FIGURE 4: Results for a configuration with best parameters values: LSTM RNN with 2 layers of 1350 units, dropout rate 0.1, vocabulary size 100k, training on 90%, and lexical embedding dimension size 150", "page": 10}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 369.00146484375, "y1": 504.049072265625, "x1": 63.0, "y2": 532.3770141601562}, "imageText": ["supervised", "summing", "method", "verb", "targeted", "method", "1", "0.9", "0.8", "0.7", "0.6", "0.5", "0", "1", "2", "3", "4", "5", "6", "7", "0.4"], "regionBoundary": {"x2": 348.91253662109375, "y1": 329.3398742675781, "x1": 80.0, "y2": 483.5769958496094}, "caption": "FIGURE 5: Comparing LSTM trained language model (with voc. size 100 and 1000 units) for the two methods of predicting verb number. The solid blue line represents our (supervised) benchmark LSTM RNN.", "page": 10}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 369.001220703125, "y1": 574.2540893554688, "x1": 63.0, "y2": 602.58203125}, "imageText": ["(f)", "Comparing", "embedding", "dimensions", "17", "150", "50", "450", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(e)", "Comparing", "dropout", "rates", "0.0", "0.2", "0.1", "0.5", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(d)", "Comparing", "number", "of", "layers", "1", "layer", "4", "layers", "2", "layers", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(c)", "Comparing", "memory", "size", "50", "450", "150", "1350", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(b)", "Comparing", "architectures", "LSTM", "CNN", "GRU", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(a)", "Comparing", "size", "of", "training", "set", "10%", "90%", "50%", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6"], "regionBoundary": {"x2": 362.75762939453125, "y1": 67.85588836669922, "x1": 75.18699645996094, "y2": 557.052978515625}, "caption": "FIGURE 3: Results of testing the effect of various hyper-parameters. The reference (solid blue line) is an LSTM architecture, vocabulary size 10000, training set 90%, single layer, 150 memory units, no drop out.", "page": 9}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 333.5730895996094, "y1": 228.32708740234375, "x1": 98.42900085449219, "y2": 232.7449951171875}, "imageText": ["1", "\u00b7", "106", "1", "\u00b7", "105", "10,000", "1,000", "0", "1", "2", "3", "4", "5", "6", "7"], "regionBoundary": {"x2": 322.2671203613281, "y1": 66.0, "x1": 109.73100280761719, "y2": 201.59600830078125}, "caption": "FIGURE 6: Number of test examples per number of attractors", "page": 11}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 348.5307922363281, "y1": 241.53509521484375, "x1": 83.46900177001953, "y2": 245.9530029296875}, "imageText": ["(b)", "For", "CNN", "architecture", "100", "100k", "10k", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6", "(a)", "For", "LSTM", "100", "100k", "10k", "1", "0.9", "0.8", "0.7", "0", "1", "2", "3", "4", "5", "6", "7", "0.6"], "regionBoundary": {"x2": 345.6201171875, "y1": 67.85588836669922, "x1": 67.05500030517578, "y2": 224.33401489257812}, "caption": "FIGURE 2: Comparing effect of vocabulary size across architectures.", "page": 8}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 280.1084899902344, "y1": 355.5120849609375, "x1": 151.89199829101562, "y2": 359.92999267578125}, "imageText": ["dense", "6-dilated", "convolution,", "\ufb01lter", "size", "=", "3", "4-dilated", "convolution,", "\ufb01lter", "size", "=", "5", "2-dilated", "convolution,", "\ufb01lter", "size", "=", "5", "convolution,", "\ufb01lter", "size", "=", "7", "{0,", "1}voc.", "size", "embedding", "R50", "R20", "R15", "R10", "R5", "class"], "regionBoundary": {"x2": 291.2779846191406, "y1": 74.50438690185547, "x1": 144.70799255371094, "y2": 330.6400146484375}, "caption": "FIGURE 1: Our CNN Architecture", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 389.03956943088104, "y1": 493.76678466796875, "x1": 210.9611087375217, "y2": 499.9027676052517}, "name": "1", "caption_text": "FIGURE 1: Our CNN Architecture", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 102.0, "x1": 213.0, "y2": 458.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 484.0705447726779, "y1": 335.46541002061633, "x1": 115.92916912502712, "y2": 341.6013929578993}, "name": "2", "caption_text": "FIGURE 2: Comparing effect of vocabulary size across architectures.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 480.0, "y1": 92.0, "x1": 93.0, "y2": 315.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 512.501695421007, "y1": 797.5751241048176, "x1": 87.5, "y2": 836.9194878472222}, "name": "3", "caption_text": "FIGURE 3: Results of testing the effect of various hyper-parameters. The reference (solid blue line) is an LSTM architecture, vocabulary size 10000, training set 90%, single layer, 150 memory units, no drop out.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 504.0, "y1": 378.0, "x1": 104.0, "y2": 777.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 512.5033484564887, "y1": 315.7251146104601, "x1": 87.5, "y2": 355.0708346896701}, "name": "4", "caption_text": "FIGURE 4: Results for a configuration with best parameters values: LSTM RNN with 2 layers of 1350 units, dropout rate 0.1, vocabulary size 100k, training on 90%, and lexical embedding dimension size 150", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 386.0, "y1": 134.0, "x1": 211.0, "y2": 287.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 512.5020345052084, "y1": 700.0681559244791, "x1": 87.5, "y2": 739.4125196668837}, "name": "5", "caption_text": "FIGURE 5: Comparing LSTM trained language model (with voc. size 100 and 1000 units) for the two methods of predicting verb number. The solid blue line represents our (supervised) benchmark LSTM RNN.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 453.0, "y1": 455.0, "x1": 112.0, "y2": 675.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 463.29595777723523, "y1": 317.1209547254774, "x1": 136.70694563123914, "y2": 323.2569376627604}, "name": "6", "caption_text": "FIGURE 6: Number of test examples per number of attractors", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 448.0, "y1": 91.0, "x1": 153.0, "y2": 281.0}, "page": 11, "dpi": 0}], "error": null, "pdf": "/work/host-output/fb92ccadf502e66e3e7d72b6beaba1b9721a6276/2017.lilt-15.3.pdf", "dpi": 100}