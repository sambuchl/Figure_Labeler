{"raw_detected_boxes": [[], [{"x2": 687.0, "y1": 88.0, "x1": 146.0, "y2": 214.0}, {"x2": 687.0, "y1": 290.0, "x1": 146.0, "y2": 372.0}], [{"x2": 712.0, "y1": 97.0, "x1": 104.0, "y2": 219.0}], [{"x2": 720.0, "y1": 90.0, "x1": 110.0, "y2": 182.0}], [], [{"x2": 729.0, "y1": 86.0, "x1": 434.0, "y2": 199.0}, {"x2": 392.0, "y1": 86.0, "x1": 108.0, "y2": 298.0}, {"x2": 710.0, "y1": 281.0, "x1": 443.0, "y2": 409.0}], [{"x2": 377.0, "y1": 88.0, "x1": 123.0, "y2": 172.0}, {"x2": 360.0, "y1": 276.0, "x1": 112.0, "y2": 464.0}], [{"x2": 388.0, "y1": 86.0, "x1": 112.0, "y2": 158.0}], [{"x2": 665.0, "y1": 86.0, "x1": 162.0, "y2": 158.0}], [], [], [{"x2": 724.0, "y1": 94.0, "x1": 434.0, "y2": 267.0}, {"x2": 386.0, "y1": 529.0, "x1": 116.0, "y2": 691.0}], [{"x2": 637.0, "y1": 86.0, "x1": 186.0, "y2": 141.0}, {"x2": 705.0, "y1": 343.0, "x1": 448.0, "y2": 880.0}], [{"x2": 704.0, "y1": 271.0, "x1": 120.0, "y2": 839.0}], [{"x2": 383.0, "y1": 268.0, "x1": 114.0, "y2": 836.0}], [{"x2": 706.0, "y1": 426.0, "x1": 117.0, "y2": 729.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.2001342773438, "y1": 157.03054809570312, "x1": 306.9670104980469, "y2": 186.94305419921875}, "imageText": ["System", "Metric", "Opt.", "F1", "AUC", "Last", "F1", "CopyAttention", "35.4", "20.4", "32.8", "CoverageAttention", "41.8", "22.1", "41.8", "CoverageAttention+BERT", "47.9", "27.9", "47.9", "Diverse", "Beam", "Search", "46.1", "26.1", "39.6", "IMOJIE", "(w/o", "BERT)", "37.9", "19.1", "36.6", "IMOJIE", "53.2", "33.1", "52.4"], "regionBoundary": {"x2": 525.0, "y1": 62.8900146484375, "x1": 308.0, "y2": 143.8900146484375}, "caption": "Table 4: Models to solve the redundancy issue prevalent in Generative Neural OpenIE systems. All systems are bootstrapped on OpenIE-4.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 291.9243469238281, "y1": 226.56954956054688, "x1": 71.69100189208984, "y2": 292.34808349609375}, "imageText": ["System", "Metric", "Opt.", "F1", "AUC", "Last", "F1", "Stanford-IE", "23", "13.4", "22.9", "OllIE", "41.1", "22.5", "40.9", "PropS", "31.9", "12.6", "31.8", "MinIE", "41.9", "-\u2217", "41.9", "OpenIE-4", "51.6", "29.5", "51.5", "OpenIE-5", "48.5", "25.7", "48.5", "ClausIE", "45.1", "22.4", "45.1", "CopyAttention", "35.4", "20.4", "32.8", "RNN-OIE", "49.2", "26.5", "49.2", "Sense-OIE", "17.2", "-\u2217", "17.2", "Span-OIE", "47.9", "-\u2217", "47.9", "CopyAttention", "+", "BERT", "51.6", "32.8", "49.6", "IMOJIE", "53.5", "33.3", "53.3"], "regionBoundary": {"x2": 284.0, "y1": 62.8900146484375, "x1": 76.0, "y2": 214.8900146484375}, "caption": "Table 3: Comparison of various OpenIE systems - nonneural, neural and proposed models. (*) Cannot compute AUC as Sense-OIE, MinIE do not emit confidence values for extractions and released code for Span-OIE does not provision calculation of confidence values. In these cases, we report the Last F1 as the Opt. F1", "page": 5}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 527.2002563476562, "y1": 306.3495178222656, "x1": 306.9670104980469, "y2": 348.21697998046875}, "imageText": ["Bootstrapping", "Metric", "Systems", "Opt.", "F1", "AUC", "Last", "F1", "ClausIE", "49.2", "31.4", "45.5", "RnnOIE", "51.3", "31.1", "50.8", "OpenIE-4", "53.2", "33.1", "52.4", "OpenIE-4+ClausIE", "51.5", "32.5", "47.1", "OpenIE-4+RnnOIE", "53.1", "32.1", "53.0", "ClausIE+RnnOIE", "50.9", "32.2", "49.8", "All", "53.5", "33.3", "53.3"], "regionBoundary": {"x2": 512.0, "y1": 202.8900146484375, "x1": 319.0, "y2": 293.8900146484375}, "caption": "Table 5: IMOJIE trained with different combinations of bootstrapping data from 3 systems - OpenIE-4, ClausIE, RNNOIE. Graph filtering is not used over single datasets.", "page": 5}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 278.6279296875, "y1": 621.3685913085938, "x1": 83.63999938964844, "y2": 627.3710327148438}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 188.8900146484375, "x1": 72.0, "y2": 609.8900146484375}, "caption": "Figure 9: BERT attention for the word \u2018minister\u2019", "page": 14}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 502.8540954589844, "y1": 166.39456176757812, "x1": 94.37999725341797, "y2": 172.39703369140625}, "imageText": ["IMOJIE", "(", "He", ";", "was", "appointed", ";", "Commander", "of", "the", "Order", "...", "Birthday", "Honours", ")(", "He", ";", "was", "knighted", ";", "in", "the", "1953", "Coronation", "Honours", ")", "CopyAttention", "(", "He", ";", "was", "appointed", ";", "Commander", "...", "Birthday", "Honours", ")", "(", "He", ";", "was", "appointed", ";", "Commander", "...", "Birthday", "Honours", "and", "was", "knighted", "...", "Honours", ")", "(", "Queen", "\u2019s", "Birthday", "Honours", ";", "was", "knighted", ";", "in", "the", "1953", "Coronation", "Honours", ")", "(", "He", ";", "was", "appointed", ";", "Commander", "of", "the", "Order", "of", "the", "British", "Empire", "in", "the", "1948", ")", "(", "the", "1948", ";", "was", "knighted", ";", "in", "the", "1953", "Coronation", "Honours)", "Sentence", "He", "was", "appointed", "Commander", "of", "the", "Order", "of", "the", "British", "Empire", "in", "the", "1948Queen\u2019s", "Birthday", "Honours", "and", "was", "knighted", "in", "the", "1953", "Coronation", "Honours", "."], "regionBoundary": {"x2": 496.0, "y1": 62.8900146484375, "x1": 100.0, "y2": 153.8900146484375}, "caption": "Table 1: IMOJIE vs. CopyAttention. CopyAttention suffers from stuttering, which IMOJIE does not.", "page": 1}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5476684570312, "y1": 281.5635681152344, "x1": 71.69100189208984, "y2": 299.52105712890625}, "imageText": ["IMOJIE", "(", "a", "slave", ";", "might", "fear", ";", "a", "cruel", "and", "capricious", "master", ")", "(", "Greek", "and", "Roman", "pagans", ";", "scorned", ";", "the", "man", "who", "...", "capricious", "master", ")", "(", "the", "man", ";", "constantly", "trembled", ";", "with", "fear", "at", "the", "thought", "of", "the", "gods", ")", "(", "Greek", "and", "Roman", "pagans", ";", "saw", ";", "their", "relations", "with", "the", "gods", "in", "political", "and", "social", "terms", ")", "Sentence", "Greek", "and", "Roman", "pagans", ",", "who", "saw", "their", "relations", "with", "the", "gods", "in", "political", "and", "social", "terms", ",", "scorned", "the", "man", "who", "constantly", "trembled", "with", "fear", "at", "the", "thought", "of", "the", "gods", ",", "as", "a", "slave", "might", "fear", "a", "cruel", "and", "capricious", "master", ".", "OpenIE-4", "(", "the", "man", ";", "constantly", "trembled", ";", ")"], "regionBoundary": {"x2": 495.0, "y1": 187.8900146484375, "x1": 100.0, "y2": 269.8900146484375}, "caption": "Table 2: IMOJIE vs. OpenIE-4. Pipeline nature of OpenIE-4 can get confused by long convoluted sentences, but IMOJIE responds gracefully.", "page": 1}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 291.9243469238281, "y1": 136.10855102539062, "x1": 71.69100189208984, "y2": 177.97705078125}, "imageText": ["Filtering", "Metric", "Opt.", "F1", "AUC", "Last", "F1", "None", "49.7", "34.5", "37.4", "Extraction-based", "46", "29.2", "44.9", "Sentence-based", "49.5", "32.7", "48.6", "Score-And-Filter", "53.5", "33.3", "53.3"], "regionBoundary": {"x2": 272.0, "y1": 62.8900146484375, "x1": 88.0, "y2": 123.8900146484375}, "caption": "Table 6: Performance of IMOJIE on aggregated dataset OpenIE-4+ClausIE+RnnOIE, with different filtering techniques. For comparison, SenseOIE trained on multiple system extractions gives an F1 of 17.2 on CaRB.", "page": 6}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 287.1966857910156, "y1": 348.0985412597656, "x1": 75.072998046875, "y2": 354.10101318359375}, "imageText": [], "regionBoundary": {"x2": 280.0, "y1": 179.8900146484375, "x1": 72.0, "y2": 335.8900146484375}, "caption": "Figure 3: Precision-Recall curve of OpenIE Systems.", "page": 6}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 509.19622802734375, "y1": 622.4755859375, "x1": 86.96299743652344, "y2": 628.47802734375}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 187.8900146484375, "x1": 72.0, "y2": 610.8900146484375}, "caption": "Figure 7: BERT attention for the word \u2018justice\u2019 Figure 8: BERT attention for the word \u2018prime\u2019", "page": 13}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5413208007812, "y1": 173.73452758789062, "x1": 72.0, "y2": 191.6929931640625}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 161.8900146484375}, "caption": "Figure 1: One step of the sequential decoding process, for generating the ith extraction, which takes the original sentence and all extractions numbered 1, . . . , i\u2212 1, previously generated, as input.", "page": 2}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 515.5624389648438, "y1": 656.4895629882812, "x1": 317.2569885253906, "y2": 662.4920043945312}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 241.8900146484375, "x1": 307.0, "y2": 644.8900146484375}, "caption": "Figure 6: BERT attention for the word \u2018founding\u2019", "page": 12}, {"figType": "Table", "name": "9", "captionBoundary": {"x2": 441.9596862792969, "y1": 121.1645278930664, "x1": 155.2760009765625, "y2": 127.1669921875}, "imageText": ["Model", "Dataset", "Wire57", "Penn", "Web", "CopyAttention", "+", "BERT", "45.60,", "27.70,", "39.70", "18.20,", "7.9,", "12.40", "30.10,", "18.00,", "14.60", "IMOJIE", "46.20,", "26.60,", "46.20", "20.20,", "8.70,", "15.50", "30.40,", "15.50,", "26.40"], "regionBoundary": {"x2": 468.0, "y1": 62.8900146484375, "x1": 130.0, "y2": 103.8900146484375}, "caption": "Table 9: Evaluation on other datasets with the CaRB evaluation strategy", "page": 12}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 290.2705993652344, "y1": 126.14554595947266, "x1": 71.69100189208984, "y2": 156.05902099609375}, "imageText": ["Extractions", "Metric", "MNO", "IOU", "#Tuples", "CopyAttention+BERT", "2.805", "0.463", "3159", "IMOJIE", "1.282", "0.208", "1620", "Gold", "1.927", "0.31", "2650"], "regionBoundary": {"x2": 280.0, "y1": 62.8900146484375, "x1": 80.0, "y2": 113.8900146484375}, "caption": "Table 7: Measuring redundancy of extractions. MNO stands for Mean Number of Occurrences. IOU stands for Intersection over Union.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2009887695312, "y1": 143.37454223632812, "x1": 71.7509994506836, "y2": 161.33203125}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 131.8900146484375}, "caption": "Figure 2: Ranking-Filtering subsystem for combining extractions from multiple open IE systems in an unsupervised fashion. (\u2018Exts\u2019=extractions.)", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.2705383300781, "y1": 515.6145629882812, "x1": 72.0, "y2": 533.572021484375}, "imageText": [], "regionBoundary": {"x2": 286.0, "y1": 373.8900146484375, "x1": 77.0, "y2": 503.8900146484375}, "caption": "Figure 4: Measuring performance with varying input sentence lengths", "page": 11}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5465087890625, "y1": 208.98855590820312, "x1": 306.9169921875, "y2": 226.946044921875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 196.8900146484375}, "caption": "Figure 5: Measuring performance of CopyAttention with BERT model upon changing the beam size", "page": 11}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 443.6836853027344, "y1": 126.14554595947266, "x1": 153.55299377441406, "y2": 132.14801025390625}, "imageText": ["System", "Bootstrapping", "System", "OpenIE-4", "OpenIE-5", "ClausIE", "RnnOIE", "Base", "50.7,", "29,", "50.7", "47.4,", "25.1,", "47.4", "45.1,", "22.4,", "45.1", "49.2,", "26.5,", "49.2", "CopyAttention+BERT", "51.6,", "32.8,", "49.6", "48.7,", "29.4,", "48.0", "47.4,", "30.2,", "43.6", "47.9,", "30.6,", "41.1", "IMOJIE", "53.2,", "33.1,", "52.4", "48.8,", "27.9,", "48.7", "49.2,", "31.4,", "45.5", "51.3,", "31.1,", "50.8"], "regionBoundary": {"x2": 480.0, "y1": 62.8900146484375, "x1": 115.0, "y2": 113.8900146484375}, "caption": "Table 8: Evaluating models trained with different bootstrapping systems.", "page": 8}, {"figType": "Figure", "name": "10", "captionBoundary": {"x2": 387.89276123046875, "y1": 549.9685668945312, "x1": 209.65199279785156, "y2": 555.9710083007812}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 260.8900146484375, "x1": 72.0, "y2": 537.8900146484375}, "caption": "Figure 10: Attention weights for the decoder", "page": 15}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 698.4084659152561, "y1": 231.10355801052518, "x1": 131.08332951863608, "y2": 239.44032457139755}, "name": "1", "caption_text": "Table 1: IMOJIE vs. CopyAttention. CopyAttention suffers from stuttering, which IMOJIE does not.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 689.0, "y1": 86.0, "x1": 131.0, "y2": 231.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9273173014323, "y1": 391.0605112711588, "x1": 99.57083596123589, "y2": 416.001468234592}, "name": "2", "caption_text": "Table 2: IMOJIE vs. OpenIE-4. Pipeline nature of OpenIE-4 can get confused by long convoluted sentences, but IMOJIE responds gracefully.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 688.0, "y1": 273.0, "x1": 139.0, "y2": 374.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9185011121962, "y1": 241.29795498318143, "x1": 100.0, "y2": 266.2402682834201}, "name": "1", "caption_text": "Figure 1: One step of the sequential decoding process, for generating the ith extraction, which takes the original sentence and all extractions numbered 1, . . . , i\u2212 1, previously generated, as input.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 97.0, "x1": 104.0, "y2": 220.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2235955132378, "y1": 199.13130866156683, "x1": 99.6541659037272, "y2": 224.072265625}, "name": "2", "caption_text": "Figure 2: Ranking-Filtering subsystem for combining extractions from multiple open IE systems in an unsupervised fashion. (\u2018Exts\u2019=extractions.)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 87.0, "x1": 100.0, "y2": 199.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.222408718533, "y1": 218.09798346625433, "x1": 426.3430701361762, "y2": 259.64313083224823}, "name": "4", "caption_text": "Table 4: Models to solve the redundancy issue prevalent in Generative Neural OpenIE systems. All systems are bootstrapped on OpenIE-4.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 427.0, "y2": 200.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 314.679929945204, "x1": 99.57083596123589, "y2": 406.03900485568573}, "name": "3", "caption_text": "Table 3: Comparison of various OpenIE systems - nonneural, neural and proposed models. (*) Cannot compute AUC as Sense-OIE, MinIE do not emit confidence values for extractions and released code for Span-OIE does not provision calculation of confidence values. In these cases, we report the Last F1 as the Opt. F1", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 394.0, "y1": 86.0, "x1": 100.0, "y2": 315.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 425.48544141981336, "x1": 426.3430701361762, "y2": 483.6346944173177}, "name": "5", "caption_text": "Table 5: IMOJIE trained with different combinations of bootstrapping data from 3 systems - OpenIE-4, ClausIE, RNNOIE. Graph filtering is not used over single datasets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 281.0, "x1": 426.0, "y2": 426.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 189.03965420193143, "x1": 99.57083596123589, "y2": 247.19034830729166}, "name": "6", "caption_text": "Table 6: Performance of IMOJIE on aggregated dataset OpenIE-4+ClausIE+RnnOIE, with different filtering techniques. For comparison, SenseOIE trained on multiple system extractions gives an F1 of 17.2 on CaRB.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 377.0, "y1": 86.0, "x1": 106.0, "y2": 189.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.88428582085504, "y1": 483.4701961941189, "x1": 104.26805284288194, "y2": 491.8069627549913}, "name": "3", "caption_text": "Figure 3: Precision-Recall curve of OpenIE Systems.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 360.0, "y1": 276.0, "x1": 107.0, "y2": 464.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 175.20214716593424, "x1": 99.57083596123589, "y2": 216.74864027235242}, "name": "7", "caption_text": "Table 7: Measuring redundancy of extractions. MNO stands for Mean Number of Occurrences. IOU stands for Intersection over Union.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 86.0, "x1": 100.0, "y2": 175.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 616.2273406982422, "y1": 175.20214716593424, "x1": 213.26804690890842, "y2": 183.53890313042535}, "name": "8", "caption_text": "Table 8: Evaluating models trained with different bootstrapping systems.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 667.0, "y1": 86.0, "x1": 160.0, "y2": 175.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 290.26188320583765, "x1": 426.27360026041663, "y2": 315.2028401692708}, "name": "5", "caption_text": "Figure 5: Measuring performance of CopyAttention with BERT model upon changing the beam size", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 94.0, "x1": 434.0, "y2": 267.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15352545844183, "y1": 716.1313374837239, "x1": 100.0, "y2": 741.072252061632}, "name": "4", "caption_text": "Figure 4: Measuring performance with varying input sentence lengths", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 390.0, "y1": 528.0, "x1": 116.0, "y2": 691.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 613.8328976101345, "y1": 168.28406651814777, "x1": 215.6611124674479, "y2": 176.62082248263889}, "name": "9", "caption_text": "Table 9: Evaluation on other datasets with the CaRB evaluation strategy", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 649.0, "y1": 86.0, "x1": 180.0, "y2": 144.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 716.0589430067274, "y1": 911.7910597059462, "x1": 440.63470628526477, "y2": 920.1277838812933}, "name": "6", "caption_text": "Figure 6: BERT attention for the word \u2018founding\u2019", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 705.0, "y1": 340.0, "x1": 448.0, "y2": 891.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 707.2169833713108, "y1": 864.5494249131945, "x1": 120.78194088406032, "y2": 872.8861490885416}, "name": "7", "caption_text": "Figure 7: BERT attention for the word \u2018justice\u2019 Figure 8: BERT attention for the word \u2018prime\u2019", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 706.0, "y1": 264.0, "x1": 110.0, "y2": 845.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 386.9832356770833, "y1": 863.0119323730469, "x1": 116.16666581895616, "y2": 871.348656548394}, "name": "9", "caption_text": "Figure 9: BERT attention for the word \u2018minister\u2019", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 383.0, "y1": 265.0, "x1": 114.0, "y2": 842.0}, "page": 14, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 538.7399461534288, "y1": 763.8452317979601, "x1": 291.18332333034937, "y2": 772.1819559733073}, "name": "10", "caption_text": "Figure 10: Attention weights for the decoder", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 714.0, "y1": 426.0, "x1": 117.0, "y2": 729.0}, "page": 15, "dpi": 0}], "error": null, "pdf": "/work/host-output/33e8154a9cd1d70b8b7ad6e4b58251e96772abed/2020.acl-main.521.pdf", "dpi": 100}