{"raw_detected_boxes": [[{"x2": 728.0, "y1": 311.0, "x1": 428.0, "y2": 470.0}, {"x2": 684.0, "y1": 1012.0, "x1": 426.0, "y2": 1081.0}], [{"x2": 718.0, "y1": 93.0, "x1": 109.0, "y2": 239.0}], [], [{"x2": 709.0, "y1": 207.0, "x1": 448.0, "y2": 311.0}, {"x2": 644.0, "y1": 732.0, "x1": 520.0, "y2": 817.0}], [{"x2": 392.0, "y1": 95.0, "x1": 104.0, "y2": 311.0}, {"x2": 724.0, "y1": 98.0, "x1": 434.0, "y2": 383.0}, {"x2": 396.0, "y1": 429.0, "x1": 103.0, "y2": 577.0}], [{"x2": 714.0, "y1": 86.0, "x1": 116.0, "y2": 333.0}, {"x2": 384.0, "y1": 900.0, "x1": 118.0, "y2": 985.0}], [{"x2": 723.0, "y1": 256.0, "x1": 432.0, "y2": 524.0}, {"x2": 722.0, "y1": 668.0, "x1": 436.0, "y2": 938.0}], [], [], [], [], [], [{"x2": 716.0, "y1": 583.0, "x1": 444.0, "y2": 687.0}], [{"x2": 726.0, "y1": 210.0, "x1": 429.0, "y2": 396.0}, {"x2": 728.0, "y1": 733.0, "x1": 430.0, "y2": 960.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5465698242188, "y1": 354.1375427246094, "x1": 307.2760009765625, "y2": 407.9609680175781}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 221.8900146484375, "x1": 307.0, "y2": 341.8900146484375}, "caption": "Figure 1: Inline citations and references to figures and tables are annotated in S2ORC\u2019s structured full text. Citations are linked to bibliography entries, which are linked to other papers in S2ORC. Figure and table references are linked to their captions.", "page": 0}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 290.2705993652344, "y1": 721.3875732421875, "x1": 72.0, "y2": 739.3450317382812}, "imageText": ["Paper", "clustering", "0.93", "0.89", "Bib.", "linking", "(GROBID)", "1.00", "0.96", "Bib.", "linking", "(LATEX)", "1.00", "0.92", "Evaluated", "task", "Title", "Authors"], "regionBoundary": {"x2": 277.0, "y1": 642.8900146484375, "x1": 85.0, "y2": 708.8900146484375}, "caption": "Table 6: Accuracy of paper clustering and bibliography linking for titles and authors in sampled evaluation sets.", "page": 5}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5472412109375, "y1": 251.93954467773438, "x1": 71.99996948242188, "y2": 317.71710205078125}, "imageText": ["Multi-domain", "PaperField", "Beltagy", "et", "al.", "(2019)", "CLS", "65.71", "65.99", "\u00b1", "0.08", "Biomed", "&", "CS", "SciCite", "Cohan", "et", "al.", "(2019)", "CLS", "85.49", "84.76", "\u00b1", "0.37", "ACL-ARC", "Jurgens", "et", "al.", "(2018)", "CLS", "70.98", "68.45", "\u00b1", "2.47", "SciERC", "Luan", "et", "al.", "(2018)", "NER", "67.57", "68.93", "\u00b1", "0.19", "CS", "SciERC", "Luan", "et", "al.", "(2018)", "REL", "79.97", "81.77", "\u00b1", "1.64", "Biomed", "EBM-NLP", "Nye", "et", "al.", "(2018)", "PICO", "72.28", "72.35", "\u00b1", "0.95", "GENIA", "Kim", "et", "al.", "(2003)", "DEP", "(LAS)", "90.43", "90.80", "\u00b1", "0.19", "GENIA", "Kim", "et", "al.", "(2003)", "DEP", "(UAS)", "91.99", "92.31", "\u00b1", "0.18", "ChemProt", "Krallinger", "et", "al.", "(2017)", "REL", "83.64", "84.59", "\u00b1", "0.93", "BC5CDR", "Li", "et", "al.", "(2016)", "NER", "90.01", "90.41", "\u00b1", "0.06", "JNLPBA", "Collier", "and", "Kim", "(2004)", "NER", "77.28", "77.70", "\u00b1", "0.25", "NCBI-disease", "Dog\u0306an", "et", "al.", "(2014)", "NER", "88.57", "88.70", "\u00b1", "0.52", "Domain", "Dataset", "Reference", "Task", "SCIBERT", "S2ORC-", "SCIBERT"], "regionBoundary": {"x2": 515.0, "y1": 68.3463134765625, "x1": 82.0, "y2": 239.8900146484375}, "caption": "Table 5: S2ORC-SCIBERT test results are comparable with reported SCIBERT test results on the set of tasks and datasets from Beltagy et al. (2019), to which we refer the reader for descriptions. Reported statistics are spanlevel F1 for NER, token-level F1 for PICO, dependency parsing (DEP), and macro-F1 for relation (REL) and text (CLS) classification. We report micro-F1 for ChemProt. All S2ORC-SCIBERT results are the mean \u00b1 standard deviation of 5 runs with different random seeds. Beltagy et al. (2019) do not report standard deviation or number of runs.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.54736328125, "y1": 184.01254272460938, "x1": 71.99999237060547, "y2": 302.43798828125}, "imageText": ["Saier", "and", "Fa\u0308rber", "(2019)\u2020", "1.0M", "snippets", "no", "MAG", "physics,", "math,", "CS", "RefSeer", "(Huang", "et", "al.,", "2015)", "1.0M", "snippets", "no", "CiteSeerX", "multi", "S2ORC", "(PDF-parse)", "8.1M", "full", "text", "yes", "S2ORC", "(full)", "multi", "S2ORC", "(LATEX-parse)", "1.5M", "full", "text", "yes", "S2ORC", "(full)", "physics,", "math,", "CS", "PubMed", "Central", "(OA)", "2.6M", "full", "text", "yes", "PubMed", "bio,", "med", "AAN", "(Radev", "et", "al.,", "2009)", "25k", "full", "text", "no", "ACL", "Anthology", "comp", "ling", "Academic", "disciplines", "Linked", "to", "graph", "References", "to", "tables", "/", "\ufb01gures", "/", "equations", "Citation", "contexts", "Corpus", "Papers", "w/", "body", "text"], "regionBoundary": {"x2": 524.0, "y1": 68.14127349853516, "x1": 74.0, "y2": 171.8900146484375}, "caption": "Table 1: A comparison of S2ORC with other publicly-available academic text corpora. Of the other corpora: PubMed Central (OA) links to PubMed, which contains 30M papers at the time of writing. AAN links to the ACL Anthology (which contained 25k papers at the time of dataset construction, and 54k papers at the time of writing). Saier and Fa\u0308rber (2019) is derived from arXiv and links to MAG (which contained 213M papers and other non-paper documents at the time of dataset construction, and 226M nodes at the time of writing). RefSeer links to CiteSeerX (which contained 1M papers at the time of dataset construction, and 6M papers at the time of writing). S2ORC contains three times more full text papers than PubMed Central (OA), the next largest corpus with bibliometric enhancements, while covering a more diverse set of academic disciplines. Citations in S2ORC are linked to the full set of S2ORC papers, 81.1M paper nodes derived from Semantic Scholar. In addition, the LATEX subset of S2ORC captures additional structure omitted by Saier and Fa\u0308rber (2019), who also parse LATEX sources from arXiv. \u2020Saier and Fa\u0308rber (2020) is an update to this work which now includes full text. It is released concurrently with this work.", "page": 1}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.5465698242188, "y1": 691.6975708007812, "x1": 307.2760009765625, "y2": 733.5660400390625}, "imageText": ["cs.CL", "\u201cTransA:", "An", "Adaptive", "Approach", "for", "Knowledge", "Graph", "Embedding\u201d", "cs.AI", "\u201cTorusE:", "Knowledge", "Graph", "Embedding", "on", "a", "Lie", "Group\u201d", "cs.CV", "\u201cImage-embodied", "Knowledge", "Representa-", "tion", "Learning\u201d", "stat.ML", "\u201cNeural", "Embeddings", "of", "Graphs", "in", "Hyper-", "bolic", "Space\u201d", "Region", "B", "cs.LG", "\u201cDenoising", "Criterion", "for", "Variational", "Auto-", "Encoding", "Framework\u201d", "cs.CV", "\u201cVariational", "methods", "for", "conditional", "multi-", "modal", "deep", "learning\u201d", "with", "Semi-Supervised", "Deep", "Generative", "Models\u201d", "cs.LG", "\u201cOn", "Unifying", "Deep", "Generative", "Models\u201d", "stat.ML", "\u201cLearning", "Disentangled", "Representations", "Region", "A"], "regionBoundary": {"x2": 521.0, "y1": 476.8900146484375, "x1": 312.0, "y2": 679.8900146484375}, "caption": "Table 7: Sampled papers in clusters from t-SNE embedding space in Figure 3. Region A consists of papers related to deep generative models; region B consists of papers concerned with graph representation learning.", "page": 6}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5465087890625, "y1": 394.9195556640625, "x1": 307.2760009765625, "y2": 448.74298095703125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 166.8900146484375, "x1": 307.0, "y2": 382.8900146484375}, "caption": "Figure 3: Word2vec embeddings associated with 20k papers in six AI-related arXiv categories visualized using t-SNE (van der Maaten and Hinton, 2008). Example papers from two randomly selected sub-regions A and B are given in Table 7.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5465698242188, "y1": 705.4155883789062, "x1": 307.2760009765625, "y2": 747.2830200195312}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 503.8900146484375, "x1": 307.0, "y2": 693.8900146484375}, "caption": "Figure 4: Visualization of contextual representations from layer 9 of S2ORC-SCIBERT on numeric surface forms in a subsample of body text from S2ORC. Labels are heuristics based on token-level patterns.", "page": 13}, {"figType": "Table", "name": "9", "captionBoundary": {"x2": 525.546630859375, "y1": 297.3655700683594, "x1": 307.2760009765625, "y2": 327.278076171875}, "imageText": ["Web", "Text", "Corpus", "(~2.8B)", "GPT2", "(Radford", "et", "al.,", "2019)", "BooksCorpus", "(800M)", "CC-News", "(~3.8B)", "OpenWebText", "(~1.9B)", "Stories", "(~1.6B)", "ROBERTA", "(Liu", "et", "al.,", "2019b)", "BooksCorpus", "(800M)", "Wikipedia", "(2.5B)", "BERT", "(Devlin", "et", "al.,", "2019)", "1BW", "(800M)", "Wikipedia", "(1.9B)", "WMT", "2008-2012", "(3.6B)", "ELMO", "(Peters", "et", "al.,", "2018a)", "Language", "model", "Training", "data"], "regionBoundary": {"x2": 524.0, "y1": 147.8900146484375, "x1": 309.0, "y2": 284.8900146484375}, "caption": "Table 9: Reported and estimated (several papers report corpus size in terms of bytes) token counts of training data used to train language models.", "page": 13}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 523.1381225585938, "y1": 506.6715393066406, "x1": 309.6809997558594, "y2": 512.6740112304688}, "imageText": ["PyPDF2", "error", "0.54M", "Over", "50", "pages", "2.27M", "Page", "width", ">", "height", "0.28M", "PDFAlto", "error", "0.21M", "Filter", "Number", "of", "PDFs"], "regionBoundary": {"x2": 516.0, "y1": 413.8900146484375, "x1": 317.0, "y2": 494.8900146484375}, "caption": "Table 8: PDFs filtered out before GROBID processing", "page": 12}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 524.0864868164062, "y1": 235.78652954101562, "x1": 308.7349853515625, "y2": 241.78900146484375}, "imageText": ["No", "title", "20k", "No", "authors", "0.3M", "<", "100", "chars", "of", "text", "80.0M", "Not", "English", "15.2M", "Filter", "Number", "of", "papers"], "regionBoundary": {"x2": 510.0, "y1": 143.8900146484375, "x1": 323.0, "y2": 223.8900146484375}, "caption": "Table 2: Post-processing data quality filters for papers", "page": 3}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 290.2708435058594, "y1": 433.9895324707031, "x1": 71.99998474121094, "y2": 469.8800354003906}, "imageText": ["Bibliography", "entries", "27.6", "21.9", "Linked", "bib.", "entries", "19.3", "6.8\u2020", "Inline", "cite", "spans", "(abstract)", "0.7", "-", "Inline", "cite", "spans", "(body)", "45.2", "46.8", "Paragraphs", "(abstract)", "1.1", "-", "Paragraphs", "(body)", "9.9", "93.3*", "Statistic", "GROBID", "LATEX"], "regionBoundary": {"x2": 288.0, "y1": 307.8900146484375, "x1": 74.0, "y2": 421.8900146484375}, "caption": "Table 4: Extraction and linking statistics over PDF and LATEX parses. Reported values are averaged over all open access papers, which consist of 8.1M GROBIDparsed PDFs and 1.5M parsed LATEX sources.", "page": 4}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 290.2705993652344, "y1": 236.33255004882812, "x1": 72.0, "y2": 290.15606689453125}, "imageText": ["Papers", "w/", "PDF", "28.9M", "(35.6%)", "Papers", "w/", "bibliographies", "27.6M", "(34.1%)", "Papers", "w/", "GROBID", "full", "text", "8.1M", "(10.0%)", "Papers", "w/", "LaTeX", "full", "text", "1.5M", "(1.8%)", "Papers", "w/", "publisher", "abstract", "73.4M", "(90.4%)", "Papers", "w/", "DOIs", "52.2M", "(64.3%)", "Papers", "w/", "Pubmed", "IDs", "21.5M", "(26.5%)", "Papers", "w/", "PMC", "IDs", "4.7M", "(5.8%)", "Papers", "w/", "ArXiv", "IDs", "1.7M", "(2.0%)", "Papers", "w/", "ACL", "IDs", "42k", "(0.1%)", "Total", "papers", "81.1M"], "regionBoundary": {"x2": 288.0, "y1": 62.8900146484375, "x1": 74.0, "y2": 223.8900146484375}, "caption": "Table 3: Statistics on paper provenance. We note that categories are not mutually exclusive and do not sum to 100%. All papers in S2ORC have either a publisherprovided abstract or an associated PDF from which we derive full text and/or bibliography entries, or both.", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5465087890625, "y1": 293.4045715332031, "x1": 307.2760009765625, "y2": 311.362060546875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 281.8900146484375}, "caption": "Figure 2: Distribution of papers by Microsoft Academic field of study.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 491.8576982286241, "x1": 426.772223578559, "y2": 566.6124555799696}, "name": "1", "caption_text": "Figure 1: Inline citations and references to figures and tables are annotated in S2ORC\u2019s structured full text. Citations are linked to bibliography entries, which are linked to other papers in S2ORC. Figure and table references are linked to their captions.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 311.0, "x1": 428.0, "y2": 473.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268934461805, "y1": 255.5729760064019, "x1": 99.9999894036187, "y2": 420.0527615017361}, "name": "1", "caption_text": "Table 1: A comparison of S2ORC with other publicly-available academic text corpora. Of the other corpora: PubMed Central (OA) links to PubMed, which contains 30M papers at the time of writing. AAN links to the ACL Anthology (which contained 25k papers at the time of dataset construction, and 54k papers at the time of writing). Saier and Fa\u0308rber (2019) is derived from arXiv and links to MAG (which contained 213M papers and other non-paper documents at the time of dataset construction, and 226M nodes at the time of writing). RefSeer links to CiteSeerX (which contained 1M papers at the time of dataset construction, and 6M papers at the time of writing). S2ORC contains three times more full text papers than PubMed Central (OA), the next largest corpus with bibliometric enhancements, while covering a more diverse set of academic disciplines. Citations in S2ORC are linked to the full set of S2ORC papers, 81.1M paper nodes derived from Semantic Scholar. In addition, the LATEX subset of S2ORC captures additional structure omitted by Saier and Fa\u0308rber (2019), who also parse LATEX sources from arXiv. \u2020Saier and Fa\u0308rber (2020) is an update to this work which now includes full text. It is released concurrently with this work.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 86.0, "x1": 100.0, "y2": 256.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 727.8978983561198, "y1": 327.48129102918836, "x1": 428.798590766059, "y2": 335.81805759006073}, "name": "2", "caption_text": "Table 2: Post-processing data quality filters for papers", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 709.0, "y1": 199.0, "x1": 431.0, "y2": 328.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 328.2396528455946, "x1": 100.0, "y2": 402.9945373535156}, "name": "3", "caption_text": "Table 3: Statistics on paper provenance. We note that categories are not mutually exclusive and do not sum to 100%. All papers in S2ORC have either a publisherprovided abstract or an associated PDF from which we derive full text and/or bibliography entries, or both.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 100.0, "y2": 328.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 407.506349351671, "x1": 426.772223578559, "y2": 432.44730631510413}, "name": "2", "caption_text": "Figure 2: Distribution of papers by Microsoft Academic field of study.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 93.0, "x1": 433.0, "y2": 383.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15394931369354, "y1": 602.7632395426432, "x1": 99.99997880723741, "y2": 652.6111602783203}, "name": "4", "caption_text": "Table 4: Extraction and linking statistics over PDF and LATEX parses. Reported values are averaged over all open access papers, which consist of 8.1M GROBIDparsed PDFs and 1.5M parsed LATEX sources.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 428.0, "x1": 103.0, "y2": 586.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 349.91603427463104, "x1": 99.99995761447482, "y2": 441.27375284830725}, "name": "5", "caption_text": "Table 5: S2ORC-SCIBERT test results are comparable with reported SCIBERT test results on the set of tasks and datasets from Beltagy et al. (2019), to which we refer the reader for descriptions. Reported statistics are spanlevel F1 for NER, token-level F1 for PICO, dependency parsing (DEP), and macro-F1 for relation (REL) and text (CLS) classification. We report micro-F1 for ChemProt. All S2ORC-SCIBERT results are the mean \u00b1 standard deviation of 5 runs with different random seeds. Beltagy et al. (2019) do not report standard deviation or number of runs.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 86.0, "x1": 100.0, "y2": 350.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1536102294922, "y1": 1001.9271850585938, "x1": 100.0, "y2": 1026.8680996365017}, "name": "6", "caption_text": "Table 6: Accuracy of paper clustering and bibliography linking for titles and authors in sampled evaluation sets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 392.0, "y1": 892.0, "x1": 101.0, "y2": 1002.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 548.4993828667534, "x1": 426.772223578559, "y2": 623.2541402180989}, "name": "3", "caption_text": "Figure 3: Word2vec embeddings associated with 20k papers in six AI-related arXiv categories visualized using t-SNE (van der Maaten and Hinton, 2008). Example papers from two randomly selected sub-regions A and B are given in Table 7.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 239.0, "x1": 432.0, "y2": 530.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 960.6910705566406, "x1": 426.772223578559, "y2": 1018.8417222764757}, "name": "7", "caption_text": "Table 7: Sampled papers in clusters from t-SNE embedding space in Figure 3. Region A consists of papers related to deep generative models; region B consists of papers concerned with graph representation learning.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 662.0, "x1": 433.0, "y2": 944.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 726.5807257758246, "y1": 703.710471259223, "x1": 430.1124996609158, "y2": 712.0472378200955}, "name": "8", "caption_text": "Table 8: PDFs filtered out before GROBID processing", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 575.0, "x1": 430.0, "y2": 704.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 413.0077362060547, "x1": 426.772223578559, "y2": 454.5528835720486}, "name": "9", "caption_text": "Table 9: Reported and estimated (several papers report corpus size in terms of bytes) token counts of training data used to train language models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 204.0, "x1": 427.0, "y2": 413.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 979.7438727484808, "x1": 426.772223578559, "y2": 1037.89308336046}, "name": "4", "caption_text": "Figure 4: Visualization of contextual representations from layer 9 of S2ORC-SCIBERT on numeric surface forms in a subsample of body text from S2ORC. Labels are heuristics based on token-level patterns.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 716.0, "x1": 429.0, "y2": 960.0}, "page": 13, "dpi": 0}], "error": null, "pdf": "/work/host-output/b7fbf073699562f1243750b484effcdfa4df85d9/2020.acl-main.447.pdf", "dpi": 100}