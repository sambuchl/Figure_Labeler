{"raw_detected_boxes": [[], [], [], [{"x2": 417.0, "y1": 97.0, "x1": 93.0, "y2": 413.0}], [{"x2": 725.0, "y1": 108.0, "x1": 449.0, "y2": 355.0}], [{"x2": 754.0, "y1": 90.0, "x1": 439.0, "y2": 428.0}, {"x2": 717.0, "y1": 813.0, "x1": 468.0, "y2": 909.0}], [{"x2": 726.0, "y1": 515.0, "x1": 459.0, "y2": 725.0}], [{"x2": 723.0, "y1": 165.0, "x1": 106.0, "y2": 377.0}, {"x2": 411.0, "y1": 507.0, "x1": 105.0, "y2": 674.0}], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 540.0060424804688, "y1": 317.245361328125, "x1": 313.2010192871094, "y2": 350.176025390625}, "imageText": ["model", "Fine", "Binary", "SVM", "(Lei", "et", "al.,", "2015)", "38.3", "81.3", "Nbow(Lei", "et", "al.,", "2015)", "44.5", "82.0", "Para-vec(Le", "and", "Mikolov,", "2014)", "48.7", "87.8", "DAN(Iyyer", "et", "al.,", "2015)", "48.2", "86.8", "RAE(Socher", "et", "al.,", "2011b)", "43.2", "82.4", "MVRNN(Socher", "et", "al.,", "2012)", "44.4", "82.9", "RNTN(Socher", "et", "al.,", "2013)", "45.7", "85.4", "DRNN(Irsoy", "and", "Cardie,", "2014)", "49.8", "86.8", "RLSTM(Tai", "et", "al.,", "2015)", "51.0", "88.0", "CLSTM(Zhou", "et", "al.,", "2015)", "49.2", "87.8", "DCNN(Kalchbrenner", "et", "al.,", "2014)", "48.5", "86.9", "CNN-MC(Kim,", "2014)", "47.4", "88.1", "CNN-nostatic(Kim,", "2014)", "48.0", "87.2", "TCNN", "(Lei", "et", "al.,", "2015)", "50.6", "87.0", "TCNN+phrases(Lei", "et", "al.,", "2015)", "51.2", "88.6", "ours", "49.2", "87.2", "ours+phrases", "51.9", "88.7"], "regionBoundary": {"x2": 547.0, "y1": 61.0, "x1": 313.0, "y2": 308.0}, "caption": "Table 1: Standford Sentiment Treebank Classification accuracy results. \u201cFine\u201d denotes the accuracy on the fine-grained dataset with 5 labels. \u201cBinary\u201d denotes binary classification results.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 539.999755859375, "y1": 663.6013793945312, "x1": 313.2010192871094, "y2": 682.9830322265625}, "imageText": ["model", "Acc", "discriminative(Tur", "et", "al.,", "2010)", "95.5", "SVM", "(Shi", "et", "al.,", "2015b)", "95.6", "joint-RNN(Shi", "et", "al.,", "2015b)", "95.2", "ours", "97.9"], "regionBoundary": {"x2": 516.0, "y1": 585.0, "x1": 337.0, "y2": 655.0}, "caption": "Table 2: ATIS intent classification accuracy comparison of different models.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 539.9974365234375, "y1": 530.765380859375, "x1": 313.2010192871094, "y2": 550.14697265625}, "imageText": ["model", "Acc", "SVM", "(Silva", "et", "al.,", "2010)", "95.0", "Para-vec(Le", "and", "Mikolov,", "2014)", "91.8", "AdaSent(Zhao", "et", "al.,", "2015)", "92.4", "CNN-MC(Kim,", "2014)", "92.2", "CNN-nostatic(Kim,", "2014)", "93.6", "DCNN(Kalchbrenner", "et", "al.,", "2014)", "93.0", "LSTM(Zhou", "et", "al.,", "2015)", "93.2", "BiLSTM(Zhou", "et", "al.,", "2015)", "93.0", "CLSTM(Zhou", "et", "al.,", "2015)", "94.6", "ours", "94.8"], "regionBoundary": {"x2": 523.0, "y1": 371.0, "x1": 330.0, "y2": 522.0}, "caption": "Table 3: TREC Question type Classification accuracy comparison of different models.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 540.0029907226562, "y1": 303.6423645019531, "x1": 72.0009994506836, "y2": 336.5730285644531}, "imageText": ["Negative", "Prediction", "(groundtruth:Negative)", "-2", "-1", "0", "1", "2", "Negative", "Prediction", "(groundtruth:Negative)", "a", "waste", "of", "good", "performance", "2", "1", "0", "-1", "-2", "Postive", "Prediction", "hardly", "to", "be", "bad", "2", "1", "0", "-1", "-2", "Negative", "Prediction", "a", "successful", "failure", "2", "1", "0", "-1", "-2", "Negative", "Prediction", "not", "so", "good", "2", "1", "0", "-1", "-2"], "regionBoundary": {"x2": 524.0, "y1": 118.522216796875, "x1": 75.97467803955078, "y2": 270.0}, "caption": "Figure 4: Example predictions given by our model trained on Stanford Sentiment Treebank fine-grained data. The expected sentiment score of each word is plotted in the figure. The score range from \u22122 to 2, where a score \u22122 means very \u201cnegative\u201d, 0 stands for \u201cneutral\u201d and 2 means \u201cvery positive\u201d.", "page": 7}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 298.8060607910156, "y1": 505.9853820800781, "x1": 72.00098419189453, "y2": 579.5640258789062}, "imageText": ["depth", "3", "depth", "2", "depth", "1", "Validation", "accuracy", "cy", "u", "ra", "a", "cc", "Te", "st", "85", "85.5", "86", "86.5", "87", "87.5", "88", "88.5", "89", "89.5", "89", "88.5", "88", "87.5", "87", "86.5", "86", "85.5", "85", "84.5"], "regionBoundary": {"x2": 304.0, "y1": 361.0, "x1": 69.0, "y2": 489.0}, "caption": "Figure 3: Stanford Sentiment Treebank Binary Classification accuracy comparison among models using the same parameter configuration except the number of DLSTM layers. For each number of DLSTM layers, 10 models are run independently using different random initialization. Horizontal axis gives the validation accuracy. Vertical axis shows the test accuracy.", "page": 7}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 298.8059997558594, "y1": 313.72637939453125, "x1": 72.00098419189453, "y2": 414.404052734375}, "imageText": ["\ud835\udc3f\ud835\udc46\ud835\udc47\ud835\udc402", "\ud835\udc3f\ud835\udc46\ud835\udc47\ud835\udc401", "\ud835\udc3f\ud835\udc46\ud835\udc47\ud835\udc400", "\ud835\udc562,\ud835\udc61", "\ud835\udc532,\ud835\udc61", "\ud835\udc561,\ud835\udc61", "\ud835\udc531,\ud835\udc61", "\ud835\udc5c1,\ud835\udc61", "\ud835\udf0e", "\u210e1,\ud835\udc61", "\ud835\udf0e", "Tanh", "\ud835\udc501,\ud835\udc61", "\ud835\udf0e", "Tan", "h", "\ud835\udc5c0,\ud835\udc61", "\ud835\udc560,\ud835\udc61", "\u210e0,\ud835\udc61", "\ud835\udf0e", "Tanh", "\ud835\udc500,\ud835\udc61", "\ud835\udf0e", "Tan", "h", "\ud835\udc5c2,\ud835\udc61", "\ud835\udf0e", "\u210e2,\ud835\udc61", "\ud835\udf0e", "Tanh", "\ud835\udc502,\ud835\udc61", "\ud835\udf0e", "Tan", "h", "\ud835\udc65\ud835\udc61", "\ud835\udc562,\ud835\udc61\u22121", "\ud835\udc532,\ud835\udc61\u22121", "\ud835\udc561,\ud835\udc61\u22121", "\ud835\udc531,\ud835\udc61\u22121", "\ud835\udc5c1,\ud835\udc61\u22121", "\ud835\udf0e", "\u210e1,\ud835\udc61\u22121", "\ud835\udf0e", "Tanh", "\ud835\udc501,\ud835\udc61\u22121", "\ud835\udf0e", "Tan", "h", "\ud835\udc5c0,\ud835\udc61\u22121", "\ud835\udc560,\ud835\udc61\u22121", "\u210e0,\ud835\udc61\u22121", "\ud835\udf0e", "Tanh", "\ud835\udc500,\ud835\udc61\u22121", "\ud835\udf0e", "Tan", "h", "\ud835\udc5c2,\ud835\udc61\u22121", "\ud835\udf0e", "\u210e2,\ud835\udc61\u22121", "\ud835\udf0e", "Tanh", "\ud835\udc502,\ud835\udc61\u22121", "\ud835\udf0e", "Tan", "h", "\ud835\udc65\ud835\udc61\u22121"], "regionBoundary": {"x2": 306.0037384033203, "y1": 70.0, "x1": 64.0, "y2": 298.0}, "caption": "Figure 1: DLSTM based nonlinear feature mapping for bigram \u201cxt\u22121xt\u201d. Three LSTM units are used to extract features from each word position. The bottom LSTM0 is used for first order feature extraction from the current word. The output from the lower LSTM unit at current word position and the memory cell from lower LSTM at previous word position are fed to the higher LSTM units. Such information propagation is highlighted in the figure by bold orange lines.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 540.0057373046875, "y1": 274.9213562011719, "x1": 313.200927734375, "y2": 402.6970520019531}, "imageText": ["dh\u00d7l", "dh", "h\u00d7l", "h\u00d7l", "k\u00d7l", "Average", "pooling", "...", "Classification", "features", "Concatenate", "different", "level", "...", "x0", "x1", "x2", "DLSTM", "DLSTM", "DLSTM", "...", "High", "level", "features", "zd", "Low", "level", "features", "z0", "Word", "vector"], "regionBoundary": {"x2": 522.73388671875, "y1": 78.0, "x1": 323.2945251464844, "y2": 255.3260498046875}, "caption": "Figure 2: CNN based query classification using DLSTM feature mapping. The input sequence is represented by a k\u00d7 l matrix where column t is the word vector for the tth word in the sequence. The word vectors are mapped by a stack of DLSTM layers to multi-level feature representations z0, ...,zd . As illustrated in Figure 1, each level feature representation is the sum of outputs from different LSTM units. The multi-level features are concatenated and reduced to a dh-dimensional vector where d is the number of DLSTM layers, h is the output size of each LSTM unit. A classification layer gives the prediction output.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 415.00833299424914, "y1": 435.7310824924045, "x1": 100.00136693318684, "y2": 575.5611843532986}, "name": "1", "caption_text": "Figure 1: DLSTM based nonlinear feature mapping for bigram \u201cxt\u22121xt\u201d. Three LSTM units are used to extract features from each word position. The bottom LSTM0 is used for first order feature extraction from the current word. The output from the lower LSTM unit at current word position and the memory cell from lower LSTM at previous word position are fed to the higher LSTM units. Such information propagation is highlighted in the figure by bold orange lines.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 430.0, "y1": 97.0, "x1": 89.0, "y2": 414.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0079684787327, "y1": 381.835216946072, "x1": 435.00128851996527, "y2": 559.3014611138237}, "name": "2", "caption_text": "Figure 2: CNN based query classification using DLSTM feature mapping. The input sequence is represented by a k\u00d7 l matrix where column t is the word vector for the tth word in the sequence. The word vectors are mapped by a stack of DLSTM layers to multi-level feature representations z0, ...,zd . As illustrated in Figure 1, each level feature representation is the sum of outputs from different LSTM units. The multi-level features are concatenated and reduced to a dh-dimensional vector where d is the number of DLSTM layers, h is the output size of each LSTM unit. A classification layer gives the prediction output.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 108.0, "x1": 449.0, "y2": 355.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0083923339844, "y1": 440.6185574001736, "x1": 435.0014156765408, "y2": 486.3555908203125}, "name": "1", "caption_text": "Table 1: Standford Sentiment Treebank Classification accuracy results. \u201cFine\u201d denotes the accuracy on the fine-grained dataset with 5 labels. \u201cBinary\u201d denotes binary classification results.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 760.0, "y1": 85.0, "x1": 435.0, "y2": 445.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9996609157986, "y1": 921.6685824924044, "x1": 435.0014156765408, "y2": 948.5875447591145}, "name": "2", "caption_text": "Table 2: ATIS intent classification accuracy comparison of different models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 734.0, "y1": 813.0, "x1": 451.0, "y2": 926.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9964396158854, "y1": 737.1741400824652, "x1": 435.0014156765408, "y2": 764.093017578125}, "name": "3", "caption_text": "Table 3: TREC Question type Classification accuracy comparison of different models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 743.0, "y1": 498.0, "x1": 442.0, "y2": 742.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.004153781467, "y1": 421.72550625271265, "x1": 100.00138812594943, "y2": 467.46253967285156}, "name": "4", "caption_text": "Figure 4: Example predictions given by our model trained on Stanford Sentiment Treebank fine-grained data. The expected sentiment score of each word is plotted in the figure. The score range from \u22122 to 2, where a score \u22122 means very \u201cnegative\u201d, 0 stands for \u201cneutral\u201d and 2 means \u201cvery positive\u201d.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 162.0, "x1": 106.0, "y2": 377.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 415.00841776529944, "y1": 702.7574751112196, "x1": 100.00136693318684, "y2": 804.9500359429253}, "name": "3", "caption_text": "Figure 3: Stanford Sentiment Treebank Binary Classification accuracy comparison among models using the same parameter configuration except the number of DLSTM layers. For each number of DLSTM layers, 10 models are run independently using different random initialization. Horizontal axis gives the validation accuracy. Vertical axis shows the test accuracy.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 423.0, "y1": 502.0, "x1": 96.0, "y2": 679.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/84268c79f5eadf721224adf700d1555de33b2856/N16-1176.pdf", "dpi": 100}