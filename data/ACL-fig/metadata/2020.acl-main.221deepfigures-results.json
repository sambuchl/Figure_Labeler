{"raw_detected_boxes": [[{"x2": 729.0, "y1": 309.0, "x1": 428.0, "y2": 720.0}], [], [{"x2": 725.0, "y1": 87.0, "x1": 105.0, "y2": 268.0}], [{"x2": 636.0, "y1": 90.0, "x1": 195.0, "y2": 272.0}, {"x2": 348.0, "y1": 345.0, "x1": 148.0, "y2": 409.0}], [], [{"x2": 666.0, "y1": 87.0, "x1": 163.0, "y2": 235.0}, {"x2": 724.0, "y1": 358.0, "x1": 426.0, "y2": 608.0}, {"x2": 712.0, "y1": 702.0, "x1": 445.0, "y2": 993.0}, {"x2": 398.0, "y1": 777.0, "x1": 109.0, "y2": 879.0}], [{"x2": 730.0, "y1": 87.0, "x1": 429.0, "y2": 193.0}, {"x2": 730.0, "y1": 254.0, "x1": 429.0, "y2": 361.0}], [{"x2": 374.0, "y1": 104.0, "x1": 124.0, "y2": 306.0}], [{"x2": 728.0, "y1": 94.0, "x1": 100.0, "y2": 322.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Figure", "boundary": {"x2": 488.71343994140625, "y1": 205.76455688476562, "x1": 105.74199676513672, "y2": 211.76702880859375}, "text": "Figure 2: Segmentation of data into turn pairs, and how the inference LSTM makes predictions.", "name": "2", "page": 2}], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2002563476562, "y1": 530.675537109375, "x1": 307.2760009765625, "y2": 574.0379638671875}, "imageText": ["Response", "Offset", "(Seconds)", "0", "True", "Predicted", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "Sampling", "Output", "Probabilities", "0", "0", "0", "0", "0", "1", "System", "Turn", "User", "Turn", "Inference", "LSTM", "Feature", "extraction", "\u201cNot", "right", "now...\u201d", "work", "now?\u201d", "Response", "Encoder\u201cAre", "you", "doing", "any", "kind", "of", "volunteer"], "regionBoundary": {"x2": 524.7403564453125, "y1": 222.8900146484375, "x1": 308.4325256347656, "y2": 518.8900146484375}, "caption": "Figure 1: Overview of how our model generates the distribution of turn-switch offset timings using an encoding of a dialogue system response hz , and features extracted from the user\u2019s speech xn.", "page": 0}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.54638671875, "y1": 449.91754150390625, "x1": 306.9670104980469, "y2": 467.875}, "imageText": ["9", "wKL", "=", "10", "\u22124", "0.1122", "1.5057", "0.4689", "10", "wKL", "=", "10", "\u22123", "0.1125", "0.8015", "0.4697", "11", "wKL", "=", "10", "\u22122", "0.1181", "0.0000", "0.5035", "12", "wKL", "=", "10", "\u22121", "0.1189", "0.0000", "0.5052", "Inclusion", "of", "VAE", "8", "wKL", "=", "0.0", "0.1114", "3.3879", "0.4601", "6", "Only", "Acoustic", "0.1112", "\u2013", "0.5053", "Inference", "Ablation", "7", "Only", "Linguistic", "0.1167", "\u2013", "0.4923", "5", "Only", "Linguistic", "0.1144", "\u2013", "0.4817", "Encoder", "Ablation4", "Only", "Acoustic", "0.1114", "\u2013", "0.4627", "3", "No", "Encoder", "0.1183", "\u2013", "0.4934", "2", "Fixed", "Probability", "0.1295", "\u2013", "1.4546", "Fixed", "Probability", "1", "Full", "Model", "0.1094", "\u2013", "0.4539", "No", "VAE", "#", "Model", "LBCE", "LKL", "MAE", "Details"], "regionBoundary": {"x2": 526.0, "y1": 255.8900146484375, "x1": 307.0, "y2": 437.8900146484375}, "caption": "Table 1: Experimental results on our test set. Lower is better in all cases. Best results shown in bold.", "page": 5}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5473022460938, "y1": 183.01052856445312, "x1": 71.64099884033203, "y2": 224.8780517578125}, "imageText": ["50", "ms", ">", "<S", "IL", ">", "<w", "hy", ">", "<S", "IL", "<u", "h>", ">", "E", "C", "S", "P", "<U", "N", ">", "E", "C", "S", "P", "<U", "N", ">", "<b", "ut", ">", "E", "C", "S", "P", "<U", "N", "IL", ">", "But", "Uhhh", "Why?", "<S"], "regionBoundary": {"x2": 480.0, "y1": 62.15389633178711, "x1": 117.0, "y2": 170.8900146484375}, "caption": "Figure 5: The user\u2019s linguistic feature representation scheme. The embedding for each word is triggered 100 ms after the ground truth end of the word, to simulate ASR delay. The UNSPEC embedding begins 100ms after a word\u2019s start frame and holds information about whether a word is being spoken (before it has been recognized) and the length of each word.", "page": 5}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 290.9380187988281, "y1": 651.55859375, "x1": 72.0, "y2": 681.4710083007812}, "imageText": ["(b)", "Fixed", "Probability", "True", "Predicted", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "Offset", "(Seconds)", "(a)", "Full", "Model", "True", "Predicted", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "Offset", "(Seconds)"], "regionBoundary": {"x2": 290.33819580078125, "y1": 556.8900146484375, "x1": 72.0, "y2": 646.2030029296875}, "caption": "Figure 6: Generated offset distributions for the test set using the full model and the fixed probability (random) model.", "page": 5}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 527.2002563476562, "y1": 733.1435546875, "x1": 307.2760009765625, "y2": 751.10205078125}, "imageText": ["(b)", "Yes/No", "Vector", "Representation", "1", "0", "1.0", "0.5", "0.0", "0.5", "1.0", "Offset", "(Seconds)", "VAE", "1", "0", "No", "Encoder", "1", "0", "Random", "1", "0", "Full", "Model", "1", "0", "True", "Distribution", "yes", "no", "1", "0", "(a)", "BC/Statement", "Vector", "Representation", "1", "0", "1.0", "0.5", "0.0", "0.5", "1.0", "Offset", "(Seconds)", "VAE", "1", "0", "No", "Encoder", "1", "0", "Random", "1", "0", "Full", "Model", "1", "0", "True", "Distribution", "BC", "State", "1", "0"], "regionBoundary": {"x2": 512.5929565429688, "y1": 505.65252685546875, "x1": 320.2467041015625, "y2": 727.7890014648438}, "caption": "Figure 7: Generated offset distributions for selected response dialogue acts using different model conditions.", "page": 5}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 527.2001953125, "y1": 157.19155883789062, "x1": 307.2760009765625, "y2": 175.1490478515625}, "imageText": ["(b)", "Only", "Linguistic", "True", "Predicted", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "Offset", "(Seconds)", "(a)", "Only", "Acoustic", "True", "Predicted", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "Offset", "(Seconds)"], "regionBoundary": {"x2": 525.6132202148438, "y1": 62.8900146484375, "x1": 307.0, "y2": 151.8370361328125}, "caption": "Figure 8: Generated offset distributions for the inference network ablation.", "page": 6}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 525.5398559570312, "y1": 278.2495422363281, "x1": 307.2760009765625, "y2": 297.7010498046875}, "imageText": ["(b)", "wKL", "=", "10\u22123", "sd", "nn", "ny", "b", "(a)", "wKL", "=", "0.0", "sd", "nn", "ny", "b"], "regionBoundary": {"x2": 526.0, "y1": 182.8900146484375, "x1": 307.0, "y2": 273.89105224609375}, "caption": "Figure 9: T-SNE plots of z for four different dialogue acts using two different wKL settings.", "page": 6}, {"figType": "Figure", "name": "10", "captionBoundary": {"x2": 252.17726135253906, "y1": 237.20553588867188, "x1": 107.5999984741211, "y2": 243.2080078125}, "imageText": ["Interpolated", "Distributions", "agree-accept", "reject", "interpolated", "1.6", "1.4", "1.2", "1.0", "0.8", "0.6", "0.4", "0.2", "0.0", "1.00", "0.75", "0.50", "0.25", "0.00", "0.25", "0.50", "0.75", "1.00", "Offset", "(Seconds)"], "regionBoundary": {"x2": 272.79205322265625, "y1": 74.67047119140625, "x1": 89.36064147949219, "y2": 220.3045654296875}, "caption": "Figure 10: Interpolated distributions", "page": 7}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 209.12347412109375, "y1": 307.3135681152344, "x1": 150.6529998779297, "y2": 313.3160400390625}, "imageText": ["RELURELU", "RELU", "RELU"], "regionBoundary": {"x2": 258.0, "y1": 241.8900146484375, "x1": 105.0, "y2": 294.8900146484375}, "caption": "Figure 4: VAE", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5472412109375, "y1": 211.01956176757812, "x1": 72.0, "y2": 228.97705078125}, "imageText": ["Master", "Linguistic", "Acoustic", ">", "O", "K", "IT", "T", "<W", "A", "K", ">", "T", "O", "N", "E", "<N", "O", "k", "w", "or", "ss", "C", "ro", "K", ">", "T", "O", "uh", "R", "ed", "<S", "IL", "do", "ne", "bu", "t", "I", "ha", "ve", "no", "w", "N", "ot", "rig", "ht"], "regionBoundary": {"x2": 458.0, "y1": 62.372840881347656, "x1": 140.4159393310547, "y2": 198.8900146484375}, "caption": "Figure 3: The encoder is three stacked Bi-LSTMs. We use special embeddings (shown in purple) to represent the acoustic states corresponding to the first and last tokens (WAIT and NONE) of the system\u2019s turn.", "page": 3}, {"figType": "Figure", "name": "11", "captionBoundary": {"x2": 373.4373474121094, "y1": 250.09750366210938, "x1": 224.10800170898438, "y2": 256.0999755859375}, "imageText": ["(b)", "Generated", "distributions", "for", "six", "turn", "pairs.", "The", "high-", "lighted", "regions", "indicate", "the", "region", "that", "was", "preferred", "by", "listeners.", "The", "red", "line", "indicates", "the", "ground", "truth", "offset.", "1", "0", "1", "Modal", "Offsets", "1", "0", "1", "1", "0", "1", "Non-Modal", "Offsets", "(a)", "Early,", "modal,", "and", "late", "regions.", "1.4", "Mode", "=", "+157", "ms", "Early", "/", "Late", "Cutoffs", "1.2", "1.0", "0.8", "0.6", "0.4", "0.2", "1.5", "1.0", "0.5", "0.0", "0.5", "1.0", "1.5", "0.0"], "regionBoundary": {"x2": 527.03369140625, "y1": 62.65403747558594, "x1": 71.83848571777344, "y2": 244.74200439453125}, "caption": "Figure 11: Listening test experiments", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 737.0493570963541, "x1": 426.772223578559, "y2": 797.2749498155382}, "name": "1", "caption_text": "Figure 1: Overview of how our model generates the distribution of turn-switch offset timings using an encoding of a dialogue system response hz , and features extracted from the user\u2019s speech xn.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 309.0, "x1": 427.0, "y2": 737.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 678.7686665852864, "y1": 285.78410678439667, "x1": 146.86388439602322, "y2": 294.1208733452691}, "name": "2", "caption_text": "Figure 2: Segmentation of data into turn pairs, and how the inference LSTM makes predictions.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 87.0, "x1": 100.0, "y2": 285.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 293.08272467719183, "x1": 100.0, "y2": 318.023681640625}, "name": "3", "caption_text": "Figure 3: The encoder is three stacked Bi-LSTMs. We use special embeddings (shown in purple) to represent the acoustic states corresponding to the first and last tokens (WAIT and NONE) of the system\u2019s turn.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 636.0, "y1": 86.0, "x1": 195.0, "y2": 276.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 290.4492696126302, "y1": 426.82440016004773, "x1": 209.24027760823566, "y2": 435.1611667209201}, "name": "4", "caption_text": "Figure 4: VAE", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 358.0, "y1": 336.0, "x1": 145.0, "y2": 426.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 254.18128967285156, "x1": 99.50138727823892, "y2": 312.33062744140625}, "name": "5", "caption_text": "Figure 5: The user\u2019s linguistic feature representation scheme. The embedding for each word is triggered 100 ms after the ground truth end of the word, to simulate ASR delay. The UNSPEC embedding begins 100ms after a word\u2019s start frame and holds information about whether a word is being spoken (before it has been recognized) and the length of each word.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 666.0, "y1": 87.0, "x1": 163.0, "y2": 236.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925537109375, "y1": 624.8854743109808, "x1": 426.3430701361762, "y2": 649.8263888888889}, "name": "1", "caption_text": "Table 1: Experimental results on our test set. Lower is better in all cases. Best results shown in bold.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 356.0, "x1": 426.0, "y2": 625.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 1018.2549370659722, "x1": 426.772223578559, "y2": 1043.197292751736}, "name": "7", "caption_text": "Figure 7: Generated offset distributions for selected response dialogue acts using different model conditions.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 702.0, "x1": 445.0, "y2": 1010.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 404.08058166503906, "y1": 904.9424913194445, "x1": 100.0, "y2": 946.4875115288628}, "name": "6", "caption_text": "Figure 6: Generated offset distributions for the test set using the full model and the fixed probability (random) model.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 403.0, "y1": 773.0, "x1": 100.0, "y2": 896.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2224934895833, "y1": 218.3216094970703, "x1": 426.772223578559, "y2": 243.26256646050345}, "name": "8", "caption_text": "Figure 8: Generated offset distributions for the inference network ablation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 87.0, "x1": 427.0, "y2": 210.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9164666069878, "y1": 386.4576975504557, "x1": 426.772223578559, "y2": 413.4736802842882}, "name": "9", "caption_text": "Figure 9: T-SNE plots of z for four different dialogue acts using two different wKL settings.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 237.0, "x1": 426.0, "y2": 378.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 350.2461963229709, "y1": 329.45213317871094, "x1": 149.44444232516818, "y2": 337.7888997395833}, "name": "10", "caption_text": "Figure 10: Interpolated distributions", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 379.0, "y1": 104.0, "x1": 124.0, "y2": 307.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 518.6629825168186, "y1": 347.3576439751519, "x1": 311.2611134847005, "y2": 355.6944105360243}, "name": "11", "caption_text": "Figure 11: Listening test experiments", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 87.0, "x1": 100.0, "y2": 339.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/30f4a5b66ef98fddbd9277ef6d942e6ad25b804c/2020.acl-main.221.pdf", "dpi": 100}