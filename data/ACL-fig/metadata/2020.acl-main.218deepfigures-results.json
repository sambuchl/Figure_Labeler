{"raw_detected_boxes": [[{"x2": 727.0, "y1": 286.0, "x1": 430.0, "y2": 566.0}], [], [{"x2": 707.0, "y1": 87.0, "x1": 115.0, "y2": 220.0}, {"x2": 718.0, "y1": 319.0, "x1": 109.0, "y2": 487.0}], [{"x2": 399.0, "y1": 88.0, "x1": 101.0, "y2": 234.0}], [{"x2": 705.0, "y1": 135.0, "x1": 119.0, "y2": 281.0}], [{"x2": 726.0, "y1": 89.0, "x1": 104.0, "y2": 325.0}, {"x2": 395.0, "y1": 426.0, "x1": 108.0, "y2": 501.0}], [{"x2": 401.0, "y1": 136.0, "x1": 100.0, "y2": 306.0}], [{"x2": 728.0, "y1": 90.0, "x1": 106.0, "y2": 376.0}, {"x2": 726.0, "y1": 460.0, "x1": 111.0, "y2": 639.0}], [], [], [], [{"x2": 395.0, "y1": 334.0, "x1": 101.0, "y2": 486.0}], [], [{"x2": 721.0, "y1": 288.0, "x1": 106.0, "y2": 811.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.1922607421875, "y1": 423.19354248046875, "x1": 307.2760009765625, "y2": 441.1510009765625}, "imageText": [], "regionBoundary": {"x2": 525.0, "y1": 203.8900146484375, "x1": 308.0, "y2": 410.8900146484375}, "caption": "Figure 1: Explicit (top) and implicit (bottom) examples of yes-ands in the SPOLIN corpus. The text high-", "page": 0}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.197021484375, "y1": 252.01956176757812, "x1": 71.69100189208984, "y2": 281.93304443359375}, "imageText": ["95%", "Other", "P:", "I", "feel", "different", "right", "now.", "R:", "You", "wait", "and", "see.", "You\u2019re", "going", "to", "marry", "a", "big", "hero!", "5%", "Contra", "P:", "Hey,", "hey,", "aren\u2019t", "you", "afraid", "you\u2019ll", "burn", "out", "a", "tonsil?", "R:", "Tonsil?", "Me?", "No!", "Me", "burn", "a", "tonsil?", "My", "tonsils", "won\u2019t", "burn", "-", "As", "life\u2019s", "corners", "I...", "non-yes-and", "7%", "yes-but", "P:", "We", "all", "must", "say", "the", "chant", "that", "we", "say", "to", "the", "king.", "R:", "No,", "it\u2019s", "too", "erotic,", "please", "don\u2019t.", "78%", "Implicit", "P:", "Alright,", "pull", "up", "that", "plate", "so", "I", "can", "take", "a", "picture.", "R:", "Sorry,", "the", "coleslaw", "is", "de\ufb01nitely", "giving", "off", "a", "lot", "of", "glare.", "15%", "Explicit", "P:", "Does", "this", "map", "look", "homemade", "to", "you?", "R:", "Yeah,", "it", "looks", "like", "someone", "without", "a", "grasp", "of", "English", "drew", "it.", "yes-and", "Type", "Example", "%"], "regionBoundary": {"x2": 526.0, "y1": 65.33797454833984, "x1": 72.0, "y2": 236.16058349609375}, "caption": "Table 2: Examples and proportions of yes-and and non-yes-and types from annotations of 200 yes-ands and nonyes-ands in SPOLIN\u2019s development set. Determining whether a given dialogue pair is a yes-and or not is a non-trivial task, as the agreement or contradiction of the previous dialogue turn\u2019s context is usually implicit.", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 291.9258728027344, "y1": 373.1655578613281, "x1": 71.69100189208984, "y2": 450.8989562988281}, "imageText": ["yes-ands", "non-yes-ands", "Spontaneanation", "10,959", "6,087\u2217", "Cornell", "15,476", "18,351", "Total", "26,435", "24,438"], "regionBoundary": {"x2": 285.0, "y1": 308.3562927246094, "x1": 77.0, "y2": 360.8900146484375}, "caption": "Table 3: Composition of SPOLIN, including the development set. yes-ands and non-yes-ands from Cornell are validated by Turkers. \u2217Spontaneanation nonyes-ands are sampled from random combination of prompts and responses in Spontaneanation yes-ands to balance the dataset for training the classifier in the final iteration, as shown in the last column of Table 1.", "page": 5}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 525.5472412109375, "y1": 668.0015869140625, "x1": 72.0, "y2": 685.958984375}, "imageText": [], "regionBoundary": {"x2": 523.0, "y1": 135.8900146484375, "x1": 75.0, "y2": 655.8900146484375}, "caption": "Figure 8: Common mistakes that Turkers made in the early stages of data collection were corrected and added to the guidelines to aid new Turkers.", "page": 14}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.9242248535156, "y1": 233.45352172851562, "x1": 72.0, "y2": 311.18707275390625}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 221.8900146484375}, "caption": "Figure 5: Interface used by human evaluators to rank responses based on their quality as a yes-and, where a rank of 1 is most preferred. The correct ranking is shown for this example. The option ranked 1 is a yesbut: it does not reject a reality but rather rejects a suggestion and provides refining information that is most coherent to the prompt.", "page": 6}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 527.197509765625, "y1": 598.2655639648438, "x1": 71.99996948242188, "y2": 616.2230224609375}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 205.8900146484375, "x1": 75.0, "y2": 586.8900146484375}, "caption": "Figure 7: Explanation of the label space for yes-ands and non-yes-ands and the detailed instructions for the transcription task.", "page": 13}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.2010498046875, "y1": 363.04754638671875, "x1": 72.0, "y2": 392.96099853515625}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 225.8900146484375, "x1": 75.0, "y2": 350.8900146484375}, "caption": "Figure 3: Amazon Mechanical Turk interface for transcribing yes-ands from Spontaneanation episodes. Approximate transcriptions with speaker turns and time stamps generated from Amazon Transcribe are provided for additional guidance.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.1956176757812, "y1": 180.66152954101562, "x1": 72.0, "y2": 210.57501220703125}, "imageText": [], "regionBoundary": {"x2": 515.0, "y1": 61.8900146484375, "x1": 82.0, "y2": 168.8900146484375}, "caption": "Figure 2: An illustration of the yes-and collection workflow. The core SPOLIN corpus comprises Spontaneanation yes-ands and Cornell yes-ands (in blue boxes). However, SPOLIN can be augmented by including other generalpurpose dialogue corpora in place of Cornell in this workflow, as described in Section 5.", "page": 2}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 490.6805725097656, "y1": 741.0426025390625, "x1": 106.86299896240234, "y2": 747.0450439453125}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 74.8900146484375, "x1": 75.0, "y2": 728.8900146484375}, "caption": "Figure 6: Explanation of the objective and yes-and in the yes-and guideline provided to Turkers.", "page": 12}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.5447998046875, "y1": 283.2005310058594, "x1": 71.69100189208984, "y2": 313.113037109375}, "imageText": ["SPOLIN", "3.32", "I\u2019m", "in", "here.", "I\u2019m", "just", "trying", "to", "make", "sure", "I", "can", "get", "a", "bagel.", "DailyDialog+SPOLIN", "3.31", "Oh,", "yeah,", "the", "guy", "who", "left", "the", "bagel.", "Gold", "1.87", "I", "can", "help", "you.", "The", "problem", "is", "that", "the", "bagels", "are", "burned.", "I\u2019m", "sorry,", "sir.", "I\u2019m", "not", "in", "the", "mood.", "I\u2019m", "not", "in", "the", "mood.", "DailyDialog", "3.37", "Excuse", "me.", "Is", "anybody", "in", "here?", "I\u2019d", "like", "a", "bagel.", "Hello?", "Is", "anybody", "in", "here?", "What?", "SPOLIN", "3.39", "And", "it\u2019s", "delicious!", "Cornell+SPOLIN", "3.34", "That\u2019s", "the", "kind", "of", "thing", "you", "do", "when", "you\u2019re", "in", "love.", "Gold", "2.01", "It", "was", "genius.", "It\u2019s", "making", "me", "hungry", "thinking", "about", "it.", "I", "made", "this", "beautiful", "salmon", "mousse", "that", "just", "looked", "like", "a", "puddle", "of", "spit.", "oh", "my", "goodness,", "i", "don\u2019t", "know", "her", "SPOLIN", "3.41", "Yeah,", "she\u2019s", "a", "bit", "of", "a", "mystery.", "Persona-chat+SPOLIN", "3.17", "So", "you", "remember", "her?", "I", "remember", "her", "in", "the", "shower.", "Gold", "1.92", "She", "does.", "From", "when", "you", "were", "a", "boy.", "Cornell", "3.73", "I", "know", "alotta", "women", "and", "I\u2019m", "sure", "she", "remembers", "me.", "Dataset", "Avg", "Rank", "\u2193", "Example", "Prompt", "Example", "Responses", "Persona-chat", "3.67"], "regionBoundary": {"x2": 526.0, "y1": 64.39251708984375, "x1": 71.0, "y2": 270.8900146484375}, "caption": "Table 4: Average human ranking of responses to prompts from Spontaneanation generated by models trained with SPOLIN, an existing dialog corpus, or both, based on the yes-and criteria. Rank is scaled from 1 to 4, lower is better.", "page": 7}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5469970703125, "y1": 471.99554443359375, "x1": 71.67098999023438, "y2": 501.9079895019531}, "imageText": ["Dataset", "Source", "Size\u2217", "DailyDialog", "(Li", "et", "al.,", "2017b)", "Crowdsourced", "104K", "Cornell", "Movie-Dialogs", "Corpus", "(Danescu-Niculescu-Mizil", "and", "Lee,", "2011)", "Movie", "scripts", "304K", "Persona-chat", "(Zhang", "et", "al.,", "2018)", "Crowdsourced", "162K", "The", "Ubuntu", "Dialogue", "Corpus", "(Lowe", "et", "al.,", "2015)", "Ubuntu", "chat", "logs", "7M", "Twitter", "Triple", "Conversations", "(Sordoni", "et", "al.,", "2015)", "Social", "media", "6K", "OpenSubtitles", "(Lison", "and", "Tiedemann,", "2016)", "Subtitles", "441M", "sentences", "SubTle", "(Eng)", "(Ameixa", "et", "al.,", "2013)", "Subtitles", "3.3M", "pairs", "London-Lund", "Corpus", "(Greenbaum", "and", "Svartvik,", "1990)", "Various", "sources", "500K", "words", "London-Lund", "Corpus", "2", "(P\u00f5ldvere", "et", "al.,", "2017)", "Various", "sources", "500K", "words", "SPOLIN", "(yes-and", "only)", "Improv,", "Movie", "scripts", "26K", "pairs", "SPOLIN-extended", "(yes-and", "only)", "Improv,", "Movie", "scripts,", "subtitles", "68K", "pairs"], "regionBoundary": {"x2": 526.0, "y1": 328.72039794921875, "x1": 71.0, "y2": 459.8900146484375}, "caption": "Table 5: A survey of publicly available English language text-based corpora frequently used for open-domain dialogue systems. The last two rows are our contribution. \u2217Size is measured as the number of total utterances (dialogue turns) unless otherwise specified.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 292.0146484375, "y1": 183.54153442382812, "x1": 71.69100189208984, "y2": 321.0511474609375}, "imageText": ["Iteration", "1", "2", "3", "4", "Spontaneanation", "+", "10,459", "10,459", "10,459", "10,459", "Spontaneanation", "\u2013", "-", "-", "3,225", "5,587", "Cornell", "+", "-", "3,327", "8,464", "12,220", "Cornell", "\u2013", "10,459", "13,786", "15,698", "17,092", "Total", "Training", "Samples", "20,198", "27,572", "37,846", "45,358", "Dev", "Set", "Acc.", "(Spont)", "80.9%", "73.6%", "71.6%", "73.0%", "Dev", "Set", "Acc.", "(Cornell)", "52.2%", "56.8%", "62.1%", "64.5%", "Con\ufb01dence", "Threshold", "95%", "70%", "50%", "50%", "New", "Extraction", "Volume", "12,360", "12,802", "5,150", "3,515", "New", "Proportion", "of", "yes-ands", "26.9%", "44.0%", "72.9%", "78.4%"], "regionBoundary": {"x2": 291.0, "y1": 64.90886688232422, "x1": 71.0, "y2": 168.280029296875}, "caption": "Table 1: Iterative data collection results over Cornell. + indicates yes-ands and \u2013 indicates non-yes-ands. These counts exclude 500 turns collected from each of Spontaneanation and Cornell to form the validation set. The New Extraction Volume row indicates the new number of yes-and candidates identified with the given confidence threshold, and the New Proportion of yes-and row show as a percentage how many of these candidates were indeed evaluated as yes-ands by Turkers. The proportion of yes-ands increases after each iteration despite the lower confidence threshold used to filter the new predictions with the updated classifier.", "page": 3}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 291.9244384765625, "y1": 362.446533203125, "x1": 71.64102172851562, "y2": 440.179931640625}, "imageText": ["Iteration", "4", "5", "6", "7", "Spontaneanation", "+", "10,459", "10,459", "10,459", "10,459", "Spontaneanation", "-", "5,587", "5,587", "5,587", "5,587", "Cornell", "+", "12,220", "14,976", "14,976", "14,976", "Cornell-", "17,092", "17,701", "17,701", "17,701", "SubTle", "+", "-", "2,621", "20,617", "33,155", "SubTle-", "-", "7,865", "14,799", "17,325", "Total", "Training", "Samples", "45,358", "59,209", "84,319", "99,203", "Dev", "Set", "Acc.", "(Spont)", "73.0%", "72.1%", "68.4%", "75.2%", "Dev", "Set", "Acc.", "(Cornell)", "64.5%", "63.3%", "63.3%", "61.0%", "Con\ufb01dence", "Threshold", "50%", "/", "70%*", "70%", "70%", "70%", "New", "Extraction", "Volume", "3,515", "/", "10,486*", "36,608", "15,424", "14,979", "New", "Proportion", "of", "yes-ands", "78.4%", "/", "25.0%*", "58.4%", "83.2%", "76.0%", "A", "Appendix"], "regionBoundary": {"x2": 291.0, "y1": 207.72100830078125, "x1": 72.0, "y2": 350.8900146484375}, "caption": "Table 6: Continuation of Table 1 with the extended version of SPOLIN that includes extracted yes-ands from SubTle. SubTle is collected from the fourth iteration onwards. *Statistics for Cornell/SubTle are shown separately. The same classifier is used for extracting candidates from Cornell and SubTle, but they are datasets with significantly different characteristics.", "page": 11}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 527.286865234375, "y1": 220.06552124023438, "x1": 71.64105224609375, "y2": 249.97802734375}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 61.8900146484375, "x1": 75.0, "y2": 207.8900146484375}, "caption": "Figure 4: Amazon Mechanical Turk interface for validating yes-and candidates determined by the yes-and classifier. Turkers are asked to correct minor errors in grammar, spelling, and punctuation for qualifying yes-and candidates, which are then categorized as \u2018Typo/Fix.\u2019", "page": 4}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 525.5439453125, "y1": 651.7825927734375, "x1": 72.0, "y2": 669.739990234375}, "imageText": [], "regionBoundary": {"x2": 523.0, "y1": 151.8900146484375, "x1": 75.0, "y2": 639.8900146484375}, "caption": "Figure 9: Annotated examples provided to Turkers for understanding the label space of the yes-and transcription task.", "page": 15}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2114732530382, "y1": 587.768809000651, "x1": 426.772223578559, "y2": 612.709723578559}, "name": "1", "caption_text": "Figure 1: Explicit (top) and implicit (bottom) examples of yes-ands in the SPOLIN corpus. The text high-", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 286.0, "x1": 430.0, "y2": 569.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2161356608073, "y1": 250.91879102918836, "x1": 100.0, "y2": 292.46529473198785}, "name": "2", "caption_text": "Figure 2: An illustration of the yes-and collection workflow. The core SPOLIN corpus comprises Spontaneanation yes-ands and Cornell yes-ands (in blue boxes). However, SPOLIN can be augmented by including other generalpurpose dialogue corpora in place of Cornell in this workflow, as described in Section 5.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 707.0, "y1": 87.0, "x1": 115.0, "y2": 233.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2236802842882, "y1": 504.23270331488715, "x1": 100.0, "y2": 545.7791646321614}, "name": "3", "caption_text": "Figure 3: Amazon Mechanical Turk interface for transcribing yes-ands from Spontaneanation episodes. Approximate transcriptions with speaker turns and time stamps generated from Amazon Transcribe are provided for additional guidance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 314.0, "x1": 100.0, "y2": 504.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.57590060763886, "y1": 254.91879781087238, "x1": 99.57083596123589, "y2": 445.9043714735243}, "name": "1", "caption_text": "Table 1: Iterative data collection results over Cornell. + indicates yes-ands and \u2013 indicates non-yes-ands. These counts exclude 500 turns collected from each of Spontaneanation and Cornell to form the validation set. The New Extraction Volume row indicates the new number of yes-and candidates identified with the given confidence threshold, and the New Proportion of yes-and row show as a percentage how many of these candidates were indeed evaluated as yes-ands by Turkers. The proportion of yes-ands increases after each iteration despite the lower confidence threshold used to filter the new predictions with the updated classifier.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 88.0, "x1": 99.0, "y2": 236.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3428683810764, "y1": 305.6465572781033, "x1": 99.50146145290799, "y2": 347.19170464409723}, "name": "4", "caption_text": "Figure 4: Amazon Mechanical Turk interface for validating yes-and candidates determined by the yes-and classifier. Turkers are asked to correct minor errors in grammar, spelling, and punctuation for qualifying yes-and candidates, which are then categorized as \u2018Typo/Fix.\u2019", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 118.0, "x1": 117.0, "y2": 281.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2180853949652, "y1": 350.0271691216363, "x1": 99.57083596123589, "y2": 391.57367282443573}, "name": "2", "caption_text": "Table 2: Examples and proportions of yes-and and non-yes-and types from annotations of 200 yes-ands and nonyes-ands in SPOLIN\u2019s development set. Determining whether a given dialogue pair is a yes-and or not is a non-trivial task, as the agreement or contradiction of the previous dialogue turn\u2019s context is usually implicit.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 89.0, "x1": 100.0, "y2": 331.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4526011149088, "y1": 518.2854970296224, "x1": 99.57083596123589, "y2": 626.2485504150391}, "name": "3", "caption_text": "Table 3: Composition of SPOLIN, including the development set. yes-ands and non-yes-ands from Cornell are validated by Turkers. \u2217Spontaneanation nonyes-ands are sampled from random combination of prompts and responses in Spontaneanation yes-ands to balance the dataset for training the classifier in the final iteration, as shown in the last column of Table 1.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 396.0, "y1": 426.0, "x1": 100.0, "y2": 518.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45031229654944, "y1": 324.2410024007161, "x1": 100.0, "y2": 432.20426771375867}, "name": "5", "caption_text": "Figure 5: Interface used by human evaluators to rank responses based on their quality as a yes-and, where a rank of 1 is most preferred. The correct ranking is shown for this example. The option ranked 1 is a yesbut: it does not reject a reality but rather rejects a suggestion and provides refining information that is most coherent to the prompt.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 403.0, "y1": 122.0, "x1": 100.0, "y2": 323.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9233330620659, "y1": 393.3340708414713, "x1": 99.57083596123589, "y2": 434.87921820746527}, "name": "4", "caption_text": "Table 4: Average human ranking of responses to prompts from Spontaneanation generated by models trained with SPOLIN, an existing dialog corpus, or both, based on the yes-and criteria. Rank is scaled from 1 to 4, lower is better.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 88.0, "x1": 99.0, "y2": 393.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9263848198784, "y1": 655.5493672688801, "x1": 99.5430416531033, "y2": 697.0944298638237}, "name": "5", "caption_text": "Table 5: A survey of publicly available English language text-based corpora frequently used for open-domain dialogue systems. The last two rows are our contribution. \u2217Size is measured as the number of total utterances (dialogue turns) unless otherwise specified.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 457.0, "x1": 99.0, "y2": 656.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4506089952257, "y1": 503.39796278211804, "x1": 99.50141906738281, "y2": 611.3610161675347}, "name": "6", "caption_text": "Table 6: Continuation of Table 1 with the extended version of SPOLIN that includes extracted yes-ands from SubTle. SubTle is collected from the fourth iteration onwards. *Statistics for Cornell/SubTle are shown separately. The same classifier is used for extracting candidates from Cornell and SubTle, but they are datasets with significantly different characteristics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 330.0, "x1": 100.0, "y2": 503.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.218763563368, "y1": 830.9243943956163, "x1": 99.99995761447482, "y2": 855.8653089735243}, "name": "7", "caption_text": "Figure 7: Explanation of the label space for yes-ands and non-yes-ands and the detailed instructions for the transcription task.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 288.0, "x1": 106.0, "y2": 811.0}, "page": 13, "dpi": 0}], "error": null, "pdf": "/work/host-output/c84c1cfd6e2c67efbb972ecd2a06cdbff1915a95/2020.acl-main.218.pdf", "dpi": 100}