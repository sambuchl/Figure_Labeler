{"raw_detected_boxes": [[], [{"x2": 707.0, "y1": 86.0, "x1": 474.0, "y2": 283.0}], [], [{"x2": 739.0, "y1": 86.0, "x1": 104.0, "y2": 189.0}], [{"x2": 732.0, "y1": 89.0, "x1": 118.0, "y2": 203.0}, {"x2": 737.0, "y1": 249.0, "x1": 447.0, "y2": 407.0}], [{"x2": 401.0, "y1": 343.0, "x1": 110.0, "y2": 462.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "3", "captionBoundary": {"x2": 293.3641052246094, "y1": 329.1320495605469, "x1": 79.37879943847656, "y2": 334.9060974121094}, "imageText": ["Verb", "number", "28", "Training", "data", "111.25", "Testing", "data", "46.39", "FNN", "0.76", "0.82", "0.67", "SEB", "0.62", "MTTSEM1", "(verb-speci\ufb01c", "sentences)", "MTTSEM2", "(gold", "annotations)", "MTTSEM3", "(automatic", "annotations)"], "regionBoundary": {"x2": 293.0, "y1": 247.0, "x1": 80.0, "y2": 325.0}, "caption": "Table 3: Results on MTTSEM with different preprocessing.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 497.041015625, "y1": 146.0414276123047, "x1": 114.49410247802734, "y2": 151.81549072265625}, "imageText": ["Verb-speci\ufb01c", "Sentences", "Verb-speci\ufb01c", "Semantic", "Frames", "Mary", "resisted", "the", "temptation", "to", "answer", "her", "back", "and", "after", "a", "moment\u2019s", "silence", "[[Human", "1]]", "answer", "([[Human", "2]])", "back", "[[Human", "1]]", "Pamala", "Klein", "would", "seem", "to", "have", "a", "lot", "to", "answer", "for.", "[[Human]]", "have", "a", "lot", "to", "answer", "for", "[NO", "OBJ]", "and", "I", "will", "answer", "for", "her", "safety", "[[Human]]", "answer", "[NO", "OBJ]", "for", "[[Eventuality]]", "he", "cannot", "answer", "for", "Labour", "party", "policies", "[[Human]]", "answer", "[NO", "OBJ]", "for", "[[Eventuality]]", "it", "is", "\ufb01ction", "and", "can", "not", "be", "made", "real", "by", "acting", "it", "out", "[[Human]]", "act", "[[Event", "or", "Human", "Role", "or", "Emotion]]", "out", "You", "should", "try", "to", "build", "up", "a", "network", "of", "people", "you", "trust", "[[Human]]", "build", "([[Entity]])", "up"], "regionBoundary": {"x2": 529.0, "y1": 63.0, "x1": 83.0, "y2": 142.0}, "caption": "Table 2: Example results of our FNN model mapping verb-specific sentences to semantic frames on PDEV.", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 537.4297485351562, "y1": 318.1331787109375, "x1": 312.8999938964844, "y2": 364.14080810546875}, "imageText": ["Training", "data", "FNN", "SEB", "co", "re", "F", "-s", "1", "1", ".6", "3", "2", "5", ".2", "9", "5", "3", ".1", "7", "1", "0", "9", ".3", "7", "2", "2", "2", ".8", "1", "4", "4", "9", ".9", "8", "904", ".86", "1", "4", "2", "1", ".2", "2", "0.85", "0.80", "0.75", "0.70", "0.65", "0.60", "0.55"], "regionBoundary": {"x2": 531.0, "y1": 179.0, "x1": 323.96234130859375, "y2": 293.0}, "caption": "Figure 2: Results of FNN on PDEV2. The testing data is fixed at 606.60. The training data increases two times at each step. Y-axis represents B-cubed F-score for SEB and micro-average F-score for FNN.", "page": 4}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 537.4269409179688, "y1": 214.49998474121094, "x1": 312.8999938964844, "y2": 300.76104736328125}, "imageText": ["Vehicle", "Human", "move", "Human", "Entity", "move", "\u25cf", "\u25cf...\u25cf", "softmax", "...", "moved", "the", "old", "manThe", "old", "music", "deeply", "\u25cf", "\u25cf...\u25cf", "\u25cf...\u25cf\u25cf...\u25cf"], "regionBoundary": {"x2": 508.75909423828125, "y1": 62.0, "x1": 340.9764099121094, "y2": 201.351806640625}, "caption": "Figure 1: Model architecture for an example of learning semantic frames directly from verb-specific sentence. The sentence is divided into two windows. \u201dThe old music deeply\u201d is in the left window and \u201dthe old man\u201d is in the right window. The target verb \u201dmoved\u201d is not used in the input. The input is connected to output layer. Each unit of output layer corresponds to one semantic frame of the target verb.", "page": 1}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 537.4215087890625, "y1": 131.27061462402344, "x1": 74.11199951171875, "y2": 163.86383056640625}, "imageText": ["PDEV1", "407", "373.49", "158.32", "6.53", "0.73", "0.63", "-", "-", "PDEV2", "63", "1421.22", "606.60", "9.60", "0.82", "0.64", "-", "-", "MTDSEM", "4", "136.5", "159", "4.86", "0.7", "0.59", "0.52", "0.74", "3", "1546.33", "214.67", "Datasets", "Statistics", "B-cubed", "or", "micro-average", "F-score", "of", "Methods", "Verb", "number", "Training", "data", "Testing", "data", "Semantic", "frame", "number", "FNN", "SEB", "DULUTH", "BOB90"], "regionBoundary": {"x2": 532.0, "y1": 63.0, "x1": 80.0, "y2": 127.0}, "caption": "Table 1: Summary statistics for the datasets (left) and results of our FNN model against other methods (right). On the right side, MTDSEM is evaluated by B-cubed F-score for clustering. On PDEV1 and PDEV2, FNN model is evaluated by micro-average F-score. SEB is always evaluated by B-cubed F-score as the base score. DULUTH and BOB90 are Participant teams in 2015.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 746.4263068305121, "y1": 297.91664547390405, "x1": 434.5833248562283, "y2": 417.72367689344617}, "name": "1", "caption_text": "Figure 1: Model architecture for an example of learning semantic frames directly from verb-specific sentence. The sentence is divided into two windows. \u201dThe old music deeply\u201d is in the left window and \u201dthe old man\u201d is in the right window. The target verb \u201dmoved\u201d is not used in the input. The input is connected to output layer. Each unit of output layer corresponds to one semantic frame of the target verb.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 707.0, "y1": 86.0, "x1": 472.0, "y2": 300.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 746.4187622070312, "y1": 182.32029808892145, "x1": 102.93333265516493, "y2": 227.58865356445312}, "name": "1", "caption_text": "Table 1: Summary statistics for the datasets (left) and results of our FNN model against other methods (right). On the right side, MTDSEM is evaluated by B-cubed F-score for clustering. On PDEV1 and PDEV2, FNN model is evaluated by micro-average F-score. SEB is always evaluated by B-cubed F-score as the base score. DULUTH and BOB90 are Participant teams in 2015.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 746.0, "y1": 85.0, "x1": 103.0, "y2": 206.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 690.3347439236111, "y1": 202.83531612820096, "x1": 159.01958677503796, "y2": 210.85484822591144}, "name": "2", "caption_text": "Table 2: Example results of our FNN model mapping verb-specific sentences to semantic frames on PDEV.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 734.0, "y1": 85.0, "x1": 115.0, "y2": 214.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 746.4302062988281, "y1": 441.8516370985243, "x1": 434.5833248562283, "y2": 505.7511223687066}, "name": "2", "caption_text": "Figure 2: Results of FNN on PDEV2. The testing data is fixed at 606.60. The training data increases two times at each step. Y-axis represents B-cubed F-score for SEB and micro-average F-score for FNN.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 738.0, "y1": 246.0, "x1": 447.0, "y2": 407.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 407.4501461452908, "y1": 457.12784661187067, "x1": 110.24833255343967, "y2": 465.14735751681854}, "name": "3", "caption_text": "Table 3: Results on MTTSEM with different preprocessing.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 407.0, "y1": 326.0, "x1": 110.0, "y2": 468.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/9d04258144f2b97ef492bf762b0e46e8b4065bf9/N16-2001.pdf", "dpi": 100}