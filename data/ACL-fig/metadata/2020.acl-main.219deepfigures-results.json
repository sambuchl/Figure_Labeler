{"raw_detected_boxes": [[], [], [{"x2": 722.0, "y1": 96.0, "x1": 109.0, "y2": 347.0}, {"x2": 718.0, "y1": 434.0, "x1": 435.0, "y2": 535.0}], [{"x2": 382.0, "y1": 87.0, "x1": 116.0, "y2": 460.0}], [], [{"x2": 719.0, "y1": 89.0, "x1": 108.0, "y2": 211.0}, {"x2": 707.0, "y1": 267.0, "x1": 123.0, "y2": 391.0}], [{"x2": 726.0, "y1": 128.0, "x1": 103.0, "y2": 933.0}], [{"x2": 400.0, "y1": 88.0, "x1": 104.0, "y2": 219.0}, {"x2": 727.0, "y1": 88.0, "x1": 430.0, "y2": 215.0}], [], [], [{"x2": 639.0, "y1": 86.0, "x1": 517.0, "y2": 210.0}], [{"x2": 722.0, "y1": 170.0, "x1": 109.0, "y2": 551.0}, {"x2": 718.0, "y1": 591.0, "x1": 105.0, "y2": 952.0}], [{"x2": 718.0, "y1": 106.0, "x1": 106.0, "y2": 462.0}, {"x2": 722.0, "y1": 636.0, "x1": 105.0, "y2": 961.0}], [{"x2": 722.0, "y1": 283.0, "x1": 100.0, "y2": 812.0}], [{"x2": 728.0, "y1": 363.0, "x1": 100.0, "y2": 730.0}], [{"x2": 637.0, "y1": 125.0, "x1": 190.0, "y2": 352.0}, {"x2": 699.0, "y1": 837.0, "x1": 125.0, "y2": 983.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 516.5307006835938, "y1": 170.97756958007812, "x1": 78.2130126953125, "y2": 178.47503662109375}, "imageText": ["Model", "Combiner", "Text", "Encoders", "Image", "Encoder", "Turn", "1", "Turn", "2", "Turn", "3", "All", "R@1", "R@1", "R@1", "R@1", "R@1", "R@1", "R@5", "IR", "Baseline", "n/a", "n/a", "n/a", "-", "-", "-", "2.15", "5.86", "TRANSRESNETRET", "MM-Att", "Separate", "ResNet152", "35.7", "44.5", "40.5", "40.2", "67.0", "TRANSRESNETRET", "MM-Sum", "Separate", "ResNet152", "34.5", "46.0", "41.3", "40.6", "67.2", "TRANSRESNETRET", "MM-Sum", "Shared", "ResNeXt-IG-3.5B", "53.6", "47.0", "41.3", "47.3", "73.1", "TRANSRESNETRET", "MM-Att", "Shared", "ResNeXt-IG-3.5B", "54.4", "49.0", "43.3", "48.9", "74.2", "TRANSRESNETRET", "MM-Att", "Separate", "ResNeXt-IG-3.5B", "53.5", "50.5", "43.8", "49.3", "74.7", "TRANSRESNETRET", "MM-Sum", "Separate", "ResNeXt-IG-3.5B", "54.0", "51.9", "44.8", "50.3", "75.4"], "regionBoundary": {"x2": 522.0, "y1": 61.8900146484375, "x1": 76.0, "y2": 153.8900146484375}, "caption": "Table 2: Module choices on IMAGE-CHAT. We compare different module variations for TRANSRESNETRET .", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.716552734375, "y1": 300.6915588378906, "x1": 71.69100952148438, "y2": 342.55902099609375}, "imageText": ["TRANSRESNETRET", "(R@1/100", ")", "TRANSRESNETGEN", "(ROUGE-L)", "Modules", "Turn", "1", "Turn", "2", "Turn", "3", "All", "Turn", "1", "Turn", "2", "Turn", "3", "All", "Image", "Only", "37.6", "28.1", "20.7", "28.7", "21.1", "21.9", "22.4", "21.8", "Style", "Only", "18.3", "15.3", "17.0", "16.9", "20.2", "20.9", "22.0", "21.0", "Dialogue", "History", "Only", "1.0", "33.7", "32.3", "22.3", "18.9", "22.7", "23.7", "21.8", "Style", "+", "Dialogue", "(no", "image)", "18.3", "45.4", "43.1", "35.4", "20.4", "24.1", "24.8", "23.1", "Image", "+", "Dialogue", "(no", "style)", "37.6", "39.4", "32.6", "36.5", "21.3", "22.8", "23.6", "22.6", "Image", "+", "Style", "(no", "dialogue)", "54.0", "41.1", "35.2", "43.4", "23.7", "23.2", "23.8", "23.5", "Style", "+", "Dialogue", "+", "Image", "(full", "model)", "54.0", "51.9", "44.8", "50.3", "23.7", "24.2", "24.9", "24.3"], "regionBoundary": {"x2": 509.0, "y1": 191.8900146484375, "x1": 88.0, "y2": 283.8900146484375}, "caption": "Table 3: Ablations on IMAGE-CHAT. We compare variants of our best TRANSRESNET generative and retrieval models (ResNeXt-IG-3.5B image encoder, and MM-Sum + separate text encoders for retrieval) where we remove modalities: image, dialogue history and style conditioning, reporting R@1/100 for retrieval and ROUGE-L for generation for dialogue turns 1, 2 and 3 independently, as well as the average over all turns.", "page": 5}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 527.19677734375, "y1": 170.57955932617188, "x1": 306.9670104980469, "y2": 212.44708251953125}, "imageText": ["Style", "Score", "Neutral", "1.55", "Charming", "1.55", "Extravagant", "1.55", "Calm", "1.57", "Sweet", "1.58", "Spirited", "1.60", "Enthusiastic", "1.61", "Human", "2.55"], "regionBoundary": {"x2": 461.0, "y1": 61.8900146484375, "x1": 372.0, "y2": 153.8900146484375}, "caption": "Table 4: IGC Human Evaluation on responses from our TRANSRESNET MM-SUM model conditioned on various personalities. Responses were rated on a quality scale from 1 to 3, where 3 is the highest.", "page": 10}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.5407104492188, "y1": 542.3475341796875, "x1": 71.69100189208984, "y2": 560.3049926757812}, "imageText": ["Human", "Response", "The", "cemetary", "is", "at", "the", "foot", "a", "beautiful", "quartz", "mountain.", "TransResNet", "MM-Sum", "Well", "she\u2019s", "just", "a", "walking,", "talking", "garden!", "Context", "This", "woman", "is", "visiting", "the", "grave", "of", "a", "loved", "one.", "Question", "Where", "is", "the", "cemetery?", "Human", "Response", "What", "is", "ke\ufb01r?", "TransResNet", "MM-Sum", "You", "can", "get", "all", "the", "protein", "you", "want", "form", "the", "sugar.", "Context", "I", "cannot", "decide", "if", "this", "is", "milk", "or", "something", "else.", "Question", "It", "looks", "like", "milk,", "but", "it", "could", "also", "be", "ke\ufb01r.", "Human", "Response", "Yes,", "except", "for", "the", "silver", "portion", "at", "the", "end.", "TransResNet", "MM-Sum", "Just", "got", "my", "new", "wheels!", "Context", "I\u2019m", "thinking", "of", "getting", "these", "shocks", "on", "my", "bike.", "Question", "Are", "the", "shocks", "black", "in", "color?", "Human", "Response", "We", "started", "with", "a", "glass", "base", "and", "went", "from", "there.", "TransResNet", "MM-Sum", "OHMYGOSH", "EASTER", "EGG", "HUNT!", "I", "want", "to", "hunt", "for", "Easter", "eggs", "too!", "Context", "These", "are", "Easter", "eggs", "we", "made", "for", "art", "class.", "Question", "How", "did", "you", "make", "them?", "F", "Poorly", "Rated", "Examples", "from", "IGC", "Image", "IGC", "Round", "Output"], "regionBoundary": {"x2": 531.27587890625, "y1": 262.3431396484375, "x1": 72.0, "y2": 528.8900146484375}, "caption": "Table 6: Low rated examples from the IGC dataset test split where TRANSRESNETRET MM-Sum responses were rated the lowest (score of 1) by human evaluators.", "page": 14}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5482788085938, "y1": 690.4095458984375, "x1": 72.0, "y2": 732.2770385742188}, "imageText": ["A:", "Sweet", "I", "wish", "you", "could", "take", "me", "there,", "I", "would", "love", "to", "go", "with", "you!", "B:", "Spontaneous", "Then", "lets", "go", "there", "right", "now!", "Just", "you", "and", "me.", "Model", "prediction:", "A:", "Sweet", "This", "is", "so", "beautiful,", "I", "love", "nature", "and", "would", "love", "to", "see", "this", "place", "and", "meet", "the", "people", "who", "live", "there!", "A:", "Pompous", "Please.", "I", "could", "show", "you", "much", "prettier", "places", "in", "my", "own", "back", "yard.", "B:", "Offhand", "Its", "about", "as", "boring", "as", "you!!", "Model", "prediction:", "A:", "Pompous", "This", "archway", "is", "so", "dull", "and", "boring.", "I", "could", "have", "done", "a", "much", "better", "job", "with", "the", "garden", "in", "my", "own", "back", "yard.", "Model", "prediction:", "A:", "Happy", "Ooh,", "the", "wind", "looks", "perfect", "to", "\ufb02y", "this", "awesome", "kite!", "A:", "Happy", "This", "looks", "like", "something", "fun", "and", "exciting", "to", "do", "on", "vacation!", "B:", "Anxious", "oh", "dear", "what", "happens", "if", "he", "gets", "taken", "with", "the", "wind", "Turn", "3", "examples", "B:", "Whimsical", "Nonsense,", "this", "would", "be", "a", "great", "place", "to", "play!", "B:", "Blunt", "I", "would", "rather", "\ufb01nd", "some", "lawn.", "Those", "rocks", "look", "uncomfortable", "A:", "Maternal", "It", "must", "be", "very", "dangerous", "if", "children", "play", "there.", "Model", "predictions:", "B:", "Questioning", "Do", "you", "really", "think", "it", "is", "feasible?", "B:", "Amusing", "Well", "I", "would", "try", "to", "top", "you", "with", "a", "back\ufb02ip.", "A:", "Playful", "i", "would", "jump", "inside", "that", "waterfall", "Model", "predictions:", "B:", "Aloof", "It\u2019s", "just", "a", "regular", "old", "\ufb01eld.", "B:", "Frivolous", "So", "is", "every", "grass", "in", "the", "country", "A:", "Empathetic", "I", "understand", "that", "an", "open", "\ufb01eld", "full", "of", "beautiful", "foliage", "is", "a", "testament", "to", "our", "environment.", "Model", "predictions:", "Turn", "2", "examples", "paralyzed", "at", "the", "beach.", "A:", "Confused", "I", "don\u2019t", "understand", "why", "would", "you", "put", "rocks", "there?", "natures", "rocks", "at", "their", "best.", "A:", "Shy", "While", "the", "area", "looks", "nice,", "I\u2019d", "stay", "away,", "fear", "of", "tsunamis", "leaves", "me", "Model", "predictions:", "A:", "Respectful", "What", "an", "honor", "to", "have", "beautiful", "places", "like", "these", "to", "contemplate", "A:", "Opinionated", "This", "puppy", "looks", "cold", "get", "him", "a", "blanket.", "A:", "Imaginative", "Puppies", "are", "just", "the", "universe\u2019s", "way", "of", "telling", "us", "everything", "will", "be", "okay.", "Model", "predictions:", "A:", "Wishful", "I", "hope", "one", "day", "to", "have", "a", "dog", "this", "majestic.", "to", "get", "started", "with", "the", "restoration!", "A:", "Monstrous", "Some", "wretched", "town!.", "A:", "Earnest", "Yeah,", "we", "have", "\ufb01nally", "arrived", "at", "Grandpa\u2019s", "old", "barnhouse!", "I", "can\u2019t", "wait", "Model", "predictions:", "A:", "Artful", "This", "looks", "like", "a", "painting.", "Something", "out", "of", "a", "Norman", "Rockwell.", "Image", "Style", "Conversation", "Turn", "1", "examples"], "regionBoundary": {"x2": 524.0, "y1": 89.8900146484375, "x1": 74.0, "y2": 676.8900146484375}, "caption": "Figure 3: Example predictions from our TRANSRESNETRET (MM-Sum) model on the evaluation set using all candidates for turns 1\u20133 . Two speakers A & B with given style traits discuss a photo. The dialogue context before the model prediction is completed by humans, followed by one or more possible model responses, given different style conditioning. The model clearly uses the image, given style and dialogue history in formulating its response.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5418701171875, "y1": 601.1865844726562, "x1": 71.64102172851562, "y2": 619.14404296875}, "imageText": ["Human", "Response", "Yes,", "and", "I", "would", "quite", "enjoy", "spending", "a", "day", "here.", "TransResNet", "MM-Sum", "I", "think", "a", "picnic", "is", "more", "than", "a", "great", "possibility!", "Context", "This", "would", "be", "a", "great", "place", "to", "have", "a", "picnic.", "Question", "yes", "it", "would", "it", "seems", "very", "relaxing", "doesnt", "it?", "Human", "Response", "I", "am", "so", "proud,", "because", "he\u2019s", "been", "working", "really", "hard.", "TransResNet", "MM-Sum", "I", "am", "so", "proud", "of", "all", "that", "they", "accomplished.", "Context", "My", "nephew\u2019s", "choir", "did", "so", "well", "yesterday!", "Question", "That", "is", "great.", "You", "must", "be", "proud", "Human", "Response", "Yeah,", "they", "practice", "in", "this", "area", "for", "their", "shows.", "TransResNet", "MM-Sum", "These", "are", "the", "Blue", "Angels,", "they", "are", "truly", "one", "of", "a", "kind", "Context", "These", "just", "\ufb02ew", "over", "my", "house!", "Question", "Wow,", "aren\u2019t", "those", "Blue", "Angels?", "Human", "Response", "It", "de\ufb01nitely", "looks", "like", "it.", "TransResNet", "MM-Sum", "Oh", "my", "goodness,", "yes!", "I", "love", "Amsterdam!", "Context", "I\u2019d", "love", "to", "visit", "this", "city.", "Question", "Is", "this", "some", "city", "in", "Europe?", "Human", "Response", "I", "think", "it\u2019s", "a", "mortar", "and", "pestle.", "TransResNet", "MM-Sum", "I\u2019m", "not", "sure,", "but", "you", "could", "sell", "it", "for", "some", "cash!", "Context", "I", "bought", "this", "at", "a", "\ufb02ea", "market.", "Question", "What", "is", "this", "for?", "Human", "Response", "I", "don\u2019t", "know", "but", "they", "are", "so", "pretty.", "TransResNet", "MM-Sum", "I", "don\u2019t", "know", "but", "these", "\ufb02owers", "are", "gorgeous", "and", "look", "so", "bright!", "Context", "These", "\ufb02owers", "are", "growing", "in", "my", "back", "yard.", "Question", "What", "type", "of", "\ufb02owers", "are", "they?", "E", "Highly", "Rated", "Examples", "from", "IGC", "Image", "IGC", "Round", "Output"], "regionBoundary": {"x2": 526.0, "y1": 203.503173828125, "x1": 72.0, "y2": 587.8900146484375}, "caption": "Table 5: Highly rated examples from the IGC dataset test split where TRANSRESNETRET MM-Sum responses were rated the highest (score of 3) by human evaluators.", "page": 13}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 495.47760009765625, "y1": 397.0435485839844, "x1": 334.5429992675781, "y2": 403.0460205078125}, "imageText": ["Split", "train", "valid", "test", "Number", "of", "Images", "186,782", "5,000", "9,997", "Number", "of", "Dialogues", "186,782", "5,000", "9,997", "Number", "of", "Utterances", "355,862", "15,000", "29,991", "Style", "Types", "215", "215", "215", "Vocabulary", "Size", "46,371", "9,561", "13,550", "Tokens", "per", "Utterance", "12.3", "12.4", "12.4"], "regionBoundary": {"x2": 520.0, "y1": 312.8900146484375, "x1": 313.0, "y2": 384.8900146484375}, "caption": "Table 1: IMAGE-CHAT dataset statistics.", "page": 2}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5452270507812, "y1": 271.9135437011719, "x1": 72.0, "y2": 289.87103271484375}, "imageText": ["A:", "Not", "sure", "but", "fried", "goodness.", "A:", "I", "would", "never", "go", "camping", "in", "the", "woods", "for", "this", "very", "reason.", "A:", "There\u2019s", "probably", "more", "lame", "pave-", "ment", "on", "the", "other", "side!", "B:", "What", "is", "it", "called", "again?", "B:", "It", "was", "probably", "a", "Wolf", "coming", "to", "eat", "us", "because", "you", "talk", "too", "much.", "B:", "I", "doubt", "that\u2019s", "even", "a", "forest,", "it", "looks", "like", "a", "line", "of", "trees.", "A:", "I\u2019m", "so", "thankful", "for", "this", "delicious", "food.", "A:", "I", "just", "heard", "something", "out", "there", "and", "I", "have", "no", "idea", "what", "it", "was.", "A:", "What", "is", "the", "difference", "between", "the", "forest", "and", "the", "trees?", "Oh", "look,", "dry", "pave-", "ment.", "A:", "Peaceful", "B:", "Absentminded", "A:", "Fearful", "B:", "Miserable", "A:", "Erratic", "B:", "Skeptical"], "regionBoundary": {"x2": 519.8060302734375, "y1": 68.8900146484375, "x1": 78.67900085449219, "y2": 248.7340087890625}, "caption": "Figure 1: Some samples from the IMAGE-CHAT training set. For each sample we asked humans to engage in a conversation about the given image, where the two speakers, A and B, each have a given provided style.", "page": 2}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 291.9243469238281, "y1": 345.7365417480469, "x1": 72.0, "y2": 363.6940002441406}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 94.8900146484375, "x1": 72.0, "y2": 333.8900146484375}, "caption": "Figure 8: Instructions pane for crowdworkers when collecting the IMAGE-CHAT Evaluations.", "page": 12}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 291.9243469238281, "y1": 704.8865966796875, "x1": 72.0, "y2": 722.8450317382812}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 466.8900146484375, "x1": 72.0, "y2": 692.8900146484375}, "caption": "Figure 9: Instructions pane for crowdworkers when collecting the IGC Evaluations.", "page": 12}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 291.9244079589844, "y1": 172.63851928710938, "x1": 71.99998474121094, "y2": 226.4620361328125}, "imageText": [], "regionBoundary": {"x2": 290.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 160.8900146484375}, "caption": "Figure 4: Human evaluations on IMAGE-CHAT. Engagingness win rates of pairwise comparisons between human utterances and TRANSRESNETRET (ResNet152 or ResNeXt-IG-3.5B) or TRANSRESNETGEN , comparing over the rounds of dialogue.", "page": 7}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 527.2003784179688, "y1": 169.79556274414062, "x1": 307.1960144042969, "y2": 247.52911376953125}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 157.8900146484375}, "caption": "Figure 5: IGC Evaluations. The best model from Mostafazadeh et al. (2017) is compared to our best TRANSRESNETRET and TRASNRESNETGEN models. On the left, annotator\u2019s ratings of responses from the models are shown as a percentage of the annotator\u2019s ratings of human responses. On the right, BLEU-4 scores on the response task are shown.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 291.9243469238281, "y1": 347.3365478515625, "x1": 71.69098663330078, "y2": 413.1149597167969}, "imageText": [], "regionBoundary": {"x2": 279.0, "y1": 61.8900146484375, "x1": 83.0, "y2": 335.8900146484375}, "caption": "Figure 2: The TRANSRESNETRET multimodal architecture for grounded dialogue. There are several options: different image encoders (ResNet152 or ResNeXt-IG-3.5B), text encoders (shared or separate Transformers for history and response), and different multimodal combiners (sum or attention-based).", "page": 3}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 482.12921142578125, "y1": 409.4605407714844, "x1": 115.41600036621094, "y2": 415.4630126953125}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 136.8900146484375, "x1": 72.0, "y2": 397.8900146484375}, "caption": "Figure 6: Instructions pane for crowdworkers when collecting the second round of dialogue.", "page": 11}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 477.70538330078125, "y1": 697.8656005859375, "x1": 119.83899688720703, "y2": 703.8680419921875}, "imageText": [], "regionBoundary": {"x2": 522.0, "y1": 419.8900146484375, "x1": 72.0, "y2": 685.8900146484375}, "caption": "Figure 7: Instructions pane for crowdworkers when collecting the third round of dialogue.", "page": 11}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 527.2017822265625, "y1": 727.7945556640625, "x1": 71.69097900390625, "y2": 757.7080078125}, "imageText": ["Modules", "Turn", "1", "Turn", "2", "Turn", "3", "All", "Turn", "1", "Turn", "2", "Turn", "3", "All", "Image", "Only", "10.8", "11.0", "11.2", "11.0", "1.1", "1.3", "1.2", "1.2", "Style", "Only", "10.4", "9.8", "10.4", "10.2", "1.4", "1.5", "1.4", "1.4", "Dialogue", "History", "Only", "9.9", "11.4", "12.2", "11.2", "1.0", "1.9", "1.8", "1.6", "Style", "+", "Dialogue", "(no", "image)", "9.6", "12.5", "13.1", "11.7", "1.5", "2.1", "2.0", "1.9", "Image", "+", "Dialogue", "(no", "style)", "10.7", "11.1", "11.7", "11.2", "1.1", "1.7", "1.6", "1.5", "Image", "+", "Style", "(no", "dialogue)", "12.1", "11.6", "11.6", "11.8", "1.6", "1.5", "1.5", "1.6", "Style", "+", "Dialogue", "+", "Image", "(full", "model)", "12.3", "12.5", "13.1", "12.6", "1.7", "2.1", "2.0", "1.9", "H", "Additional", "Ablation", "Results", "TRANSRESNETGEN", "(F1)", "TRANSRESNETGEN", "(BLEU-4)"], "regionBoundary": {"x2": 507.0, "y1": 603.3211669921875, "x1": 71.99998474121094, "y2": 710.8900146484375}, "caption": "Table 7: Ablations on IMAGE-CHAT. We compare variants of our best TRANSRESNET generative model (ResNeXtIG-3.5B image encoder) where we remove modalities: image, dialogue history and style conditioning, reporting F1 and BLEU-4 for generation for dialogue turns 1, 2 and 3 independently, as well as the average over all turns.", "page": 15}, {"figType": "Figure", "name": "10", "captionBoundary": {"x2": 513.7211303710938, "y1": 581.9585571289062, "x1": 83.82498168945312, "y2": 587.9609985351562}, "imageText": ["A:", "It", "would", "take", "hard", "will", "and", "determination", "to", "scale", "that", "mighty", "peak", "B:", "Maybe", "one", "day", "on", "a", "smaller", "mountain", "A:", "Climbing", "a", "mountain", "can", "give", "one", "a", "special", "strength,", "you", "need", "to", "experience", "it", "B:", "I", "really", "don\u2019t", "think", "I", "could", "A:", "But", "could", "you?", "Could", "you", "truly", "climb", "this?", "B:", "Wow,", "that\u2019s", "fast.", "I", "would", "ski", "down", "that", "but", "I", "would", "need", "a", "lift", "to", "take", "me", "up", "A:", "I", "did", "it;", "i", "conquered", "this", "climb", "in", "only", "7", "hours", "and", "10", "minutes!", "B:", "You", "have", "climbed", "that?", "That", "seems", "really", "hard", "A:", "They", "are", "a", "mountain", "range", "I\u2019ve", "climed", "many", "times!", "B:", "It", "looks", "really", "cool!", "I", "wonder", "if", "you", "can", "ski", "on", "it", "A:", "It\u2019s", "the", "most", "beautiful", "mountain", "in", "the", "world!", "A:", "TransResNetRET", "MM-Sum", "(Extraordinary)", "B:", "Human", "(no", "style)"], "regionBoundary": {"x2": 463.0, "y1": 89.8900146484375, "x1": 135.0, "y2": 565.5650024414062}, "caption": "Figure 10: Long-form conversation with the model. The model is given a style here, while the human is not.", "page": 15}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9239264594183, "y1": 377.65769958496094, "x1": 100.0, "y2": 402.5986565483941}, "name": "1", "caption_text": "Figure 1: Some samples from the IMAGE-CHAT training set. For each sample we asked humans to engage in a conversation about the given image, where the two speakers, A and B, each have a given provided style.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 722.0, "y1": 96.0, "x1": 108.0, "y2": 348.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 688.163333468967, "y1": 551.4493730333116, "x1": 464.6430545383029, "y2": 559.786139594184}, "name": "1", "caption_text": "Table 1: IMAGE-CHAT dataset statistics.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 722.0, "y1": 434.0, "x1": 435.0, "y2": 552.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 482.411872016059, "x1": 99.5708147684733, "y2": 573.7707773844401}, "name": "2", "caption_text": "Figure 2: The TRANSRESNETRET multimodal architecture for grounded dialogue. There are several options: different image encoders (ResNet152 or ResNeXt-IG-3.5B), text encoders (shared or separate Transformers for history and response), and different multimodal combiners (sum or attention-based).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 387.0, "y1": 87.0, "x1": 116.0, "y2": 465.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 717.4037509494358, "y1": 237.46884663899738, "x1": 108.62918429904514, "y2": 247.88199530707465}, "name": "2", "caption_text": "Table 2: Module choices on IMAGE-CHAT. We compare different module variations for TRANSRESNETRET .", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 86.0, "x1": 105.0, "y2": 214.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.161878797743, "y1": 417.62716505262586, "x1": 99.57084655761719, "y2": 475.7764180501302}, "name": "3", "caption_text": "Table 3: Ablations on IMAGE-CHAT. We compare variants of our best TRANSRESNET generative and retrieval models (ResNeXt-IG-3.5B image encoder, and MM-Sum + separate text encoders for retrieval) where we remove modalities: image, dialogue history and style conditioning, reporting R@1/100 for retrieval and ROUGE-L for generation for dialogue turns 1, 2 and 3 independently, as well as the average over all turns.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 707.0, "y1": 267.0, "x1": 123.0, "y2": 394.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9281650119358, "y1": 958.9021470811632, "x1": 100.0, "y2": 1017.0514424641926}, "name": "3", "caption_text": "Figure 3: Example predictions from our TRANSRESNETRET (MM-Sum) model on the evaluation set using all candidates for turns 1\u20133 . Two speakers A & B with given style traits discuss a photo. The dialogue context before the model prediction is completed by humans, followed by one or more possible model responses, given different style conditioning. The model clearly uses the image, given style and dialogue history in formulating its response.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 124.0, "x1": 103.0, "y2": 941.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4505666097005, "y1": 239.77572123209634, "x1": 99.99997880723741, "y2": 314.53060574001734}, "name": "4", "caption_text": "Figure 4: Human evaluations on IMAGE-CHAT. Engagingness win rates of pairwise comparisons between human utterances and TRANSRESNETRET (ResNet152 or ResNeXt-IG-3.5B) or TRANSRESNETGEN , comparing over the rounds of dialogue.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 88.0, "x1": 104.0, "y2": 219.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2227478027344, "y1": 235.82717047797308, "x1": 426.661131117079, "y2": 343.7904357910156}, "name": "5", "caption_text": "Figure 5: IGC Evaluations. The best model from Mostafazadeh et al. (2017) is compared to our best TRANSRESNETRET and TRASNRESNETGEN models. On the left, annotator\u2019s ratings of responses from the models are shown as a percentage of the annotator\u2019s ratings of human responses. On the right, BLEU-4 scores on the response task are shown.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 88.0, "x1": 430.0, "y2": 215.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2177463107639, "y1": 236.91605461968314, "x1": 426.3430701361762, "y2": 295.06539238823785}, "name": "4", "caption_text": "Table 4: IGC Human Evaluation on responses from our TRANSRESNET MM-SUM model conditioned on various personalities. Responses were rated on a quality scale from 1 to 3, where 3 is the highest.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 640.0, "y1": 86.0, "x1": 517.0, "y2": 213.0}, "page": 10, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 669.6239047580295, "y1": 568.6951955159504, "x1": 160.30000050862628, "y2": 577.0319620768229}, "name": "6", "caption_text": "Figure 6: Instructions pane for crowdworkers when collecting the second round of dialogue.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 163.0, "x1": 100.0, "y2": 568.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 663.4796990288628, "y1": 969.2577785915798, "x1": 166.443051232232, "y2": 977.594502766927}, "name": "7", "caption_text": "Figure 7: Instructions pane for crowdworkers when collecting the third round of dialogue.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 574.0, "x1": 100.0, "y2": 969.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 480.18964131673175, "x1": 100.0, "y2": 505.1305558946397}, "name": "8", "caption_text": "Figure 8: Instructions pane for crowdworkers when collecting the IMAGE-CHAT Evaluations.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 89.0, "x1": 100.0, "y2": 479.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45048183865015, "y1": 979.0091620551215, "x1": 100.0, "y2": 1003.9514329698351}, "name": "9", "caption_text": "Figure 9: Instructions pane for crowdworkers when collecting the IGC Evaluations.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 622.0, "x1": 100.0, "y2": 978.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9192640516493, "y1": 834.9813673231337, "x1": 99.50141906738281, "y2": 859.9222819010416}, "name": "5", "caption_text": "Table 5: Highly rated examples from the IGC dataset test split where TRANSRESNETRET MM-Sum responses were rated the highest (score of 3) by human evaluators.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 281.0, "x1": 100.0, "y2": 817.0}, "page": 13, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9176534016926, "y1": 753.2604641384548, "x1": 99.57083596123589, "y2": 778.2013787163628}, "name": "6", "caption_text": "Table 6: Low rated examples from the IGC dataset test split where TRANSRESNETRET MM-Sum responses were rated the lowest (score of 1) by human evaluators.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 737.0, "y1": 363.0, "x1": 100.0, "y2": 735.0}, "page": 14, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 713.5015699598524, "y1": 808.2757737901476, "x1": 116.423585679796, "y2": 816.6124979654948}, "name": "10", "caption_text": "Figure 10: Long-form conversation with the model. The model is given a style here, while the human is not.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 642.0, "y1": 125.0, "x1": 188.0, "y2": 369.0}, "page": 15, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2246975368923, "y1": 1010.8257717556423, "x1": 99.57080417209201, "y2": 1052.3722330729167}, "name": "7", "caption_text": "Table 7: Ablations on IMAGE-CHAT. We compare variants of our best TRANSRESNET generative model (ResNeXtIG-3.5B image encoder) where we remove modalities: image, dialogue history and style conditioning, reporting F1 and BLEU-4 for generation for dialogue turns 1, 2 and 3 independently, as well as the average over all turns.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 705.0, "y1": 836.0, "x1": 108.0, "y2": 987.0}, "page": 15, "dpi": 0}], "error": null, "pdf": "/work/host-output/b7a8c8204ee2b0e4d2248f407271da01e48f5651/2020.acl-main.219.pdf", "dpi": 100}