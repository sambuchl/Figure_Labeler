{"raw_detected_boxes": [[], [{"x2": 726.0, "y1": 86.0, "x1": 431.0, "y2": 196.0}], [{"x2": 726.0, "y1": 86.0, "x1": 431.0, "y2": 219.0}, {"x2": 344.0, "y1": 89.0, "x1": 157.0, "y2": 297.0}], [{"x2": 717.0, "y1": 994.0, "x1": 427.0, "y2": 1056.0}], [{"x2": 710.0, "y1": 94.0, "x1": 124.0, "y2": 311.0}], [{"x2": 389.0, "y1": 86.0, "x1": 110.0, "y2": 225.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 290.2705078125, "y1": 232.84555053710938, "x1": 72.0, "y2": 250.80303955078125}, "imageText": ["Encoder", "Decoder", "Others", "11%", "35%", "54%"], "regionBoundary": {"x2": 250.29403686523438, "y1": 61.8900146484375, "x1": 110.0, "y2": 214.08642578125}, "caption": "Figure 1: Profiling of the throughput during inference on newstest2018 using a 35-6 model.", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.546630859375, "y1": 176.55654907226562, "x1": 306.9670104980469, "y2": 230.38006591796875}, "imageText": ["Model", "Param.", "Speedup", "BLEU", "Teacher-40-6", "168M", "1x", "44.5", "Student-35-6", "152M", "1.1x", "44.6", "Student-35-1", "131M", "1.6x", "44.3", "Student-18-1", "77M", "2.0x", "43.4", "Student-9-1", "49M", "2.4x", "42.9", "Student-tiny", "25M", "2.9x", "37.2"], "regionBoundary": {"x2": 523.0, "y1": 62.8900146484375, "x1": 310.0, "y2": 159.8900146484375}, "caption": "Table 2: Results on newstest18. The students were trained by sequence-level knowledge distillation. The tiny setting keeps the 9-1 model\u2019s configurations except for using a model size of 256. We report the translation speed on a single 2080Ti.", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 291.92437744140625, "y1": 174.16256713867188, "x1": 71.69100189208984, "y2": 227.986083984375}, "imageText": ["Student-9-1-tiny\u2020", "67", "810.9", "37.2", "Student-35-6", "305", "3166.4", "44.6", "Student-35-1", "264", "2023.3", "44.3", "Student-18-1", "156", "1355.0", "43.4", "Student-9-1", "99", "977.6", "42.9", "Model", "MiB", "Time", "BLEU"], "regionBoundary": {"x2": 283.0, "y1": 62.8900146484375, "x1": 79.0, "y2": 161.8900146484375}, "caption": "Table 3: Results of all submissions. \u2020 indicates the CPU system. All student systems were running with greedy search. The time was measured by the organizers on their test set and we only report the BLEU on the newstest2018.", "page": 5}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 526.2907104492188, "y1": 242.40859985351562, "x1": 72.0, "y2": 284.276123046875}, "imageText": ["(b)", "Operations", "after", "optimizing", "Conversion", "Others", "Add", "TopK", "CopyBlocks", "Softmax", "Memcpy", "12%", "MM", "24%", "9%7%", "6%", "10%", "14%", "18%", "(a)", "Operations", "before", "optimizing.", "Others", "Add", "TopK", "CopyBlocks", "Softmax", "Memcpy", "17%", "MM", "11%", "4%", "8%", "12%11%", "37%"], "regionBoundary": {"x2": 510.8370361328125, "y1": 66.8900146484375, "x1": 86.0, "y2": 223.15704345703125}, "caption": "Figure 2: Profiling results of all operations during inference before or after optimizing on newstest2018 using a 9-1 model on a 2080Ti. We performed decoding for ten times to get more convincing results. Before optimizing, the decoding time is 76.9 seconds. The combination of different optimizations reduces the time to 24.9 seconds. MM is matrix multiplication, and CopyBlocks is used in the tensor copy.", "page": 4}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.547607421875, "y1": 157.62753295898438, "x1": 306.9670104980469, "y2": 187.541015625}, "imageText": ["Model", "Param.", "BLEU", "Transformer-35-6", "152M", "43.3", "Transformer-35-6+DLCL", "152M", "43.7", "Transformer-40-6", "168M", "44.5", "Transformer-40-6+DLCL", "168M", "43.9", "Ensemble", "640M", "45.5"], "regionBoundary": {"x2": 523.0, "y1": 62.8900146484375, "x1": 310.0, "y2": 145.8900146484375}, "caption": "Table 1: Results on newstest18 - Teacher Models. 35-6 means that the model contains 35 encoder layers and 6 decoder layers.", "page": 1}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.927232530382, "y1": 218.9271291097005, "x1": 426.3430701361762, "y2": 260.4736328125}, "name": "1", "caption_text": "Table 1: Results on newstest18 - Teacher Models. 35-6 means that the model contains 35 encoder layers and 6 decoder layers.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 86.0, "x1": 431.0, "y2": 202.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 245.21742926703558, "x1": 426.3430701361762, "y2": 319.9723137749566}, "name": "2", "caption_text": "Table 2: Results on newstest18. The students were trained by sequence-level knowledge distillation. The tiny setting keeps the 9-1 model\u2019s configurations except for using a model size of 256. We report the translation speed on a single 2080Ti.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 86.0, "x1": 431.0, "y2": 221.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15348307291663, "y1": 323.39659796820746, "x1": 100.0, "y2": 348.3375549316406}, "name": "1", "caption_text": "Figure 1: Profiling of the throughput during inference on newstest2018 using a 35-6 model.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 347.0, "y1": 87.0, "x1": 157.0, "y2": 297.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 730.9593200683594, "y1": 336.6786109076606, "x1": 100.0, "y2": 394.82794867621527}, "name": "2", "caption_text": "Figure 2: Profiling results of all operations during inference before or after optimizing on newstest2018 using a 9-1 model on a 2080Ti. We performed decoding for ten times to get more convincing results. Before optimizing, the decoding time is 76.9 seconds. The combination of different optimizations reduces the time to 24.9 seconds. MM is matrix multiplication, and CopyBlocks is used in the tensor copy.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 93.0, "x1": 120.0, "y2": 313.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45052422417535, "y1": 241.89245435926648, "x1": 99.57083596123589, "y2": 316.6473388671875}, "name": "3", "caption_text": "Table 3: Results of all submissions. \u2020 indicates the CPU system. All student systems were running with greedy search. The time was measured by the organizers on their test set and we only report the BLEU on the newstest2018.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 393.0, "y1": 86.0, "x1": 100.0, "y2": 242.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/18f86146a095a30d57569197c04f807bb10064e8/2020.ngt-1.24.pdf", "dpi": 100}