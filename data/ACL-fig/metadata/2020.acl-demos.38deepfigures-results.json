{"raw_detected_boxes": [[{"x2": 712.0, "y1": 314.0, "x1": 441.0, "y2": 583.0}], [{"x2": 719.0, "y1": 93.0, "x1": 108.0, "y2": 382.0}], [{"x2": 728.0, "y1": 90.0, "x1": 429.0, "y2": 240.0}], [{"x2": 725.0, "y1": 88.0, "x1": 429.0, "y2": 259.0}, {"x2": 726.0, "y1": 285.0, "x1": 432.0, "y2": 507.0}], [], [{"x2": 712.0, "y1": 90.0, "x1": 105.0, "y2": 234.0}, {"x2": 718.0, "y1": 366.0, "x1": 439.0, "y2": 501.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 527.2003784179688, "y1": 432.08154296875, "x1": 307.2760009765625, "y2": 485.90496826171875}, "imageText": [], "regionBoundary": {"x2": 515.0, "y1": 221.8900146484375, "x1": 318.0, "y2": 419.8900146484375}, "caption": "Figure 1: Distribution of binary trees over an 1000- token sequence. Coloring shows the marginal probabilities of every span. Torch-Struct is an optimized collection of common CRF distributions used in NLP that is designed to integrate with deep learning frameworks.", "page": 0}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 527.2899780273438, "y1": 376.6525573730469, "x1": 307.2760009765625, "y2": 418.5199890136719}, "imageText": ["`2,\u00b7,\u00b7`1,\u00b7,\u00b7", "\u2295", "\u2297", "`4,\u00b7,\u00b7`3,\u00b7,\u00b7", "\u2297", "\u2295", "\u2297", "\u2295", "`6,\u00b7,\u00b7`5,\u00b7,\u00b7", "\u2295", "\u2297", "I`7,\u00b7,\u00b7", "\u2297", "A(`)", "\u2295", "\u2297", "\u2295"], "regionBoundary": {"x2": 516.2096557617188, "y1": 267.0074768066406, "x1": 315.752197265625, "y2": 359.14031982421875}, "caption": "Figure 4: Parallel scan implementation of the linearchain CRF inference algorithm (parallel forward). Here \u2295 \u2297 represents a semiring matrix operation and I is padding to produce a balanced tree.", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.200927734375, "y1": 183.30953979492188, "x1": 72.0, "y2": 237.133056640625}, "imageText": [], "regionBoundary": {"x2": 516.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 171.8900146484375}, "caption": "Figure 3: Speed impact of optimizations. Time is given in seconds for 10 runs with batch 16. (a) Speed of a linearchain forward with 20 classes for lengths up to 500. Compares left-to-right ordering to parallel scan. (b) Speed of CKY inside with lengths up to 80. Compares inner loop versus vectorization. (c) Speed of linear-chain forward of length 20 with up to 100 classes. Compares broadcast-reduction versus CUDA semiring kernel. (Baseline memory is exhausted after 100 classes.)", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2867431640625, "y1": 292.7575378417969, "x1": 71.69100189208984, "y2": 334.62603759765625}, "imageText": ["60", "-", "(Tillmann", "and", "Ney,", "2003)", "Auto-Regressive", "Sequence", "Pre\ufb01x", "(CN", ")", "Greedy", "Search,", "Beam", "Search", "40", "1.1m", "(Koo", "et", "al.,", "2007)", "(McDonald", "et", "al.,", "2005)", "Dep", "(NP)", "Non-Proj.", "Tree", "Arcs", "(N2)", "Matrix-Tree", "Chiu-Liu", "(MAP)", "Dependency", "Proj.", "Tree", "Arcs", "(N2)", "Eisner", "Alg", "40", "28k", "(Eisner,", "2000)", "Semi-Markov", "Seg.", "Labels", "Edge(NKC2)", "Segmental", "F-B", "30", "87k", "(Baum", "and", "Petrie,", "1966)", "(Sarawagi", "and", "Cohen,", "2005)", "Context-Free", "Labeled", "Tree", "CF", "Rules", "(G)", "Term.", "(CN)", "I-O", "CKY", "70", "37k", "(Kasami,", "1966)", "Simple", "CKY", "Labeled", "Tree", "Splits", "(CN2)", "0-th", "order", "CKY", "30", "118k", "(Kasami,", "1966)", "DTW,", "CTC", "50", "13k", "(Needleman", "and", "Wunsch,", "1970)", "Alignment", "Alignment", "Match", "(NM)", "Skips", "(2NM)", "Factorial", "F-B", "20", "25k", "(Ghahramani", "and", "Jordan,", "1996)", "Factorial-HMM", "Labeled", "Chains", "Trans.", "(LC2)", "Obs.", "(NCL)", "20", "390k", "(Lafferty", "et", "al.,", "2001)", "Labeled", "Chain", "Edges", "(NC2)", "Forward-", "Backward", "Linear-Chain,", "HMM", "LoC", "T/S", "Sample", "Reference", "Name", "Structure", "(Z)", "Parts", "(P)", "Algorithm", "(A(`))"], "regionBoundary": {"x2": 525.0, "y1": 67.58395385742188, "x1": 72.0, "y2": 280.8900146484375}, "caption": "Table 1: Models and algorithms implemented in Torch-Struct. Notation is developed in Section 5. Parts are described in terms of sequence lengths N,M , label size C, segment length K, and layers / grammar size L,G. Lines of code (LoC) is from the log-partition (A(`)) implementation. T/S is the tokens per second of a batched computation, computed with batch 32, N = 25, C = 20,K = 5, L = 3 (K80 GPU run on Google Colab).", "page": 1}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.287841796875, "y1": 188.55459594726562, "x1": 306.947021484375, "y2": 266.28814697265625}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 176.8900146484375}, "caption": "Figure 2: Latent Tree CRF example where each cell represents a span (i, j). Torch-Struct can be used to compute many different properties of a structured distribution. (a) Log-potentials ` for each part/span. (b) Marginals for CRF(`) computed by backpropagation. (c) A single argmax tree argmaxz CRF(z; `). (d) A single sampled tree z \u223c CRF(`).", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.2900390625, "y1": 382.5155334472656, "x1": 306.9469909667969, "y2": 436.3389587402344}, "imageText": ["Exp.", "See", "(Li", "and", "Eisner,", "2009)", "Sparsemax", "See", "(Mensch", "and", "Blondel,", "2018)"], "regionBoundary": {"x2": 526.0, "y1": 168.92373657226562, "x1": 307.0, "y2": 380.8900146484375}, "caption": "Table 2: (Top) Semirings implemented in Torch-Struct. Backprop/Gradients gives overridden backpropagation computation and value computed by this combination. (Bot) Example of gradients from different semirings on sequence alignment with dynamic time warping.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 732.2227478027344, "y1": 600.1132541232639, "x1": 426.772223578559, "y2": 674.8680114746094}, "name": "1", "caption_text": "Figure 1: Distribution of binary trees over an 1000- token sequence. Coloring shows the marginal probabilities of every span. Torch-Struct is an optimized collection of common CRF distributions used in NLP that is designed to integrate with deep learning frameworks.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 314.0, "x1": 427.0, "y2": 600.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3426988389757, "y1": 406.60769144694007, "x1": 99.57083596123589, "y2": 464.75838555230035}, "name": "1", "caption_text": "Table 1: Models and algorithms implemented in Torch-Struct. Notation is developed in Section 5. Parts are described in terms of sequence lengths N,M , label size C, segment length K, and layers / grammar size L,G. Lines of code (LoC) is from the log-partition (A(`)) implementation. T/S is the tokens per second of a batched computation, computed with batch 32, N = 25, C = 20,K = 5, L = 3 (K80 GPU run on Google Colab).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 101.0, "y2": 390.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.344224717882, "y1": 261.8813832600911, "x1": 426.3153076171875, "y2": 369.84464857313367}, "name": "2", "caption_text": "Figure 2: Latent Tree CRF example where each cell represents a span (i, j). Torch-Struct can be used to compute many different properties of a structured distribution. (a) Log-potentials ` for each part/span. (b) Marginals for CRF(`) computed by backpropagation. (c) A single argmax tree argmaxz CRF(z; `). (d) A single sampled tree z \u223c CRF(`).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 90.0, "x1": 426.0, "y2": 245.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3472764756945, "y1": 531.2715742323134, "x1": 426.3152652316623, "y2": 606.0263315836588}, "name": "2", "caption_text": "Table 2: (Top) Semirings implemented in Torch-Struct. Backprop/Gradients gives overridden backpropagation computation and value computed by this combination. (Bot) Example of gradients from different semirings on sequence alignment with dynamic time warping.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 285.0, "x1": 432.0, "y2": 507.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2235107421875, "y1": 254.5965830485026, "x1": 100.0, "y2": 329.3514675564236}, "name": "3", "caption_text": "Figure 3: Speed impact of optimizations. Time is given in seconds for 10 runs with batch 16. (a) Speed of a linearchain forward with 20 classes for lengths up to 500. Compares left-to-right ordering to parallel scan. (b) Speed of CKY inside with lengths up to 80. Compares inner loop versus vectorization. (c) Speed of linear-chain forward of length 20 with up to 100 classes. Compares broadcast-reduction versus CUDA semiring kernel. (Baseline memory is exhausted after 100 classes.)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 713.0, "y1": 90.0, "x1": 104.0, "y2": 234.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.347191704644, "y1": 523.1285519070095, "x1": 426.772223578559, "y2": 581.2777625189887}, "name": "4", "caption_text": "Figure 4: Parallel scan implementation of the linearchain CRF inference algorithm (parallel forward). Here \u2295 \u2297 represents a semiring matrix operation and I is padding to produce a balanced tree.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 718.0, "y1": 366.0, "x1": 439.0, "y2": 501.0}, "page": 5, "dpi": 0}], "error": null, "pdf": "/work/host-output/5be048d96f1a081c79f67bdd2cb3deeba125c20a/2020.acl-demos.38.pdf", "dpi": 100}