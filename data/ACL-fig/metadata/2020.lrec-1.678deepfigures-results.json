{"raw_detected_boxes": [[{"x2": 670.0, "y1": 471.0, "x1": 501.0, "y2": 658.0}], [{"x2": 686.0, "y1": 108.0, "x1": 134.0, "y2": 503.0}], [], [{"x2": 724.0, "y1": 95.0, "x1": 90.0, "y2": 488.0}, {"x2": 712.0, "y1": 560.0, "x1": 460.0, "y2": 957.0}], [{"x2": 733.0, "y1": 97.0, "x1": 89.0, "y2": 384.0}, {"x2": 712.0, "y1": 534.0, "x1": 460.0, "y2": 937.0}], [{"x2": 386.0, "y1": 95.0, "x1": 88.0, "y2": 282.0}, {"x2": 717.0, "y1": 103.0, "x1": 456.0, "y2": 675.0}], [{"x2": 716.0, "y1": 95.0, "x1": 107.0, "y2": 725.0}, {"x2": 324.0, "y1": 814.0, "x1": 147.0, "y2": 995.0}, {"x2": 655.0, "y1": 816.0, "x1": 518.0, "y2": 995.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 539.7141723632812, "y1": 492.0805358886719, "x1": 304.8659973144531, "y2": 510.03900146484375}, "imageText": ["43%", "other", "verbs", "57%", "to", "be"], "regionBoundary": {"x2": 483.0, "y1": 340.0777587890625, "x1": 361.0, "y2": 475.8900146484375}, "caption": "Figure 1: Distribution of verbs in the VQA dataset (Antol et al., 2015a), \u2019to be\u2019 versus \u2019other verbs\u2019.", "page": 0}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 287.00537109375, "y1": 222.17556762695312, "x1": 52.15700149536133, "y2": 240.133056640625}, "imageText": ["Template", "questions", "Realized", "questions", "y", "ue", "nc", "fr", "eq", "tiv", "e", "re", "la", "length", "of", "question", "in", "number", "of", "words", "30", "20", "10", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"], "regionBoundary": {"x2": 278.0, "y1": 68.8900146484375, "x1": 64.39517211914062, "y2": 202.7327880859375}, "caption": "Figure 4: Distribution of template questions vs realized questions based on length.", "page": 5}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 539.7142333984375, "y1": 511.9965515136719, "x1": 304.8659973144531, "y2": 529.9539794921875}, "imageText": ["(b)", "(a)"], "regionBoundary": {"x2": 520.0, "y1": 68.8900146484375, "x1": 324.0, "y2": 486.697021484375}, "caption": "Figure 5: imSituVQA word clouds of (a) answers and (b) frame elements.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 534.9111938476562, "y1": 384.0745544433594, "x1": 53.87699890136719, "y2": 390.0770263671875}, "imageText": ["Place", "body", "of", "water", "Place", "outside", "\u2014\u2013", "Place", "workstation", "catching", "painting", "attaching", "opening", "Agent", "bear", "Agent", "man", "Agent", "woman", "Agent", "cat", "Caughtitem", "\ufb01sh", "Item", "boat", "Item", "fabric", "Item", "door", "Tool", "mouth", "Tool", "roller", "Tool", "hand", "Tool", "paw", "Place", "roof", "Place", "kitchen", "Place", "shoe", "shop", "Part", "tile", "Container", "wok", "Goal", "land", "Payment", "credit", "card", "Tool", "hammer", "Tool", "spatula", "Seller", "person", "\ufb01xing", "cooking", "falling", "buying", "Agent", "man", "Agent", "boy", "Agent", "leaf", "Agent", "woman", "Object", "roof", "Food", "meat", "Source", "tree", "Goods", "shoe"], "regionBoundary": {"x2": 496.0, "y1": 77.8900146484375, "x1": 96.0, "y2": 362.8900146484375}, "caption": "Table 1: Sample imSitu (Yatskar et al., 2016) annotations of images about different events described by semantic frame.", "page": 1}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 539.71435546875, "y1": 738.1135864257812, "x1": 304.8659973144531, "y2": 756.072021484375}, "imageText": ["man", "13,527", "woman", "10,763", "people", "9,228", "room", "8,323", "outside", "6,881", "inside", "6,679", "person", "5,625", "hand", "4,238", "\ufb01eld", "3,086", "Answer", "frequency", "outdoors", "14,621"], "regionBoundary": {"x2": 472.0, "y1": 583.8900146484375, "x1": 373.0, "y2": 716.8900146484375}, "caption": "Table 6: Top 10 frequent answers in imSituVQA training samples.", "page": 6}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 539.717529296875, "y1": 543.6585693359375, "x1": 52.15800094604492, "y2": 561.615966796875}, "imageText": ["?", "door", "ITEM", "VERB", "What", "item", "does", "the", "cat", "AGENT", "open", "What", "item", "does", "the", "bear", "AGENT", "catch", "VERB", "?", "\ufb01sh", "CAUGHTITEM", "TOOL", "the", "door", "ITEM", "?", "paw", "VERB", "What", "does", "the", "cat", "AGENT", "use", "to", "open", "PLACE", "Where", "does", "the", "bear", "AGENT", "catch", "VERB", "\ufb01sh", "CAUGHTITEM", "?", "body", "of", "water", "cat", "AGENT", "the", "door", "ITEM", "VERB", "Who", "opens", "VERB", "AGENT", "doing", "?", "catching", "QUESTION", "ANSWER", "QUESTION", "ANSWER", "What", "is", "the", "bear", "IMAGE", "about", "catching", "IMAGE", "about", "opening", "SELLER", "shoes", "ITEM", "from", "?", "person", "VERB", "Who", "does", "the", "woman", "AGENT", "buy", "cook", "VERB", "meat", "FOOD", "in", "wok", "CONTAINER", "?", "kitchen", "PLACE", "AGENT", "Where", "does", "the", "boy", "shoes", "GOODS", "?", "shoe", "store", "PLACE", "VERB", "Where", "does", "the", "woman", "AGENT", "buy", "?", "meat", "FOOD", "TOOL", "cook", "VERB", "with", "spatula", "AGENT", "What", "does", "the", "boy", "shoes", "ITEM", "?", "woman", "AGENT", "?", "VERB", "Who", "is", "buying", "AGENT", "?", "boy", "VERB", "QUESTION", "ANSWER", "QUESTION", "ANSWER", "Who", "is", "cooking", "IMAGE", "about", "cooking", "IMAGE", "about", "buying"], "regionBoundary": {"x2": 516.0, "y1": 69.45952606201172, "x1": 76.0, "y2": 522.8900146484375}, "caption": "Table 4: imSituVQA dataset samples about cooking, buying, catching and opening. The imSituVQA dataset includes frame element annotations for each question answer pair.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 287.0063781738281, "y1": 738.1135864257812, "x1": 52.15800094604492, "y2": 756.072021484375}, "imageText": ["VICTIM", "3,932", "TARGET", "3,860", "VEHICLE", "3,706", "DESTINATION", "3,238", "COAGENT", "2,544", "OBJECT", "2,317", "Frame", "element", "frequency", "PLACE", "100,006", "AGENT", "49,976", "ITEM", "24,376", "TOOL", "13,908"], "regionBoundary": {"x2": 233.0, "y1": 583.8900146484375, "x1": 106.0, "y2": 716.8900146484375}, "caption": "Table 5: Top 10 frequent frame elements in imSituVQA training samples.", "page": 6}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 500.0766296386719, "y1": 373.17755126953125, "x1": 88.71099853515625, "y2": 379.1800231933594}, "imageText": ["The", "AGENT", "opens", "the", "ITEM", "with", "the", "TOOL", "at", "the", "PLACE.", "What", "does", "the", "AGENT", "use", "to", "open", "ITEM", "?", "TOOL", "Who", "opens", "ITEM", "?", "AGENT", "What", "item", "does", "the", "AGENT", "opens", "?", "ITEM", "Where", "does", "the", "AGENT", "opens", "ITEM", "with", "TOOL", "PLACE", "An", "AGENT", "catches", "a", "CAUGHTITEM", "with", "a", "TOOL", "at", "a", "PLACE.", "Who", "catches", "at", "PLACE", "?", "AGENT", "What", "is", "the", "AGENT", "doing", "?", "VERB", "What", "item", "does", "the", "AGENT", "catches", "with", "TOOL", "CAUGHTITEM", "Where", "does", "the", "AGENT", "catches", "CAUGHTITEM", "?", "PLACE", "Who", "is", "buying", "GOODS", "?", "AGENT", "What", "is", "the", "AGENT", "doing", "?", "VERB", "What", "item", "does", "the", "AGENT", "buy", "with", "PAYMENT", "?", "GOODS", "Who", "does", "the", "AGENT", "buy", "GOODS", "from?", "SELLER", "Where", "does", "the", "AGENT", "buy", "GOODS", "?", "PLACE", "The", "AGENT", "buys", "GOODS", "with", "PAYMENT", "from", "the", "SELLER", "in", "a", "PLACE", "Who", "is", "cooking?", "AGENT", "What", "does", "the", "AGENT", "cook", "with", "TOOL?", "FOOD", "What", "is", "the", "AGENT", "doing", "?", "VERB", "What", "does", "the", "AGENT", "use", "to", "cook", "in", "CONTAINER", "?", "TOOL", "Where", "does", "the", "AGENT", "cook", "FOOD", "in", "CONTAINER", "?", "PLACE", "An", "AGENT", "cooks", "a", "FOOD", "in", "a", "CONTAINER", "over", "a", "HEATSOURCE", "using", "a", "TOOL", "in", "a", "PLACE.", "Abstract", "de\ufb01nition", "from", "imSitu", "dataset", "Sample", "Generated", "Question", "Templates", "ReponseFrame", "Element"], "regionBoundary": {"x2": 528.0, "y1": 69.8900146484375, "x1": 64.0, "y2": 351.8900146484375}, "caption": "Table 2: A subset of Question Answer templates generated for cooking, buying, catching and opening.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 539.7142944335938, "y1": 702.2085571289062, "x1": 304.8659973144531, "y2": 732.1220092773438}, "imageText": ["(b)", "6.03%", "2.03%", "what", "[other]", "2.12%", "what", "part", "17.50%", "what", "container", "what", "item", "28.40%", "what", "does", "43.92%", "(a)", "what", "is", "24%", "where", "33%", "who", "43%", "what"], "regionBoundary": {"x2": 513.1819458007812, "y1": 404.1907653808594, "x1": 331.4016418457031, "y2": 687.904052734375}, "caption": "Figure 2: Distribution of questions in templates. (a) covers all questions while (b) includes questions starting with question word \u201dwhat\u201d", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 539.7142944335938, "y1": 688.0855712890625, "x1": 304.8659973144531, "y2": 717.998046875}, "imageText": ["(b)", "9.7", "%", "2.84%", "what", "[other]", "3.06%", "what", "part", "5.52%", "what", "container", "what", "vehicle", "39.28%", "what", "item", "39.60%", "what", "does", "43%", "where", "31%", "who", "26%", "what", "(a)"], "regionBoundary": {"x2": 513.0346069335938, "y1": 385.2261962890625, "x1": 331.54962158203125, "y2": 673.7233276367188}, "caption": "Figure 3: Distribution of questions in imSituVQA. (a) covers all questions while (b) includes questions starting with question word \u201dwhat\u201d", "page": 4}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 455.7783203125, "y1": 298.1655578613281, "x1": 133.00999450683594, "y2": 304.16802978515625}, "imageText": ["IMITATION,", "MATERIAL,", "INSTRUMENT,", "PHENOMENON,", "OBSTACLE,", "EVENT", "What", "does", "the", "[AGENT]", "use", "to", "CROWN,", "BRUSH,", "CONNECTOR,", "GLUE,", "WRAPPINGITEM,", "COMPONENT,", "LOCK,", "COVER,", "DYE,", "PARACHUTE,", "ACTION,", "SEALANT", "Element]", "VEHICLE,", "CONTAINER,", "SKILL,", "SHAPE,", "PATH,", "LIQUID", "RECIPIENTPART,", "AGENTPART,", "OBJECTPART,", "COAGENTPART", "What", "[Frame", "What", "part", "PART,", "BODYPART,", "YANKEDPART,", "VICTIMPART,", "ITEMPART,", "DRENCHEDITEM,", "REMOVEDITEM,", "DEFLECTEDITEM,", "WRAPPEDITEM", "What", "item", "ITEM,", "SIGNEDITEM,", "CAUGHTITEM,", "TURNEDITEM,", "GOODS,", "HIDINGITEM", "OCCASION,", "SUBSTANCE,", "CLOTH", "COMPONENTS,", "DEPICTED,", "REFERENCE,", "AGENTTYPE,", "FOOD,", "CENTER,", "CLOTH", "What", "OBJECT,", "HUNTED,", "BORINGTHING,FOCUS,", "SURFACE,", "RECIPIENTS,CONTAINER,", "GOAL,", "STAGE,", "SCAFFOLD", "Where", "PLACE,", "TARGET,ADDRESSEE,", "SURFACE,", "GROUND,", "END,", "SOURCE,", "SHELTER,", "COAGENT,", "VOTEFOR,", "PERFORMER,", "EXPERIENCER,", "TICKLED,", "SELLER,", "EATER", "Who", "COMPETITOR,", "VICTIM,", "LISTENER,", "INDIVIDUALS,", "MOURNER,", "FOLLOWER,", "Question", "Word", "Frame", "Elements"], "regionBoundary": {"x2": 528.0, "y1": 69.8900146484375, "x1": 64.0, "y2": 276.8900146484375}, "caption": "Table 3: A subset of frame elements and the question words they are mapped to.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 749.6030171712239, "y1": 683.4451887342665, "x1": 423.4249962700738, "y2": 708.3875020345051}, "name": "1", "caption_text": "Figure 1: Distribution of verbs in the VQA dataset (Antol et al., 2015a), \u2019to be\u2019 versus \u2019other verbs\u2019.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 672.0, "y1": 471.0, "x1": 501.0, "y2": 658.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 742.9322136773003, "y1": 533.4368811713324, "x1": 74.82916514078775, "y2": 541.7736477322048}, "name": "1", "caption_text": "Table 1: Sample imSitu (Yatskar et al., 2016) annotations of images about different events described by semantic frame.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 688.0, "y1": 108.0, "x1": 134.0, "y2": 503.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 694.5508744981554, "y1": 518.3021545410156, "x1": 123.20972018771701, "y2": 526.6389211018881}, "name": "2", "caption_text": "Table 2: A subset of Question Answer templates generated for cooking, buying, catching and opening.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 733.0, "y1": 95.0, "x1": 89.0, "y2": 488.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031867133246, "y1": 975.2896626790364, "x1": 423.4249962700738, "y2": 1016.8361239963107}, "name": "2", "caption_text": "Figure 2: Distribution of questions in templates. (a) covers all questions while (b) includes questions starting with question word \u201dwhat\u201d", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 717.0, "y1": 560.0, "x1": 460.0, "y2": 974.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 633.0254448784722, "y1": 414.1188303629557, "x1": 184.73610348171658, "y2": 422.4555969238281}, "name": "3", "caption_text": "Table 3: A subset of frame elements and the question words they are mapped to.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 733.0, "y1": 95.0, "x1": 89.0, "y2": 384.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031867133246, "y1": 955.6744045681423, "x1": 423.4249962700738, "y2": 997.2195095486111}, "name": "3", "caption_text": "Figure 3: Distribution of questions in imSituVQA. (a) covers all questions while (b) includes questions starting with question word \u201dwhat\u201d", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 534.0, "x1": 460.0, "y2": 937.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.61857096354163, "y1": 308.5771772596571, "x1": 72.4402798546685, "y2": 333.51813422309027}, "name": "4", "caption_text": "Figure 4: Distribution of template questions vs realized questions based on length.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 386.0, "y1": 95.0, "x1": 86.0, "y2": 283.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031019422743, "y1": 711.1063215467665, "x1": 423.4249962700738, "y2": 736.0471937391493}, "name": "5", "caption_text": "Figure 5: imSituVQA word clouds of (a) answers and (b) frame elements.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 717.0, "y1": 99.0, "x1": 456.0, "y2": 679.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.607679578993, "y1": 755.0813462999132, "x1": 72.44166798061795, "y2": 780.0221761067708}, "name": "4", "caption_text": "Table 4: imSituVQA dataset samples about cooking, buying, catching and opening. The imSituVQA dataset includes frame element annotations for each question answer pair.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 95.0, "x1": 106.0, "y2": 725.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6199696858724, "y1": 1025.157758924696, "x1": 72.44166798061795, "y2": 1050.1000298394097}, "name": "5", "caption_text": "Table 5: Top 10 frequent frame elements in imSituVQA training samples.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 324.0, "y1": 810.0, "x1": 147.0, "y2": 995.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.603271484375, "y1": 1025.157758924696, "x1": 423.4249962700738, "y2": 1050.1000298394097}, "name": "6", "caption_text": "Table 6: Top 10 frequent answers in imSituVQA training samples.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 655.0, "y1": 810.0, "x1": 518.0, "y2": 995.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/d7a3a570c12baf73aff0fa086ee0b580a289c026/2020.lrec-1.678.pdf", "dpi": 100}