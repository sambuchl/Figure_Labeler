{"raw_detected_boxes": [[], [{"x2": 384.0, "y1": 102.0, "x1": 78.0, "y2": 296.0}], [{"x2": 725.0, "y1": 132.0, "x1": 84.0, "y2": 336.0}, {"x2": 666.0, "y1": 383.0, "x1": 514.0, "y2": 673.0}], [{"x2": 762.0, "y1": 117.0, "x1": 427.0, "y2": 554.0}, {"x2": 741.0, "y1": 619.0, "x1": 424.0, "y2": 933.0}], [{"x2": 350.0, "y1": 97.0, "x1": 121.0, "y2": 267.0}], [{"x2": 731.0, "y1": 105.0, "x1": 433.0, "y2": 216.0}, {"x2": 383.0, "y1": 150.0, "x1": 76.0, "y2": 380.0}, {"x2": 390.0, "y1": 420.0, "x1": 69.0, "y2": 576.0}, {"x2": 695.0, "y1": 307.0, "x1": 435.0, "y2": 440.0}], [{"x2": 716.0, "y1": 148.0, "x1": 454.0, "y2": 370.0}], [{"x2": 370.0, "y1": 163.0, "x1": 101.0, "y2": 486.0}], [], [], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "4", "captionBoundary": {"x2": 287.00634765625, "y1": 79.20802307128906, "x1": 52.15800094604492, "y2": 97.81805419921875}, "imageText": ["Num", "of", "workers", "160", "(R)", "and", "72", "(C)", "Blocked", "workers", "8", "Mean", "activation", "3.62\u00b10.91", "(R)3.69\u00b10.81", "(C)", "Mean", "valence", "5.26\u00b10.95", "(R)5.37\u00b11.00", "(C)", "Crowdsourced", "Data", "Mean", "no.", "of", "utterances/monologue", "9.69\u00b1", "2.55", "Mean", "duration", "of", "utterances", "12.44\u00b1", "6.72", "seconds", "Total", "no.", "of", "utterances", "2,648", "Selected", "no.", "of", "utterances", "2,574", "Gender", "distribution", "19", "(M)", "and", "9", "(F)", "Total", "annotated", "speech", "duration", "\u223c", "10", "hours", "Monologue", "Subset"], "regionBoundary": {"x2": 285.0, "y1": 103.8900146484375, "x1": 54.0, "y2": 277.8900146484375}, "caption": "Table 4: Data summary (R:random, C:context, F:female, M:male).", "page": 5}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 287.00634765625, "y1": 433.2929992675781, "x1": 52.158016204833984, "y2": 463.8590087890625}, "imageText": [], "regionBoundary": {"x2": 290.0, "y1": 296.8900146484375, "x1": 46.0, "y2": 418.8900146484375}, "caption": "Figure 4: Distribution of the activation and valence ratings in random labeling scheme (on left) and contextual labeling scheme (on right).", "page": 5}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 539.7142333984375, "y1": 181.6690216064453, "x1": 304.86602783203125, "y2": 200.279052734375}, "imageText": [], "regionBoundary": {"x2": 536.0, "y1": 68.8900146484375, "x1": 309.0, "y2": 166.8900146484375}, "caption": "Figure 5: An overview of the instructions provided to the annotators for annotating an utterance.", "page": 5}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 539.71435546875, "y1": 335.447998046875, "x1": 304.86602783203125, "y2": 366.01300048828125}, "imageText": [], "regionBoundary": {"x2": 537.0, "y1": 206.8900146484375, "x1": 307.0, "y2": 320.8900146484375}, "caption": "Figure 6: Annotation scale used by MTurk workers to annotate the emotional content of the corpus. They annotate valence and activation for each utterance.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 261.8016052246094, "y1": 229.4149932861328, "x1": 77.36399841308594, "y2": 236.07000732421875}, "imageText": [], "regionBoundary": {"x2": 288.0, "y1": 68.8900146484375, "x1": 52.0, "y2": 214.8900146484375}, "caption": "Figure 1: Broad visual overview of recordings", "page": 1}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 539.7144165039062, "y1": 79.20808410644531, "x1": 304.86602783203125, "y2": 97.818115234375}, "imageText": ["Ensemble", "A+L", "0.987", "0.981", "A+V", "0.970", "0.899", "L+V", "0.981", "0.901", "A+L+V", "0.972", "0.856\u2217", "A+L+V+T", "(All)", "0.961\u2217", "0.868", "Activation", "Valence", "Unimodal", "Models", "Acoustic", "(A)", "1.004\u2217", "1.122", "Lexical", "(L)", "1.343", "0.980", "Close", "Video", "(V)", "1.111", "0.879\u2217\u2217", "Thermal", "(T)", "2.012", "1.565"], "regionBoundary": {"x2": 515.0, "y1": 100.8900146484375, "x1": 327.0, "y2": 270.8900146484375}, "caption": "Table 5: RMSE for emotion classification models using multiple modalities. Significance established at p < 0.05.", "page": 6}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 539.717529296875, "y1": 79.20802307128906, "x1": 52.15800094604492, "y2": 97.81805419921875}, "imageText": ["Corpus", "Size", "Speakers", "Rec.", "Type", "Language", "Modality", "Annotation", "Type", "1.", "IEMOCAP", "12h26m", "10", "improv/acted", "English", "A,", "V,", "L", "Ordinal,", "Categorical", "2.", "MSP-Improv", "9h35m", "12", "improv/acted", "English", "A,", "V", "Ordinal", "3.", "VAM", "12h", "47", "spontaneous", "German", "A,", "V", "Ordinal", "4.", "SEMAINE", "6h21m", "20", "spontaneous", "English", "A,", "V", "Ordinal,", "Categorical", "5.", "RECOLA", "2h50m", "46", "spontaneous", "French", "A,", "V,", "P", "Ordinal", "6.", "FAU-AIBO", "9h12m", "51", "spontaneous", "German", "A,", "L", "Categorical", "7.", "TUM", "AVIC", "0h23m", "21", "spontaneous", "English", "A,", "V,", "L", "Categorical", "8.", "Emotion", "Lines", "30k", "samples", "-", "spont/scripted", "English", "A,", "L", "Categorical", "9.", "OMG-Emotion", "2.4k", "samples", "-", "spontaenous", "English", "A,", "V,", "L", "Ordinal", "10.", "MSP-Podcast", "27h42m", "151", "spontaenous", "English", "A", "Ordinal,", "Categorical", "11.", "MuSE", "10h", "28", "spontaneous", "English", "A,", "V,", "L,", "T,", "P", "Ordinal", "(Random,", "Context)"], "regionBoundary": {"x2": 526.0, "y1": 100.8900146484375, "x1": 64.0, "y2": 245.8900146484375}, "caption": "Table 1: Summary of some of the existing emotion corpora. Lexical modality is mentioned for manually transcribed datasets. A - Audio, L - Lexical, T- Thermal, V- Visual, P - Physiological.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 517.144775390625, "y1": 503.1889953613281, "x1": 327.43701171875, "y2": 509.8440246582031}, "imageText": ["or", "ia", "l,", "30", "-s", "ec", "m", "on", "o.", "Final", "Survey:", "PSS", "Amusement", "a", "/b", "Sadness", "a", "/b", "Anger", "a", "/b", "C", "at", "eg", "Watch", "Videos:", "Happiness", "a/b", "l/A", "ct", "lf", "Va", "Set", "1a/b,", "2a/b,", "3a/b", "End", "a/b", "Se", "Monologues:", "Icebreaker", "/b", "Initial", "Surveys:", "PSS"], "regionBoundary": {"x2": 480.0, "y1": 287.8900146484375, "x1": 370.0, "y2": 487.8900146484375}, "caption": "Figure 2: Experimental Protocol For Recording", "page": 2}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 287.00640869140625, "y1": 79.20802307128906, "x1": 52.15800094604492, "y2": 109.7730712890625}, "imageText": ["4.", "Physiological", "Features.", "While", "the", "physiological", "fea-", "tures", "varied", "greatly", "per", "second", "to", "be", "informative", "for", "emotion,", "they", "are", "informative", "for", "recognizing", "pres-", "ence", "or", "absence", "of", "stress.", "We", "consider", "the", "raw", "mea-", "surements", "for", "heart", "rate,", "breathing", "rate,", "skin", "conduc-", "tance", "and", "skin", "temperature", "and", "compute", "the", "\ufb01rst", "four", "measures", "of", "central", "tendency,", "e.g.", "mean,", "standard", "de-", "viation,", "skewness,", "and", "kurtosis.", "units.", "Landmarks", "locations", "o\ufb00set", "by", "the", "nose", "location.", "We", "window", "the", "data", "into", "segments", "of", "one-second", "win-", "dows", "with", "0.5", "second", "overlap", "and", "calculate", "summary", "statistics", "(maximum,", "minimum,", "mean,", "variance).", "We", "retain", "the", "top", "300", "features", "based", "on", "the", "F", "values", "be-", "tween", "the", "training", "features", "and", "corresponding", "labels", "(stressed", "vs", "non-stressed).", "Recording", "Parts", "A", "P", "R", "F1", "Thermal", "Neutral", "0.61", "0.67", "0.62", "0.64", "Questions", "0.50", "0.64", "0.52", "0.57", "Wide-angle", "Video", "Neutral", "0.66", "0.41", "0.96", "0.58", "Questions", "0.69", "0.45", "0.82", "0.58", "Close-up", "Video", "Neutral", "0.61", "0.78", "0.33", "0.46", "Questions", "0.65", "0.65", "0.69", "0.67", "Physiological", "Neutral", "0.66", "0.47", "0.89", "0.64", "Questions", "0.70", "0.55", "0.88", "0.67", "Audio", "-", "Per", "utterance", "Questions", "0.67", "0.70", "0.69", "0.69", "Text", "-", "Per", "utterance", "Questions", "0.60", "0.74", "0.61", "0.67", "Late", "Fusion", "-", "Voting", "Questions", "0.60", "0.74", "0.61", "0.67"], "regionBoundary": {"x2": 287.0111999511719, "y1": 112.8900146484375, "x1": 59.625003814697266, "y2": 552.3818359375}, "caption": "Table 6: Baseline results for classifying stressed and non-stressed situations per time unit, unless specified otherwise. A - Accuracy, P - Precision, R - Recall.", "page": 7}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 499.69573974609375, "y1": 79.20802307128906, "x1": 344.8869934082031, "y2": 85.863037109375}, "imageText": ["2.", "If", "you", "could", "wake", "up", "tomorrow", "having", "gained", "one", "quality", "or", "ability,", "what", "would", "it", "be?", "mind", "or", "body", "of", "a", "30-year", "old", "for", "the", "last", "60", "years", "of", "your", "life,", "which", "would", "you", "choose?", "Ending", "1.", "If", "you", "were", "able", "to", "live", "to", "the", "age", "of", "90", "and", "retain", "either", "the", "2.", "Your", "house,", "containing", "everything", "you", "own,", "catches", "\ufb01re.", "After", "saving", "your", "loved", "ones", "and", "pets,", "you", "have", "time", "to", "safely", "make", "a", "\ufb01nal", "dash", "to", "save", "any", "one", "item.", "What", "would", "it", "be?", "Why?", "nicate", "with", "anyone,", "what", "would", "you", "most", "regret", "not", "having", "told", "someone?", "Intensity", "1.", "If", "youwere", "to", "die", "this", "eveningwith", "no", "opportunity", "to", "commu-", "what", "would", "it", "be?", "2.", "Share", "an", "embarrassing", "moment", "in", "your", "life.", "Negative", "1.", "If", "you", "could", "change", "anything", "about", "the", "way", "you", "were", "raised,", "Positive", "1.", "For", "what", "in", "your", "life", "do", "you", "feel", "most", "grateful?", "2.", "What", "is", "the", "greatest", "accomplishment", "of", "your", "life?", "want", "as", "a", "dinner", "guest?", "2.", "Would", "you", "like", "to", "be", "famous?", "In", "what", "way?", "Icebreaker", "1.", "Given", "the", "choice", "of", "anyone", "in", "the", "world,", "whom", "would", "you"], "regionBoundary": {"x2": 552.0, "y1": 88.8900146484375, "x1": 304.0, "y2": 402.8900146484375}, "caption": "Table 2: Emotion elicitation questions.", "page": 3}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 490.4104919433594, "y1": 425.8909912109375, "x1": 354.1719970703125, "y2": 432.5460205078125}, "imageText": ["2.", "Raspberry", "Pi", "with", "camera", "module", "V2", "with", "wide-", "angle", "lens", "used", "for", "the", "waist", "up", "shot", "of", "the", "subject.", "We", "have", "chosen", "Raspberry", "Pi\u2019s", "due", "to", "its", "low", "price", "1.", "FLIRThermovisionA40", "thermal", "camera", "for", "record-", "ing", "the", "close-up", "thermal", "recording", "of", "the", "subject\u2019s", "face.", "This", "camera", "provides", "a", "640x512", "image", "in", "the", "thermal", "infrared", "spectrum.", "A", "display", "of", "zig-zag", "lines", "across", "the", "screen", "Screen-saver", "pattern", "of", "changing", "colors", "Neutral", "Benny", "and", "Joone", "Actor", "plays", "the", "fool", "in", "a", "co\ufb00ee", "shop", "Something", "About", "Mary", "Ben", "Stiller", "\ufb01ghts", "with", "a", "dog", "High", "Valence,", "High", "Activation", "(Amusement)", "Wall-E", "Two", "robots", "dance", "and", "fall", "in", "love", "Love", "Actually", "Surprise", "orchestra", "at", "the", "wedding", "High", "Valence,", "Low", "Activation", "(Contentment)", "Sleepers", "Sexual", "abuse", "of", "children", "Schindler\u2019s", "List:", "Killing", "of", "Jews", "during", "WWII", "Low", "Valence,", "High", "Activation", "(Anger)", "mates", "has", "died", "City", "of", "Angels", "Maggie", "dies", "in", "Seth\u2019s", "arms", "Dangerous", "Minds", "Students", "\ufb01nd", "that", "one", "of", "their", "class-", "Low", "Valence,", "Low", "Activation", "(Sad)", "Movie", "Description"], "regionBoundary": {"x2": 539.72021484375, "y1": 438.8900146484375, "x1": 304.0, "y2": 789.1650390625}, "caption": "Table 3: Emotion elicitation clips.", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 287.00634765625, "y1": 207.7210235595703, "x1": 52.15800094604492, "y2": 226.3310546875}, "imageText": [], "regionBoundary": {"x2": 252.0, "y1": 68.8900146484375, "x1": 87.0, "y2": 192.8900146484375}, "caption": "Figure 3: Close-up view of the thermal and video recording equipment.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 363.61334058973523, "y1": 318.6319351196289, "x1": 107.44999779595268, "y2": 327.875010172526}, "name": "1", "caption_text": "Figure 1: Broad visual overview of recordings", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 384.0, "y1": 101.0, "x1": 78.0, "y2": 296.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.607679578993, "y1": 110.01114315456815, "x1": 72.44166798061795, "y2": 135.85840861002603}, "name": "1", "caption_text": "Table 1: Summary of some of the existing emotion corpora. Lexical modality is mentioned for manually transcribed datasets. A - Audio, L - Lexical, T- Thermal, V- Visual, P - Physiological.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 742.0, "y1": 115.0, "x1": 72.0, "y2": 341.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 718.2566324869791, "y1": 698.8736046685112, "x1": 454.77362738715277, "y2": 708.116700914171}, "name": "2", "caption_text": "Figure 2: Experimental Protocol For Recording", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 677.0, "y1": 366.0, "x1": 497.0, "y2": 678.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 694.0218607584635, "y1": 110.01114315456815, "x1": 479.0097130669488, "y2": 119.25421820746527}, "name": "2", "caption_text": "Table 2: Emotion elicitation questions.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 767.0, "y1": 109.0, "x1": 423.0, "y2": 559.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 681.1256832546658, "y1": 591.5152655707465, "x1": 491.9055514865451, "y2": 600.7583618164062}, "name": "3", "caption_text": "Table 3: Emotion elicitation clips.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 744.0, "y1": 602.0, "x1": 423.0, "y2": 946.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.61992730034723, "y1": 288.5014216105143, "x1": 72.44166798061795, "y2": 314.34868706597223}, "name": "3", "caption_text": "Figure 3: Close-up view of the thermal and video recording equipment.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 350.0, "y1": 96.0, "x1": 121.0, "y2": 267.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6031019422743, "y1": 252.31808556450736, "x1": 423.42503865559894, "y2": 278.16535101996527}, "name": "5", "caption_text": "Figure 5: An overview of the instructions provided to the annotators for annotating an utterance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 740.0, "y1": 99.0, "x1": 433.0, "y2": 226.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.61992730034723, "y1": 110.01114315456815, "x1": 72.44166798061795, "y2": 135.85840861002603}, "name": "4", "caption_text": "Table 4: Data summary (R:random, C:context, F:female, M:male).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 395.0, "y1": 133.0, "x1": 72.0, "y2": 386.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.61992730034723, "y1": 601.7958323160807, "x1": 72.44168917338052, "y2": 644.2486233181423}, "name": "4", "caption_text": "Figure 4: Distribution of the activation and valence ratings in random labeling scheme (on left) and contextual labeling scheme (on right).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 395.0, "y1": 420.0, "x1": 69.0, "y2": 576.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.603271484375, "y1": 465.89999728732636, "x1": 423.42503865559894, "y2": 508.35138956705725}, "name": "6", "caption_text": "Figure 6: Annotation scale used by MTurk workers to annotate the emotional content of the corpus. They annotate valence and activation for each utterance.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 292.0, "x1": 434.0, "y2": 440.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.6033562554253, "y1": 110.01122792561848, "x1": 423.42503865559894, "y2": 135.85849338107639}, "name": "5", "caption_text": "Table 5: RMSE for emotion classification models using multiple modalities. Significance established at p < 0.05.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 733.0, "y1": 131.0, "x1": 437.0, "y2": 376.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 398.6200120713976, "y1": 110.01114315456815, "x1": 72.44166798061795, "y2": 152.4625990125868}, "name": "6", "caption_text": "Table 6: Baseline results for classifying stressed and non-stressed situations per time unit, unless specified otherwise. A - Accuracy, P - Precision, R - Recall.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 370.0, "y1": 146.0, "x1": 84.0, "y2": 486.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/794b179e073d85dca17c8238a2ef5234e15519b7/2020.lrec-1.187.pdf", "dpi": 100}