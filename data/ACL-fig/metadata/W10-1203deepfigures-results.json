{"raw_detected_boxes": [[], [], [{"x2": 642.0, "y1": 107.0, "x1": 212.0, "y2": 451.0}, {"x2": 392.0, "y1": 541.0, "x1": 117.0, "y2": 823.0}], [{"x2": 397.0, "y1": 122.0, "x1": 103.0, "y2": 387.0}, {"x2": 749.0, "y1": 160.0, "x1": 440.0, "y2": 466.0}, {"x2": 714.0, "y1": 645.0, "x1": 472.0, "y2": 842.0}], [], [{"x2": 393.0, "y1": 109.0, "x1": 116.0, "y2": 456.0}], [{"x2": 607.0, "y1": 119.0, "x1": 243.0, "y2": 231.0}, {"x2": 708.0, "y1": 327.0, "x1": 120.0, "y2": 540.0}, {"x2": 621.0, "y1": 641.0, "x1": 229.0, "y2": 941.0}], [{"x2": 639.0, "y1": 100.0, "x1": 211.0, "y2": 229.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "5", "captionBoundary": {"x2": 298.7993469238281, "y1": 347.30865478515625, "x1": 72.00080108642578, "y2": 364.7881164550781}, "imageText": ["105", "9x3x5=105", "n", "number", "of", "words", "9", "3", "5", "Legend", "n", "IDF", "n", "number", "of", "senses", "token", "16.0307", "5.97082", "5.18994", "4.86996", "39x7x7=1911", "1911", "39", "7", "7", "1", "1", "1", "2", "2", "enhancer", "enhancement", "enhanced", "enhance", "enhancive", "1", "1", "5", "1", "2", "3", "3", "3", "6", "6", "7", "8", "organs", "soiling", "soiled", "soil", "organically", "organized", "organ", "organize", "organization", "organizer", "organism", "organic", "organ", "soil", "enhanc", "organic", "soil", "enhancement", "organic", "soil", "enhancement"], "regionBoundary": {"x2": 287.0, "y1": 76.0, "x1": 84.0, "y2": 328.0}, "caption": "Figure 5: Example of ambiguity indicators on the query \u201corganic soil enhancement\u201d", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 500.7064208984375, "y1": 182.44662475585938, "x1": 108.20980072021484, "y2": 188.4490966796875}, "imageText": ["Feature", "Coef\ufb01cient", "R-square", "P-value", "length", "-0.06811", "0.07864", "5.768e-05*", "log(sense", "prod)", "-0.034692", "0.1482", "1.819e-08*", "log(word", "prod)", "-0.04557", "0.09426", "9.78e-06*", "sqrt(ds", "ratio)", "-0.021657", "0.03738", "0.006088*", "idf", "sum", "0.008498", "0.04165", "0.003747*"], "regionBoundary": {"x2": 437.0, "y1": 85.0, "x1": 175.0, "y2": 166.0}, "caption": "Table 2: Results of simple linear regression on the MAP of stemmed queries in MLT query model.", "page": 6}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 535.7994384765625, "y1": 412.6696472167969, "x1": 76.20480346679688, "y2": 418.672119140625}, "imageText": ["Actual", "Best", "Lexical", "Analysis", "id", "f_", "su", "m", "35", "25", "30", "15", "20", "5", "10", "dep", "raw", "stem", "lo", "g(", "w", "or", "d_", "pr", "od", ")", "Actual", "Best", "Lexical", "Analysis", "4", "5", "2", "3", "0", "1", "dep", "raw", "stem", "lo", "g(", "se", "ns", "e_", "pr", "od", ")", "Actual", "Best", "Lexical", "Analysis", "8", "10", "4", "6", "0", "2", "dep", "raw", "stem"], "regionBoundary": {"x2": 515.0, "y1": 250.0, "x1": 87.45948028564453, "y2": 387.38543701171875}, "caption": "Figure 6: Boxplots of the distribution of three ambiguity properties in each actual best text normalization technique", "page": 6}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 472.2524719238281, "y1": 698.9576416015625, "x1": 139.75079345703125, "y2": 704.9600830078125}, "imageText": ["highest", "predicted", "MAP", "score", "Select", "the", "text", "normalization", "technique", "with", "1", "1", "1", "Average", "Precision", "(MAP)", "Testing", "and", "predicting", "Mean", "(SVR)", "models", "Building", "Support", "Vector", "Regression", "SVR", "for", "stemmed", "queries", "2", "3", "4", "5", "queries", "SVR", "for", "depluralized", "2", "3", "4", "5", "SVR", "for", "raw", "queries", "2", "3", "4", "5", "MAP", "score", "from", "stemmed", "queries", "MAP", "score", "from", "depluralized", "queries", "MAP", "score", "from", "raw", "queries", "Training", "groups", "Divide", "all", "query", "topics", "into", "\ufb01ve", "5", "1", "4", "3", "2"], "regionBoundary": {"x2": 448.1051330566406, "y1": 461.67236328125, "x1": 160.98548889160156, "y2": 678.0}, "caption": "Figure 7: Five-fold cross validation on query-based selection model (hybrid model)", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 387.7291259765625, "y1": 349.7056579589844, "x1": 224.27279663085938, "y2": 355.7081298828125}, "imageText": ["Text", "Ambiguity", "Measures", "Regression", "Weka", "SVM", "Paired", "T-test", "Wilcoxon", "Tests", "GraphsGraphsGraphs", "Performance", "Score", "Search", "Results", "Query", "Topics", "Data", "Legend", "DBMS", "Process", "Trec", "Eval", "Document", "Ambiguity", "Calculator", "TREC", "Robust", "Track", "2004", "Index", "FilesXML", "Documents", "Index", "Files", "Index", "Files", "Lucene", "Lexicon", "Analysis", "Lexicon", "Analysis", "R", "XMLParser", "Postgres", "DBMS", "Lucene"], "regionBoundary": {"x2": 465.0, "y1": 71.0, "x1": 143.0, "y2": 331.0}, "caption": "Figure 1: Flow chart of experiment setup", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 298.7994384765625, "y1": 614.501708984375, "x1": 72.00079345703125, "y2": 712.3201293945312}, "imageText": ["^0.939", "fuel^0.631", "hydrogen", "automobile", "hydrogen", "OR", "fuel", "OR", "automobile", "Index", "hydrogen", "AND", "fuel", "AND", "automobile", "Stemmed", "Index", "Depluralized", "Index", "StemmerDepluralizer", "hydrogen", "fuel", "automobiles", "hydrogen", "fuel", "automobil", "hydrogen", "fuel", "automobile", "Query", "Model", "Lucene", "MoreLikeThisOR", "boolean", "AND", "boolean", "Lexicon", "Analysis", "Query", "Topic", "Text", "Normalization", "Final", "Query"], "regionBoundary": {"x2": 287.0, "y1": 387.0, "x1": 84.0, "y2": 598.0}, "caption": "Figure 2: Using the query \u201chydrogen fuel automobiles\u201d as an example, the depluralized query becomes \u201chydrogen fuel automobile\u201d and the stemmed query becomes \u201chydrogen fuel automobil.\u201d Final boolean queries for depluralized topic become \u201chydrogen AND fuel AND automobile\u201d and \u201chydrogen OR fuel OR automobil.\u201d MoreLikeThis (MLT) is the Lucene class used for cosine similarity retrieval. A term vector score appends each word in the topic.", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 540.0037841796875, "y1": 176.39462280273438, "x1": 72.00080108642578, "y2": 205.35107421875}, "imageText": ["p-value", "3.979e-05*", "0.000939*", "0.09677", "Raw", "Dep", "Stem", "Hybrid", "AND", "MAP", "0.1213", "0.1324", "0.1550", "0.2094", "p-value", "<2.2e-16*", "<2.2e-16*", "<2.2e-16*", "OR", "MAP", "0.1851", "0.1922", "0.2069", "0.2131", "p-value", "1.286e-05*", "0.0003815*", "0.09", "MLT", "MAP", "0.1893", "0.1959", "0.2093", "0.2132"], "regionBoundary": {"x2": 461.0, "y1": 72.0, "x1": 151.0, "y2": 165.0}, "caption": "Table 3: Paired T-test was performed to examine the differences of each text normalization techniques (raw, depluralizer, and stemmer) and query-based selection model (hybrid model). Significant differences between models are labeled with *.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 540.0042114257812, "y1": 622.6986694335938, "x1": 313.2008056640625, "y2": 686.0861206054688}, "imageText": ["Combined", "Topic", "Set", "Run", "MAP", "p-value", "AND", "Raw", "0.1213", "N/A", "AND", "Dep", "0.1324", "5.598e-06*", "AND", "Stem", "0.1550", "\u2020", "1.599e-07*", "OR", "Raw", "0.1851", "N/A", "OR", "Dep", "0.1922", "0.03035*", "OR", "Stem", "0.2069", "0.01123*", "MLT", "Raw", "0.1893", "N/A", "MLT", "Dep", "0.1959", "0.04837*", "MLT", "Stem", "0.2093", "0.009955*"], "regionBoundary": {"x2": 514.0, "y1": 461.0, "x1": 339.0, "y2": 606.0}, "caption": "Table 1: Paired Wilcoxon signed-ranked test on Mean Average Precision (MAP), utilizing raw query as the baseline. Significant differences between query models are labeled with *. Results labeled with \u2020 indicate significant differences between depluralized queries and a stemmed queries.", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 539.9993896484375, "y1": 358.6956481933594, "x1": 313.2008056640625, "y2": 387.652099609375}, "imageText": [], "regionBoundary": {"x2": 548.0, "y1": 103.0, "x1": 313.0, "y2": 344.0}, "caption": "Figure 4: Example of relative performance similarities among text normalization techniques. The cluster analysis uses the MAP scores of the MLT query model", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 244.78787231445312, "y1": 305.4926452636719, "x1": 126.01380157470703, "y2": 311.4951171875}, "imageText": ["1", ".2", "Mean", "Average", "Precision", "vs.", "Query", "Model", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "0", ".0", "0", ".2", "0", ".4", "0", ".6", "0", ".8", "1", ".0", "1", ".2", "raw", "deplural", "stem", "1", ".0", "0", ".8", "0", ".6", "0", ".4", "0", ".2", "0", ".0", "and", "or", "mlt", "io", "n", "re", "c", "is", "e", "P", "ra", "g", "A", "v", "e", "Query", "Model"], "regionBoundary": {"x2": 292.0, "y1": 85.75, "x1": 76.38411712646484, "y2": 279.30474853515625}, "caption": "Figure 3: Profile plot of MAP", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 538.5126749674479, "y1": 485.7023027208116, "x1": 311.489995320638, "y2": 494.039069281684}, "name": "1", "caption_text": "Figure 1: Flow chart of experiment setup", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 646.0, "y1": 107.0, "x1": 207.0, "y2": 455.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.9992201063368, "y1": 853.474595811632, "x1": 100.00110202365451, "y2": 989.3335130479601}, "name": "2", "caption_text": "Figure 2: Using the query \u201chydrogen fuel automobiles\u201d as an example, the depluralized query becomes \u201chydrogen fuel automobile\u201d and the stemmed query becomes \u201chydrogen fuel automobil.\u201d Final boolean queries for depluralized topic become \u201chydrogen AND fuel AND automobile\u201d and \u201chydrogen OR fuel OR automobil.\u201d MoreLikeThis (MLT) is the Lucene class used for cosine similarity retrieval. A term vector score appends each word in the topic.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 538.0, "x1": 117.0, "y2": 826.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 339.983155992296, "y1": 424.2953406439887, "x1": 175.01916885375977, "y2": 432.6321072048611}, "name": "3", "caption_text": "Figure 3: Profile plot of MAP", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 405.0, "y1": 117.0, "x1": 103.0, "y2": 390.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9991522894965, "y1": 498.1884002685547, "x1": 435.00111897786456, "y2": 538.4056939019097}, "name": "4", "caption_text": "Figure 4: Example of relative performance similarities among text normalization techniques. The cluster analysis uses the MAP scores of the MLT query model", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 751.0, "y1": 160.0, "x1": 440.0, "y2": 466.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0058492024739, "y1": 864.8592631022135, "x1": 435.00111897786456, "y2": 952.8973897298176}, "name": "1", "caption_text": "Table 1: Paired Wilcoxon signed-ranked test on Mean Average Precision (MAP), utilizing raw query as the baseline. Significant differences between query models are labeled with *. Results labeled with \u2020 indicate significant differences between depluralized queries and a stemmed queries.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 714.0, "y1": 640.0, "x1": 471.0, "y2": 842.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.9990929497613, "y1": 482.37313164605035, "x1": 100.0011126200358, "y2": 506.65016174316406}, "name": "5", "caption_text": "Figure 5: Example of ambiguity indicators on the query \u201corganic soil enhancement\u201d", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 106.0, "x1": 116.0, "y2": 456.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 695.4255845811632, "y1": 253.39808993869357, "x1": 150.2913898891873, "y2": 261.734856499566}, "name": "2", "caption_text": "Table 2: Results of simple linear regression on the MAP of stemmed queries in MLT query model.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 607.0, "y1": 117.0, "x1": 243.0, "y2": 231.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 744.1658867730034, "y1": 573.1522878011067, "x1": 105.84000481499565, "y2": 581.4890543619791}, "name": "6", "caption_text": "Figure 6: Boxplots of the distribution of three ambiguity properties in each actual best text normalization technique", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 326.0, "x1": 118.0, "y2": 540.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 655.9062110053168, "y1": 970.7745022243923, "x1": 194.09832424587674, "y2": 979.1112263997395}, "name": "7", "caption_text": "Figure 7: Five-fold cross validation on query-based selection model (hybrid model)", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 622.0, "y1": 641.0, "x1": 224.0, "y2": 941.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0052558051215, "y1": 244.9925316704644, "x1": 100.0011126200358, "y2": 285.20982530381946}, "name": "3", "caption_text": "Table 3: Paired T-test was performed to examine the differences of each text normalization techniques (raw, depluralizer, and stemmer) and query-based selection model (hybrid model). Significant differences between models are labeled with *.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 652.0, "y1": 100.0, "x1": 194.0, "y2": 246.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/78bf13153817ecceba30fbdd590d9ef40dc4a3fa/W10-1203.pdf", "dpi": 100}