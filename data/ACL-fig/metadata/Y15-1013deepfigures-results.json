{"raw_detected_boxes": [[{"x2": 741.0, "y1": 356.0, "x1": 440.0, "y2": 576.0}], [{"x2": 724.0, "y1": 101.0, "x1": 459.0, "y2": 165.0}], [], [{"x2": 741.0, "y1": 100.0, "x1": 444.0, "y2": 439.0}], [{"x2": 406.0, "y1": 103.0, "x1": 104.0, "y2": 212.0}, {"x2": 745.0, "y1": 101.0, "x1": 436.0, "y2": 326.0}], [{"x2": 738.0, "y1": 148.0, "x1": 446.0, "y2": 225.0}, {"x2": 402.0, "y1": 106.0, "x1": 100.0, "y2": 358.0}, {"x2": 746.0, "y1": 289.0, "x1": 444.0, "y2": 392.0}], [{"x2": 385.0, "y1": 126.0, "x1": 113.0, "y2": 337.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "1", "captionBoundary": {"x2": 539.99853515625, "y1": 432.3675231933594, "x1": 313.20001220703125, "y2": 450.3249816894531}, "imageText": ["Replace", "lexical", "feature", "templates", "by", "embedding", "features", "W(s0e1)", "\u22ee", "W(s0ed)", "W(q0e1)", "\u22ee", "W(q0ed)", "\u00b7", "=", "Scores", "\u2026", "\u2026", "s0esaw", "=", "(0.6,", "\u2026", ",", "0.2)", "s0elook", "=", "(0.4,", "\u2026", ",", "0.3)", "q0eyou", "=", "(0.5,", "\u2026", ",", "0.8)", "q0eme", "=", "(0.7,", "\u2026", ",", "0.9)", "Features:", "s0e1,", "\u2026", ",", "s0ed", "q0e1,", "\u2026", ",", "q0ed", "\u00b7", "=", "Scores", "Weights:", "\u22ee", "\u22ee", "W(q0wyou)", "W(q0wme)", "\u22ee", "W(s0wsaw)", "W(s0wlook)", "\u2026", "\u2026", "q0w", "Lexicon:", "\u2026", "you", "me", "\u2026", "q0wyou", "=", "(\u2026", "1", "0", "\u2026)", "q0wme", "=", "(\u2026", "0", "1", "\u2026)", "Lexicon:", "\u2026", "saw", "look", "\u2026", "s0wsaw", "=", "(\u2026", "1", "0", "\u2026)", "s0wlook", "=", "(\u2026", "0", "1", "\u2026)", "Templates:", "s0w"], "regionBoundary": {"x2": 534.0, "y1": 256.71234130859375, "x1": 317.0, "y2": 417.0}, "caption": "Figure 1: Each lexical feature template is replaced by a small number of embedding features.", "page": 0}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 298.7984924316406, "y1": 274.24456787109375, "x1": 72.0, "y2": 292.2020263671875}, "imageText": ["slide", "through.\u201d", "tutional,", "it", "is", "of", "course", "conceivable", "that", "in", "modern", "California", "it", "could", "\u201cWhile", "it", "is", "possible", "that", "the", "Big", "Green", "initiative", "will", "be", "ruled", "unconsti-", "(a)", "Using", "Lexical", "Features", "(Green", "is", "correct)", "root", "...", ",", "it", "is", "of", "course", "conceivable", "that", "...", "(b)", "Using", "Embedding", "Features", "(Green", "is", "correct)", "root", "...", ",", "it", "is", "of", "course", "conceivable", "that", "...", "(a)", "Using", "Lexical", "Features", "(Red", "is", "wrong)"], "regionBoundary": {"x2": 298.7973937988281, "y1": 76.25019836425781, "x1": 72.0, "y2": 258.32904052734375}, "caption": "Figure 5: Improved parsing results with unseen (bold) words.", "page": 5}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 539.99853515625, "y1": 310.2745361328125, "x1": 313.20001220703125, "y2": 328.23199462890625}, "imageText": ["Max", "3200,", "one", "of", "the", "fastest", "and", "most", "sensitive", "monochrome", "\ufb01lms.\u201d", "\u201cThe", "Rochester,", "N.Y.,", "photographic", "giant", "recently", "began", "marketing", "T-", "...", ",", "one", "of", "the", "fastest", "and", "most", "sensitive", "monochrome", "\ufb01lms", ".", "(b)", "Using", "Embedding", "Features", "(Green", "is", "correct)", "...", ",", "one", "of", "the", "fastest", "and", "most", "sensitive", "monochrome", "\ufb01lms", ".", "(a)", "Using", "Lexical", "Features", "(Red", "is", "wrong)"], "regionBoundary": {"x2": 539.9974975585938, "y1": 76.0948486328125, "x1": 313.20001220703125, "y2": 294.3590087890625}, "caption": "Figure 6: Improved parsing results on parallel structure of adjectives.", "page": 5}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.397216796875, "y1": 136.30953979492188, "x1": 325.8039855957031, "y2": 142.31201171875}, "imageText": ["s1s2s3", "q2", "her", "s0l", "s0", "q0", "q1", "you", "with", "stack", "queue", "I", "saw"], "regionBoundary": {"x2": 523.0, "y1": 71.24613952636719, "x1": 330.0, "y2": 119.0}, "caption": "Figure 2: An internal state of a dependency parser.", "page": 1}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 298.79864501953125, "y1": 257.9895324707031, "x1": 72.0, "y2": 263.99200439453125}, "imageText": ["baseline", "STATE", "+", "OUTER", "90", "92", "UA", "S", "ac", "ur", "ac", "y", "88", "86", "84", "82", "0.01", "0.1", "1", "Used", "proportion", "of", "training", "data"], "regionBoundary": {"x2": 279.072021484375, "y1": 89.0, "x1": 85.20182037353516, "y2": 240.85211181640625}, "caption": "Figure 7: UAS on Dev. set, of models trained on less data.", "page": 6}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 539.9986572265625, "y1": 329.2315368652344, "x1": 313.199951171875, "y2": 371.0989685058594}, "imageText": ["Bansal", "et", "al.", "(2014)", "92.06", "91.75", "90.13", "Neural", "Network", "(Chen", "and", "Manning,", "2014):", "Random", "86.37", "86.19", "81.06", "PLAIN", "90.68", "90.48", "87.02", "TREE", "91.06", "90.82", "87.38", "STATE", "91.03", "90.57", "87.88", "PLAIN", "92.33\u2217", "91.78", "90.08\u2217", "TREE", "92.37\u2217", "92.09\u2217", "89.82", "STATE", "92.57\u2217", "92.20\u2217", "90.27\u2217", "Cluster", "Bit", "String:", "PLAIN", "91.71", "91.20", "89.18", "TREE", "90.38", "90.07", "88.00", "STATE", "91.31", "90.96", "89.04", "CONCATENATION", "92.18", "91.86", "89.96", "Different", "Embeddings,", "using", "OUTER", "operation:", "SUM", "92.25\u2217", "91.85", "90.10\u2217", "Different", "Operations,", "using", "STATE", "embedding:", "OUTER", "92.57\u2217", "92.20\u2217", "90.27\u2217", "Dev", "Test", "Unseen", "Huang", "et", "al.", "(2012)", "91.93", "91.68", "89.01"], "regionBoundary": {"x2": 534.0, "y1": 72.0, "x1": 320.0, "y2": 318.0}, "caption": "Table 1: Parsing Results (UAS). Numbers marked by asterisk (\u2217) are statistically significant (p < 0.05), compared to the baseline (Huang et al., 2012) under a paired bootstrap test.", "page": 3}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 540.0035400390625, "y1": 243.34249877929688, "x1": 313.2000427246094, "y2": 297.1659851074219}, "imageText": ["!$", "!\"#$", "!\"%$", "!\"&$", "!\"'$", "($", "($", "!\"'$", "!\"&$", "!\"%$", "!\"#$", "!$", "!\"#$", "!\"%$", "!\"&$", "!\"'$", "($", "($", "!\"'$", "!\"&$", "!\"%$", "!\"#$", "\"%", "\"#&%", "\"#$%", "\"#'%", "\"#(%", "\"#)%", "\"#*%", "\"#+%", "\"#,%", "\"#-%", "&%", "\"#'%", "\"#$%", "\"#&%", "\"%", "!\"#&%", "!\"#$%", "\"%", "\"#$%", "\"#(%", "\"#)%", "\"#*%", "&%", "\"#'%", "\"#$%", "\"#&%", "\"%", "!\"#&%", "!\"#$%"], "regionBoundary": {"x2": 537.0, "y1": 72.0, "x1": 314.0, "y2": 235.0}, "caption": "Figure 4: We plot X by cosine similarities between words, and Y by cosine similarities of weights, learned for lexical features (Upper) and embedding features (Lower). Words are of high (Left) and middle (Right) frequencies.", "page": 4}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 298.79998779296875, "y1": 161.22854614257812, "x1": 72.0, "y2": 191.14105224609375}, "imageText": ["!%#$", "!%&$", "!#$", "&$", "#$", "%&$", "%#$", "%#$", "#$", "!#$", "!%#$", "!\"#$", "!&'$", "!\"'$", "!%'$", "'$", "%'$", "\"'$", "%#$", "#$", "!#$", "!%#$", "!\"#$"], "regionBoundary": {"x2": 295.0, "y1": 72.0, "x1": 72.0, "y2": 153.0}, "caption": "Figure 3: We plot X by the weight of the feature s0wx, and Y by the weight of s0ex, for x of high (Left) and middle (Right) frequency words.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 749.9979654947916, "y1": 600.5104488796658, "x1": 435.0000169542101, "y2": 625.4513634575737}, "name": "1", "caption_text": "Figure 1: Each lexical feature template is replaced by a small number of embedding features.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 741.0, "y1": 356.0, "x1": 440.0, "y2": 579.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.4961344401041, "y1": 189.31880527072482, "x1": 452.50553554958765, "y2": 197.65557183159723}, "name": "2", "caption_text": "Figure 2: An internal state of a dependency parser.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 101.0, "x1": 459.0, "y2": 165.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9981350368923, "y1": 457.2660234239366, "x1": 434.99993218315973, "y2": 515.4152340359158}, "name": "1", "caption_text": "Table 1: Parsing Results (UAS). Numbers marked by asterisk (\u2217) are statistically significant (p < 0.05), compared to the baseline (Huang et al., 2012) under a paired bootstrap test.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 741.0, "y1": 100.0, "x1": 444.0, "y2": 441.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.9999830457899, "y1": 223.92853630913626, "x1": 100.0, "y2": 265.4736836751302}, "name": "3", "caption_text": "Figure 3: We plot X by the weight of the feature s0wx, and Y by the weight of s0ex, for x of high (Left) and middle (Right) frequency words.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 410.0, "y1": 101.0, "x1": 100.0, "y2": 229.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 750.0049167209202, "y1": 337.97569274902344, "x1": 435.00005933973523, "y2": 412.73053487141925}, "name": "4", "caption_text": "Figure 4: We plot X by cosine similarities between words, and Y by cosine similarities of weights, learned for lexical features (Upper) and embedding features (Lower). Words are of high (Left) and middle (Right) frequencies.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 749.0, "y1": 101.0, "x1": 435.0, "y2": 343.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.9979061550564, "y1": 380.8952331542969, "x1": 100.0, "y2": 405.83614773220484}, "name": "5", "caption_text": "Figure 5: Improved parsing results with unseen (bold) words.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 415.0, "y1": 103.0, "x1": 100.0, "y2": 362.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 749.9979654947916, "y1": 430.93685574001734, "x1": 435.0000169542101, "y2": 455.87777031792535}, "name": "6", "caption_text": "Figure 6: Improved parsing results on parallel structure of adjectives.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 749.0, "y1": 286.0, "x1": 434.0, "y2": 409.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 414.99811808268225, "y1": 358.3187950981988, "x1": 100.0, "y2": 366.65556165907117}, "name": "7", "caption_text": "Figure 7: UAS on Dev. set, of models trained on less data.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 387.0, "y1": 123.0, "x1": 113.0, "y2": 337.0}, "page": 6, "dpi": 0}], "error": null, "pdf": "/work/host-output/7f4c35d9f69ff3ca798e7f4f0947bf232a3c15e8/Y15-1013.pdf", "dpi": 100}