{"raw_detected_boxes": [[], [{"x2": 724.0, "y1": 89.0, "x1": 103.0, "y2": 323.0}], [{"x2": 399.0, "y1": 545.0, "x1": 104.0, "y2": 639.0}], [{"x2": 711.0, "y1": 795.0, "x1": 116.0, "y2": 1010.0}], [{"x2": 707.0, "y1": 94.0, "x1": 431.0, "y2": 271.0}, {"x2": 698.0, "y1": 853.0, "x1": 130.0, "y2": 1013.0}], [{"x2": 394.0, "y1": 471.0, "x1": 106.0, "y2": 604.0}, {"x2": 724.0, "y1": 570.0, "x1": 430.0, "y2": 750.0}], [{"x2": 396.0, "y1": 796.0, "x1": 103.0, "y2": 976.0}], [{"x2": 401.0, "y1": 89.0, "x1": 103.0, "y2": 249.0}], [], [{"x2": 726.0, "y1": 87.0, "x1": 435.0, "y2": 186.0}, {"x2": 725.0, "y1": 398.0, "x1": 453.0, "y2": 493.0}, {"x2": 380.0, "y1": 392.0, "x1": 103.0, "y2": 505.0}, {"x2": 697.0, "y1": 691.0, "x1": 134.0, "y2": 847.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.9231262207031, "y1": 450.5105285644531, "x1": 71.69100189208984, "y2": 516.2890014648438}, "imageText": ["Phone", "Cascade", "57hr", "39hr", "27hr", "0.7\u00d7", "Phone", "End-to-End", "42hr", "20hr", "13hr", "0.4\u00d7", "Hybrid", "Cascade", "47hr", "34hr", "24hr", "0.6\u00d7", "Baseline", "End-to-End", "118hr", "40hr", "22hr", "\u2013", "Salesky", "et", "al.", "(2019)", "41hr", "13hr", "10hr", "0.4\u00d7", "Baseline", "Cascade", "76hr", "19hr", "12hr", "0.6\u00d7", "Model", "HIGH", "MID", "LOW", "\u2206"], "regionBoundary": {"x2": 287.0, "y1": 334.8900146484375, "x1": 75.0, "y2": 434.8900146484375}, "caption": "Table 4: Total training time\u00b7E20 for all models (including time to generate phone features) on 3 resource conditions. The ASR and MT models in the baseline cascade can be trained in parallel, reflected here, while phone featured models may not as the MT requires phone features from ASR.", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.1987915039062, "y1": 555.18359375, "x1": 307.2760009765625, "y2": 597.051025390625}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 407.8900146484375, "x1": 307.0, "y2": 542.8900146484375}, "caption": "Figure 3: Phone Cascade Robustness: using phone labels in place of BPE as the text source for downstream MT. Comparing performance across our three data conditions and phone label qualities.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5472412109375, "y1": 245.54953002929688, "x1": 71.7509994506836, "y2": 287.4169921875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 233.8900146484375}, "caption": "Figure 1: Comparison between traditional cascaded and end-to-end models, and our proposed methods using phone features as (1) the intermediate representation in a cascaded model; and (2) a concatenated embedding factor in an end-to-end model. We additionally compare to previous work; (3) where phone segmentation is used for feature vector downsampling in time (Salesky et al., 2019).", "page": 1}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 291.9249267578125, "y1": 717.5115966796875, "x1": 72.0, "y2": 759.3790283203125}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 569.8900146484375, "x1": 72.0, "y2": 705.8900146484375}, "caption": "Figure 4: Phone End-to-End Robustness: trainable embeddings for phone labels are concatenated to framelevel filterbank features. Comparing performance across three data conditions and phone label qualities.", "page": 6}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 523.0538940429688, "y1": 370.1895446777344, "x1": 318.6510009765625, "y2": 412.0580139160156}, "imageText": ["Med", "24.0", "23.7", "20.8", "18.4", "16.5", "14.6", "Low", "20.5", "18.3", "17.0", "13.0", "12.2", "8.7", "Gold", "34.1", "31.3", "27.9", "23.4", "20.5", "17.2", "dev", "test", "dev", "test", "dev", "test", "160hr", "40hr", "20hr", "Phone", "Quality"], "regionBoundary": {"x2": 524.0, "y1": 281.8900146484375, "x1": 321.0, "y2": 357.8900146484375}, "caption": "Table 6: Phone End-to-End. Trainable embeddings for phone labels are concatenated to frame-level filterbank features. Comparing method robustness to phone quality and resource conditions.", "page": 9}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.540283203125, "y1": 621.8695678710938, "x1": 71.69100189208984, "y2": 639.8280029296875}, "imageText": ["po", "se", "d", "Phone", "End-to-End", "24.0", "23.7", "+4.6", "20.8", "18.4", "+8.7", "16.5", "14.6", "+10.0", "Phone", "Cascade", "24.1", "25.1", "+5.3", "21.6", "21.7", "+10.7", "18.9", "18.3", "+13.0", "Hybrid", "Cascade", "24.9", "25.9", "+6.1", "19.6", "18.2", "+8.0", "13.6", "12.6", "+7.5", "P", "ro", "el", "in", "e", "Baseline", "End-to-End", "19.0", "19.6", "\u2013", "11.5", "10.4", "\u2013", "5.9", "5.3", "\u2013", "Salesky", "et", "al.", "(2019)", "22.0", "21.9", "+2.7", "12.6", "11.6", "+1.2", "6.7", "6.2", "+0.9", "Baseline", "Cascade", "23.2", "23.7", "+4.2", "17.4", "15.7", "+5.6", "13.2", "11.8", "+6.9", "B", "as", "Model", "dev", "test", "\u2206", "dev", "test", "\u2206", "dev", "test", "\u2206", "Full", "(160hr)", "40hr", "20hr"], "regionBoundary": {"x2": 502.0, "y1": 492.8900146484375, "x1": 96.0, "y2": 609.8900146484375}, "caption": "Table 7: Results in BLEU\u2191 comparing our proposed phone featured models to baselines. We compare three resource conditions, and show average improvement for dev and test (\u2206). Best performance bolded by column.", "page": 9}, {"figType": "Table", "name": "8", "captionBoundary": {"x2": 525.5455932617188, "y1": 146.09451293945312, "x1": 306.9670104980469, "y2": 187.9630126953125}, "imageText": ["ASR\u2193", "MT\u2191", "Cascade", "End-to-End", "Data", "dev", "test", "dev", "test", "dev", "test", "dev", "test", "Full", "33.3", "30.4", "34.5", "33.6", "23.2", "23.7", "19.0", "19.6", "40hr", "44.8", "46.7", "29.9", "28.3", "17.4", "15.7", "11.5", "10.4", "20hr", "56.3", "59.1", "22.4", "22.6", "13.2", "11.8", "5.9", "5.3"], "regionBoundary": {"x2": 526.0, "y1": 62.8900146484375, "x1": 309.0, "y2": 133.8900146484375}, "caption": "Table 8: Baseline results for end-to-end and cascaded speech translation models, with component ASR and MT model performance for cascades (blue). ASR results in WER\u2193 and translation results in BLEU\u2191.", "page": 9}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 277.8396301269531, "y1": 375.8095397949219, "x1": 71.69100189208984, "y2": 417.6780090332031}, "imageText": ["High", "24.1", "25.1", "21.6", "21.7", "18.9", "18.3", "Med", "23.1", "23.4", "20.6", "20.7", "17.6", "17.2", "Low", "18.2", "19.1", "16.4", "17.0", "14.1", "14.2", "Gold", "33.3", "33.2", "29.3", "28.5", "24.4", "23.0", "dev", "test", "dev", "test", "dev", "test", "160hr", "40hr", "20hr", "Phone", "Quality"], "regionBoundary": {"x2": 277.0, "y1": 275.8900146484375, "x1": 74.0, "y2": 363.8900146484375}, "caption": "Table 5: Phone Cascades. We use frame-level phone labels as the text source for downstream MT. Comparing method robustness to phone quality and resource conditions.", "page": 9}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 291.9233093261719, "y1": 474.3725280761719, "x1": 71.53199768066406, "y2": 504.2850036621094}, "imageText": ["Gold", "\u2013", "Gold", "transcript", "High", "23.2", "Salesky", "et", "al.", "(2019)", "Med", "30.4", "Seq2Seq", "ASR", "Low", "35.5", "Kaldi", "HMM/GMM", "Alignment", "Quality", "WER", "ASR", "Supervision"], "regionBoundary": {"x2": 291.0, "y1": 392.8900146484375, "x1": 74.0, "y2": 461.8900146484375}, "caption": "Table 1: Mapping between phone quality and the ASR models used for alignment generation, with the models\u2019 WER on Fisher Spanish test.", "page": 2}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.91937255859375, "y1": 197.93356323242188, "x1": 71.6709976196289, "y2": 263.7120361328125}, "imageText": [], "regionBoundary": {"x2": 291.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 185.8900146484375}, "caption": "Figure 5: Two examples of phone sequences demonstrating differences across qualities of phone features. (See Table 1 for the mapping between quality and generation procedure). Note: word-level segmentation is not marked, as it is also not present in {speech,phone} source sequences for translation.", "page": 7}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 527.2843017578125, "y1": 739.4295654296875, "x1": 71.69100189208984, "y2": 769.342041015625}, "imageText": ["+", "Add\u2019l", "Data", "Sperber", "et", "al.", "(2019)", "\u2013", "38.8", "\u2013", "\u2013", "\u2013", "\u2013", "Stoian", "et", "al.", "(2020)", "37.9", "37.8", "\u2013", "\u2013", "20.1", "20.2", "Weiss", "et", "al.", "(2017)", "46.5", "47.3\u2217", "\u2013", "\u2013", "\u2013", "\u2013", "Salesky", "et", "al.", "(2019)", "37.6", "38.8", "21.0", "19.8", "11.1", "10.0", "Sperber", "et", "al.", "(2019)", "\u2013", "36.7", "\u2013", "31.9", "\u2013", "22.8", "Stoian", "et", "al.", "(2020)", "34.1", "34.6", "\u2013", "\u2013", "10.3", "10.2", "End-to-End", "Cascaded", "Weiss", "et", "al.", "(2017)", "45.1", "45.5", "\u2013", "\u2013", "\u2013", "\u2013", "23.2", "57.9", "Kumar", "et", "al.", "(2014)", "\u2013", "40.4\u2020", "\u2013", "\u2013", "\u2013", "\u2013", "25.3", "62.9", "Sperber", "et", "al.", "(2019)", "\u2013", "32.5", "\u2013", "16.8", "\u2013", "6.6", "40.9", "58.1", "Model", "Source", "dev", "test", "dev", "test", "dev", "test", "ASR", "\u2193", "MT", "\u2191", "HIGH", "(160hr)", "MID", "(40hr)", "LOW", "(20hr)", "Components"], "regionBoundary": {"x2": 518.0, "y1": 567.8900146484375, "x1": 80.0, "y2": 726.8900146484375}, "caption": "Table 2: End-to-end vs cascaded speech translation model performance in BLEU\u2191 on Fisher Spanish-English data from the literature. (\u2020) denotes the best previous academic result on the full dataset, (\u2217) the best from industry. Component models for cascades reported on test on full dataset: ASR reported in WER\u2193 and MT in BLEU\u2191.", "page": 3}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.540283203125, "y1": 741.4215698242188, "x1": 71.69100189208984, "y2": 759.3790283203125}, "imageText": ["po", "se", "d", "Phone", "End-to-End", "40.5", "42.1", "+8.3", "34.5", "33.0", "+15.3", "26.7", "26.2", "+16.7", "Phone", "Cascade", "41.6", "43.3", "+9.4", "37.2", "37.4", "+18.9", "32.2", "31.5", "+22.1", "Hybrid", "Cascade", "42.9", "45.0", "+10.9", "33.3", "31.2", "+13.8", "23.2", "21.5", "+12.6", "P", "ro", "el", "in", "e", "Baseline", "End-to-End", "32.4", "33.7", "\u2013", "19.5", "17.4", "\u2013", "9.8", "9.8", "\u2013", "Salesky", "et", "al.", "(2019)", "37.6", "38.8", "+5.2", "21.0", "19.8", "+2.0", "11.1", "10.0", "+0.8", "Baseline", "Cascade", "39.7", "41.0", "+7.3", "29.8", "27.1", "+10.0", "22.6", "20.2", "+11.6", "B", "as", "Model", "dev", "test", "\u2206", "dev", "test", "\u2206", "dev", "test", "\u2206", "HIGH", "(160hr)", "MID", "(40hr)", "LOW", "(20hr)"], "regionBoundary": {"x2": 504.0, "y1": 609.8900146484375, "x1": 94.0, "y2": 728.8900146484375}, "caption": "Table 3: Results in BLEU\u2191 comparing our proposed phone featured models to baselines. We compare three resource conditions, and show average improvement for dev and test (\u2206). Best performance bolded by column.", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 527.2007446289062, "y1": 212.73953247070312, "x1": 307.2760009765625, "y2": 278.51800537109375}, "imageText": [], "regionBoundary": {"x2": 515.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 200.8900146484375}, "caption": "Figure 2: Performance of all models relative to \u2018Baseline Cascade\u2019 (\u2206 = 0) across our 3 resource conditions. Cascaded models in orange, end-to-end models in purple. Our proposed models yield improvements across all three conditions, with a widening margin under low-resource conditions for the phone cascade.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 341.041013929579, "x1": 99.6541659037272, "y2": 399.1902669270833}, "name": "1", "caption_text": "Figure 1: Comparison between traditional cascaded and end-to-end models, and our proposed methods using phone features as (1) the intermediate representation in a cascaded model; and (2) a concatenated embedding factor in an end-to-end model. We additionally compare to previous work; (3) where phone segmentation is used for feature vector downsampling in time (Salesky et al., 2019).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 89.0, "x1": 100.0, "y2": 340.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.44904073079425, "y1": 658.8507334391276, "x1": 99.34999677870009, "y2": 700.3958384195963}, "name": "1", "caption_text": "Table 1: Mapping between phone quality and the ASR models used for alignment generation, with the models\u2019 WER on Fisher Spanish test.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 545.0, "x1": 103.0, "y2": 642.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.3393079969618, "y1": 1026.9855075412327, "x1": 99.57083596123589, "y2": 1068.5306125217014}, "name": "2", "caption_text": "Table 2: End-to-end vs cascaded speech translation model performance in BLEU\u2191 on Fisher Spanish-English data from the literature. (\u2020) denotes the best previous academic result on the full dataset, (\u2217) the best from industry. Component models for cascades reported on test on full dataset: ASR reported in WER\u2193 and MT in BLEU\u2191.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 719.0, "y1": 788.0, "x1": 100.0, "y2": 1027.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2232564290364, "y1": 295.47157287597656, "x1": 426.772223578559, "y2": 386.83056301540796}, "name": "2", "caption_text": "Figure 2: Performance of all models relative to \u2018Baseline Cascade\u2019 (\u2206 = 0) across our 3 resource conditions. Cascaded models in orange, end-to-end models in purple. Our proposed models yield improvements across all three conditions, with a widening margin under low-resource conditions for the phone cascade.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 94.0, "x1": 431.0, "y2": 274.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9170600043402, "y1": 1029.7521803114148, "x1": 99.57083596123589, "y2": 1054.693094889323}, "name": "3", "caption_text": "Table 3: Results in BLEU\u2191 comparing our proposed phone featured models to baselines. We compare three resource conditions, and show average improvement for dev and test (\u2206). Best performance bolded by column.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 700.0, "y1": 846.0, "x1": 113.0, "y2": 1030.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4487864176432, "y1": 625.7090674506293, "x1": 99.57083596123589, "y2": 717.0680575900608}, "name": "4", "caption_text": "Table 4: Total training time\u00b7E20 for all models (including time to generate phone features) on 3 resource conditions. The ASR and MT models in the baseline cascade can be trained in parallel, reflected here, while phone featured models may not as the MT requires phone features from ASR.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 399.0, "y1": 464.0, "x1": 104.0, "y2": 621.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2205437554253, "y1": 771.0883246527777, "x1": 426.772223578559, "y2": 829.237535264757}, "name": "3", "caption_text": "Figure 3: Phone Cascade Robustness: using phone labels in place of BPE as the text source for downstream MT. Comparing performance across our three data conditions and phone label qualities.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 724.0, "y1": 570.0, "x1": 430.0, "y2": 750.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4512871636285, "y1": 996.5438842773438, "x1": 100.0, "y2": 1054.693094889323}, "name": "4", "caption_text": "Figure 4: Phone End-to-End Robustness: trainable embeddings for phone labels are concatenated to framelevel filterbank features. Comparing performance across three data conditions and phone label qualities.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 397.0, "y1": 796.0, "x1": 103.0, "y2": 976.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4435729980469, "y1": 274.907726711697, "x1": 99.54305224948459, "y2": 366.2667168511285}, "name": "5", "caption_text": "Figure 5: Two examples of phone sequences demonstrating differences across qualities of phone features. (See Table 1 for the mapping between quality and generation procedure). Note: word-level segmentation is not marked, as it is also not present in {speech,phone} source sequences for translation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 401.0, "y1": 89.0, "x1": 103.0, "y2": 255.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9244350857205, "y1": 202.90904574924045, "x1": 426.3430701361762, "y2": 261.0597398546007}, "name": "8", "caption_text": "Table 8: Baseline results for end-to-end and cascaded speech translation models, with component ASR and MT model performance for cascades (blue). ASR results in WER\u2193 and translation results in BLEU\u2191.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 86.0, "x1": 426.0, "y2": 203.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 726.4637417263455, "y1": 514.1521453857422, "x1": 442.5708346896701, "y2": 572.3027971055773}, "name": "6", "caption_text": "Table 6: Phone End-to-End. Trainable embeddings for phone labels are concatenated to frame-level filterbank features. Comparing method robustness to phone quality and resource conditions.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 727.0, "y1": 391.0, "x1": 446.0, "y2": 497.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 385.8883751763238, "y1": 521.9576941596137, "x1": 99.57083596123589, "y2": 580.1083458794487}, "name": "5", "caption_text": "Table 5: Phone Cascades. We use frame-level phone labels as the text source for downstream MT. Comparing method robustness to phone quality and resource conditions.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 384.0, "y1": 383.0, "x1": 100.0, "y2": 522.0}, "page": 9, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9170600043402, "y1": 863.7077331542969, "x1": 99.57083596123589, "y2": 888.6500040690104}, "name": "7", "caption_text": "Table 7: Results in BLEU\u2191 comparing our proposed phone featured models to baselines. We compare three resource conditions, and show average improvement for dev and test (\u2206). Best performance bolded by column.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 697.0, "y1": 684.0, "x1": 120.0, "y2": 864.0}, "page": 9, "dpi": 0}], "error": null, "pdf": "/work/host-output/b6004737391157e38d708f83bf2058058cb25160/2020.acl-main.217.pdf", "dpi": 100}