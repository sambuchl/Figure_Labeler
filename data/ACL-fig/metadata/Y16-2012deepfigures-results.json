{"raw_detected_boxes": [[], [], [{"x2": 391.0, "y1": 149.0, "x1": 109.0, "y2": 272.0}], [{"x2": 618.0, "y1": 152.0, "x1": 213.0, "y2": 371.0}], [], [{"x2": 639.0, "y1": 179.0, "x1": 188.0, "y2": 292.0}, {"x2": 725.0, "y1": 441.0, "x1": 156.0, "y2": 918.0}], [{"x2": 690.0, "y1": 146.0, "x1": 463.0, "y2": 204.0}, {"x2": 380.0, "y1": 155.0, "x1": 104.0, "y2": 357.0}], [{"x2": 670.0, "y1": 184.0, "x1": 105.0, "y2": 420.0}, {"x2": 655.0, "y1": 531.0, "x1": 169.0, "y2": 917.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.040283203125, "y1": 221.9779052734375, "x1": 70.00244140625, "y2": 251.0609130859375}, "imageText": ["#", "MatchRef", "Prec", "Rec", "AER", "Ref", "33,377", "GIZA++", "+", "GDFA", "31,342", "18,641", "59.48", "55.85", "42.39", "fast", "align", "+", "GDFA", "25,368", "14,076", "55.49", "42.17", "52.08", "GIZA++", "+", "HSSA", "43,257", "15,209", "35.16", "45.57", "60.31", "fast", "align", "+", "HSSA", "43,070", "14,950", "34.71", "44.79", "60.89"], "regionBoundary": {"x2": 464.0, "y1": 129.0, "x1": 131.0, "y2": 211.0}, "caption": "Table 1: Word alignments comparison on Japanese-English data in terms of matches number, precision, recall and alignment error rate (AER). GDFA: an abbreviation of grow-diag-final-and. HSSA: an abbreviation of hierarchical sub-sentential alignment.", "page": 5}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.0402221679688, "y1": 681.1038208007812, "x1": 70.00247192382812, "y2": 710.1876831054688}, "imageText": ["GIZA++", "+", "grow-diag-final-and", "fast_align", "+", "grow-diag-final-and"], "regionBoundary": {"x2": 524.0, "y1": 315.0, "x1": 113.0, "y2": 661.0}, "caption": "Figure 3: Comparison of alignments output by various tools. The test sentence pair is sampled from KFTT corpus. We fed HSSA with the lexical translation table relying on the output of GIZA++. In this example, our proposed approach (GIZA++ + HSSA) generates a better alignment than GIZA++ + GDFA or fast align + GDFA.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.0360717773438, "y1": 158.4136962890625, "x1": 304.5108947753906, "y2": 175.872802734375}, "imageText": ["Train", "Tune", "Test", "Europarl", "v7", "183K", "1K", "2K", "KFTT", "330K", "1.2K", "1.2K"], "regionBoundary": {"x2": 497.0, "y1": 106.0, "x1": 333.0, "y2": 147.0}, "caption": "Table 2: Statistics on the parallel corpus used in the experiments (K=1,000 lines).", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 290.5179748535156, "y1": 278.38543701171875, "x1": 70.00250244140625, "y2": 319.09039306640625}, "imageText": [], "regionBoundary": {"x2": 273.0, "y1": 110.0, "x1": 75.0, "y2": 257.0}, "caption": "Figure 4: Average word alignment run-time (in seconds) as a function of the size of a corpus (in sentence pairs). Remember that, given the lexical translation probabilities, HSSA runs only in one iteration.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 290.5179443359375, "y1": 217.7933349609375, "x1": 70.00057983398438, "y2": 258.498291015625}, "imageText": ["\u56fd", "\u306b", "\u751f\u307e\u308c", "(a)", "(b)", "\u306bprovince", "province", "straight", "inverted", "T", ":", "S", ":", "\u5099\u4e2d", "Bipartite", "graphITG", "tree", "born", "in", "bicchu", "alignment", "S", "T", "\u5099\u4e2d", "\u56fd", "\u751f\u307e\u308c", "bicchu", "born", "in"], "regionBoundary": {"x2": 283.25885009765625, "y1": 108.19632720947266, "x1": 78.68794250488281, "y2": 195.61077880859375}, "caption": "Figure 1: Alignments representations using ITG and bipartite graph. None of the structure contains cycles. The Japanese phrase \u5099\u4e2d \u56fd \u306b \u751f\u307e\u308c means born in bicchu province in English.", "page": 2}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.0499267578125, "y1": 317.5819091796875, "x1": 70.00250244140625, "y2": 335.0410461425781}, "imageText": [], "regionBoundary": {"x2": 486.0, "y1": 137.0, "x1": 70.0, "y2": 302.0}, "caption": "Figure 5: Our proposed approach starts from alignment associations with some probabilities, which is different from the standard phrase-based SMT pipeline.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.0370483398438, "y1": 673.9996337890625, "x1": 70.002197265625, "y2": 714.7067260742188}, "imageText": ["ja-en", "GIZA++", "+", "GDFA", "18.78", "5.730", "71.25", "68.30", "65.87", "GIZA++", "+", "HSSA", "18.38", "5.659", "70.61", "68.40", "65.53", "fast", "align", "+", "GDFA", "18.23", "5.628", "71.26", "68.01", "65.25", "fast", "align", "+", "HSSA", "18.24", "5.659", "70.61", "68.27", "65.46", "en-ja", "GIZA++", "+", "GDFA", "21.59", "5.632", "74.12", "74.99", "68.10", "GIZA++", "+", "HSSA", "21.22", "5.585", "74.26", "73.30", "67.84", "fast", "align", "+", "GDFA", "20.80\u2021", "5.592", "74.50", "74.33", "68.13", "fast", "align", "+", "HSSA", "21.23", "5.590", "74.35", "75.48", "68.01", "en-\ufb01", "GIZA++", "+", "GDFA", "36.61", "6.608", "47.08", "41.36", "87.03", "GIZA++", "+", "HSSA", "35.15\u2021", "6.448", "47.71", "42.18", "86.60", "fast", "align", "+", "GDFA", "36.11", "6.669", "46.69", "41.29", "87.01", "fast", "align", "+", "HSSA", "35.88\u2020", "6.492", "47.32", "41.69", "86.75", "es-pt", "GIZA++", "+", "GDFA", "49.34", "9.182", "35.97", "31.74", "90.62", "GIZA++", "+", "HSSA", "49.32", "8.980", "36.99", "32.44", "90.30", "fast", "align", "+", "GDFA", "49.70", "92.06", "35.46", "31.30", "90.79", "fast", "align", "+", "HSSA", "49.51", "9.203", "35.59", "31.38", "90.79", "en-fr", "GIZA++", "+", "GDFA", "54.40", "9.483", "34.37", "30.19", "91.22", "GIZA++", "+", "HSSA", "54.42", "9.542", "34.07", "30.08", "91.25", "fast", "align", "+", "GDFA", "54.10", "9.438", "34.63", "30.45", "91.14", "fast", "align", "+", "HSSA", "54.05\u2020", "9.417", "34.72", "30.58", "91.11", "BLEU", "NIST", "TER", "WER", "RIBES"], "regionBoundary": {"x2": 473.0, "y1": 383.0, "x1": 122.0, "y2": 663.0}, "caption": "Table 3: Comparison of translation results using various configurations, GIZA++ or fast align with grow-diagfinal-and (GDFA) or hierarchical subsentential alignment (HSSA). Bold surfaces indicate the best BlEU score in each group. No significant difference between directly GIZA++ + GDFA with our proposed method except en-fi. Statistical significantly difference in BLEU score at \u2021: p < 0.01 and \u2020: p < 0.05 compared with GIZA++ + GDFA.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 516.5040283203125, "y1": 291.583740234375, "x1": 78.51170349121094, "y2": 297.419921875}, "imageText": ["Straight", "Inverted", "(X", ",Y\u0304", ")", "(m,n)", "(m,n)", "S", "=", "s", "0", ",s", "1", ",...,s", "i", ",...,s", "m", "T", "=", "t0,", "t1,", ".", ".", ".", ",", "tj", ".", ".", ".", ",", "tn", "(X,", "Y\u0304", ")", "(X\u0304,", "Y", ")(X,Y", ")", "(X\u0304,", "Y\u0304", ")", "(X\u0304,", "Y\u0304", ")", "(X,Y", ")", "(X\u0304,Y", ")"], "regionBoundary": {"x2": 440.21258544921875, "y1": 109.0, "x1": 152.0, "y2": 266.2767333984375}, "caption": "Figure 2: Translation strengths on a logarithmic scale in a English-Japanese sentence pair matrix as a grey graph.", "page": 3}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 403.4971449110243, "y1": 302.49074300130206, "x1": 97.22302754720052, "y2": 359.02540418836804}, "name": "1", "caption_text": "Figure 1: Alignments representations using ITG and bipartite graph. None of the structure contains cycles. The Japanese phrase \u5099\u4e2d \u56fd \u306b \u751f\u307e\u308c means born in bicchu province in English.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 394.0, "y1": 149.0, "x1": 109.0, "y2": 272.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 717.366706000434, "y1": 404.9774169921875, "x1": 109.04403262668185, "y2": 413.08322482638886}, "name": "2", "caption_text": "Figure 2: Translation strengths on a logarithmic scale in a English-Japanese sentence pair matrix as a grey graph.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 618.0, "y1": 151.0, "x1": 211.0, "y2": 371.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2226155598958, "y1": 308.3026462131076, "x1": 97.22561306423611, "y2": 348.6957126193576}, "name": "1", "caption_text": "Table 1: Word alignments comparison on Japanese-English data in terms of matches number, precision, recall and alignment error rate (AER). GDFA: an abbreviation of grow-diag-final-and. HSSA: an abbreviation of hierarchical sub-sentential alignment.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 653.0, "y1": 179.0, "x1": 174.0, "y2": 309.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2225307888455, "y1": 945.9775288899739, "x1": 97.22565544976128, "y2": 986.3717820909288}, "name": "3", "caption_text": "Figure 3: Comparison of alignments output by various tools. The test sentence pair is sampled from KFTT corpus. We fed HSSA with the lexical translation table relying on the output of GIZA++. In this example, our proposed approach (GIZA++ + HSSA) generates a better alignment than GIZA++ + GDFA or fast align + GDFA.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 437.0, "x1": 156.0, "y2": 918.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2167663574219, "y1": 220.0190226236979, "x1": 422.9317982991536, "y2": 244.26778157552081}, "name": "2", "caption_text": "Table 2: Statistics on the parallel corpus used in the experiments (K=1,000 lines).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 697.0, "y1": 146.0, "x1": 457.0, "y2": 221.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.49718729654944, "y1": 386.64644029405383, "x1": 97.22569783528645, "y2": 443.18110148111975}, "name": "4", "caption_text": "Figure 4: Average word alignment run-time (in seconds) as a function of the size of a corpus (in sentence pairs). Remember that, given the lexical translation probabilities, HSSA runs only in one iteration.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 380.0, "y1": 152.0, "x1": 104.0, "y2": 357.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2360093858507, "y1": 441.0859849717882, "x1": 97.22569783528645, "y2": 465.3347863091363}, "name": "5", "caption_text": "Figure 5: Our proposed approach starts from alignment associations with some probabilities, which is different from the standard phrase-based SMT pipeline.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 675.0, "y1": 180.0, "x1": 97.0, "y2": 420.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.2181226942274, "y1": 936.110602484809, "x1": 97.22527398003471, "y2": 992.6482306586371}, "name": "3", "caption_text": "Table 3: Comparison of translation results using various configurations, GIZA++ or fast align with grow-diagfinal-and (GDFA) or hierarchical subsentential alignment (HSSA). Bold surfaces indicate the best BlEU score in each group. No significant difference between directly GIZA++ + GDFA with our proposed method except en-fi. Statistical significantly difference in BLEU score at \u2021: p < 0.01 and \u2020: p < 0.05 compared with GIZA++ + GDFA.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 657.0, "y1": 531.0, "x1": 169.0, "y2": 920.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/64e510850cfddb4b33ec67d30d51eba884eab5f4/Y16-2012.pdf", "dpi": 100}