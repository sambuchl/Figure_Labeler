{"raw_detected_boxes": [[], [], [{"x2": 399.0, "y1": 91.0, "x1": 104.0, "y2": 302.0}], [{"x2": 729.0, "y1": 87.0, "x1": 427.0, "y2": 260.0}], [{"x2": 367.0, "y1": 86.0, "x1": 136.0, "y2": 236.0}, {"x2": 704.0, "y1": 88.0, "x1": 453.0, "y2": 279.0}, {"x2": 729.0, "y1": 403.0, "x1": 428.0, "y2": 563.0}], [{"x2": 399.0, "y1": 86.0, "x1": 104.0, "y2": 237.0}, {"x2": 704.0, "y1": 90.0, "x1": 453.0, "y2": 303.0}, {"x2": 728.0, "y1": 419.0, "x1": 428.0, "y2": 580.0}], [{"x2": 396.0, "y1": 86.0, "x1": 106.0, "y2": 258.0}, {"x2": 697.0, "y1": 89.0, "x1": 461.0, "y2": 163.0}, {"x2": 390.0, "y1": 325.0, "x1": 109.0, "y2": 438.0}], [{"x2": 723.0, "y1": 110.0, "x1": 106.0, "y2": 262.0}, {"x2": 722.0, "y1": 309.0, "x1": 108.0, "y2": 521.0}], [], []], "raw_pdffigures_output": {"regionless-captions": [{"figType": "Table", "boundary": {"x2": 290.2654113769531, "y1": 184.32754516601562, "x1": 71.69100189208984, "y2": 202.2850341796875}, "text": "Table 3: Performance on the global word reordering detection (WRD) task.", "name": "3", "page": 5}, {"figType": "Table", "boundary": {"x2": 291.9226989746094, "y1": 184.32754516601562, "x1": 71.69100189208984, "y2": 202.2850341796875}, "text": "Table 2: Results on the local bigram order shift detection task when SSANs are applied into different layers.", "name": "2", "page": 4}], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5465087890625, "y1": 232.26455688476562, "x1": 307.2760009765625, "y2": 274.133056640625}, "imageText": ["SANs", "SSANs", "(0,", "5]", "(5,", "10", "]", "(10", ",15", "]", "(15", ",20", "]", "(20", ",", "2", "5]", ">2", "5", "Relative", "Distance", "0.40", "0.32", "0.24", "0.16", "0.08", "0.00", "t", "ei", "gh", "n", "W", "nt", "io", "A", "tte"], "regionBoundary": {"x2": 507.0, "y1": 65.30943298339844, "x1": 330.4404296875, "y2": 218.453857421875}, "caption": "Figure 4: Attention weights over attended words with different relative distance from the query word on the global WRD task. SSANs pay more attention to the distant words (distance> 5) than SANs.", "page": 5}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 527.2003173828125, "y1": 435.91253662109375, "x1": 307.2760009765625, "y2": 477.77996826171875}, "imageText": ["(a)", "SANs", "(b)", "SSANs"], "regionBoundary": {"x2": 526.0, "y1": 299.8900146484375, "x1": 307.0, "y2": 415.614013671875}, "caption": "Figure 5: Visualization of attention weights from an example on the global reordering detection task. We highlight the attended word (Y-axis) with maximum attention weight for each query (X-axis) in red rectangles.", "page": 5}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 525.54638671875, "y1": 130.13052368164062, "x1": 306.9670104980469, "y2": 148.0889892578125}, "imageText": ["Metric", "SANs", "SSANs", "4", "BP", "21.09", "22.07", "+4.7%", "BR", "22.05", "23.07", "+4.6%", "F1", "21.56", "22.56", "+4.2%"], "regionBoundary": {"x2": 502.0, "y1": 61.8900146484375, "x1": 331.0, "y2": 117.8900146484375}, "caption": "Table 6: Evaluation on constituency trees generated from the attention distribution.", "page": 6}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.92425537109375, "y1": 197.87655639648438, "x1": 71.69100189208984, "y2": 215.83404541015625}, "imageText": ["Class", "Ratio", "SANs", "SSANs", "4", "5", "6.9%", "68.66", "75.22", "+9.6%", "6", "14.3%", "56.10", "64.09", "+14.2%", "7", "16.3%", "46.63", "55.05", "+18.1%", "8", "17.9%", "39.68", "50.88", "+28.2%", "9", "17.4%", "38.33", "50.97", "+33.0%", "10", "15.3%", "35.54", "49.88", "+40.3%", "11", "11.9%", "48.86", "56.39", "+15.4%", "All", "100%", "45.68", "55.90", "+22.4%"], "regionBoundary": {"x2": 286.0, "y1": 61.8900146484375, "x1": 76.0, "y2": 185.8900146484375}, "caption": "Table 4: F1 score on the tree depth task. \u201cRatio\u201d denotes the portion each class takes.", "page": 6}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 291.92425537109375, "y1": 327.5335388183594, "x1": 71.6709976196289, "y2": 369.4019775390625}, "imageText": ["Type", "Ratio", "SANs", "SSANs", "4", "Ques.", "10%", "95.90", "97.06", "+1.2%", "Decl.", "60%", "88.48", "91.34", "+3.2%", "Clau.", "25%", "72.78", "78.32", "+7.6%", "Other", "5%", "50.67", "61.13", "+20.6%", "All", "100%", "83.78", "87.25", "+4.1%"], "regionBoundary": {"x2": 284.0, "y1": 232.8900146484375, "x1": 78.0, "y2": 315.8900146484375}, "caption": "Table 5: F1 score on the top constituent task. We report detailed results on 4 types of sentences: question (\u201cQues.\u201d), declarative (\u201cDecl.\u201d), a clause (\u201cClau.\u201d),nd other (\u201cOther\u201d) sentences.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 291.9244384765625, "y1": 234.04653930664062, "x1": 70.67500305175781, "y2": 299.8250732421875}, "imageText": ["SANs", "Selector", "1", "1", "0", "0", "0", "1", "\u2714", "\u2714", "\u2714\u2718", "\u2718", "\u2718", "Bush", "held", "a", "talk", "with", "Sharon"], "regionBoundary": {"x2": 288.0, "y1": 65.8900146484375, "x1": 74.09638977050781, "y2": 217.8900146484375}, "caption": "Figure 1: Illustration of SSANs that select a subset of input elements with an additional selector network, on top of which self-attention is conducted. In this example, the word \u201ctalk\u201d performs attention operation over input sequence, where the words \u201cBush\u201d, \u201cheld\u201d and \u201cSharon\u201d are chosen as the truly-significant words.", "page": 2}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 525.5477294921875, "y1": 387.7915344238281, "x1": 70.67501831054688, "y2": 405.7489929199219}, "imageText": ["-F", "re", "e", "Prep.", "0.135", "0.082", "-39.3%", "0.123", "0.119", "-3.3%", "0.089", "0.032", "-64.0%", "Dete.", "0.180", "0.122", "-32.2%", "0.103", "0.073", "-29.1%", "0.070", "0.010", "-85.7%", "Punc.", "0.073", "0.068", "-6.8%", "0.078", "0.072", "-7.7%", "0.098", "0.013", "-86.7%", "Others", "0.258", "0.224", "-13.2%", "0.373", "0.286", "-23.3%", "0.102", "0.057", "-41.1%", "Total", "0.646", "0.496", "-23.3%", "0.676", "0.549", "-18.8%", "0.359", "0.111", "-69.1%", "te", "nt", "C", "on", "te", "nt", "Noun", "0.149", "0.245", "+64.4%", "0.126", "0.196", "+55.6%", "0.418", "0.689", "+64.8%", "Verb", "0.165", "0.190", "+15.2%", "0.165", "0.201", "+21.8%", "0.146", "0.126", "-13.7%", "Adj.", "0.040", "0.069", "+7.3%", "0.033", "0.054", "+63.6%", "0.077", "0.074", "-3.9%", "Total", "0.354", "0.504", "+42.4%", "0.324", "0.451", "+39.2%", "0.641", "0.889", "+38.7%", "C", "on", "Type", "TreeDepth", "TopConst", "En\u21d2De", "Translation", "SANs", "SSANs", "4", "SANs", "SSANs", "4", "SANs", "SSANs", "4"], "regionBoundary": {"x2": 520.0, "y1": 222.8900146484375, "x1": 77.0, "y2": 375.8900146484375}, "caption": "Table 7: Attention distributions on linguistic roles for the structure modeling probing tasks (\u00a75.1, \u201cTreeDepth\u201d and \u201cTopConst\u201d) and the constituency tree generation task (\u00a75.2, \u201cEn\u21d2De Translation\u201d).", "page": 7}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 463.39984130859375, "y1": 201.68954467773438, "x1": 134.14599609375, "y2": 207.6920166015625}, "imageText": ["(a)", "SANs", "(b)", "SSANs"], "regionBoundary": {"x2": 523.0, "y1": 71.8900146484375, "x1": 72.0, "y2": 186.37200927734375}, "caption": "Figure 6: Example of constituency trees generated from the attention distributions.", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2002563476562, "y1": 201.86154174804688, "x1": 306.9670104980469, "y2": 231.7750244140625}, "imageText": ["Task", "Size", "SANs", "SSANs", "4", "Natural", "Language", "Inference", "(Accuracy)", "SNLI", "550K", "85.60", "86.30", "+0.8%", "Semantic", "Role", "Labeling", "(F1", "score)", "CoNLL", "312K", "82.48", "82.88", "+0.5%", "Machine", "Translation", "(BLEU)", "En\u21d2Ro", "0.18M", "23.22", "23.91", "+3.0%", "En\u21d2Ja", "0.44M", "31.56", "32.17", "+1.9%", "En\u21d2De", "4.56M", "27.60", "28.50", "+3.3%"], "regionBoundary": {"x2": 525.0, "y1": 61.8900146484375, "x1": 308.0, "y2": 189.8900146484375}, "caption": "Table 1: Results on the NLP benchmarks. \u201cSize\u201d indicates the number of training examples, and \u201c4\u201d denotes relative improvements over the vanilla SANs.", "page": 3}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 527.20068359375, "y1": 423.44354248046875, "x1": 307.2760009765625, "y2": 465.3119812011719}, "imageText": ["(a)", "SANs", "(b)", "SSANs"], "regionBoundary": {"x2": 526.0, "y1": 286.8900146484375, "x1": 307.0, "y2": 403.14501953125}, "caption": "Figure 3: Visualization of attention weights from an example on the local reordering detection task. We highlight the attended word (Y-axis) with maximum attention weight for each query (X-axis) in red rectangles.", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5465087890625, "y1": 214.75253295898438, "x1": 307.2760009765625, "y2": 256.62005615234375}, "imageText": ["SANs", "SSANs", "(0,", "5]", "(5,", "10", "]", "(10", ",15", "]", "(15", ",20", "]", "(20", ",", "2", "5]", ">2", "5", "Relative", "Distance", "0.40", "0.32", "0.24", "0.16", "0.08", "0.00", "t", "ei", "gh", "n", "W", "nt", "io", "A", "tte"], "regionBoundary": {"x2": 715.5875854492188, "y1": 64.19859313964844, "x1": 545.18603515625, "y2": 217.34295654296875}, "caption": "Figure 2: Attention weights over attended words with different relative distance from the query word on the local reordering task. SSANs pay more attention to the adjacent words (distance=1) than SANs.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 405.4506089952257, "y1": 325.06463792588977, "x1": 98.15972646077473, "y2": 416.4237128363715}, "name": "1", "caption_text": "Figure 1: Illustration of SSANs that select a subset of input elements with an additional selector network, on top of which self-attention is conducted. In this example, the word \u201ctalk\u201d performs attention operation over input sequence, where the words \u201cBush\u201d, \u201cheld\u201d and \u201cSharon\u201d are chosen as the truly-significant words.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 91.0, "x1": 102.0, "y2": 302.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2225782606337, "y1": 280.3632524278429, "x1": 426.3430701361762, "y2": 321.90975613064234}, "name": "1", "caption_text": "Table 1: Results on the NLP benchmarks. \u201cSize\u201d indicates the number of training examples, and \u201c4\u201d denotes relative improvements over the vanilla SANs.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 86.0, "x1": 427.0, "y2": 263.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4481930202908, "y1": 256.0104793972439, "x1": 99.57083596123589, "y2": 280.95143636067706}, "name": "2", "caption_text": "Table 2: Results on the local bigram order shift detection task when SSANs are applied into different layers.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 370.0, "y1": 86.0, "x1": 133.0, "y2": 239.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 298.2674068874783, "x1": 426.772223578559, "y2": 356.41674465603296}, "name": "2", "caption_text": "Figure 2: Attention weights over attended words with different relative distance from the query word on the local reordering task. SSANs pay more attention to the adjacent words (distance=1) than SANs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 87.0, "x1": 453.0, "y2": 279.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2231716579861, "y1": 588.1160312228733, "x1": 426.772223578559, "y2": 646.2666405571831}, "name": "3", "caption_text": "Figure 3: Visualization of attention weights from an example on the local reordering detection task. We highlight the attended word (Y-axis) with maximum attention weight for each query (X-axis) in red rectangles.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 400.0, "x1": 428.0, "y2": 563.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.14640469021265, "y1": 256.0104793972439, "x1": 99.57083596123589, "y2": 280.95143636067706}, "name": "3", "caption_text": "Table 3: Performance on the global word reordering detection (WRD) task.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 86.0, "x1": 103.0, "y2": 239.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 322.58966233995227, "x1": 426.772223578559, "y2": 380.7403564453125}, "name": "4", "caption_text": "Figure 4: Attention weights over attended words with different relative distance from the query word on the global WRD task. SSANs pay more attention to the distant words (distance> 5) than SANs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 89.0, "x1": 453.0, "y2": 303.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.222663031684, "y1": 605.434078640408, "x1": 426.772223578559, "y2": 663.5832892523871}, "name": "5", "caption_text": "Figure 5: Visualization of attention weights from an example on the global reordering detection task. We highlight the attended word (Y-axis) with maximum attention weight for each query (X-axis) in red rectangles.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 419.0, "x1": 428.0, "y2": 580.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45035468207465, "y1": 274.82855055067273, "x1": 99.57083596123589, "y2": 299.7695075141059}, "name": "4", "caption_text": "Table 4: F1 score on the tree depth task. \u201cRatio\u201d denotes the portion each class takes.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 397.0, "y1": 86.0, "x1": 100.0, "y2": 275.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925537109375, "y1": 180.73683844672308, "x1": 426.3430701361762, "y2": 205.6791517469618}, "name": "6", "caption_text": "Table 6: Evaluation on constituency trees generated from the attention distribution.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 697.0, "y1": 86.0, "x1": 448.0, "y2": 180.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45035468207465, "y1": 454.9076928032769, "x1": 99.54305224948459, "y2": 513.0583021375868}, "name": "5", "caption_text": "Table 5: F1 score on the top constituent task. We report detailed results on 4 types of sentences: question (\u201cQues.\u201d), declarative (\u201cDecl.\u201d), a clause (\u201cClau.\u201d),nd other (\u201cOther\u201d) sentences.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 394.0, "y1": 323.0, "x1": 100.0, "y2": 455.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 643.6108907063801, "y1": 280.1243676079644, "x1": 186.31388346354166, "y2": 288.4611341688368}, "name": "6", "caption_text": "Figure 6: Example of constituency trees generated from the attention distributions.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 110.0, "x1": 102.0, "y2": 279.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9274020724827, "y1": 538.599353366428, "x1": 98.15974765353732, "y2": 563.5402679443359}, "name": "7", "caption_text": "Table 7: Attention distributions on linguistic roles for the structure modeling probing tasks (\u00a75.1, \u201cTreeDepth\u201d and \u201cTopConst\u201d) and the constituency tree generation task (\u00a75.2, \u201cEn\u21d2De Translation\u201d).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 309.0, "x1": 100.0, "y2": 538.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/a9e21b6d3bd6fd04b2894d8a96f4ce3f8dbab9ff/2020.acl-main.269.pdf", "dpi": 100}