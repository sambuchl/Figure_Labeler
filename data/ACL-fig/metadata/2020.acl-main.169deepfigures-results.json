{"raw_detected_boxes": [[], [], [{"x2": 712.0, "y1": 622.0, "x1": 442.0, "y2": 759.0}], [{"x2": 374.0, "y1": 266.0, "x1": 113.0, "y2": 397.0}], [{"x2": 714.0, "y1": 89.0, "x1": 127.0, "y2": 172.0}], [{"x2": 371.0, "y1": 243.0, "x1": 127.0, "y2": 353.0}], [{"x2": 682.0, "y1": 93.0, "x1": 143.0, "y2": 194.0}], [{"x2": 722.0, "y1": 93.0, "x1": 105.0, "y2": 174.0}, {"x2": 395.0, "y1": 216.0, "x1": 109.0, "y2": 397.0}], [{"x2": 718.0, "y1": 97.0, "x1": 112.0, "y2": 285.0}, {"x2": 383.0, "y1": 888.0, "x1": 119.0, "y2": 976.0}], [], [], [], [{"x2": 707.0, "y1": 103.0, "x1": 114.0, "y2": 364.0}, {"x2": 718.0, "y1": 439.0, "x1": 115.0, "y2": 1014.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "4", "captionBoundary": {"x2": 280.21209716796875, "y1": 267.5535583496094, "x1": 82.05599975585938, "y2": 273.5560302734375}, "imageText": [], "regionBoundary": {"x2": 272.0, "y1": 173.8900146484375, "x1": 90.0, "y2": 255.8900146484375}, "caption": "Figure 4: Creation of training data for add-tagger.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 427.60955810546875, "y1": 148.09756469726562, "x1": 169.6280059814453, "y2": 154.10003662109375}, "imageText": ["OURS", "89.50", "70.44", "36.26", "70.99", "82.21", "52.76", "37.42", "74.59", "87.74", "68.44", "45.44", "77.51", "CAE", "99.62", "6.94", "10.73", "25.71", "65.21", "9.25", "14.72", "42.42", "77.71", "3.17", "7.79", "27.17", "BST", "60.75", "2.55", "9.19", "18.99", "54.4", "20.73", "22.57", "55.55", "88.49", "10.71", "16.26", "41.02", "DRG", "90.25", "11.83", "18.07", "41.09", "36.29", "22.9", "22.84", "53.30", "69.79", "25.69", "21.6", "51.8", "Acc", "BL-s", "MET", "ROU", "Acc", "BL-s", "MET", "ROU", "ACC", "BL-s", "MET", "ROU", "Politeness", "Gender", "Political"], "regionBoundary": {"x2": 491.0, "y1": 62.8900146484375, "x1": 102.0, "y2": 139.8900146484375}, "caption": "Table 1: Results on the Politeness, Gender and Political datasets.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 515.8165283203125, "y1": 563.6975708007812, "x1": 317.00299072265625, "y2": 581.655029296875}, "imageText": [], "regionBoundary": {"x2": 519.0, "y1": 439.8900146484375, "x1": 314.0, "y2": 551.8900146484375}, "caption": "Figure 1: Distribution of Politeness Scores for the Enron Corpus", "page": 2}, {"figType": "Table", "name": "6", "captionBoundary": {"x2": 520.4951171875, "y1": 277.6405334472656, "x1": 76.74099731445312, "y2": 283.64300537109375}, "imageText": ["go", "ahead", "and", "sign", "it", "-", "i", "did", ".", "go", "away", "so", "we", "can", "get", "it", "approved", ".", "we", "could", "go", "ahead", "and", "sign", "it", "-", "i", "did", "look", "at", "can", "you", "explain", "a", "bit", "more", "about", "how", "those", "two", "coexist", "?", "also", "thanks", "i", "can", "explain", "how", "the", "two", "more", "than", "<unk>", "i", "can", "help", "with", "mike", "?", "can", "you", "explain", "a", "bit", "more", "about", "how", "those", "two", "coexist", "?", "also", ".....", "yes,", "we", "can", "go", "ahead", "and", "remove", "it.", "yes,", "go", "ahead", "and", "remove", "it.", "yes,", "please", "go", "to", "the", "link", "below", "and", "delete", "it.", "anyway", "you", "can", "let", "me", "know.", "anyway,", "i\u2019m", "sure", "i\u2019m", "sure.", "anyway", "please", "let", "me", "know", "as", "soon", "as", "possible", "i\u2019ll", "call", "today", "to", "discuss", "this.", "if", "you", "have", "a", "few", "minutes", "today,", "please", "give", "me", "a", "call", "at", "if", "you", "have", "a", "few", "minutes", "today,", "give", "me", "a", "call", "jon", "-", "sorry", "-", "please", "use", "this", "resigna-", "tion", "letter", "in", "lieu", "of", "the", "one", "event", "sent", "on", "-", "i", "think", "this", "would", "be", "a", "good", "idea", "if", "you", "could", "not", "be", "a", "statement", "that", "harry", "\u2019s", "signed", "in", "one", "of", "the", "sched-", "ule", ".", "jon", "-", "-", "please", "use", "this", "resignation", "let-", "ter", "in", "lieu", "of", "the", "one", "sent", "on", "friday", ".", "Non-polite", "Input", "DRG", "Our", "Model"], "regionBoundary": {"x2": 516.0, "y1": 73.8900146484375, "x1": 82.0, "y2": 262.8900146484375}, "caption": "Table 6: Additional Qualitative Examples of outputs from our Model and DRG for the Politeness Transfer Task", "page": 12}, {"figType": "Table", "name": "7", "captionBoundary": {"x2": 478.2890319824219, "y1": 742.466552734375, "x1": 118.947998046875, "y2": 748.468994140625}, "imageText": ["Fact", "\u2192", "Hum", "a", "black", "dog", "plays", "around", "in", "water", ".", "a", "black", "dog", "plays", "in", "the", "water", ".", "a", "black", "dog", "plays", "around", "in", "wa-", "ter", "looking", "for", "\ufb01sh", ".", "Fact", "\u2192", "Hum", "three", "kids", "play", "on", "a", "wall", "with", "a", "green", "ball", ".", "three", "kids", "on", "a", "bar", "on", "a", "\ufb01eld", "of", "a", "date", ".", "three", "kids", "play", "on", "a", "wall", "with", "a", "green", "ball", "\ufb01ghting", "for", "supremacy", ".", "Fact", "\u2192", "Rom", "two", "dogs", "play", "with", "a", "tennis", "ball", "in", "the", "snow", ".", "two", "dogs", "play", "with", "a", "tennis", "ball", "in", "the", "snow", ".", "two", "dogs", "play", "with", "a", "tennis", "ball", "in", "the", "snow", "celebrating", "their", "friendship", ".", "Fact", "\u2192", "Rom", "a", "woman", "is", "sitting", "near", "a", "\ufb02ower", "bed", "overlooking", "a", "tunnel", ".", "a", "woman", "is", "sitting", "near", "a", "\ufb02ower", "overlooking", "a", "tunnel,", "determined", "to", "a", "woman", "is", "sitting", "near", "a", "brick", "rope", ",", "excited", "to", "meet", "her", "boyfriend", ".", "Rep", "\u2192", "Dem", "mr.", "trump", "is", "good", "...", "but", "mr.", "marco", "rubio", "is", "great", "!", "!", "thank", "you", "mr.", "good", "...", "but", "mr.", "kaine", "is", "great", "senator", "!", "!", "mr.", "schumer", "is", "good", "...", "but", "mr.", "pallone", "is", "great", "!", "!", "Rep", "\u2192", "Dem", "video", ":", "black", "patriots", "demand", "im-", "peachment", "of", "obama", "video", ":", "black", "police", "show", "choose", "video", ":", "black", "patriots", "demand", "to", "endorse", "obama", "Dem", "\u2192", "Rep", "we", "will", "resist", "trump", "we", "will", "impeach", "obama", "we", "will", "be", "praying", "for", "trump", "Dem", "\u2192", "Rep", "i", "am", "con\ufb01dent", "of", "trumps", "slaughter", ".", "i", "am", "mia", "love", "i", "am", "con\ufb01dent", "of", "trumps", "ad-", "ministration", ".", "Neg", "\u2192", "Pos", "salsa", "is", "not", "hot", "or", "good", ".", "salsa", "is", "not", "hot", "or", "good", ".", "salsa", "is", "always", "hot", "and", "fresh", ".", "Neg", "\u2192", "Pos", "this", "is", "the", "reason", "i", "will", "never", "go", "back", ".", "this", "is", "the", "reason", "i", "will", "never", "go", "back", ".", "so", "happy", "i", "will", "de\ufb01nitely", "be", "back", ".", "Pos", "\u2192", "Neg", "i", "will", "be", "going", "back", "and", "enjoying", "this", "great", "place", "!", "i", "will", "be", "going", "back", "and", "enjoying", "this", "great", "!", "i", "will", "not", "be", "going", "back", "and", "enjoying", "this", "garbage", "!", "Pos", "\u2192", "Neg", "good", "drinks", ",", "and", "good", "company", ".", "horrible", "company", ".", "terrible", "drinks", ",", "terrible", "com-", "pany.", "Male", "\u2192", "Fem", "however", ",", "once", "inside", "the", "place", "was", "empty", ".", "however", ",", "when", "the", "restaurant", "was", "happy", "hour", "for", "dinner", ".", "however", ",", "once", "inside", "the", "place", "was", "super", "cute", ".", "Male", "\u2192", "Fem", "my", "girlfriend", "and", "i", "recently", "stayed", "at", "this", "sheraton", ".", "i", "recently", "went", "with", "the", "club", ".", "my", "husband", "and", "i", "recently", "stayed", "at", "this", "of\ufb01ce", ".", "Fem", "\u2192", "Male", "i", "\u2019", "m", "a", "fair", "person", ".", "i", "\u2019", "m", "a", "good", "job", "of", "the", "<unk>", ".", "i", "\u2019", "m", "a", "big", "guy", ".", "Fem", "\u2192", "Male", "my", "husband", "ordered", "the", "brisket", ".", "my", "wife", "had", "the", "best", "steak", ".", "my", "wife", "ordered", "the", "brisket", ".", "Task", "Non-polite", "Input", "DRG", "Our", "Model"], "regionBoundary": {"x2": 519.0, "y1": 316.8900146484375, "x1": 78.0, "y2": 729.8900146484375}, "caption": "Table 7: Additional Qualitative Examples of our Model and DRG for other Transfer Tasks", "page": 12}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 419.912353515625, "y1": 139.13052368164062, "x1": 177.322998046875, "y2": 145.13299560546875}, "imageText": ["OURS", "86.6", "47.14", "19.76", "36.26", "70.99", "66.4", "68.74", "34.80", "45.3", "83.45", "93.17", "51.01", "15.63", "43.67", "79.51", "CAE", "72.1", "19.95", "7.75", "21.70", "55.9", "78", "2.64", "1.68", "9.52", "29.16", "89.66", "2.09", "1.57", "9.61", "30.02", "DRG", "88.8", "36.69", "14.51", "32.09", "61.06", "52.2", "57.07", "29.85", "50.16", "79.31", "95.65", "31.79", "11.78", "32.45", "64.32", "Acc", "BL-s", "BL-r", "MET", "ROU", "Acc", "BL-s", "BL-r", "MET", "ROU", "Acc", "BL-s", "BL-r", "MET", "ROU", "Yelp", "Amazon", "Captions"], "regionBoundary": {"x2": 526.0, "y1": 67.8753662109375, "x1": 72.0, "y2": 129.8900146484375}, "caption": "Table 2: Results on the Yelp, Amazon and Captions datasets.", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 290.2727355957031, "y1": 240.48452758789062, "x1": 72.0, "y2": 313.780029296875}, "imageText": ["Politeness", "2.9", "3.6", "3.2", "3.6", "2.0", "3.7", "Gender", "3.0", "3.5", "-", "-", "2.2", "2.5", "Political", "2.9", "3.2", "-", "-", "2.5", "2.7", "Yelp", "3.0", "3.7", "3", "3.9", "2.7", "3.3", "DRG", "Ours", "DRG", "Ours", "DRG", "Ours", "Con", "Att", "Gra"], "regionBoundary": {"x2": 274.0, "y1": 154.8900146484375, "x1": 84.0, "y2": 232.8900146484375}, "caption": "Table 3: Human evaluation on Politeness, Gender, Political and Yelp datasets. dataset. Despite high evaluation scores, it does not reflect a high rate of success on the task. In summary, evaluation via automatic metrics might not truly correlate with task success.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 288.3768005371094, "y1": 303.4925231933594, "x1": 73.89199829101562, "y2": 322.94500732421875}, "imageText": [], "regionBoundary": {"x2": 284.0, "y1": 182.8900146484375, "x1": 79.0, "y2": 291.8900146484375}, "caption": "Figure 2: Probability of occurrence for 10 of the most common 30 words in the P0 and P9 data buckets", "page": 3}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 521.6148071289062, "y1": 220.20455932617188, "x1": 75.62100219726562, "y2": 226.20703125}, "imageText": ["please", "check", "on", "metromedia", "energy,", "thanks", "again", "on", "the", "energy", "in-", "dustry,", "please", "check", "on", "metromedia", "en-", "ergy,", "thanks", "Mitigating", "please", "start", "not", "yet-i\u2019ll", "try", "this", "wkend.", "not", "yet", "to", "say-i", "think", "this", "will", "be", "a", "<unk>", "long.", "sorry", "not", "yet-i\u2019ll", "try", "to", "make", "sure", "this", "wk", "Apologizing", "yes,", "go", "ahead", "and", "remove", "it.", "yes,", "please", "go", "to", "the", "link", "below", "and", "delete", "it.", "yes,", "we", "can", "go", "ahead", "and", "remove", "it.", "1st", "Person", "Plu-", "ral", "Counterfactual", "Modal", "what", "happened", "to", "my", "personal", "station?", "what", "happened", "to", "my", "mother", "to", "my", "co???", "could", "you", "please", "let", "me", "know", "what", "happened", "to", "my", "personal", "station?", "Input", "DRG", "Output", "Our", "Model", "Output", "Strategy"], "regionBoundary": {"x2": 519.0, "y1": 70.8643798828125, "x1": 78.0, "y2": 204.8900146484375}, "caption": "Table 4: Qualitative Examples comparing the outputs from DRG and Our model for the Politeness Transfer Task", "page": 8}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 284.85455322265625, "y1": 717.7685546875, "x1": 77.27400207519531, "y2": 735.7260131835938}, "imageText": ["Add-Tagger", "53.2", "20.66", "93.17", "15.63", "Replace-Tagger", "86.6", "19.76", "84.5", "15.04", "Combined", "72.5", "22.46", "82.17", "18.51", "Acc", "BL-r", "Acc", "BL-r", "Yelp", "Captions"], "regionBoundary": {"x2": 276.0, "y1": 634.8900146484375, "x1": 84.0, "y2": 702.8900146484375}, "caption": "Table 5: Comparison of different tagger variants for Yelp and Captions datasets", "page": 8}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 522.9574584960938, "y1": 137.66152954101562, "x1": 75.75199890136719, "y2": 160.33416748046875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 125.8900146484375}, "caption": "Figure 3: Our proposed approach: tag and generate. The tagger infers the interpretable style free sentence z(xi) for an input x(1)i in source style S1. The generator transforms x (1) i into x\u0302 (2) i which is in target style S2.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 716.4118448893229, "y1": 782.9132927788628, "x1": 440.28193155924475, "y2": 807.8542073567708}, "name": "1", "caption_text": "Figure 1: Distribution of Politeness Scores for the Enron Corpus", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 712.0, "y1": 622.0, "x1": 439.0, "y2": 759.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 400.52333407931854, "y1": 421.51739332411023, "x1": 102.62777540418837, "y2": 448.53473239474823}, "name": "2", "caption_text": "Figure 2: Probability of occurrence for 10 of the most common 30 words in the P0 and P9 data buckets", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 374.0, "y1": 266.0, "x1": 112.0, "y2": 398.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 726.3298034667969, "y1": 191.19656880696613, "x1": 105.21110958523221, "y2": 222.68634372287326}, "name": "3", "caption_text": "Figure 3: Our proposed approach: tag and generate. The tagger infers the interpretable style free sentence z(xi) for an input x(1)i in source style S1. The generator transforms x (1) i into x\u0302 (2) i which is in target style S2.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 723.0, "y1": 89.0, "x1": 127.0, "y2": 189.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 389.18346828884546, "y1": 371.60216437445746, "x1": 113.96666632758246, "y2": 379.93893093532984}, "name": "4", "caption_text": "Figure 4: Creation of training data for add-tagger.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 376.0, "y1": 243.0, "x1": 127.0, "y2": 354.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 593.9021640353733, "y1": 205.69106207953558, "x1": 235.59445275200736, "y2": 214.027828640408}, "name": "1", "caption_text": "Table 1: Results on the Politeness, Gender and Political datasets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 682.0, "y1": 86.0, "x1": 142.0, "y2": 211.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 583.2116021050347, "y1": 193.23683844672308, "x1": 246.28194173177081, "y2": 201.5736050075955}, "name": "2", "caption_text": "Table 2: Results on the Yelp, Amazon and Captions datasets.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 86.0, "x1": 100.0, "y2": 181.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15657721625433, "y1": 334.00628831651477, "x1": 100.0, "y2": 435.80559624565973}, "name": "3", "caption_text": "Table 3: Human evaluation on Politeness, Gender, Political and Yelp datasets. dataset. Despite high evaluation scores, it does not reflect a high rate of success on the task. In summary, evaluation via automatic metrics might not truly correlate with task success.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 412.0, "y1": 199.0, "x1": 100.0, "y2": 414.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 724.4650099012587, "y1": 305.83966573079425, "x1": 105.02916971842447, "y2": 314.17643229166663}, "name": "4", "caption_text": "Table 4: Qualitative Examples comparing the outputs from DRG and Our model for the Politeness Transfer Task", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 86.0, "x1": 109.0, "y2": 285.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 395.6313239203559, "y1": 996.9007703993055, "x1": 107.32500288221571, "y2": 1021.8416849772135}, "name": "5", "caption_text": "Table 5: Comparison of different tagger variants for Yelp and Captions datasets", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 383.0, "y1": 882.0, "x1": 117.0, "y2": 976.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 722.9098849826389, "y1": 385.6118520100911, "x1": 106.584718492296, "y2": 393.9486185709635}, "name": "6", "caption_text": "Table 6: Additional Qualitative Examples of outputs from our Model and DRG for the Politeness Transfer Task", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 716.0, "y1": 102.0, "x1": 114.0, "y2": 364.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 664.2903221978081, "y1": 1031.2035454644097, "x1": 165.20555284288193, "y2": 1039.5402696397568}, "name": "7", "caption_text": "Table 7: Additional Qualitative Examples of our Model and DRG for other Transfer Tasks", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 439.0, "x1": 109.0, "y2": 1031.0}, "page": 12, "dpi": 0}], "error": null, "pdf": "/work/host-output/6a96126cc60fbf924d723da80437d2da0b537705/2020.acl-main.169.pdf", "dpi": 100}