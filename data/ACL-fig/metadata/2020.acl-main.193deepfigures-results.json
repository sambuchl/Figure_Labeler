{"raw_detected_boxes": [[], [{"x2": 700.0, "y1": 87.0, "x1": 127.0, "y2": 231.0}], [], [{"x2": 671.0, "y1": 75.0, "x1": 155.0, "y2": 257.0}], [], [{"x2": 711.0, "y1": 92.0, "x1": 120.0, "y2": 314.0}], [{"x2": 725.0, "y1": 78.0, "x1": 105.0, "y2": 233.0}, {"x2": 698.0, "y1": 298.0, "x1": 455.0, "y2": 461.0}, {"x2": 725.0, "y1": 512.0, "x1": 429.0, "y2": 617.0}], [{"x2": 698.0, "y1": 90.0, "x1": 129.0, "y2": 582.0}], [{"x2": 338.0, "y1": 105.0, "x1": 165.0, "y2": 231.0}], [], [], [{"x2": 714.0, "y1": 153.0, "x1": 443.0, "y2": 925.0}], [{"x2": 719.0, "y1": 215.0, "x1": 104.0, "y2": 444.0}, {"x2": 724.0, "y1": 753.0, "x1": 106.0, "y2": 891.0}]], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5435791015625, "y1": 241.09451293945312, "x1": 72.0, "y2": 257.05999755859375}, "imageText": ["Gold", "(Upper", "Bound)", "89.48(\u00b10.32)", "89.55(\u00b10.06)", "89.51(\u00b10.21)", "92.12(\u00b10.31)", "91.73(\u00b10.09)", "91.92(\u00b10.21)", "CONNET", "(Ours)", "84.11(\u00b10.71)", "68.61(\u00b10.03)", "75.57(\u00b10.27)", "88.77(\u00b10.25)", "72.79(\u00b10.04)", "79.99(\u00b10.08)", "CONCAT-SLM", "85.95(\u00b11.00)", "57.96(\u00b10.26)", "69.23(\u00b10.13)", "91.12(\u00b10.57)", "55.41(\u00b12.66)", "68.89(\u00b11.92)", "MVT-SLM", "84.78(\u00b10.66)", "62.50(\u00b11.36)", "71.94(\u00b10.66)", "86.96(\u00b11.22)", "58.07(\u00b10.11)", "69.64(\u00b10.31)", "MVS-SLM", "84.76(\u00b10.50)", "61.95(\u00b10.32)", "71.57(\u00b10.04)", "86.95(\u00b11.12)", "56.23(\u00b10.01)", "68.30(\u00b10.33)", "DS-SLM", "(Nguyen", "et", "al.,", "2017)", "72.30\u2217", "61.17\u2217", "66.27\u2217", "-", "-", "-", "HMM-SLM", "(Nguyen", "et", "al.,", "2017)", "76.19\u2217", "66.24\u2217", "70.87\u2217", "-", "-", "-", "MTL-MVT", "(Wang", "et", "al.,", "2018)", "81.81(\u00b12.34)", "62.51(\u00b10.28)", "70.87(\u00b11.06)", "88.88(\u00b10.25)", "65.04(\u00b10.80)", "75.10(\u00b10.44)", "MTL-BEA", "(Rahimi", "et", "al.,", "2019)", "85.72(\u00b10.66)", "58.28(\u00b10.43)", "69.39(\u00b10.52)", "77.56(\u00b12.23)", "67.23(\u00b10.72)", "72.01(\u00b10.85)", "CRF-MA", "(Rodrigues", "et", "al.,", "2014)", "-", "-", "-", "49.40\u2217", "85.60\u2217", "62.60\u2217", "Crowd-Add", "(Nguyen", "et", "al.,", "2017)", "85.81(\u00b11.53)", "62.15(\u00b10.18)", "72.09(\u00b10.42)", "89.74(\u00b10.10)", "64.50(\u00b11.48)", "75.03(\u00b11.02)", "Crowd-Cat", "(Nguyen", "et", "al.,", "2017)", "85.02(\u00b10.98)", "62.73(\u00b11.10)", "72.19(\u00b10.37)", "89.72(\u00b10.47)", "63.55(\u00b11.20)", "74.39(\u00b10.98)", "CL-MW", "(Rodrigues", "and", "Pereira,", "2018)", "-", "-", "-", "66.00\u2217", "59.30\u2217", "62.40\u2217", "Precision(%)", "Recall(%)", "F1-score(%)", "Precision(%)", "Recall(%)", "F1-score(%)", "Methods", "AMTC", "AMT"], "regionBoundary": {"x2": 513.0, "y1": 67.22797393798828, "x1": 84.0, "y2": 228.8900146484375}, "caption": "Table 1: Performance on real-world crowd-sourced NER datasets. The best score in each column excepting Gold is marked bold. * indicates number reported by the paper.", "page": 5}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5443725585938, "y1": 183.92953491210938, "x1": 72.0, "y2": 201.88800048828125}, "imageText": [], "regionBoundary": {"x2": 507.0, "y1": 61.8900146484375, "x1": 91.0, "y2": 171.8900146484375}, "caption": "Figure 1: Illustration of the task settings for the two applications in this work: (a) learning consensus model from crowd annotations; (b) unsupervised cross-domain model adaptation.", "page": 1}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5399780273438, "y1": 339.2805480957031, "x1": 307.2760009765625, "y2": 355.2450256347656}, "imageText": ["F1", "(%", ")", "V)", "AP", "(PM", "V)", "AP", "(AM", "V)", "AP", "(AW", "V)", "AP", "(OM", "CR", "F", "DP", "(1)", "DP", "(2)", "DP", "(1+", "2)", "85", "80", "75", "70", "65", "60", "78.73", "79.99", "68.67", "70.53", "79.08", "72.16", "77.44", "68.89"], "regionBoundary": {"x2": 503.0, "y1": 211.73004150390625, "x1": 331.5465393066406, "y2": 332.1419677734375}, "caption": "Figure 4: Performance of CONNET variants of decoupling phase (DP) and aggregation phase (AP).", "page": 6}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 525.5455322265625, "y1": 454.4515380859375, "x1": 307.2760009765625, "y2": 480.3800354003906}, "imageText": ["(a)", "Reliability", "level", "(b)", "Number", "of", "Annotators", "MVT-SLM", "Crowd-Cat", "ConNet", "(a)", "Reliability", "Level", ")", "F1", "(%", "1/5", "1/10", "1/15", "1/30", "1/50", "80.00", "70.00", "60.00", "50.00", "ConNet", "40.00", "MVT-SLM", "Crowd-Cat", "(b)", "Annotator", "Number", ")", "F1", "(%", "5", "10", "15", "30", "50", "60.00", "55.00", "50.00", "45.00", "40.00", "35.00"], "regionBoundary": {"x2": 525.0, "y1": 363.8900146484375, "x1": 308.0, "y2": 442.1210632324219}, "caption": "Figure 5: Performance on simulated crowd-sourced NER data with (a) 5 annotators with different reliability levels; (b) different numbers of annotators with reliability r = 1/50.", "page": 6}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 525.5408325195312, "y1": 182.20352172851562, "x1": 72.0, "y2": 198.16900634765625}, "imageText": ["\u22120.5", "0.0", "0.5", "1.0", "1.5", "0.8", "0.6", "0.4", "0.2", "0.0", "snt1(PER)", "snt2(ORG)", "snt3(LOC)", "snt4(MISC)", "(b)", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "Annotator", "ID", "PER", "ORG", "LOC", "MISC", "(a)", "Overall", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46"], "regionBoundary": {"x2": 525.556396484375, "y1": 55.8900146484375, "x1": 77.32504272460938, "y2": 171.95294189453125}, "caption": "Figure 3: Visualizations of (a) the expertise of annotators; (b) attention weights for sample sentences. More cases and details are described in Appendix A.1.", "page": 6}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.54541015625, "y1": 653.800537109375, "x1": 72.0, "y2": 669.7659912109375}, "imageText": ["Gold", "(Upper", "Bound)", "81.24(\u00b11.25)", "80.52(\u00b10.37)", "80.87(\u00b10.79)", "90.45(\u00b10.71)", "CONNET", "(Ours)", "76.86(\u00b10.33)", "56.43(\u00b13.32)", "65.05(\u00b12.32)", "89.27(\u00b10.31)", "MVT-SLM", "72.21(\u00b11.63)", "51.72(\u00b13.58)", "60.21(\u00b11.87)", "87.23(\u00b10.51)", "Crowd-Add", "(Nguyen", "et", "al.,", "2017)", "75.32(\u00b11.41)", "50.80(\u00b10.30)", "60.68(\u00b10.67)", "88.20(\u00b10.36)", "Precision(%)", "Recall(%)", "F1-score(%)", "Accuracy(%)", "Methods", "AMTC", "UD"], "regionBoundary": {"x2": 524.0, "y1": 542.8900146484375, "x1": 74.0, "y2": 641.8900146484375}, "caption": "Table 4: Performance of methods with Transformer-CRF as the base model on crowd-annotation NER dataset AMTC and cross-domain POS dataset UD.", "page": 12}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 525.5472412109375, "y1": 332.8385314941406, "x1": 72.0, "y2": 350.7959899902344}, "imageText": ["2.0", "1.5", "1.0", "0.5", "0.0", "\u22120.5", "0.0", "0.2", "0.4", "0.6", "0.8", "(b)", "snt10", "snt11", "snt12", "snt13", "snt14", "snt15", "snt5", "snt6", "snt7", "snt8", "snt9", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "Annotator", "ID", "(a)", "ORG", "LOC", "MISC", "Overall", "PER", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46"], "regionBoundary": {"x2": 524.5167236328125, "y1": 154.8900146484375, "x1": 77.21544647216797, "y2": 319.55645751953125}, "caption": "Figure 7: Visualizations of (a) the expertise of annotators; (b) attention weights for additional sample sentences to Fig. 3. Details of samples are described in Tab. 3.", "page": 12}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.538818359375, "y1": 433.19354248046875, "x1": 72.0, "y2": 451.1510009765625}, "imageText": ["Gold", "(Upper", "Bound)", "78.78", "82.11", "86.21", "85.76", "83.22(\u00b10.19)", "CONNET", "78.75", "81.06", "84.12", "83.45", "81.85(\u00b10.04)", "Crowd-Add", "(Nguyen", "et", "al.,", "2017)", "75.72", "77.35", "81.25", "82.90", "79.30(\u00b19.21)", "Crowd-Cat", "(Nguyen", "et", "al.,", "2017)", "76.45", "77.37", "81.22", "83.12", "79.54(\u00b10.25)", "Tri-Training", "(Ruder", "and", "Plank,", "2018)", "77.58", "78.45", "81.95", "83.17", "80.29(\u00b10.02)", "CONCAT", "75.68", "77.02", "81.87", "83.07", "79.41(\u00b10.02)", "MTL-MVT", "(Wang", "et", "al.,", "2018)", "74.92", "74.43", "79.33", "81.47", "77.54(\u00b10.06)", "MTL-BEA", "(Rahimi", "et", "al.,", "2019)", "74.88", "74.60", "79.73", "82.82", "78.01(\u00b10.28)", "Target", "Domain", "books", "dvd", "electronics", "kitchen", "AVG", "Acc(%)", "Task", "&", "Corpus", "Multi-Domain", "Text", "Classi\ufb01cation:", "MDS", "Gold", "(Upper", "Bound)", "84.70", "46.98", "83.77", "52.57", "73.05", "70.58", "68.61(\u00b10.64)", "CONNET", "71.31", "34.06", "79.66", "52.72", "71.47", "70.71", "63.32(\u00b10.81)", "Crowd-Add", "(Nguyen", "et", "al.,", "2017)", "45.76", "32.51", "50.01", "26.47", "52.94", "28.12", "39.30(\u00b14.44)", "Crowd-Cat", "(Nguyen", "et", "al.,", "2017)", "68.95", "32.61", "78.07", "53.41", "74.22", "65.55", "62.14(\u00b10.89)", "Tri-Training", "(Ruder", "and", "Plank,", "2018)", "69.68", "33.41", "79.62", "47.91", "70.85", "68.53", "61.67(\u00b10.31)", "Target", "Domain", "nw", "wb", "bn", "tc", "bc", "mz", "AVG", "F1(%)", "CONCAT", "68.23", "32.96", "77.25", "53.66", "72.74", "62.61", "61.24(\u00b10.92)", "MTL-MVT", "(Wang", "et", "al.,", "2018)", "65.74", "33.25", "76.80", "53.16", "69.77", "63.91", "60.44(\u00b10.45)", "MTL-BEA", "(Rahimi", "et", "al.,", "2019)", "58.33", "32.62", "72.47", "47.83", "48.99", "52.68", "52.15(\u00b10.58)", "Task", "&", "Corpus", "Multi-Domain", "NER:", "OntoNotes", "v5.0", "-", "English", "Gold", "(Upper", "Bound)", "92.64", "93.10", "93.15", "91.33", "93.09", "94.67", "92.20", "92.88(\u00b10.14)", "CONNET", "92.97", "92.25", "93.15", "91.06", "92.52", "92.74", "91.66", "92.33(\u00b10.17)", "Crowd-Add", "(Nguyen", "et", "al.,", "2017)", "92.58", "91.91", "91.50", "90.73", "91.74", "90.47", "90.61", "91.36(\u00b10.14)", "Crowd-Cat", "(Nguyen", "et", "al.,", "2017)", "92.71", "91.71", "92.48", "91.15", "92.35", "91.97", "91.22", "91.94(\u00b10.08)", "Tri-Training", "(Ruder", "and", "Plank,", "2018)", "92.84", "92.15", "92.51", "91.40", "92.35", "91.29", "91.00", "91.93(\u00b10.01)", "CONCAT", "92.68", "92.12", "93.05", "90.79", "92.38", "92.32", "91.44", "92.11(\u00b10.07)", "MTL-MVT", "(Wang", "et", "al.,", "2018)", "92.42", "90.59", "91.16", "89.69", "90.75", "90.29", "90.21", "90.73(\u00b10.29)", "MTL-BEA", "(Rahimi", "et", "al.,", "2019)", "92.87", "91.88", "91.90", "91.03", "91.67", "91.31", "91.29", "91.71(\u00b10.06)", "Target", "Domain", "academic", "bio", "\ufb01ction", "news", "voyage", "wiki", "interview", "AVG", "Acc(%)", "Task", "&", "Corpus", "Multi-Domain", "POS", "Tagging:", "Universal", "Dependencies", "v2.3", "-", "GUM"], "regionBoundary": {"x2": 506.0, "y1": 62.8900146484375, "x1": 92.0, "y2": 420.8900146484375}, "caption": "Table 2: Performance on cross-domain data The best score (except the Gold) in each column that is significantly (p < 0.05) better than the second best is marked bold, while those are better but not significantly are underlined.", "page": 7}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5471801757812, "y1": 195.96652221679688, "x1": 72.0, "y2": 221.89398193359375}, "imageText": ["Decoupling", "Phase", "Aggregation", "Phase", "CRF", "Annotator", "{\ud835\udc00(1)}", "BLSTM", "CRF", "BLSTM", "Consensus", "\ud835\udc000", "\u2217", "prediction", "(\ud835\udc328", "(1))", "prediction", "(\ud835\udc328)", "Weighted", "Voting", "Attention", "(\ud835\udc10)", "source", "ID", "(\ud835\udc58)sentence", "(\ud835\udc310", "1)", "sentence", "(\ud835\udc31)"], "regionBoundary": {"x2": 483.0, "y1": 53.8900146484375, "x1": 112.0, "y2": 190.8900146484375}, "caption": "Figure 2: Overview of the CONNET framework. The decoupling phase constructs the shared model (yellow) and sourcespecific matrices (blue). The aggregation phase dynamically combines crowd components into a consensus representation (blue) by a context-aware attention module (red) for each sentence x.", "page": 3}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5465087890625, "y1": 684.2705688476562, "x1": 307.2759704589844, "y2": 714.1829833984375}, "imageText": ["10", "On", "Friday", "for", "their", "friendly", "against", "[LOC", "Scotland]", "at", "[LOC", "Murray-", "\ufb01eld]", "more", "than", "a", "year", "after", "the", "30-", "year-old", "wing", "announced", "he", "was", "re-", "tiring", "following", "differences", "over", "se-", "lection", ".", "11", "Scoreboard", "in", "the", "[MISC", "World", "Se-", "ries]", "12", "Cricket", "-", "[MISC", "Shef\ufb01eld", "Shield]", "score", ".", "13", "\u201c", "He", "ended", "the", "[MISC", "World", "Cup]", "on", "the", "wrong", "note", ",", "\u201d", "[PER", "Coste]", "said", ".", "14", "Soccer", "-", "[ORG", "Leeds]", "\u2019", "[PER", "Bowyer]", "\ufb01ned", "for", "part", "in", "fast-food", "fracas", ".", "15", "[ORG", "Rugby", "Union]", "-", "[PER", "Cut-", "titta]", "back", "for", "[LOC", "Italy]", "after", "a", "year", ".", "4", "The", "former", "[MISC", "Soviet]", "repub-", "lic", "was", "playing", "in", "an", "[MISC", "Asian", "Cup]", "\ufb01nals", "tie", "for", "the", "\ufb01rst", "time", ".", "5", "[PER", "Bitar]", "pulled", "off", "\ufb01ne", "saves", "whenever", "they", "did", ".", "6", "[PER", "Coste]", "said", "he", "had", "approached", "the", "player", "two", "months", "ago", "about", "a", "comeback", ".", "7", "[ORG", "Goias]", "1", "[ORG", "Gremio]", "3", "8", "[ORG", "Portuguesa]", "1", "[ORG", "Atletico", "Mineiro]", "0", "9", "[LOC", "Melbourne]", "1996-12-06", "Hosts", "[LOC", "UAE]", "play", "[LOC", "Kuwait]", "and", "[LOC", "South", "Korea]", "take", "on", "[LOC", "Indonesia]", "on", "Saturday", "in", "Group", "A", "matches", ".", "3", "2", "[ORG", "Plymouth]", "4", "[ORG", "Exeter]", "1", "Defender", "[PER", "Hassan", "Abbas]", "rose", "to", "intercept", "a", "long", "ball", "into", "the", "area", "in", "the", "84th", "minute", "but", "only", "man-", "aged", "to", "divert", "it", "into", "the", "top", "corner", "of", "[PER", "Bitar]", "\u2019s", "goal", ".", "1"], "regionBoundary": {"x2": 514.0, "y1": 107.8900146484375, "x1": 319.0, "y2": 671.8900146484375}, "caption": "Table 3: Sample instances in Fig. 3 and Fig. 7 with NER annotations including PER (red), ORG (blue), LOC (violet) and MISC (orange).", "page": 11}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 290.26837158203125, "y1": 183.89956665039062, "x1": 72.0, "y2": 199.86505126953125}, "imageText": [], "regionBoundary": {"x2": 255.0, "y1": 61.8900146484375, "x1": 108.0, "y2": 171.8900146484375}, "caption": "Figure 6: Heatmap of averaged attention scores from each source domain to each target domain.", "page": 8}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9227396647135, "y1": 255.4576873779297, "x1": 100.0, "y2": 280.4000006781684}, "name": "1", "caption_text": "Figure 1: Illustration of the task settings for the two applications in this work: (a) learning consensus model from crowd annotations; (b) unsupervised cross-domain model adaptation.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 701.0, "y1": 87.0, "x1": 127.0, "y2": 231.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9266391330295, "y1": 272.17572530110675, "x1": 100.0, "y2": 308.1860860188802}, "name": "2", "caption_text": "Figure 2: Overview of the CONNET framework. The decoupling phase constructs the shared model (yellow) and sourcespecific matrices (blue). The aggregation phase dynamically combines crowd components into a consensus representation (blue) by a context-aware attention module (red) for each sentence x.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 688.0, "y1": 75.0, "x1": 140.0, "y2": 274.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.921637641059, "y1": 334.8534901936849, "x1": 100.0, "y2": 357.02777438693573}, "name": "1", "caption_text": "Table 1: Performance on real-world crowd-sourced NER datasets. The best score in each column excepting Gold is marked bold. * indicates number reported by the paper.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 713.0, "y1": 86.0, "x1": 117.0, "y2": 318.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9178229437933, "y1": 253.06044684516058, "x1": 100.0, "y2": 275.23473103841144}, "name": "3", "caption_text": "Figure 3: Visualizations of (a) the expertise of annotators; (b) attention weights for sample sentences. More cases and details are described in Appendix A.1.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 78.0, "x1": 101.0, "y2": 239.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9166361490885, "y1": 471.22298346625433, "x1": 426.772223578559, "y2": 493.39586893717444}, "name": "4", "caption_text": "Figure 4: Performance of CONNET variants of decoupling phase (DP) and aggregation phase (AP).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 715.0, "y1": 293.0, "x1": 439.0, "y2": 478.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9243503146702, "y1": 631.1826917860243, "x1": 426.772223578559, "y2": 667.1944936116536}, "name": "5", "caption_text": "Figure 5: Performance on simulated crowd-sourced NER data with (a) 5 annotators with different reliability levels; (b) different numbers of annotators with reliability r = 1/50.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 729.0, "y1": 495.0, "x1": 427.0, "y2": 634.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.915025499132, "y1": 601.6576978895399, "x1": 100.0, "y2": 626.5986124674479}, "name": "2", "caption_text": "Table 2: Performance on cross-domain data The best score (except the Gold) in each column that is significantly (p < 0.05) better than the second best is marked bold, while those are better but not significantly are underlined.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 702.0, "y1": 86.0, "x1": 128.0, "y2": 585.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1505160861545, "y1": 255.4160647922092, "x1": 100.0, "y2": 277.5903489854601}, "name": "6", "caption_text": "Figure 6: Heatmap of averaged attention scores from each source domain to each target domain.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 339.0, "y1": 105.0, "x1": 163.0, "y2": 231.0}, "page": 8, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 950.3757900661892, "x1": 426.7721811930338, "y2": 991.9208102756076}, "name": "3", "caption_text": "Table 3: Sample instances in Fig. 3 and Fig. 7 with NER annotations including PER (red), ORG (blue), LOC (violet) and MISC (orange).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 714.0, "y1": 149.0, "x1": 443.0, "y2": 933.0}, "page": 11, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9267239040798, "y1": 462.2757381863064, "x1": 100.0, "y2": 487.2166527642144}, "name": "7", "caption_text": "Figure 7: Visualizations of (a) the expertise of annotators; (b) attention weights for additional sample sentences to Fig. 3. Details of samples are described in Tab. 3.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 728.0, "y1": 215.0, "x1": 100.0, "y2": 461.0}, "page": 12, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9241807725695, "y1": 908.0563015407986, "x1": 100.0, "y2": 930.2305433485243}, "name": "4", "caption_text": "Table 4: Performance of methods with Transformer-CRF as the base model on crowd-annotation NER dataset AMTC and cross-domain POS dataset UD.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 753.0, "x1": 100.0, "y2": 908.0}, "page": 12, "dpi": 0}], "error": null, "pdf": "/work/host-output/0b1bb8b6e79c8281d8b79b42c8d2324d1f426040/2020.acl-main.193.pdf", "dpi": 100}