{"raw_detected_boxes": [[], [], [{"x2": 330.0, "y1": 270.0, "x1": 173.0, "y2": 389.0}, {"x2": 704.0, "y1": 627.0, "x1": 452.0, "y2": 765.0}, {"x2": 377.0, "y1": 827.0, "x1": 100.0, "y2": 942.0}], [], [{"x2": 702.0, "y1": 87.0, "x1": 129.0, "y2": 361.0}, {"x2": 391.0, "y1": 495.0, "x1": 112.0, "y2": 649.0}], [{"x2": 710.0, "y1": 86.0, "x1": 121.0, "y2": 358.0}, {"x2": 683.0, "y1": 428.0, "x1": 135.0, "y2": 564.0}, {"x2": 389.0, "y1": 649.0, "x1": 110.0, "y2": 751.0}], [{"x2": 683.0, "y1": 87.0, "x1": 128.0, "y2": 224.0}, {"x2": 732.0, "y1": 521.0, "x1": 434.0, "y2": 691.0}], [{"x2": 400.0, "y1": 87.0, "x1": 100.0, "y2": 261.0}, {"x2": 717.0, "y1": 89.0, "x1": 428.0, "y2": 273.0}], [{"x2": 398.0, "y1": 346.0, "x1": 105.0, "y2": 474.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "1", "captionBoundary": {"x2": 527.2009887695312, "y1": 274.5895690917969, "x1": 71.69100189208984, "y2": 292.54705810546875}, "imageText": ["Mushrooms", "Water", "tower,", "lampshade,", "table", "lamp", "Mushroom,", "hen", "of", "the", "woods,", "fountain", "Blanket", "clouds", "Seashore,", "fountain,", "sandbar", "Wing,", "seashore,", "sandbar", "Sun(drawing)", "Ping", "pong", "ball,", "envelope,", "maraca", "Wall", "clock,", "analog", "clock,", "web", "site", "Ballerinas", "Spiny", "lobster,", "hoopskirt,", "fountain", "Fountain,", "king", "crab,", "pole", "Belt", "Buckle,", "muzzle,", "hair", "slide", "Buckle,", "muzzle,", "hair", "slide", "Cloud", "looking", "like", "a", "bird", "Geyser,", "lakeside,", "valley", "Valley,", "lakeside,", "worm", "fence", "screen", "Volcano,", "ski", "mask,", "jelly\ufb01sh", "Object", "VGG16", "ResNet50", "Burj", "Khalifa", "Mosque,", "obelisk,", "missile", "Mosque,", "palace,", "bell", "cote", "Mountain", "Alp,", "valley,", "mountain", "tent", "Alp,", "valley,", "mountain", "tent", "Galaxy", "Jelly\ufb01sh,", "fountain,", "window"], "regionBoundary": {"x2": 511.0, "y1": 63.8900146484375, "x1": 86.0, "y2": 257.8900146484375}, "caption": "Table 1: Comparing mis-categorisations between VGG16 and ResNet50. The first column names the object presented in the picture, the remaining two columns present the first 3 captions offered by the two models.", "page": 5}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 291.92425537109375, "y1": 552.76953125, "x1": 71.69100189208984, "y2": 582.6820068359375}, "imageText": ["InceptionResNet", "0.00", "0.01", "0.05", "ResNet50", "0.26", "0.39", "0.53", "Model", "Top", "1", "Top", "5", "Top", "20", "VGG16", "0.25", "0.39", "0.57", "VGG19", "0.23", "0.33", "0.54"], "regionBoundary": {"x2": 284.0, "y1": 467.8900146484375, "x1": 78.0, "y2": 540.8900146484375}, "caption": "Table 2: F1 scores for human-like metaphorical classification of 4 models considering the first 1, 5 and 20 results of each.", "page": 5}, {"figType": "Figure", "name": "6", "captionBoundary": {"x2": 525.5471801757812, "y1": 426.3795471191406, "x1": 72.0, "y2": 444.3370056152344}, "imageText": ["(a)", "ruler,", "band", "aid", "(b)", "hatchet,", "electric", "guitar", "(c)", "reel,", "croquet", "ball"], "regionBoundary": {"x2": 492.0, "y1": 307.8900146484375, "x1": 91.0, "y2": 406.0810241699219}, "caption": "Figure 6: Three pictures representing elements absent from our VGG16 ontology. The last picture shares obvious similarities with the first two images, but VGG16 classifies each picture in a completely different way.", "page": 5}, {"figType": "Figure", "name": "8", "captionBoundary": {"x2": 527.2003784179688, "y1": 511.7434997558594, "x1": 307.2760009765625, "y2": 553.6109619140625}, "imageText": [], "regionBoundary": {"x2": 535.0, "y1": 370.8900146484375, "x1": 307.0, "y2": 499.8900146484375}, "caption": "Figure 8: A schematic visualisation of the cosine similarities between the sky, the fire and the sky on fire vectors. The sky vector is relatively similar to the sky on fire vector and further away from the fire vector.", "page": 6}, {"figType": "Figure", "name": "7", "captionBoundary": {"x2": 525.5473022460938, "y1": 181.09951782226562, "x1": 72.0, "y2": 199.0570068359375}, "imageText": ["(a)", "Sky", "(b)", "Fire", "(c)", "Sunset"], "regionBoundary": {"x2": 492.0, "y1": 61.8900146484375, "x1": 91.0, "y2": 160.79998779296875}, "caption": "Figure 7: Samples from the three compound visual vectors we create to serve as source, target and modifier of the metaphor Sunset is Sky on Fire.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 210.48861694335938, "y1": 292.3165588378906, "x1": 151.7790069580078, "y2": 298.31903076171875}, "imageText": [], "regionBoundary": {"x2": 238.0, "y1": 194.8900146484375, "x1": 124.0, "y2": 280.8900146484375}, "caption": "Figure 1: Fire!", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 449.3158874511719, "y1": 565.5316162109375, "x1": 383.50299072265625, "y2": 571.5340576171875}, "imageText": [], "regionBoundary": {"x2": 508.0, "y1": 450.8900146484375, "x1": 325.0, "y2": 553.8900146484375}, "caption": "Figure 3: A guy.", "page": 2}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 226.50332641601562, "y1": 691.1145629882812, "x1": 135.76400756835938, "y2": 697.1170043945312}, "imageText": [], "regionBoundary": {"x2": 272.0, "y1": 592.8900146484375, "x1": 72.0, "y2": 678.8900146484375}, "caption": "Figure 2: Two dragons", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 527.2007446289062, "y1": 209.03451538085938, "x1": 306.9670104980469, "y2": 310.6790771484375}, "imageText": ["Hair", "are", "white", "waterfall", "-0.5", "0.62", "Lawn", "is", "green", "carpet", "-0.3", "0.4", "Snow", "is", "white", "carpet", "0.82", "0.90", "Blonde", "hair", "are", "river", "of", "gold", "0.01", "0.1", "Metaphor", "Sim", "ST", "Sim", "(S+M)T", "Sunset", "is", "sky", "on", "\ufb01re", "0.64", "0.82"], "regionBoundary": {"x2": 517.0, "y1": 62.8900146484375, "x1": 307.0, "y2": 196.8900146484375}, "caption": "Table 3: Compositional metaphors: the similarity between two visual vectors representing the (S)ource and the (T)arget of a metaphor increases if a modifier\u2019s vector is added to the source - (S+M)T. For example, the cosine similarity of the blonde hair vector and river in the second row is 0.01. If we sum river with a vector representing its modifier golden (which is a vector created out of several pictures of gold and golden elements) the similarity goes up to 0.1.", "page": 7}, {"figType": "Figure", "name": "9", "captionBoundary": {"x2": 291.6532897949219, "y1": 202.69656372070312, "x1": 71.64100646972656, "y2": 268.47509765625}, "imageText": [], "regionBoundary": {"x2": 299.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 190.8900146484375}, "caption": "Figure 9: A visually grounded metaphor in the visual space. If we sum the sky vector with the fire vector, we create a \u201cmetaphoric\u201d new vector which is closer to the sky on fire vector than the simple sky vector was: adding fire to the sky seems an effective way to recreate a sunset.", "page": 7}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 291.9244384765625, "y1": 353.1245422363281, "x1": 71.69100189208984, "y2": 430.8579406738281}, "imageText": ["InceptionResNet", "0.60", "0.64", "0.62", "ResNet50", "0.64", "0.73", "0.68", "ResNet50", "0.63", "0.31", "0.42", "Sum", "Precision", "Recall", "F1", "Multiply", "Precision", "Recall", "F1", "InceptionResNet", "0.55", "0.68", "0.61"], "regionBoundary": {"x2": 288.0, "y1": 249.8900146484375, "x1": 75.0, "y2": 340.8900146484375}, "caption": "Table 4: Precision, Recall and F1 for two models\u2019 metaphorical compositionality. The F-score measures to what extent the modifier improves the similarity between source and target in real metaphors (precision), but not in false metaphors (recall). We test the composition of visual vectors using multiplication (top) or sum (bottom).", "page": 8}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 525.5473022460938, "y1": 303.0005187988281, "x1": 72.0, "y2": 332.9129943847656}, "imageText": ["(d)", "Comic", "book,", "jigsaw", "puzzle,", "book", "jacket,", "theater", "curtain,", "shower", "curtain.", "(e)", "Shower", "curtain,", "pajama,", "ballpoint,", "maraca,", "rubber", "eraser.", "(f)", "Volcano,", "fountain,", "seashore,", "space", "shuttle,", "lakeside.", "(a)", "Bubble,", "Alp,", "\ufb01reboat,", "mountain", "tent,", "fountain.", "(b)", "Golf", "ball,", "gong,", "tick,", "chambered", "nautilus,", "spotlight.", "(c)", "Matchstick,", "hook,", "spotlight,", "safety", "pin,", "\ufb02atworm."], "regionBoundary": {"x2": 505.90740966796875, "y1": 61.8900146484375, "x1": 91.0, "y2": 282.70098876953125}, "caption": "Figure 4: The first 5 output categories of VGG16 for various pictures. Most of these pictures represent objects the network was not trained on. The reader can notice that some of the mis-classifications could work as metaphoric descriptions (as in b or f) more than others (as in a or e).", "page": 4}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 291.51593017578125, "y1": 482.1375427246094, "x1": 72.0, "y2": 524.0059814453125}, "imageText": [], "regionBoundary": {"x2": 282.0, "y1": 355.8900146484375, "x1": 80.0, "y2": 469.8900146484375}, "caption": "Figure 5: Two elements from our dataset. A galaxy described in the human-generated caption as a jellyfish, and a building described (and commonly known) as a cucumber/gherkin.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 292.3453013102213, "y1": 405.9952206081814, "x1": 210.8041763305664, "y2": 414.33198716905383}, "name": "1", "caption_text": "Figure 1: Fire!", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 330.0, "y1": 253.0, "x1": 158.0, "y2": 406.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 624.0498436821831, "y1": 785.4605780707465, "x1": 532.6430426703558, "y2": 793.7973022460938}, "name": "3", "caption_text": "Figure 3: A guy.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 610.0, "x1": 435.0, "y2": 768.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 314.58795335557727, "y1": 959.8813374837239, "x1": 188.56112162272134, "y2": 968.2180616590712}, "name": "2", "caption_text": "Figure 2: Two dragons", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 377.0, "y1": 810.0, "x1": 100.0, "y2": 959.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 420.8340538872613, "x1": 100.0, "y2": 462.37915886773004}, "name": "4", "caption_text": "Figure 4: The first 5 output categories of VGG16 for various pictures. Most of these pictures represent objects the network was not trained on. The reader can notice that some of the mis-classifications could work as metaphoric descriptions (as in b or f) more than others (as in a or e).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 703.0, "y1": 87.0, "x1": 127.0, "y2": 378.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 404.8832363552517, "y1": 669.6354760064019, "x1": 100.0, "y2": 727.7860853407118}, "name": "5", "caption_text": "Figure 5: Two elements from our dataset. A galaxy described in the human-generated caption as a jellyfish, and a building described (and commonly known) as a cucumber/gherkin.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 391.0, "y1": 495.0, "x1": 112.0, "y2": 652.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2235955132378, "y1": 381.3744015163845, "x1": 99.57083596123589, "y2": 406.3153584798177}, "name": "1", "caption_text": "Table 1: Comparing mis-categorisations between VGG16 and ResNet50. The first column names the object presented in the picture, the remaining two columns present the first 3 captions offered by the two models.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 710.0, "y1": 86.0, "x1": 120.0, "y2": 358.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9266391330295, "y1": 592.1938154432509, "x1": 100.0, "y2": 617.1347300211588}, "name": "6", "caption_text": "Figure 6: Three pictures representing elements absent from our VGG16 ontology. The last picture shares obvious similarities with the first two images, but VGG16 classifies each picture in a completely different way.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 683.0, "y1": 428.0, "x1": 128.0, "y2": 567.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.45035468207465, "y1": 767.7354600694445, "x1": 99.57083596123589, "y2": 809.2805650499132}, "name": "2", "caption_text": "Table 2: F1 scores for human-like metaphorical classification of 4 models considering the first 1, 5 and 20 results of each.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 649.0, "x1": 100.0, "y2": 768.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9268086751301, "y1": 251.52710808648, "x1": 100.0, "y2": 276.4680650499132}, "name": "7", "caption_text": "Figure 7: Samples from the three compound visual vectors we create to serve as source, target and modifier of the metaphor Sunset is Sky on Fire.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 683.0, "y1": 87.0, "x1": 128.0, "y2": 226.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2227478027344, "y1": 710.7548607720269, "x1": 426.772223578559, "y2": 768.9041137695312}, "name": "8", "caption_text": "Figure 8: A schematic visualisation of the cosine similarities between the sky, the fire and the sky on fire vectors. The sky vector is relatively similar to the sky on fire vector and further away from the fire vector.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 521.0, "x1": 427.0, "y2": 693.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.07401360405817, "y1": 281.5230051676432, "x1": 99.50139787462022, "y2": 372.882080078125}, "name": "9", "caption_text": "Figure 9: A visually grounded metaphor in the visual space. If we sum the sky vector with the fire vector, we create a \u201cmetaphoric\u201d new vector which is closer to the sky on fire vector than the simple sky vector was: adding fire to the sky seems an effective way to recreate a sunset.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 400.0, "y1": 87.0, "x1": 100.0, "y2": 264.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 732.2232564290364, "y1": 290.32571580674914, "x1": 426.3430701361762, "y2": 431.49871826171875}, "name": "3", "caption_text": "Table 3: Compositional metaphors: the similarity between two visual vectors representing the (S)ource and the (T)arget of a metaphor increases if a modifier\u2019s vector is added to the source - (S+M)T. For example, the cosine similarity of the blonde hair vector and river in the second row is 0.01. If we sum river with a vector representing its modifier golden (which is a vector created out of several pictures of gold and golden elements) the similarity goes up to 0.1.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 717.0, "y1": 86.0, "x1": 426.0, "y2": 290.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 405.4506089952257, "y1": 490.4507531060113, "x1": 99.57083596123589, "y2": 598.413806491428}, "name": "4", "caption_text": "Table 4: Precision, Recall and F1 for two models\u2019 metaphorical compositionality. The F-score measures to what extent the modifier improves the similarity between source and target in real metaphors (precision), but not in false metaphors (recall). We test the composition of visual vectors using multiplication (top) or sum (bottom).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 404.0, "y1": 329.0, "x1": 100.0, "y2": 491.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/0442c17a9d221b5ea3bfb82f4319e7248852fc09/2020.figlang-1.19.pdf", "dpi": 100}