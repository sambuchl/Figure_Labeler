{"raw_detected_boxes": [[], [], [{"x2": 377.0, "y1": 88.0, "x1": 115.0, "y2": 297.0}], [], [{"x2": 728.0, "y1": 87.0, "x1": 106.0, "y2": 326.0}], [{"x2": 632.0, "y1": 87.0, "x1": 197.0, "y2": 329.0}], [{"x2": 633.0, "y1": 87.0, "x1": 211.0, "y2": 260.0}, {"x2": 716.0, "y1": 334.0, "x1": 433.0, "y2": 443.0}], [{"x2": 393.0, "y1": 88.0, "x1": 109.0, "y2": 202.0}, {"x2": 732.0, "y1": 88.0, "x1": 428.0, "y2": 243.0}, {"x2": 735.0, "y1": 325.0, "x1": 432.0, "y2": 465.0}], [{"x2": 724.0, "y1": 93.0, "x1": 427.0, "y2": 451.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Figure", "name": "3", "captionBoundary": {"x2": 415.0717468261719, "y1": 249.11953735351562, "x1": 182.47500610351562, "y2": 255.12200927734375}, "imageText": [], "regionBoundary": {"x2": 458.0, "y1": 61.8900146484375, "x1": 140.0, "y2": 236.8900146484375}, "caption": "Figure 3: CARNN for context-dependent language model.", "page": 5}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 525.5477294921875, "y1": 332.4975891113281, "x1": 307.2770080566406, "y2": 362.4100341796875}, "imageText": ["Model", "Babi", "Babi", "reduced", "Frame", "nCARNN", "51.3%*", "55.8%*", "27.4%*", "iCARNN", "52.0%*", "55.2%*", "28.5%*", "sCARNN", "50.9%*", "55.9%*", "25.7%*", "CARNN", "voting", "53.2%*", "56.9%*", "29.1%*", "QRN", "(2017)", "46.8%", "54.7%", "24.0%", "GMN", "(2017)", "47.4%", "54.1%", "23.6%", "MN", "(2017)", "41.1%", "\u2013", "\u2013"], "regionBoundary": {"x2": 519.0, "y1": 238.45278930664062, "x1": 312.0, "y2": 317.1800537109375}, "caption": "Table 1: Dialog accuracy on Babi and Frame among end-to-end systems. * indicates statistical significance with p < 0.1 compared to QRN.", "page": 6}, {"figType": "Figure", "name": "4", "captionBoundary": {"x2": 386.51318359375, "y1": 207.36654663085938, "x1": 211.03201293945312, "y2": 213.3690185546875}, "imageText": [], "regionBoundary": {"x2": 458.0, "y1": 61.8900146484375, "x1": 140.0, "y2": 195.8900146484375}, "caption": "Figure 4: CARNN for Question Answering.", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 290.2716979980469, "y1": 226.03854370117188, "x1": 72.0009994506836, "y2": 267.90606689453125}, "imageText": [], "regionBoundary": {"x2": 280.0, "y1": 61.8900146484375, "x1": 82.0, "y2": 213.8900146484375}, "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm\u22121 in its gate computation, iCARNN and sCARNN do not.", "page": 2}, {"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5474243164062, "y1": 189.30752563476562, "x1": 307.2770080566406, "y2": 207.2659912109375}, "imageText": ["Model", "Penn", "Discourse", "Switchboard", "Tree", "Bank", "nCARNN", "(w/o", "latent)", "96.95", "30.17", "iCARNN", "(w/o", "latent)", "94.72", "32.49", "sCARNN", "(w/o", "latent)", "87.39", "31.50", "nCARNN", "(with", "latent)", "96.64", "29.72", "iCARNN", "(with", "latent)", "94.16", "32.16", "sCARNN", "(with", "latent)", "86.68", "31.49", "RNNLM", "(2016b)", "117.8", "56.0", "DCLM", "(2016a)", "112.2", "45.3", "DRLM", "(2016b)", "108.3", "39.6"], "regionBoundary": {"x2": 527.0, "y1": 64.37886810302734, "x1": 307.0, "y2": 172.9940185546875}, "caption": "Table 2: Perplexity on Switchboard and Penn Discourse Tree Bank.", "page": 7}, {"figType": "Figure", "name": "5", "captionBoundary": {"x2": 290.2716369628906, "y1": 160.36654663085938, "x1": 72.0009994506836, "y2": 214.1900634765625}, "imageText": ["CARNN", "action:", "api", "call", "vietnamese", "R", "location", "cheap", "QRN", "action:", "api", "call", "vietnamese", "R", "location", "R", "price", "GMN", "action:", "api", "call", "vietnamese", "R", "location", "R", "price", "U:", "im", "looking", "for", "a", "cheap", "restaurant", "S:", "...", "What", "type", "of", "food", "do", "you", "want??", "...5", "dialog", "turns...", "S:", "Could", "you", "please", "repeat", "that?", "U:", "vietnamese", "food"], "regionBoundary": {"x2": 283.0, "y1": 63.94842529296875, "x1": 72.0, "y2": 145.049072265625}, "caption": "Figure 5: Sample dialog from our system compared to the baselines. Only CARNN\u2019s predicted action takes into account the original cheap restaurant request and matches the ground truth action (in the systems\u2019 api calls, \u201cR price\u201d denotes \u201cany price\u201d).", "page": 7}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.5474243164062, "y1": 350.1285705566406, "x1": 307.2770080566406, "y2": 380.041015625}, "imageText": ["Model", "MAP", "MRR", "IWAN", "(our", "implementation)", "+", "nCARNN*", "0.827", "0.889", "IWAN", "(our", "implementation)", "+", "iCARNN*", "0.826", "0.907", "IWAN", "(our", "implementation)", "+", "sCARNN*", "0.829", "0.875", "IWAN", "(our", "implementation)", "0.794", "0.879", "IWAN", "(2017)", "0.822", "0.889", "Compare-Aggregate", "(2017)", "0.821", "0.899", "BiMPM", "(2017)", "0.802", "0.875", "NCE-CNN", "(2016)", "0.801", "0.877", "HyperQA", "(2017)", "0.784", "0.865"], "regionBoundary": {"x2": 530.0, "y1": 235.16171264648438, "x1": 306.99200439453125, "y2": 333.8150329589844}, "caption": "Table 3: MAP and MRR for question answering. * indicates statistical significance with \u03b1 < 0.05 in t-test compared to IWAN (our implementation).", "page": 7}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.5475463867188, "y1": 338.74755859375, "x1": 307.2770080566406, "y2": 368.6600036621094}, "imageText": ["There", "was", "his", "grandfather,", "Admiral", "John", "\u201cSlew\u201d", "Mc-", "Cain,", "Class", "of", "1906,", "a", "grizzled", "old", "sea", "dog", "who", "commanded", "aircraft", "carri-", "ers", "in", "the", "Paci\ufb01c", "during", "World", "War", "II.", "Slew", "McCain\u2019s", "peers", "at", "the", "Naval", "Academy", "were", "Chester", "Nimitz", "and", "William", "\u201cBull\u201d", "Halsey,", "who", "would", "become", "major", "commanders", "during", "World", "War", "II.", "Bill", "McCain,", "who", "grad-", "uated", "from", "West", "Point,", "chased", "Pancho", "Villa", "with", "Gen.", "Blackjack", "Pershing,", "served", "as", "an", "artillery", "of-", "\ufb01cer", "during", "World", "War", "I", "and", "attained", "the", "rank", "of", "brigadier", "general.", "Indeed,", "the", "ancestors", "of", "Chester", "W.", "Nimitz,", "the", "U.S.", "naval", "commander", "in", "chief", "of", "the", "Paci\ufb01c", "in", "World", "War", "II,", "were", "among", "the", "\ufb01rst", "German", "pioneers", "to", "settle", "the", "area.", "Since", "the", "museum", "opened", "in", "1983,", "Fredericksburg", "has", "become", "a", "haven", "for", "retired", "military", "service-", "men", "who", "come", "to", "trace", "Nimitz\u2019s", "career", "and", "the", "events", "of", "World", "War", "II.", "Since", "the", "museum", "opened", "in", "1983,", "Fredericksburg", "has", "become", "a", "haven", "for", "retired", "military", "service-", "men", "who", "come", "to", "trace", "Nimitz\u2019s", "career", "and", "the", "events", "of", "World", "War", "II.", "Question:", "During", "what", "war", "did", "Nimitz", "serve?", "IWAN-LSTM", "IWAN-iCARNN"], "regionBoundary": {"x2": 523.0, "y1": 63.94854736328125, "x1": 307.0, "y2": 326.8900146484375}, "caption": "Table 4: Top three answers produced by CARNN and LSTM. Blue colored answers are correct and red ones are incorrect.", "page": 8}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 357.8761901855469, "y1": 247.31655883789062, "x1": 239.67001342773438, "y2": 253.31903076171875}, "imageText": [], "regionBoundary": {"x2": 526.0, "y1": 61.8900146484375, "x1": 72.0, "y2": 235.8900146484375}, "caption": "Figure 2: CARNN for dialog.", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 403.15513610839844, "y1": 313.94242180718317, "x1": 100.00138812594943, "y2": 372.09175957573785}, "name": "1", "caption_text": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm\u22121 in its gate computation, iCARNN and sCARNN do not.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 385.0, "y1": 87.0, "x1": 100.0, "y2": 314.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 497.05026414659284, "y1": 343.4952206081814, "x1": 332.87501864963104, "y2": 351.83198716905383}, "name": "2", "caption_text": "Figure 2: CARNN for dialog.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 730.0, "y1": 87.0, "x1": 100.0, "y2": 343.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 576.488537258572, "y1": 345.99935743543836, "x1": 253.437508477105, "y2": 354.33612399631073}, "name": "3", "caption_text": "Figure 3: CARNN for context-dependent language model.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 635.0, "y1": 87.0, "x1": 197.0, "y2": 346.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 536.8238661024305, "y1": 288.00909254286023, "x1": 293.10001797146265, "y2": 296.3458591037326}, "name": "4", "caption_text": "Figure 4: CARNN for Question Answering.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 633.0, "y1": 87.0, "x1": 198.0, "y2": 271.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9274020724827, "y1": 461.80220709906683, "x1": 426.77362230088977, "y2": 503.3472696940104}, "name": "1", "caption_text": "Table 1: Dialog accuracy on Babi and Frame among end-to-end systems. * indicates statistical significance with p < 0.1 compared to QRN.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 720.0, "y1": 329.0, "x1": 433.0, "y2": 443.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.1550513373481, "y1": 222.73131476508246, "x1": 100.00138812594943, "y2": 297.4861992730035}, "name": "5", "caption_text": "Figure 5: Sample dialog from our system compared to the baselines. Only CARNN\u2019s predicted action takes into account the original cheap restaurant request and matches the ground truth action (in the systems\u2019 api calls, \u201cR price\u201d denotes \u201cany price\u201d).", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 393.0, "y1": 88.0, "x1": 100.0, "y2": 204.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9269782172308, "y1": 262.9271189371745, "x1": 426.77362230088977, "y2": 287.8694322374132}, "name": "2", "caption_text": "Table 2: Perplexity on Switchboard and Penn Discourse Tree Bank.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 732.0, "y1": 88.0, "x1": 426.0, "y2": 243.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9269782172308, "y1": 486.28968132866754, "x1": 426.77362230088977, "y2": 527.8347439236111}, "name": "3", "caption_text": "Table 3: MAP and MRR for question answering. * indicates statistical significance with \u03b1 < 0.05 in t-test compared to IWAN (our implementation).", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 735.0, "y1": 325.0, "x1": 426.0, "y2": 466.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9271477593315, "y1": 470.48272026909723, "x1": 426.77362230088977, "y2": 512.0277828640408}, "name": "4", "caption_text": "Table 4: Top three answers produced by CARNN and LSTM. Blue colored answers are correct and red ones are incorrect.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 88.0, "x1": 427.0, "y2": 454.0}, "page": 8, "dpi": 0}], "error": null, "pdf": "/work/host-output/79cce33b3a14456236b311e67d49031ef07cac33/N18-1115.pdf", "dpi": 100}