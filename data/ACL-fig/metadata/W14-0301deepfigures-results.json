{"raw_detected_boxes": [[], [], [{"x2": 735.0, "y1": 98.0, "x1": 428.0, "y2": 801.0}], [], [{"x2": 694.0, "y1": 90.0, "x1": 133.0, "y2": 409.0}, {"x2": 372.0, "y1": 509.0, "x1": 129.0, "y2": 568.0}, {"x2": 718.0, "y1": 506.0, "x1": 470.0, "y2": 612.0}], [{"x2": 670.0, "y1": 87.0, "x1": 157.0, "y2": 249.0}, {"x2": 552.0, "y1": 316.0, "x1": 274.0, "y2": 451.0}], [{"x2": 726.0, "y1": 221.0, "x1": 432.0, "y2": 310.0}], [{"x2": 725.0, "y1": 91.0, "x1": 105.0, "y2": 460.0}, {"x2": 380.0, "y1": 531.0, "x1": 114.0, "y2": 690.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 525.5466918945312, "y1": 193.2982940673828, "x1": 72.0009994506836, "y2": 213.4200439453125}, "imageText": ["Systems", "MERT", "MIRA", "BLEU", "TER", "TERp-A", "BLEU", "TER", "TERp-A", "BL", "52.31", "0.2905", "0.3058", "50.69", "0.3087", "0.3036", "BL+OR", "58.10", "0.2551", "0.2544", "55.41", "0.2778", "0.2682", "BL+WCE", "52.77", "0.2891", "0.3025", "51.01", "0.3055", "0.3012", "WCE", "+", "25%", "53.45", "0.2866", "0.2903", "51.33", "0.3010", "0.2987", "WCE", "+", "50%", "55.77", "0.2730", "0.2745", "53.63", "0.2933", "0.2903", "WCE", "+", "75%", "56.40", "0.2687", "0.2669", "54.35", "0.2848", "0.2822", "Oracle", "BLEU", "score", "BLEU=60.48"], "regionBoundary": {"x2": 486.0, "y1": 62.8900146484375, "x1": 109.0, "y2": 187.8900146484375}, "caption": "Table 2: Translation quality of the baseline system (only decoder scores) and that with additional scores from real \u201cWCE\u201d or \u201coracle\u201d WCE system", "page": 5}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 525.546630859375, "y1": 332.9412841796875, "x1": 72.0009994506836, "y2": 353.0630187988281}, "imageText": ["BL+WCE", "159", "601", "121", "BL+OR", "517", "261", "153", "WCE+25%", "253", "436", "192", "WCE+50%", "320", "449", "112", "WCE+75%", "461", "243", "177", "System", "MERT", "Better", "Equivalent", "Worse"], "regionBoundary": {"x2": 398.0, "y1": 227.8900146484375, "x1": 197.0, "y2": 324.8900146484375}, "caption": "Table 3: Quality comparison (measured by TER) between the baseline and two integrated systems in details (How many sentences are improved, kept equivalent or degraded, out of 881 test sentences?", "page": 5}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 525.546142578125, "y1": 241.77931213378906, "x1": 307.2770080566406, "y2": 261.90203857421875}, "imageText": ["System", "F(\u201cG\u201d)", "F(\u201cB\u201d)", "Overall", "F", "WCE+25%", "89.87", "58.84", "63.51", "WCE+50%", "93.21", "73.09", "76.11", "WCE+75%", "96.58", "86.87", "88.33", "Oracle", "labels", "100", "100", "100"], "regionBoundary": {"x2": 526.0, "y1": 156.8900146484375, "x1": 307.0, "y2": 227.8900146484375}, "caption": "Table 4: The performances (Fscore) of simulated WCE systems", "page": 6}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.546142578125, "y1": 595.644287109375, "x1": 307.2770080566406, "y2": 629.3150024414062}, "imageText": [], "regionBoundary": {"x2": 535.0, "y1": 61.8900146484375, "x1": 307.0, "y2": 578.8900146484375}, "caption": "Figure 1: The correlation between WQS in a sentence and its overall quality measured by : (a) BLEU, (b) TER and (c) TERp-A metrics", "page": 2}, {"figType": "Figure", "name": "3", "captionBoundary": {"x2": 290.270263671875, "y1": 517.4222412109375, "x1": 72.0009994506836, "y2": 564.6420288085938}, "imageText": [], "regionBoundary": {"x2": 281.0, "y1": 380.8900146484375, "x1": 81.0, "y2": 500.8900146484375}, "caption": "Figure 3: Comparison of the performance of various systems: the integrations of WCE features, which the quality increases gradually, lead to the linear improvement of translation outputs.", "page": 7}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 525.5465698242188, "y1": 344.1512756347656, "x1": 72.0009994506836, "y2": 364.27301025390625}, "imageText": ["Post-edition", "For", "the", "otre", ",", "the", "agreement", "risks", "\u201c", "digging", "the", "grave", "of", "a", "very", "large", "number", "of", "small-", "and", "medium-sized", "businesses", "in", "the", "next", "12", "months", "\u201d", ".", "For", "the", "otre", "agreement", ",", "the", "risk", "\u201c", "digging", "the", "grave", "of", "a", "very", "large", "number", "of", "medium-sized", "businesses", "in", "the", "next", "12", "months", "\u201d", ".", "Example", "1", "(from", "WCE+50%)", "Source", "Pour", "sa", "part", ",", "l\u2019", "avocat", "de", "Franc\u0327oise", "Bettencourt-Meyers", ",", "Olivier", "Metzner", ",", "s\u2019", "est", "fe\u0301licite\u0301", "de", "la", "de\u0301cision", "du", "tribunal", ".", "Hypothesis", "(Baseline", "SMT)", "The", "lawyer", "of", "Bettencourt-Meyers", "Franc\u0327oise", ",", "Olivier", "Metzner", ",", "welcomed", "the", "court", "\u2019s", "decision", ".", "Hypothesis", "(SMT+WCE", "scores)", "For", "his", "part", ",", "the", "lawyer", "of", "Bettencourt-Meyers", "Franc\u0327oise", ",", "Olivier", "Metzner", ",", "welcomed", "the", "court", "\u2019s", "decision", ".", "Post-edition", "For", "his", "part", ",", "the", "lawyer", "of", "Franc\u0327oise", "Bettencourt-Meyers", ",", "Olivier", "Metzner", ",", "welcomed", "the", "court", "\u2019s", "decision", ".", "Example", "2", "(from", "BL+OR)", "Source", "Pour", "l\u2019", "otre", ",", "l\u2019", "accord", "risque", "\u201c", "de", "creuser", "la", "tombe", "d\u2019", "un", "tre\u0300s", "grand", "nombre", "de", "pme", "du", "secteur", "dans", "les", "12", "prochains", "mois", "\u201d", ".", "Hypothesis", "(Baseline", "MT)", "For", "the", "otre", "the", "agreement", "is", "likely", "to", "deepen", "the", "grave", "of", "a", "very", "large", "number", "of", "smes", "in", "the", "sector", "in", "the", "next", "12", "months", "\u201d", ".", "Hypothesis", "(SMT+WCE", "scores)"], "regionBoundary": {"x2": 522.0, "y1": 65.59369659423828, "x1": 72.0, "y2": 335.8900146484375}, "caption": "Table 5: Examples of MT hypothesis before and after reranking using the additional scores from WCE+50% (Example 1) and BL+OR (Example 2) system", "page": 7}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 290.270263671875, "y1": 434.3143005371094, "x1": 72.0009994506836, "y2": 454.43603515625}, "imageText": ["Label", "Pr(%)", "Rc(%)", "F(%)", "Good", "(G)", "84.36", "91.22", "87.65", "Bad", "(B)", "51.34", "35.95", "42.29"], "regionBoundary": {"x2": 269.0, "y1": 366.8900146484375, "x1": 93.0, "y2": 408.8900146484375}, "caption": "Table 1: Pr, Rc and F for \u201cG\u201d and \u201cB\u201d labels of our WCE system", "page": 4}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 464.3633728027344, "y1": 311.4942932128906, "x1": 133.18499755859375, "y2": 318.0670166015625}, "imageText": [], "regionBoundary": {"x2": 507.0, "y1": 61.8900146484375, "x1": 90.0, "y2": 294.8900146484375}, "caption": "Figure 2: Example of our WCE classification results for one MT hypothesis", "page": 4}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 729.9251980251736, "y1": 827.2837320963541, "x1": 426.77362230088977, "y2": 874.0486145019531}, "name": "1", "caption_text": "Figure 1: The correlation between WQS in a sentence and its overall quality measured by : (a) BLEU, (b) TER and (c) TERp-A metrics", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 737.0, "y1": 90.0, "x1": 428.0, "y2": 803.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 644.9491288926866, "y1": 432.6309627956814, "x1": 184.97916327582465, "y2": 441.7597452799479}, "name": "2", "caption_text": "Figure 2: Example of our WCE classification results for one MT hypothesis", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 704.0, "y1": 87.0, "x1": 126.0, "y2": 409.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15314398871527, "y1": 603.2143063015408, "x1": 100.00138812594943, "y2": 631.1611599392361}, "name": "1", "caption_text": "Table 1: Pr, Rc and F for \u201cG\u201d and \u201cB\u201d labels of our WCE system", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 374.0, "y1": 509.0, "x1": 129.0, "y2": 568.0}, "page": 4, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9259609646267, "y1": 268.469852871365, "x1": 100.00138812594943, "y2": 296.4167277018229}, "name": "2", "caption_text": "Table 2: Translation quality of the baseline system (only decoder scores) and that with additional scores from real \u201cWCE\u201d or \u201coracle\u201d WCE system", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 675.0, "y1": 86.0, "x1": 151.0, "y2": 260.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9258761935764, "y1": 462.418450249566, "x1": 100.00138812594943, "y2": 490.3653038872613}, "name": "3", "caption_text": "Table 3: Quality comparison (measured by TER) between the baseline and two integrated systems in details (How many sentences are improved, kept equivalent or degraded, out of 881 test sentences?", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 566.0, "y1": 299.0, "x1": 258.0, "y2": 468.0}, "page": 5, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9251980251736, "y1": 335.8046001858181, "x1": 426.77362230088977, "y2": 363.7528313530816}, "name": "4", "caption_text": "Table 4: The performances (Fscore) of simulated WCE systems", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 731.0, "y1": 218.0, "x1": 426.0, "y2": 316.0}, "page": 6, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 477.98788282606336, "x1": 100.00138812594943, "y2": 505.93473646375867}, "name": "5", "caption_text": "Table 5: Examples of MT hypothesis before and after reranking using the additional scores from WCE+50% (Example 1) and BL+OR (Example 2) system", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 86.0, "x1": 101.0, "y2": 477.0}, "page": 7, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15314398871527, "y1": 718.6420016818577, "x1": 100.00138812594943, "y2": 784.2250400119358}, "name": "3", "caption_text": "Figure 3: Comparison of the performance of various systems: the integrations of WCE features, which the quality increases gradually, lead to the linear improvement of translation outputs.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 390.0, "y1": 529.0, "x1": 114.0, "y2": 695.0}, "page": 7, "dpi": 0}], "error": null, "pdf": "/work/host-output/f722bb7b36f4195301ab2cc07488a8912deda034/W14-0301.pdf", "dpi": 100}