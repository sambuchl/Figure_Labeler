{"raw_detected_boxes": [[{"x2": 722.0, "y1": 320.0, "x1": 432.0, "y2": 514.0}], [{"x2": 721.0, "y1": 824.0, "x1": 443.0, "y2": 1008.0}], [{"x2": 718.0, "y1": 292.0, "x1": 437.0, "y2": 377.0}, {"x2": 314.0, "y1": 938.0, "x1": 184.0, "y2": 1013.0}], [{"x2": 719.0, "y1": 92.0, "x1": 108.0, "y2": 244.0}, {"x2": 736.0, "y1": 307.0, "x1": 433.0, "y2": 577.0}, {"x2": 390.0, "y1": 545.0, "x1": 109.0, "y2": 620.0}], []], "raw_pdffigures_output": {"regionless-captions": [], "figures": [{"figType": "Table", "name": "2", "captionBoundary": {"x2": 290.2705383300781, "y1": 741.4215698242188, "x1": 72.0, "y2": 759.3790283203125}, "imageText": ["NOT", "8840", "OFF", "4400", "Subtask", "A", "tweets"], "regionBoundary": {"x2": 230.0, "y1": 675.8900146484375, "x1": 132.0, "y2": 728.8900146484375}, "caption": "Table 2: Distribution of the labels in the training dataset.", "page": 2}, {"figType": "Table", "name": "3", "captionBoundary": {"x2": 505.70947265625, "y1": 283.4825134277344, "x1": 327.1099853515625, "y2": 289.4849853515625}, "imageText": ["Embedding", "Precision", "Recall", "F1", "Random", "71.69", "69.47", "70.23", "Word2Vec", "70.67", "70.15", "70.38", "FastText", "71.76", "71.97", "71.86"], "regionBoundary": {"x2": 519.0, "y1": 204.8900146484375, "x1": 314.0, "y2": 270.8900146484375}, "caption": "Table 3: Evaluation of different embeddings.", "page": 2}, {"figType": "Figure", "name": "1", "captionBoundary": {"x2": 525.5465698242188, "y1": 741.4215698242188, "x1": 307.2760009765625, "y2": 759.3790283203125}, "imageText": ["Dense", "Layer", "+", "SIGMOID", "Dense", "Layer", "+", "Dropout", "+", "RELU", "Global", "Max", "Pooling", "1D", "Convolutional", "1D", "Layer", "Dropout", "Dropout", "Dropout", "Dropout", "Layer", "Type", "Target", "Output", "Layer", "Input", "Layer", "(tweets)", "Offensive", "@USER", "She", "should", "ask", "a", "few", "native", "Americans", "what", "their", "take", "on", "this", "is.", "Embedding", "Layer", "dsfdsdd"], "regionBoundary": {"x2": 525.0, "y1": 592.8900146484375, "x1": 319.0, "y2": 725.8900146484375}, "caption": "Figure 1: The CNN architecture used to identify offensive tweets using binary output layer.", "page": 1}, {"figType": "Table", "name": "4", "captionBoundary": {"x2": 518.0106811523438, "y1": 187.61355590820312, "x1": 79.53299713134766, "y2": 195.11004638671875}, "imageText": ["LR", "81.80", "75.90", "78.74", "58.27", "66.59", "62.15", "70.03", "71.24", "70.45", "CNN", "81.33", "80.50", "80.91", "62.18", "63.44", "62.81", "71.76", "71.97", "71.86", "LSTM", "77.73", "78.97", "78.34", "57.03", "55.23", "56.11", "67.38", "67.10", "67.23", "Bi-LSTM", "80.68", "81.92", "81.30", "63.11", "61.19", "62.14", "71.90", "71.56", "71.72", "FastText", "77.87", "79.02", "78.44", "57.24", "55.57", "56.39", "67.56", "67.30", "67.42", "Model", "Precision", "Recall", "F1", "Precision", "Recall", "F1", "Precision", "Recall", "F1", "Not", "Offensive", "Offensive", "Macro"], "regionBoundary": {"x2": 520.0, "y1": 65.8900146484375, "x1": 77.0, "y2": 174.8900146484375}, "caption": "Table 4: Benchmark of supervised learning models. CNN yields the best performance based on the metric F1.", "page": 3}, {"figType": "Table", "name": "5", "captionBoundary": {"x2": 290.27056884765625, "y1": 458.6425476074219, "x1": 72.0, "y2": 476.6000061035156}, "imageText": ["System", "F1", "(macro)", "Accuracy", "All", "NOT", "baseline", "0.4189", "0.7209", "All", "OFF", "baseline", "0.2182", "0.2790", "CNN", "0.7591", "0.8105"], "regionBoundary": {"x2": 286.0, "y1": 389.8900146484375, "x1": 76.0, "y2": 446.8900146484375}, "caption": "Table 5: Results for Sub-task A using CNN model compared to simple baseline.", "page": 3}, {"figType": "Figure", "name": "2", "captionBoundary": {"x2": 525.5465087890625, "y1": 433.5045471191406, "x1": 307.2760009765625, "y2": 451.4620056152344}, "imageText": ["0.8", "0.7", "0.6", "0.5", "0.4", "0.3", "0.2", "0.1", "0.0", "Confusion", "Matrix", "90", "150", "547", "73", "l", "la", "be", "Tr", "ue", "OFF", "NOT", "Predicted", "label", "OF", "F", "NO", "T"], "regionBoundary": {"x2": 529.5338134765625, "y1": 220.97801208496094, "x1": 314.5380859375, "y2": 415.3671875}, "caption": "Figure 2: Confusion matrix for Sub-task A, JTML CodaLab CNN model.", "page": 3}, {"figType": "Table", "name": "1", "captionBoundary": {"x2": 523.6329956054688, "y1": 382.5155334472656, "x1": 309.18798828125, "y2": 388.51800537109375}, "imageText": ["If", "the", "tournament", "of", "shit", "ain\u2019t", "on", "here.", ".", ".", "OFF", "UNT", "-", "He", "is", "so", "full", "of", "BS!", "OFF", "TIN", "IND", "swear", "niggas", "make", "me", "wanna", "turn", "this", "phone", "off", "OFF", "TIN", "GRP", "Kick", "the", "absolute", "shite", "out", "of", "the", "car.", "OFF", "TIN", "OTH", "A", "B", "C", "tweet", "Subtask"], "regionBoundary": {"x2": 522.0, "y1": 222.8900146484375, "x1": 311.0, "y2": 369.8900146484375}, "caption": "Table 1: Examples of Offensive Tweets in the dataset.", "page": 0}]}, "figures": [{"page_width": 0, "caption_boundary": {"x2": 727.2680494520399, "y1": 531.2715742323134, "x1": 429.4277615017361, "y2": 539.6083407931858}, "name": "1", "caption_text": "Table 1: Examples of Offensive Tweets in the dataset.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 725.0, "y1": 308.0, "x1": 429.0, "y2": 531.0}, "page": 0, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.925791422526, "y1": 1029.7521803114148, "x1": 426.772223578559, "y2": 1054.693094889323}, "name": "1", "caption_text": "Figure 1: The CNN architecture used to identify offensive tweets using binary output layer.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 726.0, "y1": 823.0, "x1": 443.0, "y2": 1008.0}, "page": 1, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 702.374267578125, "y1": 393.7257130940755, "x1": 454.31942409939234, "y2": 402.0624796549479}, "name": "3", "caption_text": "Table 3: Evaluation of different embeddings.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 721.0, "y1": 284.0, "x1": 436.0, "y2": 394.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.15352545844183, "y1": 1029.7521803114148, "x1": 100.0, "y2": 1054.693094889323}, "name": "2", "caption_text": "Table 2: Distribution of the labels in the training dataset.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 321.0, "y1": 938.0, "x1": 167.0, "y2": 1030.0}, "page": 2, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 719.4592793782551, "y1": 260.57438320583765, "x1": 110.46249601576064, "y2": 270.9861755371094}, "name": "4", "caption_text": "Table 4: Benchmark of supervised learning models. CNN yields the best performance based on the metric F1.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 722.0, "y1": 86.0, "x1": 108.0, "y2": 261.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 729.9257066514757, "y1": 602.0896487765842, "x1": 426.772223578559, "y2": 627.0305633544922}, "name": "2", "caption_text": "Figure 2: Confusion matrix for Sub-task A, JTML CodaLab CNN model.", "figure_type": "Figure", "uri": null, "page_height": 0, "figure_boundary": {"x2": 736.0, "y1": 307.0, "x1": 433.0, "y2": 578.0}, "page": 3, "dpi": 0}, {"page_width": 0, "caption_boundary": {"x2": 403.153567843967, "y1": 637.0035383436415, "x1": 100.0, "y2": 661.9444529215494}, "name": "5", "caption_text": "Table 5: Results for Sub-task A using CNN model compared to simple baseline.", "figure_type": "Table", "uri": null, "page_height": 0, "figure_boundary": {"x2": 402.0, "y1": 542.0, "x1": 100.0, "y2": 637.0}, "page": 3, "dpi": 0}], "error": null, "pdf": "/work/host-output/37530330fef4cf496b57cdb27efb14e1f64f95d0/S19-2117.pdf", "dpi": 100}